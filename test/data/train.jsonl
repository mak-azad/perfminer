{"idx": 2452, "commit_message": "added timestamp in logfile, refactored xmpp connector code, added endline in bridge/MCU transmission to improve performance", "target": 1}
{"idx": 3666, "commit_message": "[PATCH] Remove percpufication of in_flight counter in  From: Ravikiran G Thirumalai [URL]>  The routine disk_round_stats showed up considerably under oprofile for high disk io load (four processes doing dd to the same disk (different partitions) on a 4 way).  This is because the counter in_flight which is per-cpu right now gets read every time disk_round_stats gets called.  Per cpu counters like disk statistics improve write speed, but reads are slow (since all cpus' local counter values have to be read and summed up).  Considering the fact that in_flight counter is modified post disk_round_stats (which reads the in_flight counter) it is better not to per-cpu this counter.  Following patch does just that.  Below is the profile comparison before and after the change.  This was on a 4 way PIII Xeon, 1G ram, 2.6.0-test4-mm2.   Before: c010aa60 2910109  92.2249     poll_idle c0275340 23208    0.73549     __copy_to_user_ll c02753b0 11191    0.354657    __copy_from_user_ll c0114aa0 7168     0.227163    mark_offset_tsc c011ad10 6767     0.214455    schedule c011a2b0 6741     0.213631    load_balance c0138890 6710     0.212648    __generic_file_aio_write_nolock c011d302 4683     0.14841     .text.lock.sched c02e4b50 4533     0.143656    ahc_linux_isr c029cec0 3582     0.113518    disk_round_stats c0119b40 3509     0.111205    try_to_wake_up c029d320 3306     0.104771    __make_request c01567d0 3300     0.104581    __block_write_full_page c0156c00 3299     0.104549    __block_prepare_write  After: c010aa60 2777940  92.1302     poll_idle c0275340 23479    0.778679    __copy_to_user_ll c02753b0 10943    0.362924    __copy_from_user_ll c0114aa0 7022     0.232884    mark_offset_tsc c0138890 6988     0.231757    __generic_file_aio_write_nolock c011ad10 6607     0.219121    schedule c011d302 5771     0.191395    .text.lock.sched c02e4a60 4458     0.147849    ahc_linux_isr c011a2b0 3921     0.13004     load_balance c01567d0 3569     0.118366    __block_write_full_page c029d2a0 3540     0.117404    __make_request ... c029ceb0 311      0.0103143   disk_round_stats c011d5b0 299      0.00991631  remove_wait_queue", "target": 1}
{"idx": 4076, "commit_message": "[PATCH] gauge_field::FloatNOrder can now use __ldg loads.  Generally\n improves performance across the board, but some regressions at 12/8\n reconstruct so left switched off for now (USE_LDG macro in\n include/gauge_field_order.h).", "target": 1}
{"idx": 2120, "commit_message": "f2fs: support revoking atomic written pages  f2fs support atomic write with following semantics: 1. open db file 2. ioctl start atomic write 3. (write db file) * n 4. ioctl commit atomic write 5. close db file  With this flow we can avoid file becoming corrupted when abnormal power cut, because we hold data of transaction in referenced pages linked in inmem_pages list of inode, but without setting them dirty, so these data won't be persisted unless we commit them in step 4.  But we should still hold journal db file in memory by using volatile write, because our semantics of 'atomic write support' is incomplete, in step 4, we could fail to submit all dirty data of transaction, once partial dirty data was committed in storage, then after a checkpoint & abnormal power-cut, db file will be corrupted forever.  So this patch tries to improve atomic write flow by adding a revoking flow, once inner error occurs in committing, this gives another chance to try to revoke these partial submitted data of current transaction, it makes committing operation more like aotmical one.  If we're not lucky, once revoking operation was failed, EAGAIN will be reported to user for suggesting doing the recovery with held journal file, or retrying current transaction again.", "target": 1}
{"idx": 2774, "commit_message": "Refactoring.  Be more efficient. Don't do recursive copy, just read file contents once, replace placeholders, create directories where needed, and write files to their target location.  Let \"runWith\" handle getting all values, from user input or from config.  createProject now only takes targetDir, templateDir and getValues arguments.", "target": 0}
{"idx": 925, "commit_message": "sched: optimize select_best_cpu() where !sched_enable_power_aware  All CPUs power costs are fixed as its capacity when EA (energy aware scheduler) isn't enabled.  Thus select_best_cpu() doesn't need to calculate power cost delta to check if power delta exceeds when EA is off. Optimize select_best_cpu() with precalculated min/max capacity delta percentage value.", "target": 1}
{"idx": 2211, "commit_message": "Improved performance of loading FITS template. (around header handling) Thanks to K. Matsuzaki (ISAS/JAXA).", "target": 1}
{"idx": 3737, "commit_message": "(*) [CTL-81] Prevent a change in case the validationsummary has not changed which should improve performance in some cases. Note that for this     to be reliable, Catel uses the Stopwatch instead of DateTime because DateTime is not accurate enough. Since the Stopwatch is only available     in the full .NET framework, all other target frameworks will always assume a validation context or summary is outdated  This is a change for CTL-95", "target": 1}
{"idx": 2930, "commit_message": "Use private master IP in GCE kubemark tests  Currently hollow nodes communicate with kubemark master using public master IP, which results in each call going through cloud NAT. Cloud NAT limitations become performance bottleneck (see kubernetes/perf-tests/issues/874).  To mitigate this, in this change, a second kubeconfig called \"internal\" is created. It uses private master IP and is used to set up hollow nodes.  Note that we still need the original kubemark kubeconfig (using public master IP) to be able to communicate with the master from outside the cluster (when setting it up or running tests).  Testing: - set up kubemark cluster, verified apiserver logs to confirm that the call   from hollow nodes did not go through NAT", "target": 1}
{"idx": 30, "commit_message": "Added mind_values property to BeatDynamicProgramming and fixed NaNs inside", "target": 0}
{"idx": 2139, "commit_message": "This patch improves the readability of the prolog and epilog code by moving some code into separate functions.  There is no difference in generated code.  gcc/         * config/aarch64/aarch64.c (aarch64_pushwb_pair_reg): Rename.         (aarch64_push_reg): New function to push 1 or 2 registers.         (aarch64_pop_reg): New function to pop 1 or 2 registers.         (aarch64_expand_prologue): Use aarch64_push_regs.         (aarch64_expand_epilogue): Use aarch64_pop_regs.", "target": 0}
{"idx": 1684, "commit_message": "[en] improved TAG_QUESTIONS (#4853)  * [en] draft improved TAG_QUESTIONS    * [en] tag questions final", "target": 0}
{"idx": 209, "commit_message": "msm: wfd: Free ion handle on unmap  This commit fixes a memory leak incurred by not freeing the acquired handle after ion_import_dma_buf.", "target": 0}
{"idx": 3836, "commit_message": "scsi: ufs: add debug counters for recoverable errors during runtime  There is no way to know how many times various UFS errors happened while system is running if we have successfully recovered from those errors. Those failures should be counted and inspected as they might be anomaly behavior of the driver and can impact performance. This change adds support to capture these failures statistics like how many times we have seen errors, and which type of errors.  To reset the counters: echo 1 > /sys/kernel/debug/ufs/err_stats  To print them out: cat /sys/kernel/debug/ufs/err_stats  Note: There is no need to enable them as they are never disabled. This error counters are something that we always would like to have.", "target": 0}
{"idx": 531, "commit_message": "Memory friendly version of character icon view", "target": 0}
{"idx": 3387, "commit_message": "Update: Optimize square root algorithm for performance", "target": 1}
{"idx": 2098, "commit_message": "Merge pull request #906 from ampli/ppmatch  Performance improvement in post_process_match()", "target": 1}
{"idx": 2081, "commit_message": "mtd: onenand: implement cache program feature for 4KiB page onenand  Implement cache program feature for 4KiB page onenand. This feature improves the write data performance. The observed 128KiB data program speed change is from 8827KiB/s to 14156 KiB/s when the feature is enabled.", "target": 1}
{"idx": 2927, "commit_message": "Make printf_callback more efficient  Previously, log_printf(), if used along with hal_uart, was printing null character at the end of every transmission.", "target": 1}
{"idx": 2444, "commit_message": "Apply CFLAGS, -Os to decompress.o to improve decompress performance during boot-up process", "target": 1}
{"idx": 2462, "commit_message": "Merge remote-tracking branch 'remotes/amarkovic/tags/mips-queue-jun-1-2019' into staging  MIPS queue for June 1st, 2019  # gpg: Signature made Sat 01 Jun 2019 19:20:47 BST # gpg:                using RSA key D4972A8967F75A65 # gpg: Good signature from \"Aleksandar Markovic [URL]>\" [unknown] # gpg: WARNING: This key is not certified with a trusted signature! # gpg:          There is no indication that the signature belongs to the owner. # Primary key fingerprint: 8526 FBF1 5DA3 811F 4A01  DD75 D497 2A89 67F7 5A65  * remotes/amarkovic/tags/mips-queue-jun-1-2019:   target/mips: Improve performance of certain MSA instructions   target/mips: Clean up lmi_helper.c   target/mips: Clean up dsp_helper.c   tests/tcg: target/mips: Add tests for MSA bit set instructions   target/mips: Amend and cleanup MSA TCG tests   target/mips: Add emulation of MMI instruction PCPYUD   target/mips: Add emulation of MMI instruction PCPYLD   target/mips: Add emulation of MMI instruction PCPYH", "target": 1}
{"idx": 3149, "commit_message": "virtio_net: introduce VIRTIO_NET_HDR_F_DATA_VALID  There's no need for the guest to validate the checksum if it have been validated by host nics. So this patch introduces a new flag - VIRTIO_NET_HDR_F_DATA_VALID which is used to bypass the checksum examing in guest. The backend (tap/macvtap) may set this flag when met skbs with CHECKSUM_UNNECESSARY to save cpu utilization.  No feature negotiation is needed as old driver just ignore this flag.  Iperf shows 12%-30% performance improvement for UDP traffic. For TCP, when gro is on no difference as it produces skb with partial checksum. But when gro is disabled, 20% or even higher improvement could be measured by netperf.", "target": 1}
{"idx": 246, "commit_message": "BigSwitch: sync state on disassociate floating ip  Sends the state of port's parent network to the backend controller when a floating IP is disassociated from a port.  Closes-Bug: #1235074", "target": 0}
{"idx": 3608, "commit_message": "Composer will scan directory once  - `Composer` will scan the specified directory for binaries only once. This gives a performance improvement: - Regression tests execution times:     - `master`: 11:11     - `PR`: 9:56, 9:46 - Reverting the assert logic of a unit test  > We now have regression tests < 1 second as low as 0.5s!", "target": 1}
{"idx": 1881, "commit_message": "Convert format of pixels read from GL to BGRA on CPU if necessary  ReadPixels with format GL_BGRA_EXT is not necessarily supported by the GLES2-based GPU command buffer. The support for this format needs to be explicitly queried, and if it is not supported, the pixels need to be converted from RGBA to BGRA on the CPU if a BGRA result is desired.  BUG=380129 TEST=WebGL conformance tests  Review URL: [URL]/316553002", "target": 0}
{"idx": 3525, "commit_message": "[NRWT] Run performance tests with lock [URL]/show_bug.cgi?id=78628  Patch by Thiago Marcos P. Santos [URL]> on 2012-05-03 Reviewed by Tony Chang.  Locking performance tests (like we do for http tests) will force them to run in serial. This reduces the load of the machine when running perf tests and minimizes the chances of the tests to fail, specially timeouts.  * Scripts/webkitpy/layout_tests/controllers/manager.py: (Manager.__init__): (Manager._is_perf_test): (Manager._test_requires_lock): * Scripts/webkitpy/layout_tests/port/http_lock.py:", "target": 0}
{"idx": 3176, "commit_message": "habanalabs: improve a couple of error messages  This patch improves the error message that is shown when a new user tries to open a new FD while there is already an existing user that is working on the device.  It also improves the error message in case of missing firmware file.", "target": 0}
{"idx": 2702, "commit_message": "Remove all OpenBSD/NetBSD code. It was the right place to start from, but it now really gets in the way.  This allows us to fix several problems- not least of which was problems of ordering about when you'd have a device softc for an miibus child available or not. Move some steps of things around.  Put the ifnet/arpcom structure at the head of the softc (PR 29249).  Don't do tx gc in the interrupt service routine- that seems to make things a bit more efficient.  Enable jumbo support by default- but this version of 'jumbo' is broken because it really is just using multiple tfd/rfd's to match a packet, which will never be > CLSIZE anyway.  This should begin the first steps toward cleaning this driver up.  PR:                29249 MFC after:        1 week", "target": 0}
{"idx": 1214, "commit_message": "Improve docs, simplify data return types, rename alt_client", "target": 0}
{"idx": 936, "commit_message": "mwan3: Packet Loss & Latency Check  1. Test link quality based on packet loss & latency w.r.t. pre-defined high and low watermark values. 2. Extended ubus support to provide packet loss & latency information per wan per track_ip", "target": 0}
{"idx": 4099, "commit_message": "[PATCH] Made gmx_numzero static for performance reasons.", "target": 1}
{"idx": 2433, "commit_message": "Fixed performance problems with '--strict' option: + Replaced skipEndline with \"option ' ' newline\" where possible. + Replaced \"notFollowedBy' header\" in definition of endline with   a faster but equally accurate test for a folliwng header. + Removed check at the beginning of 'reference' for   a noteStart: This is not needed, because note comes before   referenceKey in the definition of block. + Replaced check for a following anyHtmlBlockTag in autoLink   with a check for anyHtmlTag or anyHtmlEndTag. + Other small code cleanups.", "target": 1}
{"idx": 2011, "commit_message": "Merge pull request #13 from toofishes/perf  Performance and consistency fixups", "target": 1}
{"idx": 1161, "commit_message": "drivers: cpufreq: Upstream optimizations  * Clean up and optimize cpufreq driver. * This is needed for good multi cpu   policy control via msm limiter.", "target": 1}
{"idx": 725, "commit_message": "Synchronized to hipl--cert--2.6--patch-189 Patches applied:   * [URL]--hipl/hipl--cert--2.6--patch-156    Syncronized to hipl--userspace--2.6--patch-1461   * [URL]--hipl/hipl--cert--2.6--patch-157    save commit   * [URL]--hipl/hipl--cert--2.6--patch-158    save commit, x509 support not ready   * [URL]--hipl/hipl--cert--2.6--patch-159    save commit, almost done x509v3 creation functionality   * [URL]--hipl/hipl--cert--2.6--patch-160    save commit   * [URL]--hipl/hipl--cert--2.6--patch-161    x509 signing finished now it has to be sent back to the client   * [URL]--hipl/hipl--cert--2.6--patch-162    save commit: stack smashing problem   * [URL]--hipl/hipl--cert--2.6--patch-163    Fixed stack smashing discovered seg fault on another machine (this one works the other does not)   * [URL]--hipl/hipl--cert--2.6--patch-164    Removed some debug crap, 32 bit works spki and x509 both have some 64 bit issues, fixing...   * [URL]--hipl/hipl--cert--2.6--patch-165    Fixed spki msg init problem on 64 bit machine   * [URL]--hipl/hipl--cert--2.6--patch-166    fixed the x509 segfault on 64 bit machine   * [URL]--hipl/hipl--cert--2.6--patch-167    adding extensions to the x509 certificate works   * [URL]--hipl/hipl--cert--2.6--patch-168    Cleaned the code and added some communication stuff between daemon and the client, also added one debugging/displaying function for x509   * [URL]--hipl/hipl--cert--2.6--patch-169    save commit   * [URL]--hipl/hipl--cert--2.6--patch-170    something weird still with x509 creation because verification with my function and openssl one result in same error   * [URL]--hipl/hipl--cert--2.6--patch-171    Added x509v3 support that the self-signed cert can be verified, no someway to send 1,5K of certs from client to daemon is needed, because the verification needs the cert and the signers self-signed cert to be verified correctly   * [URL]--hipl/hipl--cert--2.6--patch-172    save commit, x509 in state of transition from pem to der encoding on the wire and the code seg faults   * [URL]--hipl/hipl--cert--2.6--patch-173    save commit   * [URL]--hipl/hipl--cert--2.6--patch-174    Transformation from PEM to DER is complete and both SPKI and X509 certificates can be signed and verified, builder for CERT parameter is missing   * [URL]--hipl/hipl--cert--2.6--patch-175    Added functionality to use get dsa key from hostid to dsa struct for certificates to use   * [URL]--hipl/hipl--cert--2.6--patch-176    Synchronized to hipl--userspace--2.6--patch-1524   * [URL]--hipl/hipl--cert--2.6--patch-177    Fixed spki signature and verification after merge   * [URL]--hipl/hipl--cert--2.6--patch-178    Added issue and subject alt name to be added always with IP: content   * [URL]--hipl/hipl--cert--2.6--patch-179    Cert algos RSA works, DSA signing SPKI works, other DSA stuff on the way   * [URL]--hipl/hipl--cert--2.6--patch-180    DSA SPKI verification works, now on todo list DSA to work with X.509.v3   * [URL]--hipl/hipl--cert--2.6--patch-181    Certs support DSA and RSA algorithms   * [URL]--hipl/hipl--cert--2.6--patch-182    Synchronized to hipl--userspace--2.6--patch-1630   * [URL]--hipl/hipl--cert--2.6--patch-183    Synchronized to hipl--userspace--2.6--patch-1640   * [URL]--hipl/hipl--cert--2.6--patch-184    Synchronized to hipl--userspace--2.6--patch-1650   * [URL]--hipl/hipl--cert--2.6--patch-185    Synchronized to hipl--userspace--2.6--patch-1660   * [URL]--hipl/hipl--cert--2.6--patch-186    Synchronized to hipl--userspace--2.6--patch-1670   * [URL]--hipl/hipl--cert--2.6--patch-187    Synchronized to hipl--userspace--2.6--patch-1600   * [URL]--hipl/hipl--cert--2.6--patch-188    Synchronized to hipl--userspace--2.6--patch-1614   * [URL]--hipl/hipl--cert--2.6--patch-189    Synchronized to hipl--userspace--2.6--patch-1621", "target": 0}
{"idx": 1843, "commit_message": "Merge branch 'fix_gq_str_sv' of [URL]/Clinical-Genomics/scout into fix_gq_str_sv", "target": 0}
{"idx": 1515, "commit_message": "ARM: 7583/1: decompressor: Enable unaligned memory access for  v6 and above  Modern GCC can generate code which makes use of the CPU's native unaligned memory access capabilities.  This is useful for the C decompressor implementations used for unpacking compressed kernels.  This patch disables alignment faults and enables the v6 unaligned access model on CPUs which support these features (i.e., v6 and later), allowing full unaligned access support for C code in the decompressor.  The decompressor C code must not be built to assume that unaligned access works if support for v5 or older platforms is included in the kernel.  For correct code generation, C decompressor code must always use the get_unaligned and put_unaligned accessors when dealing with unaligned pointers, regardless of this patch.", "target": 0}
{"idx": 3088, "commit_message": "TJShow: - Changes because of the change in the GC system that does not allow non-polymorphic types anymore; in particular, interface methods like GetResources, GetDevices, GetEndpoints etc returned a ref< std::vector<T> >, which is not possible anymore. This is now handled by a std::vector<T>& parameter (which also makes it a little faster because no heap allocation is required anymore; also, code is shorter since there are less null checks).  TJDMXEngine: - ArtNet could send out bogus data if universe set to the number of universes. With 2 univeres, setting the universe to 2 (which is the third) would send out data in memory after the DMX buffer, which is a bad thing.", "target": 1}
{"idx": 2137, "commit_message": "improve memory performance of get_reuters_estimates_reindexed_like by casting UpdatedDate to date", "target": 1}
{"idx": 2255, "commit_message": "Use an rbtree for finding vrrp instance for socket timeout  Previously the code search a list of pointers to vrrp instances and looked for matching file descriptor and sands < time_now. In order to optimise this, it was implemented using an mlist whose index was a hash of the fd.  This commit changes the approach and uses a second rbtree for each sock_t. Since the sock_t that the timeout occurred on is known, the rbtree search is only searching for a match of the sands.  Not only is this more efficient, but it is simpler, uses standard code, and reduces the code by over 220 lines.", "target": 1}
{"idx": 2234, "commit_message": "Merge pull request #369 from kerumai/master  Performance optimization for primitive Dynamic***Property classes Thanks @kerumai for your contributions!", "target": 1}
{"idx": 2679, "commit_message": "API changes, performance improvement, a test script", "target": 1}
{"idx": 1468, "commit_message": "Network Constants Added few changes to network", "target": 0}
{"idx": 3974, "commit_message": "A new version of swap that's more efficient and compatible with all 6502 processors.", "target": 1}
{"idx": 2091, "commit_message": "Revert 148127 \"Simplify ContainerNode::removeChildren and make i...\"  > Simplify ContainerNode::removeChildren and make it faster >  > Simplify ContainerNode::removeChildren by merging the loops and removing > willRemoveChildren. This removes 3+ traversals of the children, avoids > refing and derefing all the children once, avoids allocating a second > NodeVector of children, and means we detach() in the same order as > normal removal. >  > This does mean you can get into an infinite loop with DOMNodeRemoved > listeners by continously adding nodes but this is true in all other browsers > and the current behavior is bad because it means you don't get notified > of nodes added during removal (which other browsers do notify of). This > patch removes the containerNode.html test that originally tested for this > infinite loop and adds a new one that tests that all nodes get notified. >  > This makes PerformanceTests/Parser/innerHTML-setter.html 2-6% faster. >  > There's also a new test verifying ranges remain consistent if modified > inside an mutation event handler. Without the patch it's possible to create > a range with boundaries outside of the DOM tree. This test was imported from > [URL]/show_bug.cgi?id=113517 and written by Andrei > Bucur who landed a modified version of my patch in WebKit. >  > Review URL: [URL]/13901002  This causes use after frees inside the Widget tree, and also inside node lists and other things because we allow script to run before updating the widget tre or calling childrenChanged or calling the ChildNodeRemovalNotifier. We need to reconsider how this works.  [URL] Review URL: [URL]/13874006", "target": 1}
{"idx": 1067, "commit_message": "usbblaster_spi.c: Refactor singleton states into reentrant pattern  Move global singleton states into a struct and store within the spi_master data field for the life-time of the driver.  This is one of the steps on the way to move spi_master data memory management behind the initialisation API, for more context see other patches under the same topic \"register_master_api\".  This patch also introduces shutdown function for usbblaster, because there was none previously and without shutdown function there is no way to free spi_master data at the end of driver lifecycle.  BUG=b:185191942 TEST=builds", "target": 0}
{"idx": 1613, "commit_message": "Splitted ServiceSelect into a new improved component.  Properly filters by current serverboard", "target": 0}
{"idx": 2085, "commit_message": "Fixed NAK's, this massively improves networking performance!", "target": 1}
{"idx": 4004, "commit_message": "[PATCH] resolved performance degrating changed introduced in revision\n 1319", "target": 1}
{"idx": 3244, "commit_message": "Improve performance for looking up queue processes (#897)", "target": 1}
{"idx": 3647, "commit_message": "Revert \"Revert \"Use debug level instead of info for logging, and some logging performance improvements\"\"  This reverts commit d7c2463abd8fc265e7a657ded00c6f5330c50a27.", "target": 1}
{"idx": 79, "commit_message": "Fix memory leaks in ofnet.         Reported by: Francesco Lavra.", "target": 0}
{"idx": 3381, "commit_message": "- Update Xen patches to 2.6.34-rc2 and c/s 1007. - Update config files. - config.conf: Re-enable Xen configs. - patches.xen/xen-floppy: Xen: improve floppy behavior   (bnc#584216). - patches.xen/xen-vscsi-module-alias: allow pv scsi hba driver   to be loaded automatically. - patches.xen/xen-vusb-module-alias: allow pv usb hcd driver to   be loaded automatically (bnc#584213).  suse-commit: 50fe57f9474e10b1d1ca254c319f6a84606adca8", "target": 0}
{"idx": 562, "commit_message": "Add WIP DeltaSol MX 2.x configuration optimizer.", "target": 0}
{"idx": 1817, "commit_message": "finagle|finatra|util: Introduce polymorphic Reader/Writer  # Problem  Both `Reader` and `Writer` are efficient and easy to reason about streaming APIs. Yet their usages are very limited given the fixed in/out types they operate on (`Buf`).  # Solution  Abstract both `Reader` and `Writer` over their produced/consumed type.  ``` // before trait Reader {   def read(): Future[Option[Buf]] }  trait Writer {   def write(b: Buf): Future[Unit] }  // after trait Reader[+A] {    def read(): Future[Option[A]] }  trait Writer[-A] {   def write(a: A): Future[Unit] } ```  JIRA Issues: CSL-6684  TBR=true  Differential Revision: [URL]/D195638", "target": 0}
{"idx": 3555, "commit_message": "net: Don't force epoll/kqueue to wake up in order to add new events.  In conjunction with the non-blocking system call CL, this gives about an 8% performance improvement on a client/server test running on my local machine.  R=rsc, iant2 CC=golang-dev [URL]/4272057", "target": 1}
{"idx": 256, "commit_message": "Merge \"[FIX] sap.ui.table.Table: fixes performance issues with selectAll when having 1 million rows or more", "target": 1}
{"idx": 780, "commit_message": "cpufreq.c: enable screen off CPU scaling by default", "target": 0}
{"idx": 1338, "commit_message": "Merge pull request #3781 from yogstation13/upstream-merge-41832  [MIRROR] Cleans up and improves microwave code", "target": 0}
{"idx": 2303, "commit_message": "Fix update_lines performance issues  This resolves performance issues with the `update_lines` method that  were caused by excessive updates without underlines or strikeout  present.    This also resolves a bug that was causing the underline and strikeout to  extend beyond the end of line in some rare cases.    This fixes #114.", "target": 1}
{"idx": 2488, "commit_message": "1. Add reverse hessian sparsity to user atomic functions (not yet tested). 2. In all sweep routines, resize vectors in groups with exact same size. 3. In sweep routines, improve comments about UserOp operator.  rev_sparse_hes.hpp: correction to documentation. sparse_set.hpp: comment about optimizing set operations. wish_list.omh: Add an item about optimizing set operations.", "target": 0}
{"idx": 1311, "commit_message": "Merge tag 'drm-intel-fixes-2018-09-11' of [URL]/drm/drm-intel into drm-fixes  This contains a regression fix for video playbacks on gen 2 hardware, a IPS timeout error suppression on Broadwell and GVT bucked with \"Most critical one is to fix KVM's mm reference when we access guest memory, issue was raised by Linus [1], and another one with virtual opregion fix.\"  [1] - [URL]/archives/intel-gvt-dev/2018-August/004130.html", "target": 0}
{"idx": 2436, "commit_message": "Trap Handlers in C Patch 1 of X (Patch by Sir_Richard [URL]>):     [NTOS]: The kernel normally does not save FPU state during Ring 0 transitions since the FPU should not be used. The one exception is when a kernel debugger is attached. Unfortunately, the latter check in ReactOS results in even \"print on the serial line\" to count as \"debugger attached\", and thus FPU state was almost always saved, slowing down traps significantly.     [NTOS]: The kernel also does not typically save DRx (debug) registers unless they were in use. During an exception dispatch, they are zeroed out, and later during trap exit, if any debug register is set, DR7 is updated to enable that hardware breakpoint. Unfortunately, the code to clear the debug registers had a bug: DR2 was never cleared. Because DR2 ended up being a random stack value during trap frame generation, this caused a bogus address to be added to DR2, and DR7 would then enable the 2nd hardware breakpoint. This caused the kernel to always save DRx state, which is slow, and worse, could cause random hardware breakpoints to fire.     [NTOS]: Start implementing trap handling in C. ASM trap handlers will now only be 5 lines of assembly including a function call to a C handler. All C handling code uses maximum two arguments and is all FASTCALL for efficiency.     [NTOS]: Implement C versions of TRAP_PROLOG and TRAP_EPILOG. Implement C version of Ki386EoiHelper. Implement C version of CommonDispatchException (and helper) and KiFatalSystemException. Implement C version of CHECK_FOR_APC_DELIVER. Implement trap debugging checks as a separate entity instead of always doing them.     [NTOS]: Add missing intrinsics for DS/ES/GS segment query.  The kernel is now ready for some trap handling to be done in C. Due to the FPU/Debug fixes and relaxation of paranoid debug checks, the C code will likely be faster than the original assembly.", "target": 1}
{"idx": 2809, "commit_message": "thermophysicalModels: Changed specie thermodynamics from mole to mass basis  The fundamental properties provided by the specie class hierarchy were mole-based, i.e. provide the properties per mole whereas the fundamental properties provided by the liquidProperties and solidProperties classes are mass-based, i.e. per unit mass.  This inconsistency made it impossible to instantiate the thermodynamics packages (rhoThermo, psiThermo) used by the FV transport solvers on liquidProperties.  In order to combine VoF with film and/or Lagrangian models it is essential that the physical propertied of the three representations of the liquid are consistent which means that it is necessary to instantiate the thermodynamics packages on liquidProperties.  This requires either liquidProperties to be rewritten mole-based or the specie classes to be rewritten mass-based.  Given that most of OpenFOAM solvers operate mass-based (solve for mass-fractions and provide mass-fractions to sub-models it is more consistent and efficient if the low-level thermodynamics is also mass-based.  This commit includes all of the changes necessary for all of the thermodynamics in OpenFOAM to operate mass-based and supports the instantiation of thermodynamics packages on liquidProperties.  Note that most users, developers and contributors to OpenFOAM will not notice any difference in the operation of the code except that the confusing      nMoles     1;  entries in the thermophysicalProperties files are no longer needed or used and have been removed in this commet.  The only substantial change to the internals is that species thermodynamics are now \"mixed\" with mass rather than mole fractions.  This is more convenient except for defining reaction equilibrium thermodynamics for which the molar rather than mass composition is usually know. The consequence of this can be seen in the adiabaticFlameT, equilibriumCO and equilibriumFlameT utilities in which the species thermodynamics are pre-multiplied by their molecular mass to effectively convert them to mole-basis to simplify the definition of the reaction equilibrium thermodynamics, e.g. in equilibriumCO      // Reactants (mole-based)     thermo FUEL(thermoData.subDict(fuelName)); FUEL *= FUEL.W();      // Oxidant (mole-based)     thermo O2(thermoData.subDict(\"O2\")); O2 *= O2.W();     thermo N2(thermoData.subDict(\"N2\")); N2 *= N2.W();      // Intermediates (mole-based)     thermo H2(thermoData.subDict(\"H2\")); H2 *= H2.W();      // Products (mole-based)     thermo CO2(thermoData.subDict(\"CO2\")); CO2 *= CO2.W();     thermo H2O(thermoData.subDict(\"H2O\")); H2O *= H2O.W();     thermo CO(thermoData.subDict(\"CO\")); CO *= CO.W();      // Product dissociation reactions      thermo CO2BreakUp     (         CO2 == CO + 0.5*O2     );      thermo H2OBreakUp     (         H2O == H2 + 0.5*O2     );  Please report any problems with this substantial but necessary rewrite of the thermodynamic at [URL]  Henry G. Weller CFD Direct Ltd.", "target": 0}
{"idx": 623, "commit_message": "improved db_reporter: unlimited number of reports storeable", "target": 0}
{"idx": 2358, "commit_message": "Switch to more in-depth time accounting and balancing, with some minor scene changes to improve performance", "target": 1}
{"idx": 776, "commit_message": "Base: Check network status on resume regardless of page", "target": 0}
{"idx": 3114, "commit_message": "8172921: Zip filesystem performance improvement and code cleanup", "target": 1}
{"idx": 31, "commit_message": "Merge pull request #3973 from Sage-Bionetworks/release-258  merge release-258 into develop", "target": 0}
{"idx": 152, "commit_message": "interfaces/network-control: additional ethernet rule  This should allow an access of the form:  AVC apparmor=\"DENIED\" operation=\"open\" profile=\"snap.name.app\" name=/sys/devices/platform/ /30800000.bus/30be0000.ethernet/net/eth0/address pid=18219 comm=\"vgc-bc\" requested_mask=\"r\" denied_mask=\"r\" fsuid=0 ouid=0", "target": 0}
{"idx": 1215, "commit_message": "Removing crash tag for canvas-imageSmoothingQuality-pixel.html  Removing crash tag for \"virtual/gpu/fast/canvas/canvas-imageSmoothingQuality-pixel.html\" layout test from TestExpectations as according to [URL]/p/chromium/issues/detail?id=712629#c12 the bug is fixed in [URL]/c/13962/.  BUG=712629  Review-Url: [URL]/2845663002", "target": 0}
{"idx": 1980, "commit_message": "slab.h: sprinkle __assume_aligned attributes  The various allocators return aligned memory.  Telling the compiler that allows it to generate better code in many cases, for example when the return value is immediately passed to memset().  Some code does become larger, but at least we win twice as much as we lose:  $ scripts/bloat-o-meter /tmp/vmlinux vmlinux add/remove: 0/0 grow/shrink: 13/52 up/down: 995/-2140 (-1145)  An example of the different (and smaller) code can be seen in mm_alloc(). Before:  :       48 8d 78 08             lea    0x8(%rax),%rdi :       48 89 c1                mov    %rax,%rcx :       48 89 c2                mov    %rax,%rdx :       48 c7 00 00 00 00 00    movq   $0x0,(%rax) :       48 c7 80 48 03 00 00    movq   $0x0,0x348(%rax) :       00 00 00 00 :       31 c0                   xor    %eax,%eax :       48 83 e7 f8             and    $0xfffffffffffffff8,%rdi :       48 29 f9                sub    %rdi,%rcx :       81 c1 50 03 00 00       add    $0x350,%ecx :       c1 e9 03                shr    $0x3,%ecx :       f3 48 ab                rep stos %rax,%es:(%rdi)  After:  :       48 89 c2                mov    %rax,%rdx :       b9 6a 00 00 00          mov    $0x6a,%ecx :       31 c0                   xor    %eax,%eax :       48 89 d7                mov    %rdx,%rdi :       f3 48 ab                rep stos %rax,%es:(%rdi)  So gcc's strategy is to do two possibly (but not really, of course) unaligned stores to the first and last word, then do an aligned rep stos covering the middle part with a little overlap.  Maybe arches which do not allow unaligned stores gain even more.  I don't know if gcc can actually make use of alignments greater than 8 for anything, so one could probably drop the __assume_xyz_alignment macros and just use __assume_aligned(8).  The increases in code size are mostly caused by gcc deciding to opencode strlen() using the check-four-bytes-at-a-time trick when it knows the buffer is sufficiently aligned (one function grew by 200 bytes). Now it turns out that many of these strlen() calls showing up were in fact redundant, and they're gone from -next. Applying the two patches to next-20151001 bloat-o-meter instead says  add/remove: 0/0 grow/shrink: 6/52 up/down: 244/-2140 (-1896)", "target": 0}
{"idx": 3638, "commit_message": "Upgrade to Netty 4.1.52.Final  - Update Netty to 4.1.52.Final which includes both security fixes and AArch64 performance improvements - Refer release notes for detail:   - https://netty.io/news/2020/05/13/4-1-50-Final.html   - https://netty.io/news/2020/09/08/4-1-52-Final.html", "target": 1}
{"idx": 504, "commit_message": "Changing back to the more effective control flow in TraverseReadOptimized()", "target": 1}
{"idx": 1758, "commit_message": "Add more memory usage stats  Added support for teasing apart different parts of the dalvik heap.  Note this adds more public api and we should talk to hackbod before going into master with this.  (cherry picked from commit 73407daf3f6110e933d8614605b21586c4c5fde2)", "target": 0}
{"idx": 100, "commit_message": "massive speed and memory optimizations around scrollable view", "target": 1}
{"idx": 4040, "commit_message": "[PATCH] efficient sparsity pattern computation for the case when the\n user specifies the DOF coupling", "target": 1}
{"idx": 3412, "commit_message": "Core: Rework fiber scheduling to fix broken behavior.  Tasks waiting on a timeout could end up being repeatedly scheduled, leading to chaos. Fortunately, nothing aggressively used this functionality (although this may have caused extremely infrequent bugs in SwiftShader fences).  The problem was mostly in `marl::ConditionVariable`: Between the fiber being placed on the `waiting` set and the call to `yield()`, `ConditionVariable::notify_`xxx`()` methods could be called, which would end up waking the fiber twice (one immediate, one with timeout).  This change tackles the problem in two ways: 1) The `marl::Scheduler::Fiber::wait` method has been changed to    mirror `ConditionVariable::wait` signature - it takes a lock,    predicate and optional timeout. This ensures the scheduler    worker lock is held while the predicate is evaluated, preventing    a notify sneeking in before the fiber is suspended. 2) The scheduler now keeps much better track of the state of each    fiber, and now simply ignores calls to notify() when it is    already running or queued. I've also littered the code with    sanity checks to try and catch any cases where the logic goes    off the rails.  The new early outs may also have some performance gains - benchmarks will confirm.  Also tweaked the EventWaitStressTest so that the old bug is far more easily reproduced. Without this tweak it might reproduce 1/10, now is is almost certain (without this included fix).", "target": 0}
{"idx": 3548, "commit_message": "(PDB-4895) storage: add a few new type annotations  These aren't likely performance critical, but were noticed when examining the input hashing performance and won't hurt.  Though this doesn't fix all the reflection warnings.  I left some date operations alone for now.", "target": 0}
{"idx": 3541, "commit_message": "Merge pull request #7 from jbt/patch-1  Update Job removal to make more efficient use of redis", "target": 1}
{"idx": 3508, "commit_message": "ASoC: Make LZO cache compression optional  Make LZO cache compression optional as it pulls in the kernel wide LZO implementation and rbtree compression is generally more efficient for typical register maps, especially in terms of CPU performance.", "target": 1}
{"idx": 502, "commit_message": "ISIS-121: Minor cleanup - DRY: re-used repeated code and possibly improved re-use of the AdapterManager.", "target": 0}
{"idx": 3704, "commit_message": "Add more efficient implementation of multiple summations.", "target": 1}
{"idx": 2378, "commit_message": "Chunk save queue improvements.  For some unknown reason, Minecraft is sleeping 10ms between every single chunk being saved to disk. Under high chunk load/unload activity (lots of movement / teleporting), this causes the chunk unload queue to build up in size.  This has multiple impacts: 1) Performance of the unload queue itself - The save thread is pretty ineffecient for how it accesses it    By letting the queue get larger, checking and popping work off the queue can get less performant. 2) Performance of chunk loading - As with #1, chunk loads also have to check this queue when loading    chunk data so that it doesn't load stale data if new data is pending write to disk. 3) Memory Usage - The entire chunk has been serialized to NBT, and now sits in this queue. This leads to    elevated memory usage, and then the objects used in the serialization sit around longer than needed    resulting in promotion to Old Generation instead of dying young.  To optimize this, we change the entire unload queue to be a proper queue.This improves the behavior of popping the first queued chunk off, instead of abusing iterators like Mojang was doing.  This also improves reliability of chunk saving, as the previous hack job had a race condition that could fail to save some chunks.  Then finally, Sleeping will by default be removed, but due to known issues with 1.9, a config option was added. But if sleeps are to remain enabled, we at least lower the sleep interval so it doesn't have as much negative impact.", "target": 1}
{"idx": 222, "commit_message": "Improve floattypes.h, cleanup  - add include guards - let it include gmp.h as it requires it - let it include GAP headers, as it needs them; and since we now   require GAP 4.11, also change the header included for that from   `src/compiled.h` to `gap_all.h` - move `cpoly_CXSC` declaration to its own header file, to avoid annoying   include order shenanigans", "target": 0}
{"idx": 1069, "commit_message": "gex: optimization and clean up  * remove unnecessary eval  * calculate the same author information only once  * update comments", "target": 1}
{"idx": 3357, "commit_message": "We meant fIsAutoParsingSuspended instead of IsAutoLoadingEnabled()  There used to be just one way of resolving an unknown name (eg. MyClass) -- by using the TCling::AutoLoad interface. However, there are two ingredients to resolve a name -- make the name known to the cling and make its library known to the JIT. Historically, these were one function.  Later, we implemented performance optimization on top which divides the two steps in order to avoid excessive library loading. Now we have an auto parse step which is designed to avoid the heavy TCling::Autoload.  The particular callback calls tryAutoParseInternal which is controlled by fIsAutoParsingSuspended.", "target": 1}
{"idx": 2355, "commit_message": "i965: Calculate appropriate L3 partition weights for the current pipeline state.  This calculates a rather conservative partitioning of the L3 cache based on the shaders currently bound to the pipeline and whether they use SLM, atomics, images or scratch space.  The result is intended to be fine-tuned later on based on other pipeline state.  Note that the L3 partitioning calculated for VLV in the non-SLM non-DC case differs from the hardware defaults in that it doesn't include a DC partition and has twice as much RO cache space -- This is an intentional functional change that improves performance in several bandwidth-bound benchmarks on VLV (5% significance): SynMark OglTexFilterAniso by 14.18%, SynMark OglTexFilterTri by 7.15%, Unigine Heaven by 4.91%, SynMark OglShMapPcf by 2.15%, GpuTest Fur by 1.83%, SynMark OglDrvRes by 1.80%, SynMark OglVsTangent by 1.71%, and a few other benchmarks from the Finnish system by less than 1%.", "target": 1}
{"idx": 2771, "commit_message": "Improve runtime performance by lazy creating function contexts", "target": 1}
{"idx": 2664, "commit_message": "Moved uniform setters to be more efficient", "target": 1}
{"idx": 3120, "commit_message": "don't alter HTTP/2.0 support  HTTP/2.0 downsides are performance issues associated to another flow control mechanism (alike TCP-over-TCP) and a rushed protocol release. Overall performance is still improved (request multiplexing in single SSL/TLS/TCP sessions). No known security implications.", "target": 1}
{"idx": 2146, "commit_message": "FLEX-33829 improve create UID performance and use", "target": 1}
{"idx": 1575, "commit_message": "-  Added PointLight attenuation. - Small optimizations and fixes. - Test scene improvements.", "target": 0}
{"idx": 3501, "commit_message": "Merge pull request #205 from johnbacon/patch-1  Various improvements to README.rst", "target": 0}
{"idx": 3648, "commit_message": "use atomic.Value to improve parallel performance by up to 20%", "target": 1}
{"idx": 1746, "commit_message": "GPU process does not fall back to alternative GL implementation.  Unless the --use-gl command line switch is specified, only the default GL implementation will be used. On windows this is ANGLE. On other platforms it it OpenGL.  Falling back on OpenGL implementations that are generally not as reliable as the default was causing crashes.  TEST=try, check GL implementation does not fallback BUG=none  Review URL: [URL]/6246116", "target": 0}
{"idx": 1458, "commit_message": "[Utils/Str] Avoid some overhead in Str::at() and Str::characters() since those may be used for traversing. Not DRY, but faster.", "target": 1}
{"idx": 3236, "commit_message": "Build support libs with AAPT2  Use AAPT2 to build the framework support libraries. Apps built with AAPT2 can more efficiently link against these libraries by specifying their module name in LOCAL_STATIC_ANDROID_LIBRARIES.  Ex:  LOCAL_STATIC_ANDROID_LIBRARIES := android-support-v7-appcompat android-support-v4  Apps built with AAPT2 do not need to specify --auto-add-overlay or --extra-packages, as these are automatically added as needed by the build system.  This change will not affect any apps that currently depend on the support libraries. This is because they import the resources directly.  We use LOCAL_JAR_EXCLUDE_FILES := none only to support javac when building javadoc. Jack builds are correct because the build system passes in the latest generated R.java ahead of any previous ones packaged in classes.jack. This means we can dynamically reference a support lib module, correctly seeing non-final R.java. Then at app package time, we only include the final R.java generated by the AAPT2 packaging step.  Bug:25958912", "target": 1}
{"idx": 693, "commit_message": "Improve import error reporting. PEP8 tweaks.", "target": 0}
{"idx": 597, "commit_message": "Improved feedback after an action (on redirect) and also put a navigation check link up the top.", "target": 0}
{"idx": 3441, "commit_message": "Make VideoDecodeAcceleratorTest work for VAVDA and fixed a bunch of bugs the test found - The bulk of the CL turns RenderingHelperEGL into RenderingHelperGL (by making   it EGL-vs-GLX-agnostic) - VaapiH264Decoder::AssignPictureBuffer: it's fine to restart decode after a   Reset(), so allow that. - VaapiH264Decoder::FillVARefFramesFromDPB: faster/clearer error condition, and   small cleanup. - VaapiH264Decoder::Flush: emit the final in-progress picture. - VaapiH264Decoder::DecodeOneFrame: insist on having at least two output   surfaces before attempting a decode to avoid running out. - VaapiVideoDecodeAccelerator::client_ is now a WeakPtr instead of a raw   pointer, to do correct lifetime accounting.  This also allows dropping the   helper methods on VAVDA whose only purpose was to triple-check client_'s   presence before dispatching calls on it. - VaapiVideoDecodeAccelerator::InitialDecodeTask: account for the possibility of   multiple in-flight Decode()s, and remove unnecessary task-posting.  Two remaining issues are: - the test-25fps.h264 testdata file triggers bug#135548 - the pure-decode performance (at least in Debug) of VAVDA is not as good as the reference that vdatest was originally built for, so some tests \"fail\" on lower-than-expected fps rates.  This probably just needs to be a per-platform expectation.  [URL]  Review URL: [URL]/10701071", "target": 0}
{"idx": 783, "commit_message": "perf/x86: Synchronize PMU task contexts on optimized context switches  Install Intel specific PMU task context synchronization adapter and extend optimized context switch path with PMU specific task context synchronization to fix LBR callstack virtualization on context switches.", "target": 0}
{"idx": 2715, "commit_message": "Optimize construction and extraction of array data (#89)  We introduce a new `arrayBytes` method on Data objects that returns a  view of the underlying bytes of the array. We then use this to implement  optimized getters and constructors of arrays of primitive fixed-width  types such as int and double. Benchmarks indicate that the getters  (converting from data to `Array[Int]` or `Array[Double]`) are about 10x  faster, while constructors (building Data of type \"*i\" or \"*v\" from  scala Arrays) are about 5x faster. In addition, because the `arrayBytes`  method is public, applications can implement their own optimized  routines for other cases, though of course care must be taken to handle  the raw bytes correctly.    Review:", "target": 1}
{"idx": 820, "commit_message": "Merge pull request #2 from M4R7iNP/master  Improved indenting and syntax highlighting", "target": 0}
{"idx": 3779, "commit_message": "Producer.cpp: make RTP header extensions mangling more efficient", "target": 1}
{"idx": 1587, "commit_message": "Added version field and other improvements to state syncing #463", "target": 0}
{"idx": 373, "commit_message": "Increase memory in the test because 8.0 simply does not work with just 256M any more", "target": 0}
{"idx": 1834, "commit_message": "Improve response handling for asynchronous 'erpc' requests  receive_response/3, wait_response/3, and check_response/3 in 'erpc' can now take a collection of request identifiers as argument and handle any responses corresponding a request identifier in the collection.", "target": 0}
{"idx": 201, "commit_message": "Adds DynamicDataConsolidator and uses in ResolveConsolidator  Also renamed example algorithm filenames to match the type name", "target": 0}
{"idx": 2104, "commit_message": "Update a lot of stuff  - Added new Vim plugins, vim-submode and vim-unimpared - Added new Vim mode with vim-submode, ^W mode, what will make working with vim panes, splits and windows easier, than just always pressing ^W when wanting to make change - Added Vi keymode to Bash - Bash completion is now loaded correctly on both macOS and Linux systems - Removed some weird Vim bindings I added for no reason (like <leader>q instead of :q, why I even did it?) - Added better tab completion to bash (and all other readline-based programs) - Totally restructured entire vimrc, cleaned it from useless junk, optimized performance by disabling gitgutter signs and numbers by default (added new command to toggle this, :Info). Also, added :Paste command for smart pasting from clipboard. - Added optional fuzzy completion for all file-related commands in Vim - Speeded up complete menu to removing searching in includes - Fixed height of URL bar in firefox theme - And a lot of other stuff that I don't really remember, but it is cool", "target": 1}
{"idx": 2763, "commit_message": "PM / devfreq: Add cache HW monitor governor  The cache HW monitor devfreq governor uses the hardware counters to determine the load on the cache and the appropriate frequency needed to support that load. This governor can be used in conjunction with the cache devfreq device to dynamically scale the cache frequency based on the demand/actual usage from the CPU subsystem.  The governor is written to be agnostic of the actual counters used to determine the load. On Krait based CPUs, the governor uses the Krait L2 PM counters which can conflict with certain profiling tools.  The Krait L2 performance monitor counters have the capability to count different types of requests going to the L2 cache. They also have the capability to raise interrupts when they overflow. This driver uses those counters to determine the true usage of L2 from the Krait processor subsystem and then recommends L2 frequency based on the measured values and the following tunable parameters.  The driver provides various tunables that allow it to be tuned more in favor of power or performance:  - cycles_per_high_req: The no. of cache clock cycles that are necessary to   efficiently process a high-work request to the cache. A higher value   means higher power and potentially higher performance. A lower value   means lower power and potentially lower performance.  - cycles_per_med_req: The no. of cache clock cycles that are necessary to   efficiently process a medium-work request to the cache. A higher value   means higher power and potentially higher performance. A lower value   means lower power and potentially lower performance.  - polling_ms: The sampling period in milliseconds. This only affects the   sampling period when cache use is ramping down or is increasing very   slowly (See tolerance_mrps).  - min_busy: The minimum percentage of time the cache should be busy. This   is also applied as a lower bound to the measured busy percentage before   it's used in calculations. This has to be lower than or equal to   max_busy. Lower values will make the scaling more aggressive.  - max_busy: The maximum percentage of time the cache should be busy. This   is also applied as an upper bound to the measured busy percentage before   it's used in calculations. This has to be greater than or equal to   min_busy. Lower values will make the scaling more aggressive.  - tolerance_mrps: The minimum increase (in millions of requests per second)   in cache requests, compared to previous sample, that will trigger an IRQ   to immediately re-evaluate the cache frequency.  - decay_rate: The parameter controls the rate at which the history is   forgotten when ramping down. This is expressed as a percentage of history   to be forgotten. So 100% means ignore history, 0% means never forget the   historical max. The default 90% means forget 90% of history each time.  - guard_band_mhz: This is a margin that's added to the computed cache   frequency to account for the time it takes between the load increasing   and the governor/device finishes ramping up the cache frequency.", "target": 0}
{"idx": 1477, "commit_message": "[type] minor improve of type transformer", "target": 0}
{"idx": 1025, "commit_message": "* ada-mode.el: Really fix bug#5400 (comment in [URL] was erroneous).   (ada-matching-decl-start-re): Move into ada-goto-decl-start.   (ada-goto-decl-start): Rename from ada-goto-matching-decl-start; callers   changed.  Delete RECURSIVE parameter; never used.  Improve doc string.   Improve comments in \"is\" portion.  Handle null procedure declaration.   (ada-move-to-end): Improve doc string.", "target": 0}
{"idx": 2460, "commit_message": "Limit BeiDou GEO satellites extend_correlation_symbols to 2  ...to improve tracking performance", "target": 1}
{"idx": 3473, "commit_message": "Merge branch 'sprint-1' into ignite-128  Conflicts: \texamples/src/main/java/org/apache/ignite/examples/datagrid/hibernate/HibernateL2CacheExampleNodeStartup.java \tmodules/clients/src/test/java/org/apache/ignite/client/ClientPutPortableTask.java \tmodules/clients/src/test/java/org/apache/ignite/client/integration/package.html \tmodules/clients/src/test/java/org/apache/ignite/client/router/package.html \tmodules/clients/src/test/java/org/apache/ignite/internal/TaskEventSubjectIdSelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/internal/client/ClientPortableArgumentTask.java \tmodules/clients/src/test/java/org/apache/ignite/internal/client/ClientPutPortableTask.java \tmodules/clients/src/test/java/org/apache/ignite/internal/client/ClientTestPortable.java \tmodules/clients/src/test/java/org/apache/ignite/internal/client/ClientTestPortableAffinityKeyTask.java \tmodules/clients/src/test/java/org/apache/ignite/internal/client/integration/ClientAbstractSelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/internal/processors/rest/RestBinaryProtocolSelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/internal/processors/rest/RestProcessorMultiStartSelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/internal/processors/rest/TaskCommandHandlerSelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/internal/processors/rest/TestBinaryClient.java \tmodules/clients/src/test/java/org/apache/ignite/jdbc/JdbcComplexQuerySelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/jdbc/JdbcEmptyCacheSelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/jdbc/JdbcLocalCachesSelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/jdbc/JdbcMetadataSelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/jdbc/JdbcPreparedStatementSelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/jdbc/JdbcResultSetSelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/jdbc/JdbcStatementSelfTest.java \tmodules/clients/src/test/java/org/apache/ignite/loadtests/client/ClientTcpSslLoadTest.java \tmodules/clients/src/test/resources/spring-cache.xml \tmodules/clients/src/test/resources/spring-server-node.xml \tmodules/clients/src/test/resources/spring-server-ssl-node.xml \tmodules/core/src/main/java/org/apache/ignite/IgniteBasicWarmupClosure.java \tmodules/core/src/main/java/org/apache/ignite/client/balancer/package.html \tmodules/core/src/main/java/org/apache/ignite/client/impl/package.html \tmodules/core/src/main/java/org/apache/ignite/client/marshaller/jdk/package.html \tmodules/core/src/main/java/org/apache/ignite/client/marshaller/optimized/package.html \tmodules/core/src/main/java/org/apache/ignite/client/marshaller/package.html \tmodules/core/src/main/java/org/apache/ignite/client/package.html \tmodules/core/src/main/java/org/apache/ignite/client/router/impl/package.html \tmodules/core/src/main/java/org/apache/ignite/client/router/package.html \tmodules/core/src/main/java/org/apache/ignite/client/ssl/package.html \tmodules/core/src/main/java/org/apache/ignite/client/util/package.html \tmodules/core/src/main/java/org/apache/ignite/configuration/ConnectorConfiguration.java \tmodules/core/src/main/java/org/apache/ignite/configuration/IgniteConfiguration.java \tmodules/core/src/main/java/org/apache/ignite/internal/IgniteKernal.java \tmodules/core/src/main/java/org/apache/ignite/internal/IgnitionEx.java \tmodules/core/src/main/java/org/apache/ignite/internal/client/GridClientCompute.java \tmodules/core/src/main/java/org/apache/ignite/internal/client/GridClientConfiguration.java \tmodules/core/src/main/java/org/apache/ignite/internal/client/impl/GridClientComputeImpl.java \tmodules/core/src/main/java/org/apache/ignite/internal/client/impl/GridClientImpl.java \tmodules/core/src/main/java/org/apache/ignite/internal/client/impl/connection/GridClientConnectionManagerAdapter.java \tmodules/core/src/main/java/org/apache/ignite/internal/client/marshaller/optimized/GridClientOptimizedMarshaller.java \tmodules/core/src/main/java/org/apache/ignite/internal/processors/portable/GridPortableProcessor.java \tmodules/core/src/main/java/org/apache/ignite/internal/processors/portable/os/GridOsPortableProcessor.java \tmodules/core/src/main/java/org/apache/ignite/internal/processors/rest/GridRestProcessor.java \tmodules/core/src/main/java/org/apache/ignite/internal/processors/rest/client/message/GridClientLogRequest.java \tmodules/core/src/main/java/org/apache/ignite/internal/processors/rest/handlers/log/GridLogCommandHandler.java \tmodules/core/src/main/java/org/apache/ignite/internal/processors/rest/handlers/log/package.html \tmodules/core/src/main/java/org/apache/ignite/internal/processors/rest/protocols/tcp/GridTcpRestDirectParser.java \tmodules/core/src/main/java/org/apache/ignite/internal/visor/node/VisorExecutorServiceConfiguration.java \tmodules/core/src/test/config/default-spring-url-testing.xml \tmodules/core/src/test/config/example-cache.xml \tmodules/core/src/test/config/io-manager-benchmark.xml \tmodules/core/src/test/config/job-loadtest/client.xml \tmodules/core/src/test/config/job-loadtest/server.xml \tmodules/core/src/test/config/jobs-load-base.xml \tmodules/core/src/test/config/load/cache-benchmark.xml \tmodules/core/src/test/config/load/cache-client-benchmark.xml \tmodules/core/src/test/config/load/dsi-load-base.xml \tmodules/core/src/test/config/load/merge-sort-base.xml \tmodules/core/src/test/config/loaders/grid-cfg-2-grids.xml \tmodules/core/src/test/config/loaders/grid-cfg.xml \tmodules/core/src/test/config/spring-cache-put-remove-load.xml \tmodules/core/src/test/config/spring-start-nodes-attr.xml \tmodules/core/src/test/config/spring-start-nodes.xml \tmodules/core/src/test/config/streamer/spring-streamer-base.xml \tmodules/core/src/test/config/websession/spring-cache-1.xml \tmodules/core/src/test/config/websession/spring-cache-2.xml \tmodules/core/src/test/config/websession/spring-cache-3.xml \tmodules/core/src/test/java/org/apache/ignite/internal/GridDiscoveryEventSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/GridStartStopSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/cache/GridCacheDaemonNodeAbstractSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/cache/GridCacheDeploymentSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/cache/GridCacheLuceneQueryIndexTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/cache/datastructures/GridCacheQueueMultiNodeAbstractSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/cache/distributed/GridCacheMultithreadedFailoverAbstractTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/cache/distributed/GridCachePreloadLifecycleAbstractTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/cache/distributed/near/GridCacheNearReaderPreloadSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/cache/distributed/near/GridCachePartitionedLockSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/dataload/GridDataLoaderPerformanceTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/fs/GridCacheGgfsPerBlockLruEvictionPolicySelfTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/fs/GridGgfsAbstractSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/fs/GridGgfsModesSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/processors/rest/handlers/cache/GridCacheCommandHandlerSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/internal/util/GridStartupWithUndefinedIgniteHomeSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/spi/GridTcpSpiForwardingSelfTest.java \tmodules/core/src/test/java/org/apache/ignite/spi/discovery/tcp/TcpDiscoverySelfTest.java \tmodules/core/src/test/java/org/apache/ignite/spi/discovery/tcp/TcpDiscoverySnapshotHistoryTest.java \tmodules/core/src/test/java/org/apache/ignite/testframework/junits/GridAbstractTest.java \tmodules/hadoop/src/test/java/org/apache/ignite/ignitefs/GridGgfsHadoopDualAbstractSelfTest.java \tmodules/hadoop/src/test/java/org/apache/ignite/ignitefs/GridGgfsHadoopFileSystemHandshakeSelfTest.java \tmodules/hadoop/src/test/java/org/apache/ignite/ignitefs/GridGgfsHadoopFileSystemLoggerStateSelfTest.java \tmodules/hadoop/src/test/java/org/apache/ignite/internal/processors/hadoop/GridHadoopAbstractSelfTest.java \tmodules/log4j/src/test/java/org/apache/ignite/logger/log4j/GridLog4jCorrectFileNameTest.java \tmodules/spring/src/test/java/org/apache/ignite/internal/GridFactorySelfTest.java \tmodules/spring/src/test/java/org/apache/ignite/internal/GridSpringBeanSerializationSelfTest.java \tmodules/yardstick/config/ignite-base-config.xml \tmodules/yardstick/config/ignite-store-config.xml \tmodules/yardstick/src/main/java/org/apache/ignite/yardstick/cache/store/jdbc/IgniteJdbcStoreGetTxBenchmark.java \tpom.xml", "target": 0}
{"idx": 3563, "commit_message": "dm snapshot: workaround for a false positive lockdep warning  commit 5ea330a75bd86b2b2a01d7b85c516983238306fb upstream.  The kernel reports a lockdep warning if a snapshot is invalidated because it runs out of space.  The lockdep warning was triggered by commit 0976dfc1d0cd80a4e9dfaf87bd87 (\"workqueue: Catch more locking problems with flush_work()\") in v3.5.  The warning is false positive.  The real cause for the warning is that the lockdep engine treats different instances of md->lock as a single lock.  This patch is a workaround - we use flush_workqueue instead of flush_work. This code path is not performance sensitive (it is called only on initialization or invalidation), thus it doesn't matter that we flush the whole workqueue.  The real fix for the problem would be to teach the lockdep engine to treat different instances of md->lock as separate locks.", "target": 0}
{"idx": 3402, "commit_message": "IB/qib: Convert qib_user_sdma_pin_pages() to use get_user_pages_fast()  commit 603e7729920e42b3c2f4dbfab9eef4878cb6e8fa upstream.  qib_user_sdma_queue_pkts() gets called with mmap_sem held for writing. Except for get_user_pages() deep down in qib_user_sdma_pin_pages() we don't seem to need mmap_sem at all.  Even more interestingly the function qib_user_sdma_queue_pkts() (and also qib_user_sdma_coalesce() called somewhat later) call copy_from_user() which can hit a page fault and we deadlock on trying to get mmap_sem when handling that fault.  So just make qib_user_sdma_pin_pages() use get_user_pages_fast() and leave mmap_sem locking for mm.  This deadlock has actually been observed in the wild when the node is under memory pressure.", "target": 1}
{"idx": 60, "commit_message": "improve merge commit detection  See codecov/codecov-python#118", "target": 0}
{"idx": 617, "commit_message": "PM-1110 added initial support cobalt batch system used on Blue Gene systems at ALCF. The following mappings are employed to generate the right resource requirements.  Pegasus Profile Key     Batch Key in Condor submit file    Comment from Condor Team  - pegasus.cores           +NodeNumber                     This is the number of cpus you want  -  pegasus.nodes           +HostNumber                     This is the number of hosts you want  -  pegasus.ppn             +SMPGranularity                 This is the number of processes per host you want  - pegasus.project         +BatchProject                   The project to use", "target": 0}
{"idx": 3556, "commit_message": "Give utils.copy the ability to ignore files (issue 1692)  This requires a significant overhaul because we want to be able to have IGNORE_FILES apply at every level of a recursively copied directory (e.g. the theme static directory).  Since I was overhauling it anyway I changed it to use os.walk, which should be more efficient.", "target": 1}
{"idx": 1562, "commit_message": "Changes merged for Unified Memory-based tree rep on GPU. Not too good though.", "target": 0}
{"idx": 3014, "commit_message": "x86/build: Mostly disable '-maccumulate-outgoing-args'  The GCC '-maccumulate-outgoing-args' flag is enabled for most configs, mostly because of issues which are no longer relevant.  For most configs, and with most recent versions of GCC, it's no longer needed.  Clarify which cases need it, and only enable it for those cases.  Also produce a compile-time error for the ftrace graph + mcount + '-Os' case, which will otherwise cause runtime failures.  The main benefit of '-maccumulate-outgoing-args' is that it prevents an ugly prologue for functions which have aligned stacks.  But removing the option also has some benefits: more readable argument saves, smaller text size, and (presumably) slightly improved performance.  Here are the object size savings for 32-bit and 64-bit defconfig kernels:        text           data            bss             dec            hex        filename   10006710        3543328        1773568        15323606         e9d1d6        vmlinux.x86-32.before    9706358        3547424        1773568        15027350         e54c96        vmlinux.x86-32.after        text           data            bss             dec            hex        filename   10652105        4537576         843776        16033457         f4a6b1        vmlinux.x86-64.before   10639629        4537576         843776        16020981         f475f5        vmlinux.x86-64.after  That comes out to a 3% text size improvement on x86-32 and a 0.1% text size improvement on x86-64.", "target": 1}
{"idx": 2535, "commit_message": "Optimization which removes an extra function calls when processing data diffs. Improves the rendering performance when scrolling up and down very large grids.", "target": 1}
{"idx": 2577, "commit_message": "Added a module and feature to make better performance for authenticated users", "target": 1}
{"idx": 3470, "commit_message": "Big performance improvement to the AutoLink module (#766)", "target": 1}
{"idx": 2623, "commit_message": "- added some KEYs to presence tables to improve db query performance (table version increased) - did some cleanup (corrected some log messages, a bit of restructuring )", "target": 1}
{"idx": 616, "commit_message": "Fixing urlscan bug (#10366)  * Fixing urlscan bug", "target": 0}
{"idx": 265, "commit_message": "Revert: translationfrom in active language mixin (#86)  This reverts commit 3cb846d2bc0f1884653b44a3a768cfd1c67cd801 (but maintains doc improvements)", "target": 0}
{"idx": 358, "commit_message": "Properly reset state in FactorRange._init() (#9882)  * Properly reset state in FactorRange._init()    * Include paint request in ready promise chain    * Improve handling of skipped tests in devtools    * Add a test for issue #9879    * Properly distinguish tests with and w/o baselines    * Deduplicate bokehjs' unit tests", "target": 0}
{"idx": 782, "commit_message": "Merge pull request #139 from macbre/select_star-improve-sql-comments-handling  is_select_query: improve handling of SQL comments", "target": 0}
{"idx": 3275, "commit_message": "Improved performance when loading OSM data. Removed normalization, now done in profiles.", "target": 1}
{"idx": 2287, "commit_message": "This round of updates achieves two major goals      - Large (O(10-100)) speedup in handling of very       complex PDFS (>10000 nodes) by pervasive use       of self-expanding hash tables      - Fix outstanding problems with RooProdPdf       through new strategy to deal with cached       objects in cloning/server redirect operations    There is also a handful of minor fixes    ------------------------------------------------    o RooSetPair      - New auxiliary class to store pair of RooArgSet pointers     o Roo1DTable      - Don't fill entries with zero weight     o RooAbsArg      - Add optional 2nd arg to printCompactTree() to store       output to file     o RooAbsCollection      - Initialize RooLinkedLists with hashing size threshold of 43      o RooAbsGoodnessOfFit, RooAbsOptGoodnessOfFit, RooProdPdf      - Follow changes in printCompactTree() syntax      o RooAbsOptGoodnessOfFit      - Remove all methods that implement dirty state optimization       and constant term caching (migration to RooAbsReal)     o RooAbsReal      - Various fixes in plotAsymOn fix plotting of asymmetries       in conjunction with ProjWData() and Slice()      - Add methods that implement dirty state optimization       and constant term caching (migration from RooAbsOptGoodnessOfFit)     o RooDataProjBinding      - Remove some old debug code     o RooHashTable      - New constructor option allow to choose hashing by name,       pointer or objects Hash() value      - Switch to using TMath::Hash() fast hashing method       using 'especially selected random numbers' (!)      - Add kludgy support for storage of RooLinkedListElem       and RooSetPair objects, which do not inherit from TObject.        (A full redesign of RooLinkedList and RooHashTable is needed        at some point)     o RooHist      - Fix print statement     o RooHistError      - Lower (n,m) threshold for calculation of approximate binomial       error to avoid factorial overflow problems.     o RooLinkedList      - Introduce automatically activated hashing by name and pointer       to speed up handling of long lists beyond size threshold       given in ctor (zero threshold disables this features)      - Automatically rehash tables when #entries becomes greater       than hash table size     o RooNameSet      - Sort contents upon insertion. This fixes broken operator==       for certain set comparisons     o RooNormListManager      - Add support for 'sterile' operation. If contents is sterilized       via new sterilize() member function or use of sterile copy       ctor RooNormSetCache information is retained (and thus       ordering and slot indeces used by client classes) but       stored contents associated with given iset/nset pairs       is deleted. A 'setNormList()' call that maps to a       sterilized slot will recycle that slot. Optional new argument       in getNormList will tell client that requested information       has been sterilized rather than not being there.     o RooNormSetCache      - Store set pair information in hash table of RooSetPair objects       rather than two fixed size arrays of RooArgSet pointers.       This greatly improves lookup speed (indexed by set pointers)       and automatically expands the capacity of the set cache       as is needed for very complex fits.     o RooProdPdf      - Abandon strategy to forward redirectServer requests to       cached product configurations. This strategy has turned       out to be flawed as insufficient information is available       in the redirectServers context to do the right thing       under all circumstances. Invocation of redirectServerHook()       will now sterilize the cache, using new RooNormListManager       feature      - Modify getAnalyticalIntegralWN(), which looks up cached       product configurations by index to recognize sterilized       entries. If such an entry is encountered, it is reconstituted       on the fly.     o RooRealIntegral      - Store owned clones of factorizing observables instead of linking       to instances provided in ctor as ownership related of those       turns out not to be well defined.     o RooRefCountedList      - Set hashing threshold of underlying RooLinkedList at 17     o RooSimPdfBuilder      - Increase buffer sizes of RooStringVars in set returned by       createProtoBuildConfig() to accomodate requests for ever       more complex pdf configurations.", "target": 1}
{"idx": 3037, "commit_message": "Replace some endl's with \" \" in the ostream for printing the experiment.xml file in prof and prof-mpi.  Endl has the unfortunate affect of issuing a flush() on every line.  This gives truly horrendous performance on the Blue Gene compute nodes.  I left in endl in some debugging code and I didn't touch prof-flat.  Also, add an explicit 4 meg buffer for writing the struct file in hpcstruct.  Note to developers: avoid using endl in C++ output streams, except maybe for interactive or debugging code.  The extra flush()s give unacceptable performance for large files.", "target": 1}
{"idx": 1511, "commit_message": "usb: otg: Add dual-role device (DRD) support  DRD mode is a reduced functionality OTG mode. In this mode we don't support SRP, HNP and dynamic role-swap.  In DRD operation, the controller mode (Host or Peripheral) is decided based on the ID pin status. Once a cable plug (Type-A or Type-B) is attached the controller selects the state and doesn't change till the cable in unplugged and a different cable type is inserted.  As we don't need most of the complex OTG states and OTG timers we implement a lean DRD state machine in usb-otg.c. The DRD state machine is only interested in 2 hardware inputs 'id' and 'b_sess_vld'.", "target": 0}
{"idx": 3476, "commit_message": "Split up tasks across cores more efficiently", "target": 1}
{"idx": 483, "commit_message": "Start sender after receivers to improve debugability", "target": 0}
{"idx": 3786, "commit_message": "Issue #17 - improve performance running locally  Increase memory requirements to 2GB Don't process plugin and theme folder as part of \"wordpress\" core", "target": 1}
{"idx": 3021, "commit_message": "Replace the fix for parallel bundled beziers with a more robust solution  - The fix needs to be at a lower level:  The invalidation of bounds needs to happen for this case.  The rendered style calculation code is too late in the flow for that. - This makes the rendered style code simpler again. - The `ele.remove()` op needs to dirty the bounds for parallel bundled bezier edges.  This should happen only when the removed edge is also bundled so that other edge types are not negatively affected w.r.t. performance. - Improve control point check and `isBundledBezier()` check to include more general `removed()` and `takesUpSpace()` conditions. - Certain style properties need to specify whether changing the property value such that a `bounds` is triggered would dirty the bounds of the parallel bundled bezier edges.  For now, this includes the `display` and `curve-style` properties.  Ref : Bezier edges do not update when sibling edges are removed asynchronously #2317", "target": 1}
{"idx": 1821, "commit_message": "gpu: ion: Set the dma_address of the sg list at alloc time  This patch sets the dma_address field of the sglist representing an allocation at allocation time.  This technically breaks the dma api which states that these addresses should be set when a particular device takes ownership of a buffer via the dma_map apis.  In the case of our systems the only dma address space is physical addresses.  Additionally, we can not afford the overhead of calling dma_map_sg from this location as it implies a cache invalidate that is not necessary if the memory was previously mapped cached.  Instead, the expectation is that memory being returned from the heaps is ready for dma in that if any cached mappings of that memory exist they have been invalidated.", "target": 0}
{"idx": 3277, "commit_message": "[FastISel][X86] Emit more efficient instructions for integer constant materialization.  This mostly affects the i64 value type, which always resulted in an 15byte mobavsq instruction to materialize any constant. The custom code checks the value of the immediate and tries to use a different and smaller mov instruction when possible.  This fixes <rdar://problem/17420988>.", "target": 1}
{"idx": 4092, "commit_message": "[PATCH] #1295 Refactored MX::setSub(single argument) This should be\n significantly more efficient, though I didn't do any performance testing", "target": 1}
{"idx": 3949, "commit_message": "tracing: Print nasty banner when trace_printk() is in use  trace_printk() is used to debug fast paths within the kernel. Places that gets called in any context (interrupt or NMI) or thousands of times a second. Something you do not want to do with a printk().  In order to make it completely lockless as it needs a temporary buffer to handle some of the string formatting, a page is created per cpu for every context (four per cpu; normal, softirq, irq, NMI).  Since trace_printk() should only be used for debugging purposes, there's no reason to waste memory on these buffers on a production system. That means, trace_printk() should never be used unless a developer is debugging their kernel. There's macro magic to allocate the buffers if trace_printk() is used anywhere in the kernel.  To help enforce that trace_printk() isn't used outside of development, when it is used, a nasty banner is displayed on bootup (or when a module is loaded that uses trace_printk() and the kernel core does not).  Here's the banner:   **********************************************************  **   NOTICE NOTICE NOTICE NOTICE NOTICE NOTICE NOTICE   **  **                                                      **  ** trace_printk() being used. Allocating extra memory.  **  **                                                      **  ** This means that this is a DEBUG kernel and it is     **  ** unsafe for produciton use.                           **  **                                                      **  ** If you see this message and you are not debugging    **  ** the kernel, report this immediately to your vendor!  **  **                                                      **  **   NOTICE NOTICE NOTICE NOTICE NOTICE NOTICE NOTICE   **  **********************************************************  That should hopefully keep developers from trying to sneak in a trace_printk() or two.  Link: [URL]/p/", "target": 0}
{"idx": 1010, "commit_message": "cpumask: prepare for iterators to only go to nr_cpu_ids/nr_cpumask_bits.: parisc  Impact: cleanup, futureproof  In fact, all cpumask ops will only be valid (in general) for bit numbers < nr_cpu_ids.  So use that instead of NR_CPUS in various places.  This is always safe: no cpu number can be >= nr_cpu_ids, and nr_cpu_ids is initialized to NR_CPUS at boot.", "target": 0}
{"idx": 3041, "commit_message": "feat (clrs.ch22.s1): add edge iterator to graph to improve performance of edge based algorithms", "target": 1}
{"idx": 595, "commit_message": "Improved caching of empty result sets.", "target": 1}
{"idx": 492, "commit_message": "allow for horizontal scrolling with dynamic column count in horizontal mode too", "target": 0}
{"idx": 3584, "commit_message": "rewrite benchmarks  load script in example is still better to understand performance", "target": 0}
{"idx": 4003, "commit_message": "[PATCH] Update RAS-IR.\n\nNotes:\n1. Overlap and row ordering have significant effects on convergence.\n2. Lower the matrix bandwidth, better the performance ?\n3. Sync is lower, but communication becomes higher, tradeoff!\n4. Parallelism is higher, but overhead is also higher, tradeoff!\n5. Very high accurate solves, do not provide anything.\n6. Two level and multi-levels might significantly reduce number of\niterations to converge.", "target": 1}
{"idx": 3994, "commit_message": "[PATCH] changed the ndelta to setting the number of cells per cut-off\n radius to per cut-off diameter and changed the default value to 3 in\n do_inputrec, this gives at most 64 cells per icg iso 125, this gives a few\n percent performance increase in ns and domain decomposition (the cg sorting)", "target": 1}
{"idx": 248, "commit_message": "From 7bddc2ba16a2a15773c2ea8947059afa27727764 Mon Sep 17 00:00:00 2001 From: Alan Coopersmith <alan.coopersmith at [URL]> Date: Mon, 16 Sep 2013 21:47:16 -0700 Subject: [PATCH] Avoid use-after-free in dix/dixfonts.c: doImageText()  [CVE-2013-4396]  Save a pointer to the passed in closure structure before copying it and overwriting the *c pointer to point to our copy instead of the original.  If we hit an error, once we free(c), reset c to point to the original structure before jumping to the cleanup code that references *c.  Since one of the errors being checked for is whether the server was able to malloc(c->nChars * itemSize), the client can potentially pass a number of characters chosen to cause the malloc to fail and the error path to be taken, resulting in the read from freed memory.  Since the memory is accessed almost immediately afterwards, and the X server is mostly single threaded, the odds of the free memory having invalid contents are low with most malloc implementations when not using memory debugging features, but some allocators will definitely overwrite the memory there, leading to a likely crash.  Reported-by: Pedro Ribeiro <pedrib at [URL]>", "target": 0}
{"idx": 234, "commit_message": "engine: Block sync of network with QoS when not supported  When a QoS entity is attached to network, the network is supposed to appear as out-of-sync on a host, no matter the cluster compatibility version of the host. However, when the host's cluster doesn't support Host Network QoS, it shouldn't be possible to then synchronize the network (which whould also apply QoS to it).", "target": 0}
{"idx": 218, "commit_message": "Merge branch 'master' into use-pebblebed-wildcards  * master:   Don't open up for injection attacks   Set proper Cache-control header   Add `direction` option for getting posts.   Add filtering on external id   Update bengler-capistrano   Minor readability improvement   Use a common method for both POST and PUT   Add put method   Logging passes tests   Silenced activerecord log", "target": 0}
{"idx": 2073, "commit_message": "Python: Inpacket python function no longer has a memory leak  Tibia Auto: fixed some \"pipe handle not being read fast enough\" messages were caused by restarting TA  Python: Fixed Inpacket python function from passing on incomplete packets", "target": 0}
{"idx": 4068, "commit_message": "[PATCH] Force field updates.\n\nNew order for SWM4-NDP and SWM6 topologies, with SETTLE\ninstead of 3 constraints.  Performance is slightly better\nin this case.  Uploading a SWM4-NDP water box that has\nbeen equilibrated for 100 ps to serve as input for gmx\nsolvate.\n\nChange-Id: I67e10693ca76e77b99b371ea9887402e7ac0acc1", "target": 1}
{"idx": 1516, "commit_message": "[Soup] CookieJarSoup::deleteCookie() should stop looking for the cookie after it is removed [URL]/show_bug.cgi?id=110100  Reviewed by Kenneth Rohde Christiansen.  CookieJarSoup::deleteCookie() retrieves the list of cookies that apply to a given URL, then iterates through the cookies to find the one with the right name and delete it. However, the current implementation keeps on comparing cookie names after the cookie was removed. This patch introduces a \"wasDeleted\" boolean to stop comparing cookie names after the cookie was deleted. Note that we cannot break as soon as the cookie is found as we need to keep iterating so that the cookies get freed by GOwnPtr.  No new tests, no behavior change.  * platform/network/soup/CookieJarSoup.cpp: (WebCore::deleteCookie):", "target": 0}
{"idx": 107, "commit_message": "JFATrainer optimization + add a base class", "target": 1}
{"idx": 1005, "commit_message": "pprof: fix tmp filename path construction  The pprof handler was trying to store the profile data in /tmp/kudu_cpu_profile/<pid>.<rand>. The kudu_cpu_profile directory is unlikely to exist, which makes the path handler fail.  This seems to have been an accidental regression in d20b44704033d46be76ce4bfa55df09251b45520.  This restores the prior behavior of /tmp/kudu_cpu_profile.<pid>.<rand>", "target": 0}
{"idx": 2879, "commit_message": "reimplemented pipe for better performance. test now runs in 2.3sec down from 17sec before.", "target": 1}
{"idx": 2761, "commit_message": "Regex performance improvements  On nl, fr, de, it, pt, es, uk", "target": 1}
{"idx": 3622, "commit_message": "Tried (successfully) to improve chat list performance", "target": 1}
{"idx": 2403, "commit_message": "Applying Thomas Rogan's patch to COLLECTIONS-328, improving the performance to ListUtils.intersection in the manner described by Jilles van Gurp", "target": 1}
{"idx": 1689, "commit_message": "dm sysfs: fix a module unload race  commit 2995fa78e423d7193f3b57835f6c1c75006a0315 upstream.  This reverts commit be35f48610 (\"dm: wait until embedded kobject is released before destroying a device\") and provides an improved fix.  The kobject release code that calls the completion must be placed in a non-module file, otherwise there is a module unload race (if the process calling dm_kobject_release is preempted and the DM module unloaded after the completion is triggered, but before dm_kobject_release returns).  To fix this race, this patch moves the completion code to dm-builtin.c which is always compiled directly into the kernel if BLK_DEV_DM is selected.  The patch introduces a new dm_kobject_holder structure, its purpose is to keep the completion and kobject in one place, so that it can be accessed from non-module code without the need to export the layout of struct mapped_device to that code.", "target": 0}
{"idx": 3274, "commit_message": "- Patch #204083 by pwolanin: PHPdoc improvement.", "target": 0}
{"idx": 3605, "commit_message": "Fix sqlalchemy performance problem  Fixes bug #1070074 too much lazy loading on the default model.  Removed those and only added lazy loading to queries that specifically need eager loading", "target": 1}
{"idx": 3305, "commit_message": "Squashed commit of the following:  commit f55a17f71ec97513a6968b1ea3c359bc6238cc5e Author: Yakov Zhdanov [URL]> Date:   Fri Jul 31 13:32:32 2015 +0300      review  commit 58ca345f622dbadfba7ef2d3dce850c4baa1f319 Merge: 5f921f6 7ed4d15 Author: Yakov Zhdanov [URL]> Date:   Fri Jul 31 13:24:51 2015 +0300      Merge branches 'ignite-752-2' and 'master' of [URL]/repos/asf/incubator-ignite into ignite-752-2  commit 5f921f62dd6563a88b2ecdde92a2b2ee8218ec95 Author: Denis Magda [URL]> Date:   Wed Jul 29 10:40:44 2015 +0300      ignite-752-2: added info on the lowest failure detection timeout to the documentation  commit 55f0eb56967d2cc9bdf62c3fb665521a59ddaf33 Author: Denis Magda [URL]> Date:   Wed Jul 29 09:15:29 2015 +0300      ignite-752-2: supported connection check frequency even for cases when failure timeout is ignored; performance optimizations", "target": 1}
{"idx": 1856, "commit_message": "optimizations and making equal now egal by returning type as well.   Former-commit-id: 35292bad3328b6d42ce8bd3be5e6d1f705efd5da [formerly fee2f6dd254f98d5901aa46c9aecaa6a8f4b902e] Former-commit-id: 7aeb390b36d2f5909cfa9032e43150d3614cbaf4", "target": 1}
{"idx": 226, "commit_message": "Add new rtnl_link_af_data_compare function to compare af_data  This patch adds a new api rtnl_linl_af_data_compare to compare link af_data", "target": 0}
{"idx": 2523, "commit_message": "refactor: more efficient uploading & exporting  Upload functions merged into one. Export function now returns a single export format instead of setting a variable for both.", "target": 1}
{"idx": 2899, "commit_message": "Cleaning Map.search and making a performance improvement (proper use of the closed list).", "target": 1}
{"idx": 2443, "commit_message": "improve events performance and make trigger(\"x y\") equal to trigger(\"x\").trigger(\"y\")", "target": 1}
{"idx": 2274, "commit_message": "Fix state and logging loading issues  This fixes several issues:  * Fix \"double loading\" root package __init__.py.    ST loads the __init__.py package module twice, once as NeoVintageous   and once as NeoVintageous.__init__. The logger was initialised in this   module so it was being initialised twice causing log messages to be   printed twice. (Log messages were actually being printed three times   due to another issue explained below).  * Fix loading, unloading and loading again of the state module.    ST auto loads all modules in the root of a package, if it finds a   module that has already been loaded it unloads it and reloads again.   This was happening for the state module. As a result the   initialising that was being done in this module was being done   twice (probably causing some edge case issues). It was also the cause   of duplicate log messages.  With the fixes above the logger no longer prints duplicate messages, we avoid some performance penalties due to the unloading and reloading, and they probably also fix some other edge case issues.", "target": 1}
{"idx": 2063, "commit_message": "[XFS] Fix inode allocation latency  The log force added in xfs_iget_core() has been a performance issue since it was introduced for tight loops that allocate then unlink a single file. under heavy writeback, this can introduce unnecessary latency due tothe log I/o getting stuck behind bulk data writes.  Fix this latency problem by avoinding the need for the log force by moving the place we mark linux inode dirty to the transaction commit rather than on transaction completion.  This also closes a potential hole in the sync code where a linux inode is not dirty between the time it is modified and the time the log buffer has been written to disk.  SGI-PV: 972753 SGI-Modid: xfs-linux-melb:xfs-kern:30007a", "target": 1}
{"idx": 2648, "commit_message": "mmc: cmdq_hci: Add support to set priority bit for cmdq READ request  This adds support to set priority bit in task descriptor of cmdq READ request by adding a quirk in cmdq host driver.  Setting this quirk can improve random read performance by ~15% without impacting the write throughput.", "target": 1}
{"idx": 242, "commit_message": "small improvement on loading the csv files.", "target": 1}
{"idx": 2755, "commit_message": "Use ArrayMap instead of HashMap in transitions  The new ArrayMap class is more efficient for small collections. Transitions use maps all over the place to collect/use property values in setting up the transition animations. Changing to ArrayMap should be more efficient, especially in terms of memory allocations and GCs.  Issue #9276256 Transitions: Reduce memory allocations", "target": 1}
{"idx": 2669, "commit_message": "- Patch #559658 by sun, dropcube: store filter settings per format, general API clean-up and documentation improvements.", "target": 0}
{"idx": 1012, "commit_message": "Merge pull request #188 from myhpom/mh-18--select-healthcare-network--backend  Mh 18  select healthcare network  backend", "target": 0}
{"idx": 3528, "commit_message": "Jeanette/scoot25 job serialization (#97)  * Scoot-25 job serialization/desialization.  First cut at serialize/deserialize code for jobDefinition.  The test passes, need to add gopter test cases and negative tests.    * Scoot-25 job serialization/desialization.  Added error message for serializing a nil object.    * Scoot-25, gopter test is passing    * Scoot-25, setting serialization to binary for performance improvement ( json option was 2.5x slower over 1k tests)    * Scoot-25, adding generated go files    * Scoot-25 - made changes as per review comments:  - serialize at Job level instead of JobDefinition level  - refactor deserializer code to pull logic for making the sched.Job object into its own method  - cleaned up some formatting and style issues  - used DeepCopy where applicable    * Scoot-25 - refactored serializer to expose a binary and json serializer to client.  Eliminating the need for \"json\" vs \"binary\" string selectors    * Scoot-25  -moved Job (and TaskDefinition) Equal method to definitions.go  -renamed sagaLog.thrift to JobDef.thrift and had generator put object definitions in package schedthrift    * scoot-25 - changes from 'go fmt'    * scoot-25,  - updated Serializer for cleaner pointer usage  - added more testing for equals methods  - eliminated method receivers on Equals methods    * Scoot-25 - changed file names from camel case to underscore pattern    * associated Equal methods with Job and TaskDefinition structures  fmt fix    * Scoot-25 - added fake for testing errors during serialization and made test compatible with DeepEqual()    * Scoot-25 - change behavior to create new thrift serializers each time (thrift serializers appear to be state-full).  Also removed the use of ParseDuration()    * Scoot-25 - removed Equals methods - figured out why DeepEqual() wasn't working", "target": 1}
{"idx": 3354, "commit_message": "FROMLIST: sched/fair: jump to max OPP when crossing UP threshold  Since the true utilization of a long running task is not detectable while it is running and might be bigger than the current cpu capacity, create the maximum cpu capacity head room by requesting the maximum cpu capacity once the cpu usage plus the capacity margin exceeds the current capacity. This is also done to try to harm the performance of a task the least.  Original fair-class only version authored by Juri Lelli [URL]>.  BUG=chrome-os-partner:44828 TEST=Boot kernel on Oak.", "target": 0}
{"idx": 3273, "commit_message": "Use JoddArrayList in FindFile for better performances. Also removes some LinkedList usages", "target": 1}
{"idx": 20, "commit_message": "Parse correctly MIP 8 clnsig keys from vep-annotated CSQ field (#1780)  * add new VEP keys    * tentative fix on parse transctipt (CSQ field)    * add comments    * outdent code    * fixed typos and added a test    * fix comment    * final fixed hopefully    * fix code that uploads all the pathogenic variants    * better parsing code    * remove dubugging code    * black code    * fix typo in comment    * improved load variant annotated with vep97 test    * improved load variant annotated with vep97 test    * populate test VCF vep97 file    * remove unused dependency    * import was required after all    * add another test    * fix load all pathogenic also for the vep-annotated clinvar variant fields    * remove unused dependency    * fix typo    * remove unused dependency    * updated changelog    * black 2 files    * remove actions on this branch    * fix syntax error    * ignore case when checking if a clinsig is vep anno    * updated changelog with other bugfix    * remove no_assertion_criteria_provided from clinsig constansts    * fix a test", "target": 0}
{"idx": 1968, "commit_message": "improved / commented code utiliti classes", "target": 0}
{"idx": 3546, "commit_message": "drm/i915: [GEN7] Use HW scheduler for fixed function shaders  commit a1e969e0332de7a430e62822cee8f2ec8d83cd7c upstream.  This originally started as a patch from Bernard as a way of simply setting the VS scheduler. After submitting the RFC patch, we decided to also modify the DS scheduler. To be most explicit, I've made the patch explicitly set all scheduler modes, and included the defines for other modes (in case someone feels frisky later).  The rest of the story gets a bit weird. The first version of the patch showed an almost unbelievable performance improvement. Since rebasing my branch it appears the performance improvement has gone, unfortunately. But setting these bits seem to be the right thing to do given that the docs describe corruption that can occur with the default settings.  In summary, I am seeing no more perf improvements (or regressions) in my limited testing, but we believe this should be set to prevent rendering corruption, therefore cc stable.  v1: Clear bit 4 also (Ken + Eugeni) Do a full clear + set of the bits we want (Me).  Cc: Bernard Kilarski [URL]> Reviewed-by (RFC): Kenneth Graunke [URL]>", "target": 0}
{"idx": 90, "commit_message": "Finished Optimization paraagraph and started Results in README", "target": 0}
{"idx": 2032, "commit_message": "Better handling of crowded ticks closes #13  Might be performance issues when many many ticks. If so we'll open a new issue", "target": 1}
{"idx": 865, "commit_message": "8166684: PPC64: implement intrinsic code with vector instructions for Unsafe.copyMemory()", "target": 1}
{"idx": 3964, "commit_message": "improved the performance of the filesystem loader", "target": 1}
{"idx": 3720, "commit_message": "event/dlb2: optimize dequeue operation  Convert code to use x86 vector instructions, thereby significantly improving dequeue performance.", "target": 1}
{"idx": 2723, "commit_message": "Improve performance (part 2), make smaller, other fixes  Or, a lot of things yet again.  1. Prototypes are avoided. Method definitions are avoided at all costs in the    renderer. C-like structs are exclusively used internally. This helps    significantly in both speed and size.  2. The deferred implementation had a couple functions refactored into static    equivalents.  3. Only 1 test fails now.  4. Several names were changed to be much smaller. Some of the exports were    aliased. This was a pure size improvement for free.  5. Regexes are inlined. It's better to let the engine do the caching.  6. The version string was inlined. It's still at the top.  7. `this` is avoided as much as possible in the rendering.", "target": 1}
{"idx": 2998, "commit_message": "mm: introduce MADV_PAGEOUT  When a process expects no accesses to a certain memory range for a long time, it could hint kernel that the pages can be reclaimed instantly but data should be preserved for future use.  This could reduce workingset eviction so it ends up increasing performance.  This patch introduces the new MADV_PAGEOUT hint to madvise(2) syscall. MADV_PAGEOUT can be used by a process to mark a memory range as not expected to be used for a long time so that kernel reclaims *any LRU* pages instantly.  The hint can help kernel in deciding which pages to evict proactively.  A note: It doesn't apply SWAP_CLUSTER_MAX LRU page isolation limit intentionally because it's automatically bounded by PMD size.  If PMD size(e.g., 256) makes some trouble, we could fix it later by limit it to SWAP_CLUSTER_MAX[1].  - man-page material  MADV_PAGEOUT (since Linux x.x)  Do not expect access in the near future so pages in the specified regions could be reclaimed instantly regardless of memory pressure. Thus, access in the range after successful operation could cause major page fault but never lose the up-to-date contents unlike MADV_DONTNEED. Pages belonging to a shared mapping are only processed if a write access is allowed for the calling process.  MADV_PAGEOUT cannot be applied to locked pages, Huge TLB pages, or VM_PFNMAP pages.  [1] [URL]/lkml/ /  [URL]: clear PG_active on MADV_PAGEOUT]   Link: [URL] [URL]: resolve conflicts with hmm.git] Link: [URL]", "target": 1}
{"idx": 3567, "commit_message": "AP_NavEKF3: Ensure Kalman gain calculatons respect deactivated states  All Kalman gain calculations now explicity set gains for deactivated states to zero. Previous use of loops to set gains to zero have been replaced with more efficient memset operations.", "target": 1}
{"idx": 2017, "commit_message": "Fixed a bug in the new experimental xpath performance getting code that was preventing '0' values from going into returned results, causing issues with author id positioning mainly #bing direwolf", "target": 0}
{"idx": 3082, "commit_message": "Convert editing/style/style-boundary-005.html with assert_selection  This patch converts the above mentioned layout test with assert_selection to promote the use of w3c testharness and improve code health. It also merges the test case into editing/style/style_boundary.html  This is also preparation for [URL]/2720063002  BUG=679977  Review-Url: [URL]/2717333003", "target": 0}
{"idx": 2701, "commit_message": "SONARJAVA-3317 To improve performance precompute JMethodSymbol.signature", "target": 1}
{"idx": 581, "commit_message": "Emergency backout of rev 1.152.  This is a 100% guaranteed way to totally hose your system.  You end up with just about everything statically linked (except for libpam.so), which then causes all the pam users to fail. eg: login, sshd, su etc all stop working because dlopen no longer works because there is no libc.so in memory anymore.  gcc passes -L/usr/lib to ld.  The /usr/lib/libxxx.so symlink is *not* a compatability link.  It is actually the primary link.  There should be no symlinks in /lib at all.  Only /lib/libXX.so.Y.   [9:27pm]/usr/bin-104> file yppasswd yppasswd: setuid ELF 32-bit LSB executable, Intel 80386, version 1 (FreeBSD), for FreeBSD 5.1.1, dynamically linked (uses shared libs), stripped  [9:27pm]/usr/bin-105> ldd yppasswd yppasswd:         libpam.so.2 => /usr/lib/libpam.so.2 (0x280d1000)  [9:28pm]/usr/bin-106>  Note no libc.so.5.  Hence libpam.so.2 has unresolved dependencies.  I believe this is also the cause of the recent buildworld failures when pam_krb5.so references -lcrypto stuff etc and when librpcsvc.so references des_setparity() etc.  This change could not possibly have worked, unless there are other missing changes to the gcc configuration.  It won't work with ports versions of gcc either.", "target": 0}
{"idx": 3038, "commit_message": "RBD: Don't query Ceph on stats for exclusive pools  Collecting stats for provisioned_capacity_gb takes a long time since we have to query each individual image for the provisioned size.  If we are using the pool just for Cinder and/or are willing to accept a potential deviation in Cinder stats we could just not retrieve this information and calculate this based on the DB information for the volumes.  This patch adds configuration option `rbd_exclusive_cinder_pool` that allows us to disable the size collection and thus improve the stats reporting speed.", "target": 1}
{"idx": 216, "commit_message": "Printing works. But for printing children one needs Qt 2.2 since there was a bug in 2.1.  New algorithm to detect how many pages need to be printed.  Printing embedded documents works now.  No printing of an empty page.  Fixed drawing bug when making a selection. The cell with the cursor used to display a white font on a white background :-)", "target": 0}
{"idx": 554, "commit_message": "Reversed merge commit 'e05f38abc4cf1b89f09b53fe9927307c32c10f22' into 1.3.0  * commit 'e05f38abc4cf1b89f09b53fe9927307c32c10f22': (164 commits)   [maven-release-plugin] prepare release 1.3.0-release-tag   release_pre_process: Moving config files from 1.3.0-SNAPSHOT to 1.3.0   SAKIII-5704 comment out <parent> and point <distributionManagement> to Sakai repos   SAKIII-5685 Fix count issue in inserter   SAKIII-5678 Attaching event to container instead of window [URL]/browse/SAKIII-5678   SAKIII-5686 Collection viewer not usable anymore after navigating back and forth between an item in it.   SAKIII-5683 - Infinite scroll in the inserter not properly killed   SAKIII-5682 - Deleted Items Reappear [URL]/browse/SAKIII-5682   SAKIII-5679 - Item Count in Collector Widget Does Not Update [URL]/browse/SAKIII-5679   SAKIII-5661 - Filtering out the server objects   SAKIII-5661 - List of world types should be derived from .json only   SAKIII-5650 - Make the search hover style similar as the topnavigation.   SAKIII-5641 Fix up the template generator widget to work with the new content authoring structures post 1.2.0   SAKIII-5647 - fix revisions for world templates [URL]/browse/SAKIII-5647   SAKIII-5650 - Clicking on the magnifying glass in the collector to search a collection does not work   SAKIII-5643 update pom version to 1.3.0-SNAPSHOT   SAKIII-5615 - Fix recursive error in removeServerCreatedObjects   run optimizer step with node if it's on the path   SAKIII-5606 Fixed infinite repeat of image. [URL]/browse/SAKIII-5606   SAKIII-5607 - Fix the share with message [URL]/browse/SAKIII-5607   ...  Conflicts:         dev/index.html         devwidgets/addarea/bundles/default.properties         devwidgets/newaddcontent/bundles/default.properties         devwidgets/topnavigation/topnavigation.html         pom.xml (reverse-merged from commit 10f6ac685dcc4c1791d16c8557b76383ed7bd79e)", "target": 0}
{"idx": 3741, "commit_message": "New version of palettised screen scaler for DS; uses LDMs and STMs to improve performance on slow VRAM.  svn-id: r29978", "target": 1}
{"idx": 3198, "commit_message": "Do IDBKey to V8 value conversions lazily.  ** DO NOT LAND YET - this is stacked on top of [URL]/23172007 **  This tackles IDBCursor::value(), and defers deserializing to a V8 value until requested by script. This also addresses a leak that scripts can induce by writing: cursor.value.ref = cursor  A microbenchmark (iterate a cursor over 500k items in a  store) shows a 27% performance increase compared to Part 1.  BUG=273211 [URL]  Review URL: [URL]/23295004", "target": 1}
{"idx": 3935, "commit_message": "Merge [URL]/pub/scm/linux/kernel/git/steve/gfs2-2.6-nmw  * [URL]/pub/scm/linux/kernel/git/steve/gfs2-2.6-nmw: (56 commits)   [GFS2] Allow journal recovery on read-only mount   [GFS2] Lockup on error   [GFS2] Fix page_mkwrite truncation race path   [GFS2] Fix typo   [GFS2] Fix write alloc required shortcut calculation   [GFS2] gfs2_alloc_required performance   [GFS2] Remove unneeded i_spin   [GFS2] Reduce inode size by moving i_alloc out of line   [GFS2] Fix assert in log code   [GFS2] Fix problems relating to execution of files on GFS2   [GFS2] Initialize extent_list earlier   [GFS2] Allow page migration for writeback and ordered pages   [GFS2] Remove unused variable   [GFS2] Fix log block mapper   [GFS2] Minor correction   [GFS2] Eliminate the no longer needed sd_statfs_mutex   [GFS2] Incremental patch to fix compiler warning   [GFS2] Function meta_read optimization   [GFS2] Only fetch the dinode once in block_map   [GFS2] Reorganize function gfs2_glmutex_lock   ...", "target": 1}
{"idx": 460, "commit_message": "use Simon's suggestion to build low-memory CSA [URL]/simongog/sdsl-lite/issues/395)", "target": 0}
{"idx": 2439, "commit_message": "core: Remove PowerMockito from AbstractQueryTest  Removed the usage of PowerMockito from AbstractQueryTest in order to improve tests performance. PowerMokcito was (mainly) used to mock DbFacade.getInstance(), which is no longer needed since getQuery.getDbFacade() can be spied.  Note that this pactch does NOT completely remove PowerMockito from all the queries' tests. For queries that require mocking static functions in helper classes (e.g., ImagesHandler, VmHandler), PowerMockito is still required, and the further refactoring requried to get rid of it is left for a future patch. In some classes PowerMockito calls were left untouched, and in some they had to be added explicitly since the base class no longer provides this functionallity.", "target": 1}
{"idx": 3028, "commit_message": "Only set title when it changes  I've seen Chromium constantly refresh the title in the developer tools. To be honest, I'm not sure if this means Chromium wastes CPU time changing a title, but this may introduce better performance.", "target": 0}
{"idx": 3434, "commit_message": "[sil-combine] Fix a bug in the peephole performing apply{partial_apply(x,y,z)}(a) -> apply(a,x,y,z)  The peephole was retaining, but not releasing @guaranteed arguments of closures, which under certain circumstances introduced memory leaks. This patch fixes this, by inserting those missing releases for non-consumed arguments.  In addition, new temporaries are created for each indirect consumed argument (e.g. for @in argument of the closure), initialized with the original argument of the partial apply and used instead of it afterwards. This is done to extend the lifetime of the original arguments and ensure that they are alive at each apply instruction which invokes the closure created by the partial_apply.  Comments were slightly improved as well.  rdar://23100352  Swift SVN r32898", "target": 1}
{"idx": 2816, "commit_message": "Enable highQualityFilter_SSE2  With SSE2, bitmap_BGRA_8888_A_scale_rotate_bicubic gains about 40% performance improvement on desktop i7-3770.  BUG=skia:  Committed: [URL]/skia/+/b381fa10d8079c58928058bb8a6db32b39f05e51  CQ_EXTRA_TRYBOTS=tryserver.skia:Test-Mac10.6-MacMini4.1-GeForce320M-x86_64-Release-Trybot [URL], [URL]  Author: [URL]  Review URL: [URL]/525283002", "target": 1}
{"idx": 4065, "commit_message": "[PATCH] subCycle: Add special treatment for nSubCycles = 1\n\nNow running sub-cycling with nSubCycles = 1 is as efficient as running the same\ncode without the sub-cycling loop.", "target": 1}
{"idx": 1307, "commit_message": "Don't use plain \"ret\" instructions at targets of jump instructions, since the branch caches on at least Athlon XP through Athlon 64 CPU's don't understand such instructions and guarantee a cache miss taking at least 10 cycles.  Use the documented workaround \"ret $0\" instead (\"nop; ret\" also works, but \"ret $0\" is probably faster on old CPUs).  Normal code (even asm code) doesn't branch to \"ret\", since there is usually some cleanup to do, but the __mcount, .mcount and .mexitcount entry points were optimized too well to have the minimum number of instructions (3 instructions each if profiling is not enabled) and they did this.  I didn't see a significant number of cache misses for .mexitcount, but for the shared \"ret\" for __mcount and .mcount I observed cache misses costing 26 cycles each.  For a send(2) syscall that makes about 70 function calls, the cost of these cache misses alone increased the syscall time from about 4000 cycles to about 7000 cycles.  4000 is for a profiling (GUPROF) kernel with profiling disabled; after this fix, configuring profiling only costs about 600 cycles in the 4000, which is consistent with almost perfect branch prediction in the mcounting calls.", "target": 1}
{"idx": 2483, "commit_message": "Use regex! macro for better performance", "target": 1}
{"idx": 1007, "commit_message": "Clean up now-incorrect names of many of the Mac GPU bots.  Removed the OS version from the names, as it was incorrect in almost all cases. This will lose history on these bots, but they've been green for quite a long time now, so this seems like a good time to make the switch.  BUG=688887 CQ_INCLUDE_TRYBOTS=master.tryserver.chromium.linux:linux_optional_gpu_tests_rel;master.tryserver.chromium.mac:mac_optional_gpu_tests_rel;master.tryserver.chromium.win:win_optional_gpu_tests_rel;master.tryserver.chromium.android:android_optional_gpu_tests_rel [URL] NOTRY=true  Review-Url: [URL]/2679543002", "target": 0}
{"idx": 1897, "commit_message": "mm: use up free swap space before reaching OOM kill  Recently, Luigi reported there are lots of free swap space when OOM happens.  It's easily reproduced on zram-over-swap, where many instance of memory hogs are running and laptop_mode is enabled.  He said there was no problem when he disabled laptop_mode.  The problem when I investigate problem is following as.  Assumption for easy explanation: There are no page cache page in system because they all are already reclaimed.  1. try_to_free_pages disable may_writepage when laptop_mode is enabled. 2. shrink_inactive_list isolates victim pages from inactive anon lru list. 3. shrink_page_list adds them to swapcache via add_to_swap but it doesn't    pageout because sc->may_writepage is 0 so the page is rotated back into    inactive anon lru list. The add_to_swap made the page Dirty by SetPageDirty. 4. 3 couldn't reclaim any pages so do_try_to_free_pages increase priority and    retry reclaim with higher priority. 5. shrink_inactlive_list try to isolate victim pages from inactive anon lru list    but got failed because it try to isolate pages with ISOLATE_CLEAN mode but    inactive anon lru list is full of dirty pages by 3 so it just returns    without  any reclaim progress. 6. do_try_to_free_pages doesn't set may_writepage due to zero total_scanned.    Because sc->nr_scanned is increased by shrink_page_list but we don't call    shrink_page_list in 5 due to short of isolated pages.  Above loop is continued until OOM happens.  The problem didn't happen before [1] was merged because old logic's isolatation in shrink_inactive_list was successful and tried to call shrink_page_list to pageout them but it still ends up failed to page out by may_writepage.  But important point is that sc->nr_scanned was increased although we couldn't swap out them so do_try_to_free_pages could set may_writepages.  Since commit f80c0673610e (\"mm: zone_reclaim: make isolate_lru_page() filter-aware\") was introduced, it's not a good idea any more to depends on only the number of scanned pages for setting may_writepage.  So this patch adds new trigger point of setting may_writepage as below DEF_PRIOIRTY - 2 which is used to show the significant memory pressure in VM so it's good fit for our purpose which would be better to lose power saving or clickety rather than OOM killing.", "target": 0}
{"idx": 1417, "commit_message": "Fix bug in the summation algorithm.  Quick'n'dirty fix for the summation algorithm if the input series don't have the same number of data points.", "target": 0}
{"idx": 1590, "commit_message": "add anchor info and other mechanism to avoid inconsistense after network partition", "target": 0}
{"idx": 3709, "commit_message": "net: pxa168_eth: Use dma_wmb/rmb where appropriate  Update the pxa168_eth driver to use the dma_rmb/wmb calls instead of the full barriers in order to improve performance: reduced 97ns/39ns on average in tx/rx path on Marvell BG4CT platform.", "target": 1}
{"idx": 1049, "commit_message": "2016-03-07  Richard Biener  < >  \tPR tree-optimization/70115 \t* tree-ssa-loop-ivcanon.c (propagate_into_all_uses): Remove. \t(propagate_constants_for_unrolling): Use replace_uses_by.  \t* gcc.dg/torture/pr70115.c: New testcase.", "target": 0}
{"idx": 4032, "commit_message": "[PATCH] Fix AMD OpenCL float3 array optimization bug\n\nBecause float3 by OpenCL spec is 16-byte, when used as an array type\nthe allocation needs to optimized to avoid unnecessary register use.\nThe nbnxm kernels use a float3 i-force accumulator array in registers.\n\nStarting with ROCm 2.3 the AMD OpenCL compiler regressed and lost\nits ability to effectively optimize code that uses float3 register\narrays. The large amount of extra registers used limits the kernel\noccupancy and significantly impacts performance.\nOnly the AMD platform is affected, other vendors' compilers are able to\ndo the necessary transformations to avoid the extra register use.\n\nThis change converts the float3 array to a float[3] saving 8*4 bytes\nregister space. This improves nonbonded kernel performance\non an AMD Vega GPU by 25% and 40% for the most common flavor of the\nEwald and RF force-only kernels, respectively.\n\nNote that eliminating the rest of the non-array use of float3 has no\nsignificant impact.", "target": 1}
{"idx": 3301, "commit_message": "Input: Send events one packet at a time  On heavy event loads, such as a multitouch driver, the irqsoff latency can be as high as 250 us.  By accumulating a frame worth of data before passing it on, the latency can be dramatically reduced.  As a side effect, the special EV_SYN handling can be removed, since the frame is now atomic.  This patch adds the events() handler callback and uses it if it exists. The latency is improved by 50 us even without the callback.", "target": 1}
{"idx": 3318, "commit_message": "btrfs: scrub: merge SCRUB_PAGES_PER_RD_BIO and SCRUB_PAGES_PER_WR_BIO  These two values were introduced in commit ff023aac3119 (\"Btrfs: add code to scrub to copy read data to another disk\") as an optimization.  But the truth is, block layer scheduler can do whatever it wants to merge/split bios to improve performance.  Doing such \"optimization\" is not really going to affect much, especially considering how good current block layer optimizations are doing. Remove such old and immature optimization from our code.  Since we're here, also change BUG_ON()s using these two macros to use ASSERT()s.", "target": 0}
{"idx": 2913, "commit_message": "Improved query grid performance  Fixed query grid image cells not updating correctly", "target": 1}
{"idx": 1045, "commit_message": "Fixed compile error due to upstream change in how dynamic cluster and index settings are registered.  Original commit: elastic/", "target": 0}
{"idx": 3215, "commit_message": "- update of version - release notes: * Initial Cache Implementation with the providers Ehcache and Hazelcast * Rest Endpoints for client and backend * Aggregate module to build different kinds of binarycaches (standalone or inmemory /  Ehcache or Hazelcast) * Added Performance Tests * BOM module to manage dependencies", "target": 0}
{"idx": 1521, "commit_message": "Improve LuaJIT compatibility, part #1: \"*\" library list is loaded through luaL_openlibs()", "target": 0}
{"idx": 2363, "commit_message": "- Patch #11927 by stefan/Robin: improved theming of tablesort icons.", "target": 0}
{"idx": 2023, "commit_message": "Ported a patch from the old repository, which improve the suppression on Android, where high gains have been seen in the upper frequency band. Review URL: [URL]/68005", "target": 1}
{"idx": 3690, "commit_message": "CAMEL-1955 better performance as Claus suggested", "target": 1}
{"idx": 1248, "commit_message": "Default neutron dhcp_agents_per_network to number of agents  This patch will set neutron's dhcp_agents_per_network equal to the number of deployed neutron DHCP agents unless otherwise explicitly set.  Partial-bug: #1632721", "target": 0}
{"idx": 2767, "commit_message": "Feature #8733: - improving performance about the displaying of re-indexation page - cleaning and renaming some code", "target": 1}
{"idx": 2804, "commit_message": "- Code cleanups:   * Move some code to external modules.   * Make more use of exceptions. - Include some Perl module dependencies into our source tree. - Minor performance improvement in loading data files. - Make the Cryption module endian-independent. - Fix compilation on Sun Sparc.", "target": 1}
{"idx": 2814, "commit_message": "v1.13 (2016-07-31)  + option for read-only encryption + ask for master password on CM+ launch/close if read-only encryption is enabled and user is not logged in + choose what settings to restore from selected backup file + error indicators in edit window that show which field prevents cookie from saving + additional information in tooltip of content action buttons + {HOST_RAW} and {PATH_RAW} export template tags * renamed \"Backup/Restore visible\" to \"Backup/Restore shown\" (issue #103, any other suggestions are welcome) * comment header in backup cookie file to be compatible with python cookie import library (pull #102) * save unsaved read-only data to disk immediately upon CM+ window close * moved read-only settings into it's own tab * window settings are stored in storage file instead of preferences (reduces bloat of pref.js for overall browser performance) * CM+ now uses only one database file to store it's data (read-only, window settings, search history, etc) * greatly improved performance at CM+ launch with large number of stored selections * greatly improved performance when changing read-only status of large number of cookies at once * collapsed by default changes of old versions in changes log(controlled via options menu at changes log page) ! wrap action button (it still accessible from context menu) ! pre-select restored cookies (issue #104) ! encrypted read-only data is lost if user canceled master password on start-up (issue #106) ! read-only column visible when read-only feature is disabled ! reset settings clears search history ! restore settings doesn't sort info rows until CM+ restarted ! no icon shown in notification2 update pop-up ! long cookie domain would not fit properly in delete confirmation dialog ! options window doesn't remember last opened tabs (FF34+)", "target": 1}
{"idx": 1872, "commit_message": "Developed method for solving the bottom cross  Sketch uses 16996 bytes (52%) of program storage space. Global variables use 688 bytes (33%) of dynamic memory", "target": 0}
{"idx": 2472, "commit_message": "[AArch64] This is a work in progress to provide a machine description for the Cortex-A53 subtarget in the AArch64 backend.  This patch lays the ground work to annotate each AArch64 instruction (no NEON yet) with a list of SchedReadWrite types. The patch also provides the Cortex-A53 processor resources, maps those the the default SchedReadWrites, and provides basic latency. NEON support will be added in a subsequent patch with proper forwarding logic.  Verification was done by setting the pre-RA scheduler to linearize to better gauge the effect of the MIScheduler. Even without modeling the forward logic, the results show a modest improvement for Cortex-A53.  Reviewers: apazos, mcrosier, atrick Patch by Dave Estes [URL]>!", "target": 0}
{"idx": 4033, "commit_message": "[PATCH] increased granularity of performance logging, fixed a bug in\n DofMap::add_neighbors_to_send_list() which caused the _send_list to become\n excessively large.  Further, this slowed the DofMap::sort_send_list() method\n considerably.", "target": 1}
{"idx": 2360, "commit_message": "Do not spam mongodb with update on every take  Improves read performance by 200%", "target": 1}
{"idx": 3969, "commit_message": "ipv4: fix buffer overflow in ip_options_compile()  [ Upstream commit 10ec9472f05b45c94db3c854d22581a20b97db41 ]  There is a benign buffer overflow in ip_options_compile spotted by AddressSanitizer[1] :  Its benign because we always can access one extra byte in skb->head (because header is followed by struct skb_shared_info), and in this case this byte is not even used.  [28504.910798] ================================================================== [28504.912046] AddressSanitizer: heap-buffer-overflow in ip_options_compile [28504.913170] Read of size 1 by thread T15843: [28504.914026]  [<ffffffff81802f91>] ip_options_compile+0x121/0x9c0 [28504.915394]  [<ffffffff81804a0d>] ip_options_get_from_user+0xad/0x120 [28504.916843]  [<ffffffff8180dedf>] do_ip_setsockopt.isra.15+0x8df/0x1630 [28504.918175]  [<ffffffff8180ec60>] ip_setsockopt+0x30/0xa0 [28504.919490]  [<ffffffff8181e59b>] tcp_setsockopt+0x5b/0x90 [28504.920835]  [<ffffffff8177462f>] sock_common_setsockopt+0x5f/0x70 [28504.922208]  [<ffffffff817729c2>] SyS_setsockopt+0xa2/0x140 [28504.923459]  [<ffffffff818cfb69>] system_call_fastpath+0x16/0x1b [28504.924722] [28504.925106] Allocated by thread T15843: [28504.925815]  [<ffffffff81804995>] ip_options_get_from_user+0x35/0x120 [28504.926884]  [<ffffffff8180dedf>] do_ip_setsockopt.isra.15+0x8df/0x1630 [28504.927975]  [<ffffffff8180ec60>] ip_setsockopt+0x30/0xa0 [28504.929175]  [<ffffffff8181e59b>] tcp_setsockopt+0x5b/0x90 [28504.930400]  [<ffffffff8177462f>] sock_common_setsockopt+0x5f/0x70 [28504.931677]  [<ffffffff817729c2>] SyS_setsockopt+0xa2/0x140 [28504.932851]  [<ffffffff818cfb69>] system_call_fastpath+0x16/0x1b [28504.934018] [28504.934377] The buggy address ffff880026382828 is located 0 bytes to the right [28504.934377]  of 40-byte region [ffff880026382800, ffff880026382828) [28504.937144] [28504.937474] Memory state around the buggy address: [28504.938430]  ffff880026382300: ........ rrrrrrrr rrrrrrrr rrrrrrrr [28504.939884]  ffff880026382400: ffffffff rrrrrrrr rrrrrrrr rrrrrrrr [28504.941294]  ffff880026382500: .....rrr rrrrrrrr rrrrrrrr rrrrrrrr [28504.942504]  ffff880026382600: ffffffff rrrrrrrr rrrrrrrr rrrrrrrr [28504.943483]  ffff880026382700: ffffffff rrrrrrrr rrrrrrrr rrrrrrrr [28504.944511] >ffff880026382800: .....rrr rrrrrrrr rrrrrrrr rrrrrrrr [28504.945573]                         ^ [28504.946277]  ffff880026382900: ffffffff rrrrrrrr rrrrrrrr rrrrrrrr [28505.094949]  ffff880026382a00: ffffffff rrrrrrrr rrrrrrrr rrrrrrrr [28505.096114]  ffff880026382b00: ffffffff rrrrrrrr rrrrrrrr rrrrrrrr [28505.097116]  ffff880026382c00: ffffffff rrrrrrrr rrrrrrrr rrrrrrrr [28505.098472]  ffff880026382d00: ffffffff rrrrrrrr rrrrrrrr rrrrrrrr [28505.099804] Legend: [28505.100269]  f - 8 freed bytes [28505.100884]  r - 8 redzone bytes [28505.101649]  . - 8 allocated bytes [28505.102406]  x=1..7 - x allocated bytes + (8-x) redzone bytes [28505.103637] ==================================================================  [1] [URL]/p/address-sanitizer/wiki/AddressSanitizerForKernel", "target": 0}
{"idx": 2933, "commit_message": "more efficient behavior with threads, no need to reload all AR's, just use the AR from the main thread, should be fine. Still using a thread-local variable, but not reloading from db.", "target": 1}
{"idx": 2647, "commit_message": "Optimized bookmark and list generation to improve export performance.", "target": 1}
{"idx": 484, "commit_message": "Minor improvement to README. Supervisor should now work. Resolves #11", "target": 0}
{"idx": 4117, "commit_message": "[PATCH] Added code to improve performance for the structure factor\n calculations.....Works in serial...Still need to check parallel\n performance......EJB", "target": 1}
{"idx": 2338, "commit_message": "Improve the performance of isRoot() to constant time", "target": 1}
{"idx": 928, "commit_message": "Reviewed by John          Fix for these two bugs:          <rdar://problem/3938935> REGRESSION (Mail): Pasting into an empty document mangles content         <rdar://problem/3939148> REGRESSION (Mail): Pasting mistakenly reverses lines          * khtml/editing/htmlediting.cpp:         (khtml::ReplaceSelectionCommand::doApply): For 3938935, add one more case to handle an empty document; merge         neither start nor end. For 3939148, improve the code which adjusts the insertion point during         the process of pasting. It formerly handled only one of the possible cases.         * layout-tests/editing/pasteboard/paste-text-015-expected.txt: Added.         * layout-tests/editing/pasteboard/paste-text-015.html: Added.", "target": 0}
{"idx": 1185, "commit_message": "Add WrappedBlockData.getData(), improve block data test", "target": 0}
{"idx": 2579, "commit_message": "Bump http-concat to b159178  Updates CSS Minifier to 4.1.0 (lots of bug fixes and performance improvements)", "target": 1}
{"idx": 2416, "commit_message": "KVM: SVM: hyper-v: Direct Virtual Flush support  From Hyper-V TLFS:  \"The hypervisor exposes hypercalls (HvFlushVirtualAddressSpace,   HvFlushVirtualAddressSpaceEx, HvFlushVirtualAddressList, and   HvFlushVirtualAddressListEx) that allow operating systems to more   efficiently manage the virtual TLB. The L1 hypervisor can choose to   allow its guest to use those hypercalls and delegate the responsibility   to handle them to the L0 hypervisor. This requires the use of a   partition assist page.\"  Add the Direct Virtual Flush support for SVM.  Related VMX changes: commit 6f6a657c9998 (\"KVM/Hyper-V/VMX: Add direct tlb flush support\")", "target": 1}
{"idx": 2134, "commit_message": "Code cleanup. Changed format of some dynamic preprocessor and runtime predicates that deal with predicate indicators for better performance.", "target": 1}
{"idx": 2421, "commit_message": "Merge branch 'writeback' of git://git.kernel.dk/linux-2.6-block  * 'writeback' of git://git.kernel.dk/linux-2.6-block:   writeback: writeback_inodes_sb() should use bdi_start_writeback()   writeback: don't delay inodes redirtied by a fast dirtier   writeback: make the super_block pinning more efficient   writeback: don't resort for a single super_block in move_expired_inodes()   writeback: move inodes from one super_block together   writeback: get rid to incorrect references to pdflush in comments   writeback: improve readability of the wb_writeback() continue/break logic   writeback: cleanup writeback_single_inode()   writeback: kupdate writeback shall not stop when more io is possible   writeback: stop background writeback when below background threshold   writeback: balance_dirty_pages() shall write more than dirtied pages   fs: Fix busyloop in wb_writeback()", "target": 1}
{"idx": 2301, "commit_message": "Minor corrections to improve iterator's performances", "target": 1}
{"idx": 2052, "commit_message": "mtd: msm_qpic_nand: use polling for bam operations  NAND DMA transfers take a very small amount of time. So if interrupts were used, there will be overhead from both hardware and software for the interrupt to be passed along to the necessary software. Since NAND device throughputs are usually low, this overhead will affect NAND throughput.  If instead of interrupts, the NAND driver was to poll the DMA hardware for transfer completion, then there will be improvement in NAND perofrmance.  LMDD throughput testing shows the following throughput improvements  Performance Mode --------------------------------         |        Interrupts        |        Polling Read        |        7.09 MBps        |        8.24 MBps Write        |        5.31 MBps        |        5.87 MBps  Ondemand Mode --------------------------------         |        Interrupts        |        Polling Read        |        5.45 MBps        |        8.19 MBps Write        |        4.36 MBps        |        5.77 MBps  This clearly shows that polling gives better performance.", "target": 1}
{"idx": 3739, "commit_message": "defconfig: msm8916: Enable support for Large Receive Offload  In computer networking, large receive offload is a technique for increasing inbound throughput of high-bandwidth network connections by reducing CPU overhead. It works by aggregating multiple incoming packets from a single stream into a larger buffer before they are passed higher up the networking stack, thus reducing the number of packets that have to be processed.  In Linux, it is generally used in conjunction with the New API (NAPI) to also reduce the number of interrupts.  According to benchmarks, even implementing this technique entirely in software can increase network performance significantly.", "target": 1}
{"idx": 278, "commit_message": "go/printer, gofmt: improved comma placement  Not a Go 1 issue, but appeared to be fairly easy to fix.  - Note that a few existing test cases look slightly worse but   those cases were not representative for real code. All real   code looks better now.  - Manual move of the comment in go/scanner/example_test.go   before applying gofmt.  - gofmt -w $GOROOT/src $GOROOT/misc  Fixes issue 3062.  R=rsc CC=golang-dev [URL]/5674093", "target": 0}
{"idx": 1197, "commit_message": "- Optimizations: -O3 if possible (user can override CFLAGS), udp   buffers are set to 1m by default (if socket options exist),   use recvmmsg and sendmmsg, or only recvmmsg, or recvfrom.", "target": 1}
{"idx": 2140, "commit_message": "performance improvement by reducing BeanManager call.", "target": 1}
{"idx": 2133, "commit_message": "NFS: Fix Oopses in nfs_lookup_revalidate and nfs4_lookup_revalidate  [Fixed upstream as part of 0b728e1911c, but that's a much larger patch, this is only the nfs portion backported as needed.]  Fix the following Oops in 3.5.1:   BUG: unable to handle kernel NULL pointer dereference at 0000000000000038  IP: [<ffffffffa03789cd>] nfs_lookup_revalidate+0x2d/0x480 [nfs]  PGD 337c63067 PUD 0  Oops: 0000 [#1] SMP  CPU 5  Modules linked in: nfs fscache nfsd lockd nfs_acl auth_rpcgss sunrpc af_packet binfmt_misc cpufreq_conservative cpufreq_userspace cpufreq_powersave dm_mod acpi_cpufreq mperf coretemp gpio_ich kvm_intel joydev kvm ioatdma hid_generic igb lpc_ich i7core_edac edac_core ptp serio_raw dca pcspkr i2c_i801 mfd_core sg pps_core usbhid crc32c_intel microcode button autofs4 uhci_hcd ttm drm_kms_helper drm i2c_algo_bit sysimgblt sysfillrect syscopyarea ehci_hcd usbcore usb_common scsi_dh_rdac scsi_dh_emc scsi_dh_hp_sw scsi_dh_alua scsi_dh edd fan ata_piix thermal processor thermal_sys   Pid: 30431, comm: java Not tainted 3.5.1-2-default #1 Supermicro X8DTT/X8DTT  RIP: 0010:[<ffffffffa03789cd>]  [<ffffffffa03789cd>] nfs_lookup_revalidate+0x2d/0x480 [nfs]  RSP: 0018:ffff8801b418bd38  EFLAGS: 00010292  RAX: 00000000fffffff6 RBX: ffff88032016d800 RCX: 0000000000000020  RDX: ffffffff00000000 RSI: 0000000000000000 RDI: ffff8801824a7b00  RBP: ffff8801b418bdf8 R08: 7fffff0034323030 R09: fffffffff04c03ed  R10: ffff8801824a7b00 R11: 0000000000000002 R12: ffff8801824a7b00  R13: ffff8801824a7b00 R14: 0000000000000000 R15: ffff8803201725d0  FS:  00002b53a46cb700(0000) GS:ffff88033fc20000(0000) knlGS:0000000000000000  CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033  CR2: 0000000000000038 CR3: 000000020a426000 CR4: 00000000000007e0  DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000  DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400  Process java (pid: 30431, threadinfo ffff8801b418a000, task ffff8801b5d20600)  Stack:   ffff8801b418be44 ffff88032016d800 ffff8801b418bdf8 0000000000000000   ffff8801824a7b00 ffff8801b418bdd7 ffff8803201725d0 ffffffff8116a9c0   ffff8801b5c38dc0 0000000000000007 ffff88032016d800 0000000000000000  Call Trace:   [<ffffffff8116a9c0>] lookup_dcache+0x80/0xe0   [<ffffffff8116aa43>] __lookup_hash+0x23/0x90   [<ffffffff8116b4a5>] lookup_one_len+0xc5/0x100   [<ffffffffa03869a3>] nfs_sillyrename+0xe3/0x210 [nfs]   [<ffffffff8116cadf>] vfs_unlink.part.25+0x7f/0xe0   [<ffffffff8116f22c>] do_unlinkat+0x1ac/0x1d0   [<ffffffff815717b9>] system_call_fastpath+0x16/0x1b   [<00002b5348b5f527>] 0x2b5348b5f526  Code: ec 38 b8 f6 ff ff ff 4c 89 64 24 18 4c 89 74 24 28 49 89 fc 48 89 5c 24 08 48 89 6c 24 10 49 89 f6 4c 89 6c 24 20 4c 89 7c 24 30 <f6> 46 38 40 0f 85 d1 00 00 00 e8 c4 c4 df e0 48 8b 58 30 49 89  RIP  [<ffffffffa03789cd>] nfs_lookup_revalidate+0x2d/0x480 [nfs]   RSP <ffff8801b418bd38>  CR2: 0000000000000038  ---[ end trace 845113ed191985dd ]---  This Oops affects 3.5 kernels and older, and is due to lookup_one_len() calling down to the dentry revalidation code with a NULL pointer to struct nameidata.  It is fixed upstream by commit 0b728e1911c (stop passing nameidata * to ->d_revalidate())  Reported-by: Richard Ems [URL]>", "target": 0}
{"idx": 2354, "commit_message": "Improve performance of nukes and some other situations which would cause many collisions. Fixes a denial of service attack where a player could perform ridiculous movement updates and cause extremely high server load due to collisions occuring for every block in a huge area. Fix some crashes with attempted deadlock recovery.", "target": 1}
{"idx": 2657, "commit_message": "Deferred image loading to improve page loading performance.", "target": 1}
{"idx": 1203, "commit_message": "chore(main): release 0.167.0 (#3482)  :robot: I have created a release *beep* *boop* ---   ## [URL]/googleapis/java-cloud-bom/compare/v0.166.0...v0.167.0) (2022-02-07)   ### Features  * add google-cloud-logging-servlet-initializer [URL]/googleapis/java-cloud-bom/issues/3496)) [URL]/googleapis/java-cloud-bom/commit/a147d91d6846323cc47590b0eaf5420e7c45d9e9))   ### Dependencies  * **java:** update actions/github-script action to v5 [URL]/googleapis/java-cloud-bom/issues/1339)) [URL]/googleapis/java-cloud-bom/issues/3487)) [URL]/googleapis/java-cloud-bom/commit/952a72c4d8dbd7f1403b0a411233d01388d178f5)) * update actions/github-script action to v5 [URL]/googleapis/java-cloud-bom/issues/3485)) [URL]/googleapis/java-cloud-bom/commit/d28173dabf03b1265d21dd986a75b3c0eba800d7)) * update dependency com.google.cloud:google-cloud-accessapproval-bom to v2.1.10 [URL]/googleapis/java-cloud-bom/issues/3499)) [URL]/googleapis/java-cloud-bom/commit/3fdf876465e2c4fc06c7262f0881a8fc576eccb2)) * update dependency com.google.cloud:google-cloud-aiplatform-bom to v2.6.0 [URL]/googleapis/java-cloud-bom/issues/3524)) [URL]/googleapis/java-cloud-bom/commit/83429c2dece64417f006ed52c9536b0c8486e8f1)) * update dependency com.google.cloud:google-cloud-api-gateway-bom to v2.1.7 [URL]/googleapis/java-cloud-bom/issues/3500)) [URL]/googleapis/java-cloud-bom/commit/1750d638d6fc914254d41e7c077e44961028b540)) * update dependency com.google.cloud:google-cloud-artifact-registry to v1.0.0 [URL]/googleapis/java-cloud-bom/issues/3556)) [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-asset-bom to v3.2.14 [URL]/googleapis/java-cloud-bom/issues/3501)) [URL]/googleapis/java-cloud-bom/commit/a8d899f5deb7a4f86042e0724c94c860a568a7fd)) * update dependency com.google.cloud:google-cloud-assured-workloads to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-automl-bom to v2.1.13 [URL]/googleapis/java-cloud-bom/issues/3468)) [URL]/googleapis/java-cloud-bom/commit/b3b073db99f5500dee0d9b4826e83c90249bc612)) * update dependency com.google.cloud:google-cloud-automl-bom to v2.1.14 [URL]/googleapis/java-cloud-bom/issues/3559)) [URL]/googleapis/java-cloud-bom/commit/69f96b988c02456d63de30ae5e4977cd045961ff)) * update dependency com.google.cloud:google-cloud-bigquery to v2.6.2 [URL]/googleapis/java-cloud-bom/issues/3474)) [URL]/googleapis/java-cloud-bom/commit/e51135e8de7daa847dca2a1d25a30f74728208df)) * update dependency com.google.cloud:google-cloud-bigquery to v2.7.1 [URL]/googleapis/java-cloud-bom/issues/3489)) [URL]/googleapis/java-cloud-bom/commit/a4478a990eb25e2311dc098deeeb6ec780f1a2e3)) * update dependency com.google.cloud:google-cloud-bigquery to v2.8.0 [URL]/googleapis/java-cloud-bom/issues/3495)) [URL]/googleapis/java-cloud-bom/commit/524adaf8c4d80fbea3ccde7768b69bf88b4f31fe)) * update dependency com.google.cloud:google-cloud-bigqueryconnection-bom to v2.1.9 [URL]/googleapis/java-cloud-bom/issues/3560)) [URL]/googleapis/java-cloud-bom/commit/f0fb44722077df7fce896400470e32fb93844d9d)) * update dependency com.google.cloud:google-cloud-bigquerydatatransfer-bom to v2.1.0 [URL]/googleapis/java-cloud-bom/issues/3491)) [URL]/googleapis/java-cloud-bom/commit/c9b9ca30ffbb9adb9c28e007030c123a88c97552)) * update dependency com.google.cloud:google-cloud-bigquerydatatransfer-bom to v2.1.1 [URL]/googleapis/java-cloud-bom/issues/3561)) [URL]/googleapis/java-cloud-bom/commit/7f248e6c51baf49ea266fb8d5b4b5b05063f21be)) * update dependency com.google.cloud:google-cloud-bigqueryreservation-bom to v2.2.2 [URL]/googleapis/java-cloud-bom/issues/3571)) [URL]/googleapis/java-cloud-bom/commit/52542f7aa272ec0383c2582a18190aed70ac7fbd)) * update dependency com.google.cloud:google-cloud-bigquerystorage-bom to v2.8.3 [URL]/googleapis/java-cloud-bom/issues/3488)) [URL]/googleapis/java-cloud-bom/commit/6d56f31004eae92678f6635667d1a621c98ba874)) * update dependency com.google.cloud:google-cloud-bigquerystorage-bom to v2.8.4 [URL]/googleapis/java-cloud-bom/issues/3562)) [URL]/googleapis/java-cloud-bom/commit/51efe46bb86082d8ff6feb16163165c898d5a4e3)) * update dependency com.google.cloud:google-cloud-bigtable-bom to v2.5.2 [URL]/googleapis/java-cloud-bom/issues/3492)) [URL]/googleapis/java-cloud-bom/commit/0177bc1faa63a18bc12fe756153cbb8ef082d1c8)) * update dependency com.google.cloud:google-cloud-billing-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3502)) [URL]/googleapis/java-cloud-bom/commit/004e924af73d9a65990d72c0be2a1e01011a15cc)) * update dependency com.google.cloud:google-cloud-billingbudgets-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3503)) [URL]/googleapis/java-cloud-bom/commit/976336a368a8b482aa7cf8277e714cbd22a6b541)) * update dependency com.google.cloud:google-cloud-binary-authorization to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-build-bom to v3.3.8 [URL]/googleapis/java-cloud-bom/issues/3504)) [URL]/googleapis/java-cloud-bom/commit/6ae8d67334f6b6e809314701cdf551f31746ff55)) * update dependency com.google.cloud:google-cloud-channel-bom to v3.4.0 [URL]/googleapis/java-cloud-bom/issues/3525)) [URL]/googleapis/java-cloud-bom/commit/5c92f019d265eb3d707efed1fe4b77e40a2e97e6)) * update dependency com.google.cloud:google-cloud-compute-bom to v1.7.0 [URL]/googleapis/java-cloud-bom/issues/3478)) [URL]/googleapis/java-cloud-bom/commit/b8dcf89bf535b7f1b53a48becbee994c2d523b4c)) * update dependency com.google.cloud:google-cloud-compute-bom to v1.7.1 [URL]/googleapis/java-cloud-bom/issues/3586)) [URL]/googleapis/java-cloud-bom/commit/b990333f32a1ca2b9e6adce07ca14a26395001eb)) * update dependency com.google.cloud:google-cloud-container-bom to v2.3.2 [URL]/googleapis/java-cloud-bom/issues/3493)) [URL]/googleapis/java-cloud-bom/commit/1343394033432efdb151272a0d1d8d29658c7a04)) * update dependency com.google.cloud:google-cloud-containeranalysis-bom to v2.2.7 [URL]/googleapis/java-cloud-bom/issues/3563)) [URL]/googleapis/java-cloud-bom/commit/45ef652350a74c77e0c4ca177177c3eb239f810d)) * update dependency com.google.cloud:google-cloud-data-fusion to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-datacatalog-bom to v1.6.3 [URL]/googleapis/java-cloud-bom/issues/3505)) [URL]/googleapis/java-cloud-bom/commit/27eec33e09f1f8f34d84c1ec41511a8ff38078bf)) * update dependency com.google.cloud:google-cloud-datalabeling-bom to v0.122.6 [URL]/googleapis/java-cloud-bom/issues/3506)) [URL]/googleapis/java-cloud-bom/commit/aac9ce19f7d17cdc54a889a06bb7a74e905c11ae)) * update dependency com.google.cloud:google-cloud-dataproc-bom to v2.3.2 [URL]/googleapis/java-cloud-bom/issues/3507)) [URL]/googleapis/java-cloud-bom/commit/719612834b12bde62ad6c8262ae6e052f569eaba)) * update dependency com.google.cloud:google-cloud-dataproc-metastore-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3528)) [URL]/googleapis/java-cloud-bom/commit/c017036d3f3ed1eb2c06ac0d65e97e72b78b30ed)) * update dependency com.google.cloud:google-cloud-datastore-bom to v2.2.3 [URL]/googleapis/java-cloud-bom/issues/3494)) [URL]/googleapis/java-cloud-bom/commit/a3f965e46d2a60fdb07a3518ba607b4fe93574a1)) * update dependency com.google.cloud:google-cloud-datastore-bom to v2.2.4 [URL]/googleapis/java-cloud-bom/issues/3564)) [URL]/googleapis/java-cloud-bom/commit/7873e94ba03c88d3cd0a1fb8bfb527d415900de9)) * update dependency com.google.cloud:google-cloud-debugger-client-bom to v1.1.6 [URL]/googleapis/java-cloud-bom/issues/3529)) [URL]/googleapis/java-cloud-bom/commit/fab1bc70a67102283ce683244d2ef4c13ccc801e)) * update dependency com.google.cloud:google-cloud-deploy to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-dialogflow-bom to v4.5.0 [URL]/googleapis/java-cloud-bom/issues/3526)) [URL]/googleapis/java-cloud-bom/commit/0a2bdd6165ca4259ee5e50abc0421301c5beb3c6)) * update dependency com.google.cloud:google-cloud-dlp-bom to v3.1.2 [URL]/googleapis/java-cloud-bom/issues/3530)) [URL]/googleapis/java-cloud-bom/commit/72da3e120a081f63e8389d23d2fea05e0744c70b)) * update dependency com.google.cloud:google-cloud-dms-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3531)) [URL]/googleapis/java-cloud-bom/commit/e2c755687c3c58549c0619f2cdc2fb09b03002ef)) * update dependency com.google.cloud:google-cloud-dns to v2.0.5 [URL]/googleapis/java-cloud-bom/issues/3532)) [URL]/googleapis/java-cloud-bom/commit/b41a6080f6573df9ad949011fa17fc65698546de)) * update dependency com.google.cloud:google-cloud-document-ai-bom to v2.2.0 [URL]/googleapis/java-cloud-bom/issues/3569)) [URL]/googleapis/java-cloud-bom/commit/3dad26a0c2949460fa1ebc6838d8c65e0920a4c1)) * update dependency com.google.cloud:google-cloud-errorreporting-bom to v0.122.11-beta [URL]/googleapis/java-cloud-bom/issues/3472)) [URL]/googleapis/java-cloud-bom/commit/f26db2236827066aa4761eede894195213822254)) * update dependency com.google.cloud:google-cloud-errorreporting-bom to v0.122.12-beta [URL]/googleapis/java-cloud-bom/issues/3533)) [URL]/googleapis/java-cloud-bom/commit/c33b96c7c92fc9d36368affb37ab7ebc49673dfa)) * update dependency com.google.cloud:google-cloud-essential-contacts-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3534)) [URL]/googleapis/java-cloud-bom/commit/61e58a5242ead9a0045952c3c10436f4950c75e2)) * update dependency com.google.cloud:google-cloud-eventarc-bom to v1.2.0 [URL]/googleapis/java-cloud-bom/issues/3570)) [URL]/googleapis/java-cloud-bom/commit/55d4e926444d616e3d2c84813655cd126f248b3b)) * update dependency com.google.cloud:google-cloud-filestore-bom to v1.1.6 [URL]/googleapis/java-cloud-bom/issues/3555)) [URL]/googleapis/java-cloud-bom/commit/9e65a1e12e5791b1f62b8fc21e61caa0ce8dea3a)) * update dependency com.google.cloud:google-cloud-firestore-bom to v3.0.11 [URL]/googleapis/java-cloud-bom/issues/3490)) [URL]/googleapis/java-cloud-bom/commit/81d522936c81eab6a13daea4c87402ed253608b3)) * update dependency com.google.cloud:google-cloud-firestore-bom to v3.0.12 [URL]/googleapis/java-cloud-bom/issues/3590)) [URL]/googleapis/java-cloud-bom/commit/44a5c94b7f2160a2a14dc8d9455274e946830768)) * update dependency com.google.cloud:google-cloud-functions-bom to v2.3.2 [URL]/googleapis/java-cloud-bom/issues/3572)) [URL]/googleapis/java-cloud-bom/commit/c1fea47f6156adea885bcec70220e2e36a2b5001)) * update dependency com.google.cloud:google-cloud-game-servers-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3535)) [URL]/googleapis/java-cloud-bom/commit/03af3e3dc6d15920280338f4c570cb8212aa5de2)) * update dependency com.google.cloud:google-cloud-gkehub to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-gsuite-addons-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3565)) [URL]/googleapis/java-cloud-bom/commit/a968dc643f7078ee4c68a4a17927dbeafb1eda24)) * update dependency com.google.cloud:google-cloud-iamcredentials-bom to v2.0.9 [URL]/googleapis/java-cloud-bom/issues/3566)) [URL]/googleapis/java-cloud-bom/commit/47f37a88667f08a24c9f4b6a47176f81d3d718a4)) * update dependency com.google.cloud:google-cloud-ids to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-iot-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3546)) [URL]/googleapis/java-cloud-bom/commit/f6dc218c04bba216c35bad159017cf1d7a26b742)) * update dependency com.google.cloud:google-cloud-kms-bom to v2.4.0 [URL]/googleapis/java-cloud-bom/issues/3527)) [URL]/googleapis/java-cloud-bom/commit/28052d4fcff1c8408f77eae7c237e135bc26ec04)) * update dependency com.google.cloud:google-cloud-language-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3547)) [URL]/googleapis/java-cloud-bom/commit/0bda6a2ebf78c21a3837ad3c6c455240fba5a02d)) * update dependency com.google.cloud:google-cloud-logging-bom to v3.6.0 [URL]/googleapis/java-cloud-bom/issues/3475)) [URL]/googleapis/java-cloud-bom/commit/4891d92e6d4df3e3af286b0cb24e2ba2ccbfbf35)) * update dependency com.google.cloud:google-cloud-logging-bom to v3.6.1 [URL]/googleapis/java-cloud-bom/issues/3484)) [URL]/googleapis/java-cloud-bom/commit/7acdc3ae1974984ba2ae6836ba7ed9d75c619fd5)) * update dependency com.google.cloud:google-cloud-logging-bom to v3.6.2 [URL]/googleapis/java-cloud-bom/issues/3573)) [URL]/googleapis/java-cloud-bom/commit/ef8b8cefb8356da7fa60db0da89cb234ec2cea9c)) * update dependency com.google.cloud:google-cloud-logging-logback to v0.122.9-alpha [URL]/googleapis/java-cloud-bom/issues/3469)) [URL]/googleapis/java-cloud-bom/commit/b06e24f95c7499c2ae18bdbd5324ac444a97e951)) * update dependency com.google.cloud:google-cloud-logging-logback to v0.123.0-alpha [URL]/googleapis/java-cloud-bom/issues/3483)) [URL]/googleapis/java-cloud-bom/commit/73a1ef0e2f07a4a0c00c92f8fbe7e2ff11be31c1)) * update dependency com.google.cloud:google-cloud-logging-logback to v0.123.1-alpha [URL]/googleapis/java-cloud-bom/issues/3574)) [URL]/googleapis/java-cloud-bom/commit/19c46bfd8c0affe3c60b0f5843eecd3cdc295ce2)) * update dependency com.google.cloud:google-cloud-managed-identities to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-mediatranslation-bom to v0.7.6 [URL]/googleapis/java-cloud-bom/issues/3548)) [URL]/googleapis/java-cloud-bom/commit/92f395f6c5a8040125aa4fcb0f7b37bf8bf47cd0)) * update dependency com.google.cloud:google-cloud-memcache-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3557)) [URL]/googleapis/java-cloud-bom/commit/55b951972961d54679ad6cfed4244093d671de0c)) * update dependency com.google.cloud:google-cloud-monitoring-bom to v3.2.2 [URL]/googleapis/java-cloud-bom/issues/3549)) [URL]/googleapis/java-cloud-bom/commit/fc71b1c441aa832714c264899f5f3b45633d2710)) * update dependency com.google.cloud:google-cloud-monitoring-dashboard-bom to v2.2.2 [URL]/googleapis/java-cloud-bom/issues/3558)) [URL]/googleapis/java-cloud-bom/commit/3d387e8cc093dd27238e8b7d0a268615586655c1)) * update dependency com.google.cloud:google-cloud-network-management-bom to v1.1.6 [URL]/googleapis/java-cloud-bom/issues/3508)) [URL]/googleapis/java-cloud-bom/commit/c662afdc810602de3f04fa3581f123fa75483abd)) * update dependency com.google.cloud:google-cloud-networkconnectivity to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-nio to v0.123.19 [URL]/googleapis/java-cloud-bom/issues/3509)) [URL]/googleapis/java-cloud-bom/commit/13279cfe7f9c83e4668879335d9290f057b9c26b)) * update dependency com.google.cloud:google-cloud-notification to v0.122.17-beta [URL]/googleapis/java-cloud-bom/issues/3575)) [URL]/googleapis/java-cloud-bom/commit/7665f59a49d90416fbd1634afc31d1f3f7e552ce)) * update dependency com.google.cloud:google-cloud-orchestration-airflow-bom to v1.1.2 [URL]/googleapis/java-cloud-bom/issues/3510)) [URL]/googleapis/java-cloud-bom/commit/cafdbce481feee4cfbddc0d6fc51950e27eb4ef6)) * update dependency com.google.cloud:google-cloud-orgpolicy-bom to v2.0.9 [URL]/googleapis/java-cloud-bom/issues/3511)) [URL]/googleapis/java-cloud-bom/commit/0b43c681fdfdb1f1a0a2837a0a3f74c2cca944f7)) * update dependency com.google.cloud:google-cloud-os-config-bom to v2.3.2 [URL]/googleapis/java-cloud-bom/issues/3582)) [URL]/googleapis/java-cloud-bom/commit/987ad62bf2ae1578ad06ade27d2875c93fa8dabd)) * update dependency com.google.cloud:google-cloud-os-login-bom to v2.0.9 [URL]/googleapis/java-cloud-bom/issues/3512)) [URL]/googleapis/java-cloud-bom/commit/edafd522232ee2dd822b975a8a34dc1f26f3dc55)) * update dependency com.google.cloud:google-cloud-phishingprotection-bom to v0.32.6 [URL]/googleapis/java-cloud-bom/issues/3576)) [URL]/googleapis/java-cloud-bom/commit/5f159606e4f818a514a1184ad0f234c1dde69035)) * update dependency com.google.cloud:google-cloud-policy-troubleshooter to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-profiler-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3513)) [URL]/googleapis/java-cloud-bom/commit/05e90621ebdc7100707f8728194c0ca4259a09f5)) * update dependency com.google.cloud:google-cloud-pubsub-bom to v1.115.2 [URL]/googleapis/java-cloud-bom/issues/3514)) [URL]/googleapis/java-cloud-bom/commit/95cb1b96555980552e288d680c60cd9e8e4fdd14)) * update dependency com.google.cloud:google-cloud-pubsublite-bom to v1.4.9 [URL]/googleapis/java-cloud-bom/issues/3583)) [URL]/googleapis/java-cloud-bom/commit/239a0ca4ad3d2cc3e7d70b92484246ce50123f15)) * update dependency com.google.cloud:google-cloud-recaptchaenterprise-bom to v2.4.1 [URL]/googleapis/java-cloud-bom/issues/3515)) [URL]/googleapis/java-cloud-bom/commit/f565b5d8a7a15d89bda3f6b8779169de0ea39006)) * update dependency com.google.cloud:google-cloud-recommender-bom to v2.2.0 [URL]/googleapis/java-cloud-bom/issues/3551)) [URL]/googleapis/java-cloud-bom/commit/4ec6cd034225267cb71092b74a7a6fa737a4e868)) * update dependency com.google.cloud:google-cloud-redis-bom to v2.2.0 [URL]/googleapis/java-cloud-bom/issues/3592)) [URL]/googleapis/java-cloud-bom/commit/525ab66ece3c72d9529c3f1d43518809f041ac85)) * update dependency com.google.cloud:google-cloud-resource-settings-bom to v1.1.6 [URL]/googleapis/java-cloud-bom/issues/3516)) [URL]/googleapis/java-cloud-bom/commit/5414c6588cb45f143dac0c36635bd3f6d35e5d24)) * update dependency com.google.cloud:google-cloud-resourcemanager-bom to v1.2.2 [URL]/googleapis/java-cloud-bom/issues/3517)) [URL]/googleapis/java-cloud-bom/commit/30c5958c1d62a83f038870d565a3478a01d437bd)) * update dependency com.google.cloud:google-cloud-retail-bom to v2.0.8 [URL]/googleapis/java-cloud-bom/issues/3536)) [URL]/googleapis/java-cloud-bom/commit/a44096fa49b61685ef2cb22b13c92f46d8b9d37a)) * update dependency com.google.cloud:google-cloud-scheduler-bom to v2.1.12 [URL]/googleapis/java-cloud-bom/issues/3537)) [URL]/googleapis/java-cloud-bom/commit/e1845de0e83b6b81773b7c04a676607479cb7f0e)) * update dependency com.google.cloud:google-cloud-secretmanager-bom to v2.1.0 [URL]/googleapis/java-cloud-bom/issues/3552)) [URL]/googleapis/java-cloud-bom/commit/00c41a78a9ad8771d3b6e7a336450d312fe83dbd)) * update dependency com.google.cloud:google-cloud-security-private-ca-bom to v2.2.3 [URL]/googleapis/java-cloud-bom/issues/3538)) [URL]/googleapis/java-cloud-bom/commit/cde364768e0f13b886003a5b6bc0d0b657f6f05f)) * update dependency com.google.cloud:google-cloud-securitycenter-bom to v2.4.0 [URL]/googleapis/java-cloud-bom/issues/3553)) [URL]/googleapis/java-cloud-bom/commit/4bd76f12429f03cbb07368dc683082edbb7f5468)) * update dependency com.google.cloud:google-cloud-service-control-bom to v1.1.6 [URL]/googleapis/java-cloud-bom/issues/3577)) [URL]/googleapis/java-cloud-bom/commit/da41ede1573c6243f428fa270d40c8be278fdf79)) * update dependency com.google.cloud:google-cloud-service-management-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3578)) [URL]/googleapis/java-cloud-bom/commit/8df77cd623dcef63b461a3e3b170a9c184650fa6)) * update dependency com.google.cloud:google-cloud-service-usage-bom to v2.2.2 [URL]/googleapis/java-cloud-bom/issues/3579)) [URL]/googleapis/java-cloud-bom/commit/3a4e217b4915433494fb38d55d213a4a670f4962)) * update dependency com.google.cloud:google-cloud-servicedirectory-bom to v2.2.3 [URL]/googleapis/java-cloud-bom/issues/3539)) [URL]/googleapis/java-cloud-bom/commit/21b387ffdbe966091b8090aa741be5a49492cd19)) * update dependency com.google.cloud:google-cloud-shell-bom to v2.1.8 [URL]/googleapis/java-cloud-bom/issues/3540)) [URL]/googleapis/java-cloud-bom/commit/8ffef010eaf638e2b95d756f36192be2729430d3)) * update dependency com.google.cloud:google-cloud-spanner-bom to v6.18.0 [URL]/googleapis/java-cloud-bom/issues/3584)) [URL]/googleapis/java-cloud-bom/commit/5840ecb4f58f74fc84b2c32d08a41e37a45cb28b)) * update dependency com.google.cloud:google-cloud-spanner-jdbc to v2.5.8 [URL]/googleapis/java-cloud-bom/issues/3471)) [URL]/googleapis/java-cloud-bom/commit/3bcba61d0e5fb1417d8e18af5785e95cbbdc765c)) * update dependency com.google.cloud:google-cloud-spanner-jdbc to v2.5.9 [URL]/googleapis/java-cloud-bom/issues/3541)) [URL]/googleapis/java-cloud-bom/commit/c321a3927db00e80d794dec89ba8cc8dcf2d8d7f)) * update dependency com.google.cloud:google-cloud-speech-bom to v2.2.3 [URL]/googleapis/java-cloud-bom/issues/3542)) [URL]/googleapis/java-cloud-bom/commit/20b73b4ef36f0fc49e351a8018c723f1db8f4290)) * update dependency com.google.cloud:google-cloud-storage to v2.3.0 [URL]/googleapis/java-cloud-bom/issues/3481)) [URL]/googleapis/java-cloud-bom/commit/0f2302757abdbdd96669334572b51319ea2db270)) * update dependency com.google.cloud:google-cloud-storage to v2.4.0 [URL]/googleapis/java-cloud-bom/issues/3554)) [URL]/googleapis/java-cloud-bom/commit/6e5ef424d68b072a3647ce7a85827a80c72a1258)) * update dependency com.google.cloud:google-cloud-storage-transfer to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-talent-bom to v2.2.5 [URL]/googleapis/java-cloud-bom/issues/3543)) [URL]/googleapis/java-cloud-bom/commit/c68f7cae59778ddacb3f1f8d85fc9ccd8bff0f6d)) * update dependency com.google.cloud:google-cloud-tasks-bom to v2.1.2 [URL]/googleapis/java-cloud-bom/issues/3544)) [URL]/googleapis/java-cloud-bom/commit/528309e483d8782ce06ecc85dba3aa821214cd88)) * update dependency com.google.cloud:google-cloud-texttospeech-bom to v2.1.2 [URL]/googleapis/java-cloud-bom/issues/3545)) [URL]/googleapis/java-cloud-bom/commit/3c864acc80eedf275baa20cdfc24e437f4dc4a45)) * update dependency com.google.cloud:google-cloud-tpu-bom to v2.2.2 [URL]/googleapis/java-cloud-bom/issues/3589)) [URL]/googleapis/java-cloud-bom/commit/f9645374235cc72e053cf1f2d539ca5a865a5b06)) * update dependency com.google.cloud:google-cloud-trace-bom to v2.1.2 [URL]/googleapis/java-cloud-bom/issues/3550)) [URL]/googleapis/java-cloud-bom/commit/079fbd23b5a29b9ae7be4856872e3aef05eea09e)) * update dependency com.google.cloud:google-cloud-translate-bom to v2.1.10 [URL]/googleapis/java-cloud-bom/issues/3518)) [URL]/googleapis/java-cloud-bom/commit/03abf3969a6f13d4570669268039c03f77498dce)) * update dependency com.google.cloud:google-cloud-video-intelligence-bom to v2.0.14 [URL]/googleapis/java-cloud-bom/issues/3473)) [URL]/googleapis/java-cloud-bom/commit/a900b42f937f465c57658d39a446eaf2ef43f2f9)) * update dependency com.google.cloud:google-cloud-video-intelligence-bom to v2.0.15 [URL]/googleapis/java-cloud-bom/issues/3519)) [URL]/googleapis/java-cloud-bom/commit/e05fba40ff2568c083c98555e553445207a80aca)) * update dependency com.google.cloud:google-cloud-video-transcoder to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-vision-bom to v2.0.18 [URL]/googleapis/java-cloud-bom/issues/3470)) [URL]/googleapis/java-cloud-bom/commit/313d3af99faba8a761cff664c3e565372ec64cdd)) * update dependency com.google.cloud:google-cloud-vision-bom to v2.0.19 [URL]/googleapis/java-cloud-bom/issues/3567)) [URL]/googleapis/java-cloud-bom/commit/161197c43adba44d202497bd6d5b88bf2894b66a)) * update dependency com.google.cloud:google-cloud-vmmigration to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-vpcaccess-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3520)) [URL]/googleapis/java-cloud-bom/commit/dd6d2a0dcc869e249faeff45e6fcfd3371fbbad4)) * update dependency com.google.cloud:google-cloud-webrisk-bom to v2.0.9 [URL]/googleapis/java-cloud-bom/issues/3521)) [URL]/googleapis/java-cloud-bom/commit/68e8e5b0dcefe810eb93f53e9f140afff2cd5c36)) * update dependency com.google.cloud:google-cloud-websecurityscanner-bom to v2.0.10 [URL]/googleapis/java-cloud-bom/issues/3522)) [URL]/googleapis/java-cloud-bom/commit/21407ba766108980448a24761fe78113bdcd1b69)) * update dependency com.google.cloud:google-cloud-workflow-executions-bom to v2.1.2 [URL]/googleapis/java-cloud-bom/issues/3523)) [URL]/googleapis/java-cloud-bom/commit/eec9ee506eae9b1e6cee555607aefed883527c5d)) * update dependency com.google.cloud:google-cloud-workflows-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3580)) [URL]/googleapis/java-cloud-bom/commit/0b96f98a4512d2bee8c43ee20f1a9c1c796bc2c0)) * update dependency com.google.cloud:google-iam-admin-bom to v1.1.2 [URL]/googleapis/java-cloud-bom/issues/3568)) [URL]/googleapis/java-cloud-bom/commit/4cfc5143e88c07611281a124112794cf016f4d33))  --- This PR was generated with [Release [URL]/googleapis/release-please). See [URL]/googleapis/release-please#release-please).", "target": 0}
{"idx": 929, "commit_message": "auto merge of #11159 : alexcrichton/rust/native-io, r=pcwalton  The old `rtio-processes` run-pass test is now moved into libstd's `io::process` module, and all process and TCP tests are now run with `iotest!` (both a native and a green version are tested).    All TCP networking on windows is provided by `ws2_32` which is apparently very similar to unix networking (hurray!).", "target": 0}
{"idx": 4100, "commit_message": "[PATCH] PERFFIX: improved 2d convolve perf in cuda by 33%\n\n* templating cuda kernel for filter lengths increased\n  performance by 30% which is 93% of closed-source ArrayFire\n  implementation of 2d convolution\n* templating separable cuda kernel improved performance by 20%\n* separated separable convolution kernel and wrapper into their\n  own file to speed up compilation time", "target": 1}
{"idx": 717, "commit_message": "pinctrl: Fix two deadlocks  commit db93facfb0ef542aa5d8079e47580b3e669a4d82 upstream.  This patch is to fix two deadlock cases. Deadlock 1: CPU #1  pinctrl_register-> pinctrl_get ->  create_pinctrl  (Holding lock pinctrl_maps_mutex)  -> get_pinctrl_dev_from_devname  (Trying to acquire lock pinctrldev_list_mutex) CPU #0  pinctrl_unregister  (Holding lock pinctrldev_list_mutex)  -> pinctrl_put ->> pinctrl_free ->  pinctrl_dt_free_maps -> pinctrl_unregister_map  (Trying to acquire lock pinctrl_maps_mutex)  Simply to say CPU#1 is holding lock A and trying to acquire lock B, CPU#0 is holding lock B and trying to acquire lock A.  Deadlock 2: CPU #3  pinctrl_register-> pinctrl_get ->  create_pinctrl  (Holding lock pinctrl_maps_mutex)  -> get_pinctrl_dev_from_devname  (Trying to acquire lock pinctrldev_list_mutex) CPU #2  pinctrl_unregister  (Holding lock pctldev->mutex)  -> pinctrl_put ->> pinctrl_free ->  pinctrl_dt_free_maps -> pinctrl_unregister_map  (Trying to acquire lock pinctrl_maps_mutex) CPU #0  tegra_gpio_request  (Holding lock pinctrldev_list_mutex)  -> pinctrl_get_device_gpio_range  (Trying to acquire lock pctldev->mutex)  Simply to say CPU#3 is holding lock A and trying to acquire lock D, CPU#2 is holding lock B and trying to acquire lock A, CPU#0 is holding lock D and trying to acquire lock B.", "target": 1}
{"idx": 2776, "commit_message": "Merge \"Improve floatingips concurrent api performance", "target": 1}
{"idx": 3472, "commit_message": "Bunch of updates:  - Try to unbreak what I broke by screwing with the tx queuing again.   I'm waiting for a few more people to test out this code and report back   before I move it into current. Hopefully it will be soon. Basically I   reverted to the old TX queuing strategy.  - Add experimental support for the 3c900B-FL (10mbps ST fiber). The card   should be detected properly and the 10baseFL mode supported, but again   I'm still waiting for word from a tester to see if this actually works.   It shouldn't affect the other cards though; all the differences are in   media selection.  - Set the TX start threshold register to get better performance.  - Increase the size of the RX and TX rings. UDP performance was pretty   bad because the TX ring was too small. Should be substantially better   now (I can saturate the link with either TCP or UDP now).  - Change some of the #defines to reflect proper 3Com ASIC names (boomerang,   cyclone, krakatoa, hurricane).  - Simplify and reorganize interrupt handler; ack all interrupts right   away and then process them. This avoids a potential race condition.   (Noted by Matt Dillon.)  - Reorganize the bridging code to eliminate using a goto to jump into   the middle of an if() {} clause. Sorry, that just made my brain itch.  - Use m_adj() in xl_rxeof().  - Make the payload alignment in xl_newbuf() the default (instead of   just conditionally defined for the alpha) to improve NFS performance   (avoids need for nfs_realign()).", "target": 1}
{"idx": 2745, "commit_message": "Improve performance of mines render loop", "target": 1}
{"idx": 3582, "commit_message": "Implement basic flag system  Flags are set according to interrupts to process events synchronously in the main loop. This is to keep the ISR short and simple, and to limit the number of global variables.  This patch implements a basic timer system, first the user selects the time and on a button press the microcontroller activates both lamps and starts counting down. When the timer ends, both lamps are shut down and the system can start again.  Timer is set up using the timer1 peripheral, a 16 bit timer. Counting from a fixed number up in order to create an interrupt every second. Drift is minimal ( approx 0.5s every 60 seconds) and could be improved in the future.", "target": 0}
{"idx": 3019, "commit_message": "[CHG] improve performance when previewing partner and solve some deprecated methods uses", "target": 1}
{"idx": 2471, "commit_message": "Support for optimizing and emitting code in LLVM JIT provider.  This commit introduces the ability to actually generate code using LLVM. In particular, this adds:  - Ability to emit code both in heavily optimized and largely   unoptimized fashion - Batching facility to allow functions to be defined in small   increments, but optimized and emitted in executable form in larger   batches (for performance and memory efficiency) - Type and function declaration synchronization between runtime   generated code and normal postgres code. This is critical to be able   to access struct fields etc. - Developer oriented jit_dump_bitcode GUC, for inspecting / debugging   the generated code. - per JitContext statistics of number of functions, time spent   generating code, optimizing, and emitting it.  This will later be   employed for EXPLAIN support.  This commit doesn't yet contain any code actually generating functions. That'll follow in later commits.  Documentation for GUCs added, and for JIT in general, will be added in later commits.  Author: Andres Freund, with contributions by Pierre Ducroquet Testing-By: Thomas Munro, Peter Eisentraut Discussion:", "target": 1}
{"idx": 4129, "commit_message": "[PATCH] replaced std::endl with \\n in all file IO and stringstreams. \n std::endl forces a flush, which kills performance on some machines", "target": 1}
{"idx": 587, "commit_message": "Merge pull request #2435 from tomastigera/tomas-wg-fix-host-networked  WG fv test fixes and bpf code simplifications", "target": 0}
{"idx": 1711, "commit_message": "(Fdo_auto_save): Handle the case that echo_area_message is set. (Finsert_file_contents): Prevent redisplay optimizations. (Fread_file_name): Call it. (report_file_error): Return void.", "target": 0}
{"idx": 582, "commit_message": "memory: emif: Add Kconfig dependency for TI EMIF controller  Make TI_EMIF depends on ARCH_OMAP2PLUS to avoid build breaks on other architectures. In future if other TI non OMAP socs start using it, the dependency can be extended.", "target": 0}
{"idx": 4069, "commit_message": "[PATCH] Fix nblib pairlist update function\n\nPreviously the function put_atoms_in_box was called only by the\nnblib integrator, or when constructing a system via a SimulationState\nobject. In the case of the integrator, this is a needless performance\ndegradation. When using an nb force calculator without\nfirst putting atoms in the box, this could lead to a cryptic\nerror from nbnxm grid search failure. Both of these issues are\nrectified with this change, which also adds a member to the\nnon-bonded force calculator to hold the requested number of OMP\nthreads to use in a call to put_atoms_in_box_omp, which is faster\nthan the non OMP version.", "target": 1}
{"idx": 2887, "commit_message": "Change the B-frame coding structure.  Originally we can have a BRF right before an overlay frame (in display order), which might be unnecessary since we already has a quality backward reference frame (ARF). This patch avoids such a coding structure and improves the RD performance by 0.086% in Avg in the lowres dataset, and 0.153 in Avg in the midres dataset.  In the lowres dataset, significant gains are obtained for the following sequences:  mobisode2_240p: 0.563% keiba_240p: 0.440% bus_cif: 0.336% soccer_cif: 0.333%  And the performance drops only in the following four video sequences:  motherdaughter_cif: 0.028% bqsquare_240p: 0.017% basketballpass_240p: 0.015% bowing_cif: 0.006%", "target": 1}
{"idx": 3449, "commit_message": "sched: Implement smarter wake-affine logic  The wake-affine scheduler feature is currently always trying to pull the wakee close to the waker. In theory this should be beneficial if the waker's CPU caches hot data for the wakee, and it's also beneficial in the extreme ping-pong high context switch rate case.  Testing shows it can benefit hackbench up to 15%.  However, the feature is somewhat blind, from which some workloads such as pgbench suffer. It's also time-consuming algorithmically.  Testing shows it can damage pgbench up to 50% - far more than the benefit it brings in the best case.  So wake-affine should be smarter and it should realize when to stop its thankless effort at trying to find a suitable CPU to wake on.  This patch introduces 'wakee_flips', which will be increased each time the task flips (switches) its wakee target.  So a high 'wakee_flips' value means the task has more than one wakee, and the bigger the number, the higher the wakeup frequency.  Now when making the decision on whether to pull or not, pay attention to the wakee with a high 'wakee_flips', pulling such a task may benefit the wakee. Also imply that the waker will face cruel competition later, it could be very cruel or very fast depends on the story behind 'wakee_flips', waker therefore suffers.  Furthermore, if waker also has a high 'wakee_flips', that implies that multiple tasks rely on it, then waker's higher latency will damage all of them, so pulling wakee seems to be a bad deal.  Thus, when 'waker->wakee_flips / wakee->wakee_flips' becomes higher and higher, the cost of pulling seems to be worse and worse.  The patch therefore helps the wake-affine feature to stop its pulling work when:          wakee->wakee_flips > factor &&         waker->wakee_flips > (factor * wakee->wakee_flips)  The 'factor' here is the number of CPUs in the current CPU's NUMA node, so a bigger node will lead to more pulling since the trial becomes more severe.  After applying the patch, pgbench shows up to 40% improvements and no regressions.  Tested with 12 cpu x86 server and tip 3.10.0-rc7.  The percentages in the final column highlight the areas with the biggest wins, all other areas improved as well:          pgbench                    base        smart          | db_size | clients |  tps  |        |  tps  |         +---------+---------+-------+   +-------+         | 22 MB   |       1 | 10598 |   | 10796 |         | 22 MB   |       2 | 21257 |   | 21336 |         | 22 MB   |       4 | 41386 |   | 41622 |         | 22 MB   |       8 | 51253 |   | 57932 |         | 22 MB   |      12 | 48570 |   | 54000 |         | 22 MB   |      16 | 46748 |   | 55982 | +19.75%         | 22 MB   |      24 | 44346 |   | 55847 | +25.93%         | 22 MB   |      32 | 43460 |   | 54614 | +25.66%         | 7484 MB |       1 |  8951 |   |  9193 |         | 7484 MB |       2 | 19233 |   | 19240 |         | 7484 MB |       4 | 37239 |   | 37302 |         | 7484 MB |       8 | 46087 |   | 50018 |         | 7484 MB |      12 | 42054 |   | 48763 |         | 7484 MB |      16 | 40765 |   | 51633 | +26.66%         | 7484 MB |      24 | 37651 |   | 52377 | +39.11%         | 7484 MB |      32 | 37056 |   | 51108 | +37.92%         | 15 GB   |       1 |  8845 |   |  9104 |         | 15 GB   |       2 | 19094 |   | 19162 |         | 15 GB   |       4 | 36979 |   | 36983 |         | 15 GB   |       8 | 46087 |   | 49977 |         | 15 GB   |      12 | 41901 |   | 48591 |         | 15 GB   |      16 | 40147 |   | 50651 | +26.16%         | 15 GB   |      24 | 37250 |   | 52365 | +40.58%         | 15 GB   |      32 | 36470 |   | 50015 | +37.14%", "target": 1}
{"idx": 1063, "commit_message": "Merge pull request #243 from AlinXlin/master  Formula Fix - Improved Momentum Strategy on Commodities Futures", "target": 0}
{"idx": 3338, "commit_message": "SysTreeview32 TreeviewItem NVDAObject: dramatically improve performance when expanding a treeview item, by re-implementing childCount property by counting the child items directly by window messages, rather than just getting the length of the NVDAObject's children. For a treeview item with 10000 children, this change takes the time down from about 10 seconds, to 0.5 seconds or lower. We may be able to move some of this code in-process in the future which would also increase performance more, plus increase performance when arrowing up and down the children in larege treeview items. However, this improvement for now is certainly useful.", "target": 1}
{"idx": 3002, "commit_message": "Perf DB cleanup + Fin pdb verification fix (#1810)  * remove datatype 0,1 from perf_db    * rm invalid fp16 entries from pdb    * Squashed 'fin/' changes from 53d2563fe..e05dcb421    e05dcb421 perf db validation fix (#68)  260d9465d Add INT8 as a data_type v2 (#67)  b6a5b2a77 sync with fin folder in miopen (#62)  0e03399ec prep for Palamida scan (#63)  e6bd05c33 Performance db testing (#61)  30d699b9e Perf Eval Update (#60)  3535b948c PerfCompile and PerfEval changes (#59)  de79468d2 remove unneccessary solution check, add check for previously modified kernel names (#56)  6924286a2 miopen hash update (#55)  530399575 Refactor googletest infra to align with MIOpen (#53)  71c50d146 Datatype fix for BN (#57)  8abe2f5c6 Perf Eval updates, Add find info (#51)  e1c1ef0f5 filter find compile by solver input (#54)  722feea66 sp/chk precomp kernel 264 (#41)  b9aba2034 Batch norm find compile (#50)  359f3da80 Fix missing link directives in fin binary (#48)  a4020c1ba Cache Miss Fixes (#46)  2ec7ef44d Enable google test and compiling fin in the CI (#47)  8b6b453bc Applicability support for batch norm (#45)  44323aae9 Perf compile/eval for fin (#42)  ebd9aa6bd update member name (#43)  d6d798efe add cu count (#39)  8e1989a9f Add find option for selecting only dynamic solvers (#38)  0e164bf66 setting json version (#37)  f3f7fed18 Remove function redefinition (#36)  e1de51a58 Performance DB de-serialize test (#34)  043cdcdaa Layout support in Fin (#33)  3a1d58236 Hotfix (#32)  ee3f0d543 4.4 Tuning Bugfixes (#31)  832dbe234 Tunability Reporting (#27)  a564a229f include gfx90a_110 (#28)    git-subtree-dir: fin  git-subtree-split: e05dcb42187f05fe0d0d1b05b822dc4b750f199e    * fix clang-format issue", "target": 0}
{"idx": 2042, "commit_message": "Shared/Logs: Improve log performances  Improve Log::ShouldLog() performances by saving the lowest log level across all loggers and discarding any log with lower level than that.", "target": 1}
{"idx": 1116, "commit_message": "pakfire-builder: Remove --private-network switch  I do not see why we would need this here.", "target": 0}
{"idx": 2594, "commit_message": "x86: Drop CONFIG_MCORE2 check around setting of NET_IP_ALIGN  This patch removes the CONFIG_MCORE2 check from around NET_IP_ALIGN.  It is based on a suggestion from Andi Kleen.  The assumption is that there are not any x86 cores where unaligned access is really slow, and this change would allow for a performance improvement to still exist on configurations that are not necessarily optimized for Core 2.  Cc: Andi Kleen [URL]> Cc: Thomas Gleixner < > Cc: Ingo Molnar [URL]> Cc: \"H. Peter Anvin\" [URL]> Cc: [URL]", "target": 1}
{"idx": 1816, "commit_message": "Fix re2 build with libcxx.  BUG=178409  [URL] [URL]  Review URL: [URL]/12951002", "target": 0}
{"idx": 1653, "commit_message": "msm: kgsl: Remove extra interrupts when setting MMU state  The interrupts added to the ringbuffer on PTFLUSH and TLBUPDATE were causing a major increase in the number of interrupts from the GPU. This was leading to increase in power and loss of performance. Add a check to turn off IOMMU clocks when going to SLEEP.", "target": 1}
{"idx": 2878, "commit_message": "Merge pull request #337 from alex-gh/entered_optimizations  Possibly improved /turf/simulated/Entered() performance", "target": 1}
{"idx": 2442, "commit_message": "Removed FULL_PERSISTENCE setting. It was a \"feature\" that was added at a time when caching was more inefficient than now. Also the new reload mechanism make FULL_PERSISTENCE=False unfeasable. Use ndb explicitly for non-persistence.", "target": 1}
{"idx": 203, "commit_message": "Enable certain config options without segfault  Fixes the `show_recruit_stats` and `use_endurance` configuration options so they will no longer cause a segmentation fault. The need_alloc fields for the corresponding entries in the config_string array were accidentally being set non-zero. This caused inappropriate memory reallocation attempts, leading to a segmentation fault.", "target": 0}
{"idx": 3366, "commit_message": "Improve performance for parsing and formatting of timestamps while remaining thread safe", "target": 1}
{"idx": 213, "commit_message": "8008603: Improve provision of JMX providers", "target": 0}
{"idx": 1628, "commit_message": "* fixed zlib to unset AR on dynamic and set it on static", "target": 0}
{"idx": 1011, "commit_message": "ncd: modules: net_ipv4_route: allow destination network in CIDR notation", "target": 0}
{"idx": 1087, "commit_message": "catch exceptions on webhook, DriverException, improve template compilation", "target": 0}
{"idx": 1141, "commit_message": "Mikal: Fixed all of the dmalloc reported errors except for the failures to free memory...", "target": 0}
{"idx": 3870, "commit_message": "Merge pull request #3353 from kivy/dessant-patch-1  improve floatlayout docs", "target": 0}
{"idx": 2331, "commit_message": "Adding guest user for public form and uses HikariCP for more control and better performances", "target": 1}
{"idx": 3496, "commit_message": "8030714: The steps attribute, flow and desugar are unnecessary for implicit classes when compiling with -implicit:none Summary: When compiling with -implicit:none, attribute, flow and desugar is skipped for better performance.", "target": 1}
{"idx": 4125, "commit_message": "[PATCH] Modified locate region to use more efficient algorithms for\n most block-cyclic distributions.", "target": 1}
{"idx": 1971, "commit_message": "store uncompiled string in the token, not in a separate hash table. This   Thu Feb 26 02:27:06 2009  Jiri (George) Lebl [URL]>  \t* src/eval.c, src/calc.c, src/dict.[ch], src/gnome-genius.h, \t  src/structs.h, src/symbolic.c: store uncompiled string in the \t  token, not in a separate hash table.  This avoids extra lookups \t  during startup.  \t* src/calc.c: a bit more optimization for help initialization   svn path=/trunk/; revision=739", "target": 1}
{"idx": 2593, "commit_message": "Changed storage used by WrapCVPixelBuffer from UNOWNED_MEMORY to OPAQUE.  This ensures development builds of Google Cast remote display does not render the performance overlay since the video frame is unmappable.  OPAQUE is also a more accurate description for CVPixelBuffer than since it is unmappable and currently does not have any external data pointers available.  BUG=529376  Review URL: [URL]/1332063002", "target": 0}
{"idx": 3530, "commit_message": "More face detection refinements. Note massive performance improvements in release builds (~20fps) vs. debug (~4fps).", "target": 1}
{"idx": 3573, "commit_message": "PY-19075 Fixed: PyCharm 2016.1.1 freezes immediately after the update  Improve SQL injection regexps so performance become better. Also add test for whitespace string injection", "target": 1}
{"idx": 3729, "commit_message": "LUCENE-8962: Merge small segments on commit (#1617)  Add IndexWriter merge-on-commit feature to selectively merge small segments on commit,  subject to a configurable timeout, to improve search performance by reducing the number of small  segments for searching.", "target": 1}
{"idx": 2050, "commit_message": "Set up  front-end performance monitoring tool: add support for --noexternals option (BugId:17412)", "target": 0}
{"idx": 169, "commit_message": "PM QoS: Add GPU frequency limits to PM QoS  Added GPU frequency min/max as PM QoS classes.  Bug 1330780", "target": 0}
{"idx": 3346, "commit_message": "Large SVG text layout performance regression in r81168 [URL]/show_bug.cgi?id=65711  Reviewed by Zoltan Herczeg.  Source/WebCore:  Final patch fixing the performance regression from r81168 plus giving us more performance we ever had. The testcase attached to bug 65711 creates 200 tspans as <text> children, and modifies just the first <tspan>s content periodically using a timer. It ran with <3 FPS in release builds before, and now at around 60 FPS, where the most dominant code path remaining is CG painting text. Still theres room to optimize further, as Intruments shows.  Historically we rebuilt all SVGTextLayoutAttributes stored in the RenderSVGInlineText, whenever any children of the <text> subtree changed, in any way. This lead to a recomputation of the x/y/dx/dy/rotate value lists, for the whole tree, a recreation of the line box tree and finally a measurement of all characters in the subtree.  This patch, and its previous patches preparing this, introduces progressive relayout for the SVG text subtree. DOM tree mutations, x/y/dx/dy/rotate value lists changes, and measuring-all-characters are now strictly decoupled.  #1) x/y/dx/dy/rotate list changes: The x/y/dx/dy/rotate lists are only ever rebuilt, if they change or upon the initial RenderSVGText layout. This information is now cached in the so-called SVGCharacterDataMap, in each of the SVGTextLayoutAttributes, associated with a specific RenderSVGInlineText.  #2) DOM tree mutations: If a new RenderSVGInlineText gets added to the tree, we have to create SVGTextLayoutAttributes for the new renderer, measure its characters, and cache the information in the attributes. Adding a new renderer to a SVG <text> subtree can affect the positioning of the previous and next sibling in the tree, due the whitespace merging logic. Example:  <text y=\"50\" x=\"50 100 150\">A<tspan></tspan> C</text>: RenderSVGText {text} at (50,36) size 111x18 contains 1 chunk(s)   RenderSVGInlineText {#text} at (0,0) size 12x18     chunk 1 text run 1 at (50.00,50.00) startOffset 0 endOffset 1 width 12.00: \"A\"   RenderSVGTSpan {tspan} at (0,0) size 0x0   RenderSVGInlineText {#text} at (50,0) size 61x18     chunk 1 text run 1 at (100.00,50.00) startOffset 0 endOffset 1 width 4.00: \" \"     chunk 1 text run 1 at (150.00,50.00) startOffset 0 endOffset 1 width 11.00: \"C\"  <text y=\"50\" x=\"50 100 150\">A<tspan>B</tspan> C</text>: RenderSVGText {text} at (50,36) size 115x18 contains 1 chunk(s)   RenderSVGInlineText {#text} at (0,0) size 12x18     chunk 1 text run 1 at (50.00,50.00) startOffset 0 endOffset 1 width 12.00: \"A\"   RenderSVGTSpan {tspan} at (0,0) size 11x18     RenderSVGInlineText {#text} at (50,0) size 11x18       chunk 1 text run 1 at (100.00,50.00) startOffset 0 endOffset 1 width 11.00: \"B\"   RenderSVGInlineText {#text} at (100,0) size 15x18     chunk 1 text run 1 at (150.00,50.00) startOffset 0 endOffset 2 width 15.00: \" C\"  Its obvious that adding a #text node as child to the <tspan> potentially affects the next & previous siblings in the DOM tree. Take extra care of these possibilities, by properly remeasuring not only the newly added renderer, but also the previous & next siblings layout attributes.  Mutation of text nodes, or removal of text/tspan elements from the tree is handled in the same way.  #3) Measuring the text subtree: Don't cache the metrics information in the SVGRootInlineBox, as it doesn't survive relayouts (RenderSVGText::layout). They're stored in the SVGTextLayoutAttributes, and will be updated if the underlying text content changes.  Tests: svg/text/append-text-node-to-tspan.html        svg/text/modify-text-node-in-tspan.html        svg/text/remove-text-node-from-tspan.html  * rendering/svg/RenderSVGInline.cpp: (WebCore::RenderSVGInline::addChild): * rendering/svg/RenderSVGInline.h: * rendering/svg/RenderSVGInlineText.cpp: (WebCore::RenderSVGInlineText::willBeDestroyed): (WebCore::RenderSVGInlineText::setTextInternal): (WebCore::RenderSVGInlineText::styleDidChange): * rendering/svg/RenderSVGInlineText.h: (WebCore::RenderSVGInlineText::layoutAttributes): * rendering/svg/RenderSVGText.cpp: (WebCore::recursiveUpdateLayoutAttributes): (WebCore::RenderSVGText::layoutAttributesChanged): (WebCore::findPreviousAndNextAttributes): (WebCore::RenderSVGText::layoutAttributesWillBeDestroyed): (WebCore::RenderSVGText::textDOMChanged): (WebCore::RenderSVGText::layout): (WebCore::RenderSVGText::addChild): (WebCore::recursiveCollectLayoutAttributes): (WebCore::RenderSVGText::rebuildLayoutAttributes): * rendering/svg/RenderSVGText.h: (WebCore::RenderSVGText::layoutAttributes): * rendering/svg/SVGRootInlineBox.cpp: (WebCore::SVGRootInlineBox::computePerCharacterLayoutInformation): (WebCore::findFirstAndLastAttributesInVector): (WebCore::reverseInlineBoxRangeAndValueListsIfNeeded): (WebCore::SVGRootInlineBox::reorderValueLists): * rendering/svg/SVGRootInlineBox.h: * rendering/svg/SVGTextLayoutAttributes.h: * rendering/svg/SVGTextLayoutAttributesBuilder.cpp: (WebCore::SVGTextLayoutAttributesBuilder::rebuildMetricsForWholeTree): * rendering/svg/SVGTextLayoutEngine.cpp: (WebCore::SVGTextLayoutEngine::SVGTextLayoutEngine): (WebCore::SVGTextLayoutEngine::currentLogicalCharacterAttributes): (WebCore::SVGTextLayoutEngine::currentLogicalCharacterMetrics): (WebCore::SVGTextLayoutEngine::currentVisualCharacterMetrics): (WebCore::SVGTextLayoutEngine::layoutTextOnLineOrPath): * rendering/svg/SVGTextLayoutEngine.h: (WebCore::SVGTextLayoutEngine::layoutAttributes): * rendering/svg/SVGTextMetrics.h: * rendering/svg/SVGTextMetricsBuilder.cpp: (WebCore::SVGTextMetricsBuilder::measureTextRenderer): * rendering/svg/SVGTextQuery.cpp: (WebCore::SVGTextQuery::modifyStartEndPositionsRespectingLigatures): * svg/SVGTextContentElement.cpp: (WebCore::SVGTextContentElement::childrenChanged):  LayoutTests:  Update some results, that changed again slightly. Land new tests covering partial SVG <text> subtree updating.  * platform/chromium/test_expectations.txt: * [URL]/window-expected.png: * [URL]/window-expected.txt: * platform/mac/svg/custom/js-late-clipPath-and-object-creation-expected.png: * platform/mac/svg/custom/js-late-clipPath-and-object-creation-expected.txt: * platform/mac/svg/custom/js-late-gradient-and-object-creation-expected.png: * platform/mac/svg/custom/js-late-gradient-and-object-creation-expected.txt: * platform/mac/svg/custom/js-late-pattern-and-object-creation-expected.png: * platform/mac/svg/custom/js-late-pattern-and-object-creation-expected.txt: * platform/mac/svg/custom/use-detach-expected.png: * platform/mac/svg/custom/use-detach-expected.txt: * platform/mac/svg/text/append-text-node-to-tspan-expected.png: Added. * platform/mac/svg/text/append-text-node-to-tspan-expected.txt: Added. * platform/mac/svg/text/modify-text-node-in-tspan-expected.png: Added. * platform/mac/svg/text/modify-text-node-in-tspan-expected.txt: Added. * platform/mac/svg/text/remove-text-node-from-tspan-expected.png: Added. * platform/mac/svg/text/remove-text-node-from-tspan-expected.txt: Added. * svg/text/append-text-node-to-tspan.html: Added. * svg/text/modify-text-node-in-tspan.html: Added. * svg/text/remove-text-node-from-tspan.html: Added.", "target": 1}
{"idx": 2737, "commit_message": "Version 2.36b  - Fixed a cosmetic bad free() bug when aborting -S sessions. Spotted by   Johannes S.  - Made a small change to afl-whatsup to sort fuzzers by name.  - Fixed a minor issue with malloc(0) in libdislocator. Spotted by Rene   Freingruber.  - Changed the clobber pattern in libdislocator to a slightly more   reliable one. Suggested by Rene Freingruber.  - Added a note about THP performance. Suggested by Sergey Davidoff.  - Added a somewhat unofficial support for running afl-tmin with a   baseline \"mask\" that causes it to minimize only for edges that are   unique to the input file, but not to the \"boring\" baseline. Suggested   by Sami Liedes.  - \"Fixed\" a getPassName() problem with never versions of clang.   Reported by Craig Young and several other folks.  Yep, I know I have a backlog on several other feature requests. Stay tuned!", "target": 0}
{"idx": 695, "commit_message": "Create README for DynamicTriangle, not finished.", "target": 0}
{"idx": 1920, "commit_message": "DateTime handnling improved.  Now detects and uses NT extra data for dates.", "target": 0}
{"idx": 825, "commit_message": "* Optimized Minstrel job quest (rejobs3-2minstrel.txt)", "target": 1}
{"idx": 2102, "commit_message": "o Added a simple check and a read loop instead of a single read to BlobImpl    and ClobImpl.  o Small changes in LargeLOBTest.testLargeBlob1() and    TestBase.compareInputStreams()/compareReaders() to improve performance. All    three now use buffers instead of reading/writing one byte at a time.    LargeLOBTest runs now in just over a minute.  o Added a test for bug #1008816 - '\"More data in stream ...\" error when    inserting an image' to LOBTest (testBlobSet8). This seems to have been fixed    starting with 0.9-rc1.", "target": 1}
{"idx": 2087, "commit_message": "MDEV-3812: Remove unneeded extra call to engine->exec() in Item_subselect::exec, remove enum store_key_result  This task fixes an ineffeciency that is a remainder from MySQL 5.0/5.1. There, subqueries were optimized in a lazy manner, when executed for the first time. During this lazy optimization it may happen that the server finds a more efficient subquery engine, and substitute the current engine of the query being executed with the new engine. This required re-execution of the engine.  MariaDB 5.3 pre-optimizes subqueries in almost all cases, and the engine is chosen in most cases, except when subquery materialization found that it must use partial matching. In this case, the current code was performing one extra re-execution although it was not needed at all. The patch performs the re-execution only if the engine was changed while executing.  In addition the patch performs small cleanup by removing \"enum store_key_result\" because it is essentially a boolean, and the code that uses it already maps it to a boolean.", "target": 1}
{"idx": 3223, "commit_message": "simd4f: Add a simplified scalar reciprocal implementation  Check for IEEE 754 floating-point division compilance in regards to division by positive and negative 0, and rely upon it when available to simplify the scalar reciprocal implementation.  Checking for compliance reliably requires executing a test program.  The scalar implementation sees a ~18.5% performance improvement with this change.  SCALAR   BEFORE     1/1 graphene / simd-speed OK             1.62s   AFTER     1/1 graphene / simd-speed OK             1.32s", "target": 1}
{"idx": 1523, "commit_message": "Revert \"Revert back to the default GPU when no renderers are using WebXR\"  This reverts commit 0fb7ef159eacf3356dc75a2aa8919a2c07ed7475.  Reason for revert: Speculative revert May have broken webgl_conformance_tests on chromeos-amd64-generic-rel: [URL]/p/chromium/builders/ci/chromeos-amd64-generic-rel/45665  Original change's description: > Revert back to the default GPU when no renderers are using WebXR >  > The GPU process may have been restarted and initialized on a different > GPU than the default if the VR headset is not plugged into the default > GPU. Staying on this XR compatible GPU can drain battery a lot quicker. > When there are no longer any renderers using WebXR, this change reverts > reverts the GPU process back to the default GPU. >  > Bug: 1090951 >", "target": 0}
{"idx": 1302, "commit_message": "Improve run to use all UAs regardless of onlineClients.  Fixes #31.", "target": 0}
{"idx": 2089, "commit_message": "Work on /wordlist/Jena200/  - Trying to improve performance of the code in views.py:822-829   I'm uncertain how to reduce the number of queries. - Relates to #84", "target": 1}
{"idx": 3191, "commit_message": "msm: vidc: add hevc hybrid driver support  Changes to support hybrid hevc decoder in v4l2 video driver. Dsp only hevc decoder does not have mips to handle high resolution (1080p) and software only solution has thermal/power impact. Hybrid hevc decoder will have lower power numbers and better performance for high resolution (1080p).", "target": 1}
{"idx": 3833, "commit_message": "Add prefetch option for queries, which defaults to false for inserts (#6077)  ## What is the goal of this PR?    On executing a Graql query, Grakn automatically streams the first batch of responses back to the client. This ensures they get their answers to a `match` query as fast as possible. But, for an `insert` query, they usually don't need those answers. And the CPU cost of compiling these unwanted response messages was inflicting a significant performance penalty. To remedy this, we made `prefetch` a configurable per-query option, which defaults to true, except for Insert queries where it defaults to false.    ## What are the changes implemented in this PR?    - Don't prefetch responses to Insert queries unless specified with a configurable flag in QueryOptions (fixes [URL]/graknlabs/grakn/issues/6072)", "target": 1}
{"idx": 2987, "commit_message": "GRAPHICS: Improved JPEG decoder performance  Replaced the 2D IDCT by two 1D IDCT (rows, then columns). JPEG images now decode about twice as fast as they used to.  svn-id: r55794", "target": 1}
{"idx": 3097, "commit_message": "Merge pull request #524 from rtibbles/asset_bundling  Asset bundling performance improvements", "target": 1}
{"idx": 2622, "commit_message": "Deprecate MemcacheEngine and update defaults for Memcached  People should switch to Memcached instead. The underlying extension is better maintained and provides improved features and performance.  Collapse the persistent and persistentId settings, while also making non-persistent connections the default. Persistent connections should be an opt-in feature as having them enabled by default could go very wrong on shared hosting environments.", "target": 1}
{"idx": 603, "commit_message": "- Add begin and end to vector class. So we can use std::find algorithm on it. - Add the test case to test it.", "target": 0}
{"idx": 108, "commit_message": "bnxt_en: Disable/enable Bus master during suspend/resume.  Disable Bus master during suspend to prevent DMAs after the device goes into D3hot state.  The new 57500 devices may continue to DMA from context memory after the system goes into D3hot state.  This may cause some PCIe errors on some system.  Re-enable it during resume.", "target": 0}
{"idx": 3823, "commit_message": "431673 - reworking rhnServerNeededView for performance fixes.  Simplify the rhnServerNeededView and make it a bit more performant.  Also resolve some really nasty TX handling code in UpdateErrataCacheCommand.java  that wasnt rolling back if there were errors.", "target": 1}
{"idx": 1001, "commit_message": "drm/i915: Suppress a WARN on reading an object back for a GPU hang", "target": 0}
{"idx": 2986, "commit_message": "Better performance through numpy and bigger read buffer", "target": 1}
{"idx": 3260, "commit_message": "Modified duplicate code for atomic vectors to (hopefully) make it a little more efficient.", "target": 1}
{"idx": 2412, "commit_message": "Merge pull request #51 from ferranpujolcamins/Improve-DFS-Performance  Improve dfs performance", "target": 1}
{"idx": 512, "commit_message": "Fix pruning colab after [URL]/tensorflow/model-optimization/commit/105ec70c0bc86be85b15a6a9a0d657e380dadb86.  Previously pruning summaries was using the TF 2.X logging even when the colab ran on TF 1.X. TF 2.X logging had the property that TensorBoard callbacks could be reused, but TF 1.X logging doesn't allow for that.  PiperOrigin-RevId: 289514104", "target": 0}
{"idx": 759, "commit_message": "[GPU] RT size function adjustments for Vulkan convenience", "target": 0}
{"idx": 2115, "commit_message": "add immutable js and rewrite appstate to be more efficient with localstorage", "target": 1}
{"idx": 2405, "commit_message": "Some refactoring improving performance, and better tests for multiple currencies", "target": 1}
{"idx": 1122, "commit_message": "Rewrite eachOf/allOf/anyOf to use a variadic operator.  Summary: Rewrite eachOf/allOf/anyOf to use a variadic operator, instead of hand-written calls to Polymorphic matchers. This simplifies their definition and future changes to add them to the dynamic registry.  Reviewers: klimek  CC: cfe-commits, revane  Differential Revision: [URL]/D1427", "target": 0}
{"idx": 3598, "commit_message": "Additional HTML hash filtering, more efficient HTML crawl filtering.", "target": 1}
{"idx": 344, "commit_message": "Updated to Parboiled v0.9.8.2, fixed nested rule sets with combinators, small optimizations via profiling", "target": 1}
{"idx": 1310, "commit_message": "Restore inband due to memory issues", "target": 0}
{"idx": 1301, "commit_message": "implement 'down' part of MARCO algorithm", "target": 0}
{"idx": 2193, "commit_message": "f2fs: improve write performance under frequent fsync calls  When considering a bunch of data writes with very frequent fsync calls, we are able to think the following performance regression.  N: Node IO, D: Data IO, IO scheduler: cfq  Issue    pending IOs \t D1 D2 D3 D4  D1         D2 D3 D4 N1  D2            D3 D4 N1 N2  N1            D3 D4 N2 D1  --> N1 can be selected by cfq becase of the same priority of N and D.      Then D3 and D4 would be delayed, resuling in performance degradation.  So, when processing the fsync call, it'd better give higher priority to data IOs than node IOs by assigning WRITE and WRITE_SYNC respectively. This patch improves the random wirte performance with frequent fsync calls by up to 10%.", "target": 1}
{"idx": 4020, "commit_message": "[PATCH] Used sparse identity for more efficient memory utilization", "target": 1}
{"idx": 3227, "commit_message": "Handle update of crossfades on explicit relayer more efficiently.", "target": 1}
{"idx": 3932, "commit_message": "more efficient scoring for many effect nodes", "target": 1}
{"idx": 2430, "commit_message": "Update submodule vim/bundle/syntastic 2519d83...165602e  * vim/bundle/syntastic 2519d83...165602e (105):   > LLVM: avoid leaving behind junk files.   > Merge pull request #635 from superjoe30/patch-1   > Fix (again) errorformat for checkbashisms.   > Added a FAQ entry about :bdelete.   > The QuitPre event was added in Vim 7.3.544.   > Fix for #624.   > Merge branch 'testing'   > Merge pull request #625 from kisielk/patch-1   > Adds an option \"syntastic_allow_quit\".   > Merge pull request #623 from abentancur/patch-1   > Bug fix in objc/gcc.   > Gets the D checker in synch with the C/C++ ones.   > Merge pull request #620 from lafka/erl-nested-dirs   > New C checker for Secure Programming Lint.   > clisp: some fixes   > ruby/rubocop: bugfix   > Merge pull request #622 from roktas/master   > Fix error highlighting in x?html/tidy.   > Merge pull request #618 from liamcurry/py3kwarn   > Rework of the html/w3 checker.   > Typo.   > Cleanup.   > Go vet errorformat fix.   > Merge pull request #616 from kisielk/master   > add :SyntasticInfo command to echo info about current checkers   > add basic deprecation warning system   > Merge remote-tracking branch 'origin/notifiers'   > add a simple debug message system   > Merge branch 'notifiers'   > bump to version 3.0.0   > help file: add a new tag easy reference from the changelog   > contributing doc: add section about issues/bug reports   > use $SHELL for scripts without shebang   > Typo.   > Rework of the python checker.   > Cleanup for tidy.   > New checker for CSS: PrettyCSS.   > Merge pull request #610 from amouravski/add_syntax_highlighting_to_contributing   > New checker for C++: Google cpplint.   > Skip unknown error messages.   > doc: add the wiki link to the checker guide   > update contributing file   > add the first stab at the contributing doc   > Error format fix for checkbashisms.   > Error format fix for pylint.   > Fix signs initialization.   > Fix shell pipe hack.   > Fixes handling of g:syntastic_quiet_warnings.   > HTML checker using http://validator.nu.   > vhdl/ghdl checker: use syntastic#makeprg#build   > Merge pull request #601 from Jaydyou/master   > Fixes handling of g:syntastic_quiet_warnings.   > Minor cleanup.   > Makes sparse aware of &tabstop.   > Merge pull request #596 from supki/syntax-checker-coqtop   > Merge pull request #595 from joshuarh/simplify-coffeescript-checker   > Skip running in special buffers.   > php/php: prevent xdebug.cli_color from messing with checks.   > extract the vim work around code out to be more explicit   > Merge remote-tracking branch 'lcd047/vcol'   > bugfix for sourcing the syntastic class files   > Merge pull request #587 from lcd047/coffee_bitrot   > Merge pull request #585 from lcd047/sparse_fix   > Merge pull request #583 from lcd047/checkbashisms   > sh/checkbashisms: remove unneeded l: variable prefixes   > Merge pull request #574 from aswna/master   > Merge pull request #582 from lcd047/jshint_args   > Merge pull request #579 from lcd047/typo   > Merge pull request #262 from powerman/E855-on-lclose   > Merge pull request #577 from likr/togglefix   > Merge pull request #553 from amouravski/master   > Merge pull request #571 from lcd047/cleanup_dupes   > Merge pull request #536 from trprice/master   > move the modemap code out into its own class   > move the sign options into the sign class file   > fix some guards   > add syntastic_always_populate_loc_list option   > extract the sign code out into its own class   > Merge pull request #569 from lcd047/css_phpcs   > Merge pull request #570 from brianpeiris/patch-1   > ruby/mri: add highlight regex function   > Merge pull request #568 from lcd047/phpmd_syntax   > Merge pull request #567 from Chewie/syntastic_c_compiler   > Revert \"python/flake8: add some backwards compat\"   > SyntasticChecker: extract out the highlight regex population code   > Cleanup: a simpler and more efficient approach.   > Merge pull request #559 from troydm/master   > jshint: add a comment version requirements   > Merge pull request #562 from joshuarh/jshint-warnings   > Merge pull request #563 from Lasall/vala-modules-copy   > Merge pull request #564 from hdoshi/master   > python/flake8: add some backwards compat   > Merge pull request #566 from Chronial/master   > fix sign highlight groups   > Merge pull request #546 from docwhat/ver-is-at-least   > Merge pull request #465 from chazlever/master   > Merge pull request #528 from jszakmeister/add-highlight-groups   > fix syntastic_auto_jump functionality   > Merge pull request #534 from xandox/master   > Merge pull request #538 from joshuarh/simplify-ruby-checker   > Merge pull request #540 from lcd047/chktex   > Fix syntax highlighting.   > Merge pull request #547 from docwhat/puppet-lint   > Merge pull request #537 from brendanjerwin/fix_coffeelint_options   > Merge pull request #532 from dbarnett/per_buffer", "target": 0}
{"idx": 1305, "commit_message": "libs/core: mark radvd as affected by network restarts", "target": 0}
{"idx": 1223, "commit_message": "SOLR-354: optimize delete by query of all docs... changes were accidentally committed previously in r576683", "target": 1}
{"idx": 2316, "commit_message": "Some performance improvements, increased plotting reliability, minor bug improvements", "target": 1}
{"idx": 3127, "commit_message": "Improve price performance for 1000+ asset universes. (#2108)  PERF: Optimize price for liquid assets.    When using `price`, the call to `last_traded_dt` for every value retrieved  became a noticeable bottleneck in algorithms which used over 1000 assets.    Instead of calling `last_traded_dt` before every retrieval of a `close` for the  `price` field, assume that `close` will retrieve a non-empty value, and then  forward fill if it is empty.    This change optimizes for the case of a tradeable universe which is predominately  composed of liquid assets.", "target": 1}
{"idx": 3155, "commit_message": "Another huge update. Someday I will stop doing this.  The structure of the project have changed. Before, storage was unused, but now after parsing data, all data must be commited in to the storage.  Also, list model has moved to CPP code (it shows better performance and it allow to avoid mistakes with scripts)  New approach to request additional data - instead of one hude custom handler now it accumulate all simillar handlers in one and then request  This version may be called 0.3 Alpha", "target": 1}
{"idx": 1144, "commit_message": "Minor layout fixes and improvements in folder search criteria selection window.", "target": 0}
{"idx": 2798, "commit_message": "- the MODIFIERS_ESCAPE_REGEX wasn't defined; - added isInt() func; - object reverse resolution bug when key is integer; - improved error message for object reverse resolution; - introduced the resolveJSIdentifierValue() instead of evalNative() function. This function fixes resious security bug in nexl-engine. nexl sources were evaluated in js function's scope. This was given an access to nodejs global libraries. Now the scope is isolated. Now it's not a mandatory to use a VAR statement for javascript variables. They are not global anymore; - improved hasFirstLevelVars() function ( performance ) and fixed bug when the external args are not strings; - improved the extractFirstLevelVars() function; - added evalNexlExpression() function for context to evaluate nexl expressions inside nexl sources;", "target": 1}
{"idx": 1220, "commit_message": "- Fix handle close bug. The ExDestroyHandleEntry API was only killing entries unless the table wasn't being destoyed, which it actually is during process termination, and through failing, was actually not closing the handle at all. This means any killed process leaked all its handles and they were never closed. These handles are now closed, reducing memory load/leaks and opening the door for new bugs :) - Fix LPC process closing bug. - Rewrite executive timer support to make it thread-safe and use proper locking order and semantics as well as safe referencing. Also implement Windows 2003 feature of flushing DPCs when a timer is deleted, to avoid the timer from being fired after deletion.", "target": 1}
{"idx": 2264, "commit_message": "Merge remote-tracking branch 'upstream/master'  pulling latest performance improvements", "target": 1}
{"idx": 2738, "commit_message": "Improve default case performance for CollectionView. Closes gh-447.  Do not execute `$list.children` every time.", "target": 1}
{"idx": 2151, "commit_message": "change display none to opacity for better performance, render list based on search props", "target": 1}
{"idx": 1000, "commit_message": "nbd: use our own workqueue for recv threads  Since we are in the memory reclaim path we need our recv work to be on a workqueue that has WQ_MEM_RECLAIM set so we can avoid deadlocks.  Also set WQ_HIGHPRI since we are in the completion path for IO.", "target": 0}
{"idx": 802, "commit_message": "ext4: reimplement uninit extent optimization for move_extent_per_page()  Uninitialized extent may became initialized(parallel writeback task) at any moment after we drop i_data_sem, so we have to recheck extent's state after we hold page's lock and i_data_sem.  If we about to change page's mapping we must hold page's lock in order to serialize other users.", "target": 0}
{"idx": 1963, "commit_message": "added a simple pypy docker container, not impressed with performance", "target": 0}
{"idx": 3490, "commit_message": "Replace _group_matching with an inward-out grouping algorithm  All the matching between open/close was done all the time, first finding the matching closing token, and then grouping the tokens in between, and recurse over the newly created list.  Instead, it is more efficient to look for the previous open-token on finding a closing-token, group these two together, and then continue on.  squashed: Handle token indices in group_tokens_between and find_matching.", "target": 1}
{"idx": 1394, "commit_message": "ARM: 7492/1: add strstr declaration for decompressors  With the generic unaligned.h, more kernel headers get pulled in including dynamic_debug.h which needs strstr. As it is not really used, we only need a declaration here.", "target": 0}
{"idx": 2103, "commit_message": "- more OPENMP parallelization - two nested loops substitute by a lookup table for better performance thanks to Harald Klimach", "target": 1}
{"idx": 3352, "commit_message": "Reviewed by Sam Weinig.                  Fixed [URL]/show_bug.cgi?id=15958         base64 spends 1.1% of total time checking for special Infinity case                  Use a fast character test instead of calling strncmp.                  1.1% speedup on string-base64. SunSpider reports a .4% speedup overall;         Sharks reports only .1%. Who are you going to believe? Huh?          * kjs/ustring.cpp:         (KJS::UString::toDouble):", "target": 1}
{"idx": 530, "commit_message": "USB: gadget: ether: Clean up req->buf to avoid wild pointer  When OOM, the req->buf will fail to get memory from kmalloc. And all the req->buf in dev->tx_reqs will be freed in the error handler. But they are not cleared to NULL. So they are not allocated while below function got called again.  int alloc_tx_buffer(struct eth_dev *dev) {    list_for_each(act, &dev->tx_reqs) {        if ((!req->buf)         ->3. it can't allocate again.           req->buf = kmalloc();->1. it fails to get memory as OOM.        if (!req->buf)           goto free_buf;         ...    }    return 0; free_buf:    ...    kfree(req->buf);             ->2. It's freed.    return -ENOMEM; } So these pointers will be freed multi times. What's worse, once they are used as normally, system maybe be panic due to wild pointer. CRs-fixed: 571628", "target": 0}
{"idx": 889, "commit_message": "2011-10-18\tJennifer Averett [URL]>  \tPR 1917/bsps \t* shared/console/conscfg.c: Modifications to add dynamic tables for \tlibchip serial drivers.", "target": 0}
{"idx": 2732, "commit_message": "use sorted map when decoding tags (#1436)  This is typically more efficient overall as it avoids  the need to sort multiple times later on. For example,  in publish the sort is needed for computing the ids  and then ends up getting performed again to encode  as a compact batch.", "target": 1}
{"idx": 3331, "commit_message": "actually fix performance problem in Entity, add getFirstComponent method", "target": 1}
{"idx": 2959, "commit_message": "Patch for HARMONY-5026 \"[classlib][awt] Performance improvement for Big  Image drawing\"  svn path=/harmony/; revision=589194", "target": 1}
{"idx": 2671, "commit_message": "IB/qib: Convert qib_user_sdma_pin_pages() to use get_user_pages_fast()  qib_user_sdma_queue_pkts() gets called with mmap_sem held for writing. Except for get_user_pages() deep down in qib_user_sdma_pin_pages() we don't seem to need mmap_sem at all.  Even more interestingly the function qib_user_sdma_queue_pkts() (and also qib_user_sdma_coalesce() called somewhat later) call copy_from_user() which can hit a page fault and we deadlock on trying to get mmap_sem when handling that fault.  So just make qib_user_sdma_pin_pages() use get_user_pages_fast() and leave mmap_sem locking for mm.  This deadlock has actually been observed in the wild when the node is under memory pressure.  Cc: [URL]>", "target": 1}
{"idx": 3832, "commit_message": "Map decoration drawing speedup and cleanup.  - Removed drawing code from client/goto.[ch]. - Removed expensive redraws caused by calls to   update_map_canvas_visible() in popit and   selection rectangle code. - Replaced map-sized arrays by hash tables. - Added 'mapdeco' API for marking tile highlights,   tile crosshairs, and goto line segments.  See #40717  [[originally from svn r15509]]", "target": 1}
{"idx": 2988, "commit_message": "Improves performance of geometry importer  Importer no longer tries to standardise geometries for PAs that don't need to be changed", "target": 1}
{"idx": 1425, "commit_message": "Add wk headers + other improvements", "target": 0}
{"idx": 232, "commit_message": "some more stylesheet optimization thanks to new bootstrap imports", "target": 1}
{"idx": 828, "commit_message": "bacula-web: Improved and fixed small bugs in php code", "target": 0}
{"idx": 640, "commit_message": "* Scheduled Category Updater, move the CategoryUpdater from LogPublisher * to Build Service, it was manually run, now run it every 30 minutes.", "target": 0}
{"idx": 1936, "commit_message": "Apply the 'classycle' plugin consistently to all projects (#12849)  Existing cycles are now explicitly excluded in the corresponding  build scripts and are thus more visible. They may or may not be  improved on when working on the corresponding project.", "target": 0}
{"idx": 941, "commit_message": "Changed client connectors to use a shared EventLoopGroup to minimize memory footprint of the Agent if many Workers are created. The number of threads can be configured via simulator.properties (default is 0, which uses the default thread number of Netty, which is number of cpu cores * 2).", "target": 1}
{"idx": 317, "commit_message": "First working version. Memory leak exists somewhere though", "target": 0}
{"idx": 3096, "commit_message": "Merge pull request #3070 from NoelDeMartin/MOBILE-3971  MOBILE-3971: Improve config db performance", "target": 1}
{"idx": 4103, "commit_message": "[PATCH] Optimize the performance of rot by using universal intrinsics", "target": 1}
{"idx": 2123, "commit_message": "UI - Many misc fixes I can't remember  Profile editor - Removed layer outline, increasing performance by a lot Device visualizer - Streamlined custom Device providers - Added debug device provider ASUS - Added Maximus X Hero thanks @copystring Plugin core - Added PerLedLayerBrush Noise layer - Converted to PerLedLayerBrush, increasing performance and quality", "target": 1}
{"idx": 241, "commit_message": "Merge pull request #11184 from pveentjer/v3.9/fix/HttpCommunicator-further-ssl-testing-improvements  Further HttpCommunicator testing improvements", "target": 0}
{"idx": 2784, "commit_message": "dirstate: improve performance for building _dirs", "target": 1}
{"idx": 3137, "commit_message": "mm: Add UKSM support  This is an improvement upon KSM. Some basic data structures and routines are borrowed from ksm.c .  Its new features: 1. Full system scan:      It automatically scans all user processes' anonymous VMAs. Kernel-user      interaction to submit a memory area to KSM is no longer needed.  2. Rich area detection:      It automatically detects rich areas containing abundant duplicated      pages based. Rich areas are given a full scan speed. Poor areas are      sampled at a reasonable speed with very low CPU consumption.  3. Ultra Per-page scan speed improvement:      A new hash algorithm is proposed. As a result, on a machine with      Core(TM)2 Quad Q9300 CPU in 32-bit mode and 800MHZ DDR2 main memory, it      can scan memory areas that does not contain duplicated pages at speed of      627MB/sec ~ 2445MB/sec and can merge duplicated areas at speed of      477MB/sec ~ 923MB/sec.  4. Thrashing area avoidance:      Thrashing area(an VMA that has frequent Ksm page break-out) can be      filtered out. My benchmark shows it's more efficient than KSM's per-page      hash value based volatile page detection.  5. Misc changes upon KSM:      * It has a fully x86-opitmized memcmp dedicated for 4-byte-aligned page        comparison. It's much faster than default C version on x86.      * rmap_item now has an struct *page member to loosely cache a        address-->page mapping, which reduces too much time-costly        follow_page().      * The VMA creation/exit procedures are hooked to let the Ultra KSM know.      * try_to_merge_two_pages() now can revert a pte if it fails. No break_        ksm is needed for this case.  6. Full Zero Page consideration(contributed by Figo Zhang)    Now uksmd consider full zero pages as special pages and merge them to an    special unswappable uksm zero page.  ChangeLog:  2012-05-05 The creation of this Doc 2012-05-08 UKSM 0.1.1.1 libc crash bug fix, api clean up, doc clean up. 2012-05-28 UKSM 0.1.1.2 bug fix release 2012-06-26 UKSM 0.1.2-beta1 first beta release for 0.1.2 2012-07-2  UKSM 0.1.2-beta2 2012-07-10 UKSM 0.1.2-beta3 2012-07-26 UKSM 0.1.2 Fine grained speed control, more scan optimization. 2012-10-13 UKSM 0.1.2.1 Bug fixes. 2012-12-31 UKSM 0.1.2.2 Minor bug fixes 2014-07-02 UKSM 0.1.2.3 Fix a \" __this_cpu_read() in preemptible bug", "target": 1}
{"idx": 4083, "commit_message": "[PATCH] improved performance of free energy runs in water\n significantly by allowing water-water loops and added a slight speed up for\n neighborsearching for free-energy runs", "target": 1}
{"idx": 3220, "commit_message": "Update Buck to latest version  This version fixed a major issue: [1] that was a reason of frustration of many plugin developers: Not cache sources files under symbolic link. Now for all such source files, the warning is issued:  \" Disabling caching for target //plugins/wip:wip__plugin, because one or more input files are under a symbolic link ({plugins/wip=/home/davido/projects/wip}). This will severely impact performance! To resolve this, use separate rules and declare dependencies instead of using symbolic links. \"  To suppress this warning we add project.allow_symlink option. This doesn't have any impact for gerrit core but silences the warning above when plugins are built in gerrit tree mode.  As pointed out in this issue: [2], we are using some artifacts as source to the java_library() rule as well as binary_jar for prebuilt_ja rule. To avoid the warning, we rename sources to have \"-sources.jar\" suffix and we rename *.zip to end with .jar in other places.  \" Assuming edit.src.zip is a JAR and renaming to edit.src.jar in //gerrit-patch-jgit:edit_src. Change the extension of the binary_jar to '.jar' to remove this warning. \"  source_under_test attribute was removed from java_test() rule. Replication and cookbook-plugin are updated as well.  local.properties support was removed, but we use it only for download process customization in our own python script, so that we can keep it usage and not need to move it to .buckconfig.local.  [1] [URL]/facebook/buck/issues/341 [2] [URL]/facebook/buck/issues/855", "target": 0}
{"idx": 3568, "commit_message": "SCSI: sd: Fix parsing of 'temporary ' cache mode prefix  Commit 39c60a0948cc '[SCSI] sd: fix array cache flushing bug causing performance problems' added temp as a pointer to \"temporary \" and used sizeof(temp) - 1 as its length.  But sizeof(temp) is the size of the pointer, not the size of the string constant.  Change temp to a static array so that sizeof() does what was intended.", "target": 1}
{"idx": 2259, "commit_message": "use cap to start the delayed_job worker  this replaces the approach of dynamically starting a worker when it is needed and then killing it off later. Currently our servers can handle an extra processing sticking around, and leaving it running like this is more efficient and hopefully less error prone.", "target": 1}
{"idx": 2873, "commit_message": "Merge pull request #99 from Daniel-at-github/patch-scipy-2016  scipy 2016, merge and improve :+1:", "target": 0}
{"idx": 2018, "commit_message": "block_write_full_page: switch synchronous writes to use WRITE_SYNC_PLUG  Now that we have a distinction between WRITE_SYNC and WRITE_SYNC_PLUG, use WRITE_SYNC_PLUG in __block_write_full_page() to avoid unplugging the block device I/O queue between each page that gets flushed out.  Otherwise, when we run sync() or fsync() and we need to write out a large number of pages, the block device queue will get unplugged between for every page that is flushed out, which will be a pretty serious performance regression caused by commit a64c8610.", "target": 1}
{"idx": 73, "commit_message": "Add handling of scale restrictions for TF ops  This change generalized current design in QuantizationDriver to not only look for FixedOutputRangeInterface and SameScalesOpInterface, but also adds an option to denote scale requirements dynamically. This enables the other dialects to flexibly add the scale requirements without changing the dialect definition  itself.  PiperOrigin-RevId: 435264865", "target": 0}
{"idx": 1917, "commit_message": "msm: vidc: free the recon buffers in cleanup function  - The recon buffers were not released when video recording   was killed abruptly leading to memory leak.  - Fix provided to release the recon buffers when media   server killed abruptly.", "target": 0}
{"idx": 3534, "commit_message": "Wrapped tight loop in a transaction to dramatically improve performance", "target": 1}
{"idx": 2764, "commit_message": "WLAN subsystem: Sysctl support for key TCP/IP parameters  It has been observed that default values for some of key tcp/ip parameters are affecting the tput/performance of the system. Hence extending configuration capabilities to TCP/Ip stack through sysctl interface  CRs-Fixed: 507581", "target": 1}
{"idx": 364, "commit_message": "improved connection reseting for django 1.4", "target": 0}
{"idx": 2694, "commit_message": "improve statics performance  this.statics is accessed too often to constantly loop and reduce", "target": 1}
{"idx": 643, "commit_message": "lib-storage: Improved seteuid() error messages a bit.", "target": 0}
{"idx": 3850, "commit_message": "hopefully fixed regression in (so far just ubuntu 1804 regtests) - not printing any performance test results", "target": 0}
{"idx": 3370, "commit_message": "chore: release v2.6.4  * (Apollon77) Optimize performance, especially when using names instead of object ids", "target": 1}
{"idx": 534, "commit_message": "Yield the background thread when not necessary (#465)  Summary: These changes are the proposed fix for [URL]/facebook/mysql-5.6/issues/465. The intent of the background thread is to wake up once per second and call SyncWAL() if all the preconditions are met.  Previous implementation ended up constantly looping because of a logic error. This solution removes the unnecessary checks and uses a call to `mysql_cond_timedwait()` (ends up being `pthread_cond_timedwait()`) to make sure that thread yields its quantum and OS scheduler can do its thing while we're waiting for the timer to expire.  We still loop, but for the majority of the time we end up sleeping and not using the CPU.  Basic testing:    - Verify that function body is called once per second. If we need then     we can tune it to be more precise and use what approximate amount of     ms-s or ns-s we desire.   - Before the fix the code path was executed hundreds of time per     second and 25-49% of CPU was utilized. After the fix `htop` show     marginal (0.0%) utilization.   - `perf Closes [URL]/facebook/mysql-5.6/pull/467 Github Author: Gunnar Kudrjavets [URL]>  Github PR Sync: {sync, type=\"child\", parent=\"github\", parentrepo=\"facebook/mysql-5.6\", parentprnum=\"467\", parentprfbid=\"1293483337385904\"}  Test Plan: Imported from GitHub, without a `Test Plan:` line.  Reviewers: mcallaghan, herman, mung, svcscm  Reviewed By: svcscm  Subscribers: svcscm, webscalesql-eng@  Differential Revision: [URL]/D4294886  Signature: t1:4294886:1481154750:d52dbb1db1f245bddddc26cf4ff8bc3f480d0c07", "target": 1}
{"idx": 1657, "commit_message": "Force clear the vectors holding split surfaces.  Note that this is _very_ important for good memory usage.  Failing to do so will result in terrible memory fragmentation, with a degradation in total memory use which is much worse than the reasonably small amount of memory used for the storage.", "target": 1}
{"idx": 565, "commit_message": "Add docker-compose, redis  ----------------------------  Add a docker-compose.yml config file that will spin up two containers on invocation of `docker-compose up`, one running the OTA bot and another running an instance of redis connected to the OTA bot via a local network link.  From the OTA bot, a connection to the redis instance is possible using the hostname of the redis container.  -----------------------------  The redis container uses a custom config that is copied in from `config/redis.conf`. A template was added to the config directory for this file that was modified from the official redis.conf for Redis 6.0 in the following way:  $ diff redis.conf redis.conf.template -y --suppress-common-lines   tcp-backlog 511                                                   | tcp-backlog 127   logfile \"\"                                                        | # logfile \"\"   # syslog-enabled no                                               | syslog-enabled yes   # syslog-ident redis                                              | syslog-ident redis   # syslog-facility local0                                          | syslog-facility local0   stop-writes-on-bgsave-error yes                                   | stop-writes-on-bgsave-error no  -----------------------------  To access the redis while it is running inside the container, modify your `docker-compose.yml` like so:  $ git diff docker-compose.yml   diff --git a/docker-compose.yml b/docker-compose.yml   index 78a6dd0..562b7a9 100644   --- a/docker-compose.yml   +++ b/docker-compose.yml   @@ -7,5 +7,7 @@ services:      redis:        image: \"redis:latest\"        command: redis-server /usr/local/etc/redis/redis.conf   +    ports:   +      - \"6380:6379\"        volumes:          - ./config/redis.conf:/usr/local/etc/redis/redis.conf  ------------------------------  You can run the following command from your local machine to test connectivity to the redis instance:  $ redis-cli -p 6380   127.0.0.1:6380> keys \"*\"   (empty list or set)   127.0.0.1:6380>", "target": 0}
{"idx": 345, "commit_message": "Made some very subtle performance enhancements. Basically switched to using numpy random numbers instead of Python's random module. Surrounded Signal rendering by display lock() and unlock() to reduce overhead from constant locking and unlocking.", "target": 1}
{"idx": 1837, "commit_message": "Revert \"Added a discrete touchscreen driver for LG's P500. Touchscreen driver is based on MCS6000_gb version but improved for speed\"  This reverts commit c1b5b5e8c4cb0828423d114d4aabe1efc116fdcb.", "target": 0}
{"idx": 2661, "commit_message": "* UnicodeUtils.java (foldCase); Re-write to be more efficient,         and fix some corner-case errors.         Also change return type to CharSequence.          * rnrs/unicode.scm (string-foldcase): Update because         nicodeUtils:foldCase changed return type to CharSequence.          * r7rs-tests.scm: Merge some updates from upstream.", "target": 1}
{"idx": 2399, "commit_message": "improves SM cascade performances and fixes announcement text (#67240)  Changes the cascade walls from turfs to objects to improve the performances of the roundending cascade.  The issue was that ChangeTurf() was a pretty expensive proc to be called that many times so i moved the cascade wall into an object. It doesn't delete anything other than living mobs and the portal to prevent edge case runtimes.  Plus remove a span_bold() from the announcement text since it wasn't making the text bold but was leaving behind", "target": 1}
{"idx": 3562, "commit_message": "[vstool] improve NavigateTo performance by adding cache.", "target": 1}
{"idx": 475, "commit_message": "Merge branch 'upstream/xen' of [URL]/pub/scm/linux/kernel/git/jeremy/xen  * 'upstream/xen' of [URL]/pub/scm/linux/kernel/git/jeremy/xen: (23 commits)   xen/panic: use xen_reboot and fix smp_send_stop   Xen: register panic notifier to take crashes of xen guests on panic   xen: support large numbers of CPUs with vcpu info placement   xen: drop xen_sched_clock in favour of using plain wallclock time   pvops: do not notify callers from register_xenstore_notifier   Introduce CONFIG_XEN_PVHVM compile option   blkfront: do not create a PV cdrom device if xen_hvm_guest   support multiple .discard.* sections to avoid section type conflicts   xen/pvhvm: fix build problem when !CONFIG_XEN   xenfs: enable for HVM domains too   x86: Call HVMOP_pagetable_dying on exit_mmap.   x86: Unplug emulated disks and nics.   x86: Use xen_vcpuop_clockevent, xen_clocksource and xen wallclock.   implement O_NONBLOCK for /proc/xen/xenbus   xen: Fix find_unbound_irq in presence of ioapic irqs.   xen: Add suspend/resume support for PV on HVM guests.   xen: Xen PCI platform device driver.   x86/xen: event channels delivery on HVM.   x86: early PV on HVM features initialization.   xen: Add support for HVM hypercalls.   ...", "target": 0}
{"idx": 821, "commit_message": "Improved VMTK modules GUI to make them less error-prone to use", "target": 0}
{"idx": 1460, "commit_message": "Merge \"power: qpnp-smbcharger: improve handling USB insertion/removal", "target": 0}
{"idx": 745, "commit_message": "Merge pull request #1840 from poanetwork/total_supply_bug  Handle case when total supply is nil", "target": 0}
{"idx": 3296, "commit_message": "Updated expectations.  for V8 regression, adjusted rev's.  xp-release-dual-core/moz: [URL]/f/chromium/perf/xp-release-dual-core/moz/report.html?history=150&rev=-1&graph=vm_peak_r  Adjusted expectations for performance improvements from skia roll.  xp-release-dual-core/moz: [URL]/f/chromium/perf/xp-release-dual-core/moz/report.html?history=150&rev=109265&graph=total_byte_r  xp-release-dual-core/moz: [URL]/f/chromium/perf/xp-release-dual-core/moz/report.html?history=150&rev=109265&graph=total_op_r   BUG=103586,103454 TBR=cmp Review URL: [URL]/8507014", "target": 1}
{"idx": 844, "commit_message": "Merge pull request #392 from algolia/frontend_templates  Template improvements", "target": 0}
{"idx": 4038, "commit_message": "[PATCH] make skylakex sgemm code more friendly for readers\n\nBTW some kernels were adjusted to improve performance", "target": 1}
{"idx": 1793, "commit_message": "Improved animations and \"Add Book\"/\"Remove Book\". Added AnimateSelector(string selectorString, string animationString) to perform animate.css animations.", "target": 0}
{"idx": 294, "commit_message": "arm: irq: warn only when affinity really breaks  Following change causes unnecessary warnings printed for those IRQ's which are affine to several CPU's when one of these CPU's is taken off line. It shouldn't be considered a broken affinity when one online CPU can satisfy the IRQ's affinity preference.  commit 5bfaecc21018973f73bc4dc839699848b448c0e7 Author: Praveen Chidambaram [URL]> Date:   Mon Jun 23 08:58:08 2014 -0600  arm: irq: Notify affinity change when migrating IRQs during hotplug  Hotplug causes IRQs affine to a core that is being taken down to migrate to an online core. This is done by directly calling the irq_set_affinity associated with the irq_chip structure. Instead using the irq_set_affinity() api lets the notifications bubble through.", "target": 0}
{"idx": 2587, "commit_message": "Merge pull request #23 from cticenhour/perf-log-fix  Performance log deprecated parameter fix", "target": 0}
{"idx": 720, "commit_message": "MdeModulePkg: Add MorLockSmm to variable driver.  Microsoft published secure MOR implementation at [URL]/en-us/library/windows/hardware/mt270973(v=vs.85).aspx with revision 2 update. See URL for tech detail. Previous revision 1 is handled in SecurityPkgTcg MemoryOverwriteRequestControlLock. But the VarCheck API can not satisfy revision 2 requirement. So we decide include MOR lock control into variable driver directly.  This patch add standalone TcgMorLockSmm implementation.  Contributed-under: TianoCore Contribution Agreement 1.0", "target": 0}
{"idx": 2295, "commit_message": "Minor code code to improve performance", "target": 1}
{"idx": 3966, "commit_message": "Improve commit() performance and actionize it so it can be processed in a batch", "target": 1}
{"idx": 2871, "commit_message": "performance improvements:  check for empty instance before going into writeLock  configure timeout on waiting for construction thread", "target": 1}
{"idx": 1365, "commit_message": "cartesian path code clean up, small improvements", "target": 0}
{"idx": 1706, "commit_message": "[Common] [Http] Performance enhancements.  Adding a match flag to Collection operations instead of determining how a key should match.", "target": 1}
{"idx": 3445, "commit_message": "Performance Fixes  More query performance fixes for txid", "target": 1}
{"idx": 2323, "commit_message": "Filter Unneeded SnapshotInfo Instances Early in TransportGetSnapshotsAction (#78032)  Better to filter as early as possible to release the memory asap and not even fetch things we don't need to fetch to begin with.  There's still a bunch of spots remaining where similar optimizations can be added quickly before we implement the system index for the remaining searching/fetching that we can't easily exclude up-front.  This already gives vastly improved performance for many requests though for obvious reasons.", "target": 1}
{"idx": 1704, "commit_message": "more changes in the new segmentation algorithm which is not finished", "target": 0}
{"idx": 3513, "commit_message": "Change the implementation of CommaTracker to CommaMonoid  This appears to be faster, on par with Aeson, and avoids the need for implementations of methods such as    toJson :: Value a => [a] -> Json  to break the json-builder abstraction for performance reasons. So far, my attempts to improve this method by breaking abstractions has resulted in worse performance", "target": 1}
{"idx": 1389, "commit_message": "AsyncFst refactor + some minor updates elsewhere  - bumped android gradle plugin version to 3.1.3 - added fist-kt-android maven repository - AsyncFst: rewrote (again) to make timeouts work as expected - Deferred: DCL optimization to #call() - Effects: docs - ActionDsl: renamed #call to #forward; moved #defer parameter to receiver   position", "target": 0}
{"idx": 83, "commit_message": "* Dynamically generate local.properties files for android applications in order to set local SDK path", "target": 0}
{"idx": 2637, "commit_message": "can: flexcan: implement error passive state quirk  Add FLEXCAN_QUIRK_BROKEN_PERR_STATE for better description of the missing error passive interrupt quirk.  Error interrupt flooding may happen if the broken error state quirk fix is enabled. For example, in case there is singled out node on the bus and the node sends a frame, then error interrupt flooding happens and will not stop because the node cannot go to bus off. The flooding will stop after another node connected to the bus again.  If high bitrate configured on the low end system, then the flooding may causes performance issue, hence, this patch mitigates this by: 1. disable error interrupt upon error passive state transition 2. re-enable error interrupt upon error warning state transition 3. disable/enable error interrupt upon error active state transition    depends on FLEXCAN_QUIRK_BROKEN_WERR_STATE  In this way, the driver is still able to report correct state transitions without additional latency. When there are bus problems, flooding of error interrupts is limited to the number of frames required to change state from error warning to error passive if the core has [TR]WRN_INT connected (FLEXCAN_QUIRK_BROKEN_WERR_STATE is not enabled), otherwise, the flooding is limited to the number of frames required to change state from error active to error passive.", "target": 1}
{"idx": 814, "commit_message": "Minor improvements on export controller after addressing review comments: * The randomly generated token for the default export secret is now created using the more secure package crypto/rand * The default secret name is now stored in the VirtualMachineExport status", "target": 0}
{"idx": 2056, "commit_message": "Optimized DOM methods to improve performance of document updates (appending a node can be up to 20 times faster now, inserting a node maybe 2 times)  svn path=/trunk/eXist/; revision=5346", "target": 1}
{"idx": 3705, "commit_message": "Improve ReplyEditor performance by moving form data from redux into state.", "target": 1}
{"idx": 3026, "commit_message": "Add AZ64 encoding  AZ64 encoding was added to redshift on 10/8/19 and is now the default encoding for many datatypes.  let's support it.  [URL]/about-aws/whats-new/2019/10/amazon-redshift-introduces-az64-a-new-compression-encoding-for-optimized-storage-and-high-query-performance/", "target": 0}
{"idx": 2682, "commit_message": "make my sparse pca orthogonalize more efficiently/smartly", "target": 1}
{"idx": 1431, "commit_message": "dedupe: don't add extent items unless we use them  Only used for collision_check and debug output, so save memory if those aren't enabled.", "target": 1}
{"idx": 2543, "commit_message": "rbac job & job template performance fix", "target": 1}
{"idx": 1366, "commit_message": "netns: let net_generic take pointer-to-const args  This commit is same in nature as v2.6.37-rc1-755-g3654654; the network namespace itself is not modified when calling net_generic, so the parameter can be const.", "target": 0}
{"idx": 3827, "commit_message": "Improve performance of test if there are already many tickets in the system.", "target": 1}
{"idx": 2525, "commit_message": "use more efficient (?) implementation of is_power_of_two for Integers", "target": 1}
{"idx": 2506, "commit_message": "Refactored xsd package: The schema object simplified to hold all children in (rawchildren); removed all flattening, since the tree is no longer re-arraned, all node copying has been removed :-). this will greatly improve performance in schemas with lots of references.  flattening replaced by on-demaind approach using an iterator to provide a flattened view; redesigned dereferencing of @ref/@base using dependency sorted list.  This ensures that all elements in the schema are dereferenced and in the correct order.", "target": 1}
{"idx": 4136, "commit_message": "[PATCH] Optimize the performance of daxpy by using universal\n intrinsics", "target": 1}
{"idx": 2385, "commit_message": "Update cordova-android to pick up i18n performance improvement via `handleOpenForRead` API", "target": 1}
{"idx": 2842, "commit_message": "mmc: raw command logging  Propagated from (CR)  This commit implements raw command logging for the MMC driver framework. Unlike existing solutions, this facility is built with speed and efficiency in mind.  It has a negligible performance impact during driver operation and the amount of detail collected is run-time configurable. This allows for data collection that can span long periods of time. It is intended to log commands as they are programmed into the controller hardware.  This effectively unrolls some of the compound commands that are obfuscated from the higher-layer MMC_DEBUG logging.  Raw MMC commands and arguments are logged to a ring buffer.  Optionally, command R1 responses and time stamps can also be stored.  These options, the total log size, and log retrieval are all accessed via the MMC driver's debugfs directory (/sys/kernel/debug/mmcN):    cmd_log_mode - enable logging, control verbosity, dump to printk   cmd_log_size - number of records to allocate ring buffer memory for   cmd_log - read the log contents  The mode or size can be changed at any time.", "target": 1}
{"idx": 4039, "commit_message": "[PATCH] Minor performance improments\n\nMostly useful as lesson learned.\n\n1) The double precision constant forces the compiler to convert\n   the single precision variable to double, then do the multiplication\n   in double and then convert back. Using the single precsion\n   constant in double reduces the accuracy (the calculation is still done\n   double but the constant has only single precision).\n2) Using a temporary array instead of a temporary scalar causes ICC14 to\n   generate an extra store.\n\nChange-Id: Ib320ac2ae4ff80ce48277544abff468c483cc83a", "target": 1}
{"idx": 3963, "commit_message": "Performance improvement: Update textures of city labels, rather than creating a new texture and mesh for every city label update.", "target": 1}
{"idx": 3192, "commit_message": "Improved performances of presence server list notify", "target": 1}
{"idx": 3401, "commit_message": "lowmemorykiller: adapt to vmpressure  There were issues reported, where page cache thrashing was observed because of LMK not killing tasks when required, resulting in sluggishness and higher app launch latency. LMK does not kill a task for the following reasons. 1. The free and file pages are above the LMK thresholds 2. LMK tries to pick task with an adj level corresponding to current thresholds, but fails to do so because of the absence of tasks in that level. But sometimes it is better to kill a lower adj task, than thrashing. And there are cases where the number of file pages are huge, though we dont thrash, the reclaim process becomes time consuming, since LMK triggers will be delayed because of higher number of file pages. Even in such cases, when reclaim path finds it difficult to reclaim pages, it is better to trigger lmk to free up some memory faster.  The basic idea here is to make LMK more aggressive dynamically when such a thrashing scenario is detected.  To detect thrashing, this patch uses vmpressure events. The values of vmpressure upon which an action has to be taken, was derived empirically.  This patch also adds tracepoints to validate this feature, almk_shrink and almk_vmpressure.  Two knobs are available for the user to tune adaptive lmk behaviour.  /sys/module/lowmemorykiller/parameters/adaptive_lmk - Write 1 to enable the feature, 0 to disable. By default disabled.  /sys/module/lowmemorykiller/parameters/vmpressure_file_min - This parameter controls the behaviour of LMK when vmpressure is in the range of 90-94. Adaptive lmk triggers based on number file pages wrt vmpressure_file_min, when vmpressure is in the range of 90-94. Usually this is a pseudo minfree value, higher than the highest configured value in minfree array.", "target": 1}
{"idx": 4081, "commit_message": "[PATCH] Fix IR issue causing very slow to no convergence when using\n an inaccurate inner solver", "target": 1}
{"idx": 312, "commit_message": "lib/algo/src/siqs.c:      [updated]     - Added manual loop unrollings. It is slightly faster although nothing       groundbreaking (new benchmarks needed for better assessment of       improvement).  lib/algo/include/macro.h: [updated]     - Added (currently unused) loop unrolling macro DUFF_DEVICE.", "target": 1}
{"idx": 1422, "commit_message": "add memoryUsage function  It gives the memory usage (in kB) of a process, given its PID", "target": 0}
{"idx": 2603, "commit_message": "Wi-Fi Plugin: various fixes/improvements  Fix giveaways becoming frozen/endless from hotpatching, fix possible crash in lottery giveaways, simplify lottery drawings, and improve wording in multiple statements", "target": 0}
{"idx": 2200, "commit_message": "Merge pull request #113 from stof/patch-2  Improve the travis setup", "target": 0}
{"idx": 624, "commit_message": "Activate smpppd+kinternet for user controlled interfaces (#44303).  svn path=/trunk/network/; revision=18822", "target": 0}
{"idx": 1459, "commit_message": "Changed GPU status line from \"A:xxxxx R:xxx\" to \"R:0.0%\". It shows (rejected/(accepted+rejected))*100, which is the percentage of rejections for a GPU. Total accepted and rejected in top status is unchanged.  GPU status lines now show both threads and intensity.", "target": 0}
{"idx": 1052, "commit_message": "man: busctl: improve capture description (#5321)", "target": 0}
{"idx": 3218, "commit_message": "PG-1285: Made change to prevent exception when changing versification causes chapter change.ChangeToEnglishVersification.  Note: decided against trying for a more efficient approach to only changing the versification once since I couldn't come up with one that seemed certain to be more efficient and would also leave the code clean and readable.", "target": 0}
{"idx": 3625, "commit_message": "Added global NS to build-in functions and constants using PHP BackSlasher for possible performance gain. See https://veewee.github.io/blog/optimizing-php-performance-by-fq-function-calls/ and [URL]/nilportugues/php-backslasher for details.", "target": 1}
{"idx": 3908, "commit_message": "Preparations for more performance: Introducing token_key.  The first 8 characters of a token will be saved as token_key, so in future knox won't iterate over all hashes, only over all with the first 8 chars.  For a smooth migration, this minor release doesn't include the actual performance improvements. If a token is valid, it will fill the token_key, but is still running over all tokens. In the next (I would say) major release, a breaking change will come, because the token_key will become not null. All reused tokens between this and the upcoming (major) release will be updated automatically and are not affected. Any other inactive user must reauthenticate. Then the actual performance improvement will work.  Bonus: Code cleanup, more PEP8.", "target": 0}
{"idx": 1634, "commit_message": "Fixed bug in finding n_turns algorithm", "target": 0}
{"idx": 281, "commit_message": "new description for C calls  ==> ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  \t* kernel/Class.st: Implement \"active\" method annotations and \tC-call method annotations. \t* kernel/CompildMeth.st: Implement C-call method annotations. \t* kernel/ObjMemory.st: Call \"Class initialize\".  \t* examples/gdbm-c.st: Switch to new C-call description. \t* examples/md5.st: Likewise. \t* examples/regex.st: Likewise. \t* kernel/Behavior.st: Likewise. \t* kernel/CFuncs.st: Likewise. \t* kernel/ClassDesc.st: Likewise. \t* kernel/DLD.st: Likewise. \t* kernel/Directory.st: Likewise. \t* kernel/File.st: Likewise. \t* kernel/VFS.st: Likewise.  ==> gtk/ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  \t* gtk/MoreFuncs.st: Switch to new C-call descriptions. \t* gtk/funcs.awk: Switch to new C-call descriptions.  ==> blox-tk/ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  \t* blox-tk/BloxBasic.st: Switch to new C-call descriptions.  ==> tcp/ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  \t* tcp/cfuncs.st: Switch to new C-call descriptions.  ==> i18n/ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  \t* i18n/Locale.st: Switch to new C-call descriptions. \t* i18n/Sets.st: Switch to new C-call descriptions.  ==> libgst/ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  \t* libgst/comp.c (install_method): Evaluate pragma handlers. \tMake CompiledMethod read-only. \t(method_new): Do not make CompiledMethod read-only here. \t* libgst/dict.c (class_info): Include pragmaHandlers instance \tvariable for Class. \t(init_class): Initialize it here. \t* libgst/dict.h (gst_class): Include pragmaHandlers instance variable. \t* libgst/sym.c (_gst_find_pragma_handler): New. \t* libgst/sym.h (_gst_find_pragma_handler): Declare it.   git-archimport-id: [URL]--2004b/smalltalk--devo--2.2--patch-23", "target": 0}
{"idx": 2147, "commit_message": "add benchmark, improve performance with macros", "target": 1}
{"idx": 2957, "commit_message": "XML documents with \"wide\" branches causes an array out of bounds exception to be thrown. The validator, when resizing the array of children QNames at a given level, was adding new QNames to the original children array instead of the new, resized array. Since the array size was initially sized to 256, this problem appeared as soon as a branch was 256 elements wide. This bug is now fixed.  Also, after tweaking the numbers a little bit, I see no noticable difference in performance between an initial array size of 128 and 256, so I changed the default size to be 128. However, this really needs to be REVISITed because it is a waste of memory.", "target": 0}
{"idx": 4029, "commit_message": "[PATCH] Performance Improvements - changed Cartesian to\n Simple_cartesian in the examples - changed list to vector in the code -\n removed unnecessary includes - introduced multipass_distance", "target": 1}
{"idx": 2753, "commit_message": "More efficient selector  - The width was being forced on the wrapping anchor block element with the goal of resizing the image to 40x40px. Now utilizes a \"more proper\" selector by forcing the width and height of the actual image element and also now uses the max- prefix for the very rare scenario of an avatar being smaller.", "target": 1}
{"idx": 2131, "commit_message": "Stop using page load progress for diffing toolbar state.  Because the progress bar is not used for any part of the bitmap capture, triggering a capture for progress changes doesn't currently make sense. With this change we reduce the number of bitmap captures that happen, which is a performance improvement.  Bug: 1325882", "target": 1}
{"idx": 2138, "commit_message": "Improve the performance of access checking for a specific user in CourseViewList by prefetching data", "target": 1}
{"idx": 3416, "commit_message": "fix ePortfolio page performance / page timeouts  fixes OUT-2961  test plan: - have at least 2 student in a course - submit to several of the assignments in the course - go to the students ePortfolio and confirm their submissions   appear on the \"Welcome to Your ePortfolio\" page - make the ePortfolio public under 'ePortfolio' settings - view the ePortfolio as another student, confirm that no   \"Recent Submissions\" list appears for the public portfolio    (only should appear when logged in as the user who owns the    portfolio)", "target": 0}
{"idx": 2601, "commit_message": "Workaround in Spark for ConcurrentModification issue (JIRA Hadoop-10456, Spark-1097)  This fix has gone into Hadoop 2.4.1. For developers using <  2.4.1, it would be good to have a workaround in Spark as well.  Fix has been tested for performance as well, no regressions found.  Author: nravi [URL]>  Closes #1000 from nishkamravi2/master and squashes the following commits:  eb663ca [nravi] Merge branch 'master' of [URL]/apache/spark df2aeb1 [nravi] Improved fix for ConcurrentModificationIssue (Spark-1097, Hadoop-10456) 6b840f0 [nravi] Undo the fix for SPARK-1758 (the problem is fixed) 5108700 [nravi] Fix in Spark for the Concurrent thread modification issue (SPARK-1097, HADOOP-10456) 681b36f [nravi] Fix for SPARK-1758: failing test org.apache.spark.JavaAPISuite.wholeTextFiles", "target": 0}
{"idx": 1737, "commit_message": "optimization: don't tag lowercase word twice", "target": 1}
{"idx": 1125, "commit_message": "I added a Controller for running kademlia algorithm.", "target": 0}
{"idx": 162, "commit_message": "Reset network credential on selection change  The \"authorize\" checkbox would remain checked whenever the credential type was changed, however it should be reset on each type change", "target": 0}
{"idx": 3108, "commit_message": "optimize fuzz action performance + add new message action for generator", "target": 1}
{"idx": 3148, "commit_message": "powerpc/signals: Improved mark VSX not saved with small contexts fix  commit ec67ad82814bee92251fd963bf01c7a173856555 upstream.  In a recent patch:   commit c13f20ac48328b05cd3b8c19e31ed6c132b44b42   Author: Michael Neuling [URL]>   powerpc/signals: Mark VSX not saved with small contexts  We fixed an issue but an improved solution was later discussed after the patch was merged.  Firstly, this patch doesn't handle the 64bit signals case, which could also hit this issue (but has never been reported).  Secondly, the original patch isn't clear what MSR VSX should be set to.  The new approach below always clears the MSR VSX bit (to indicate no VSX is in the context) and sets it only in the specific case where VSX is available (ie. when VSX has been used and the signal context passed has space to provide the state).  This reverts the original patch and replaces it with the improved solution.  It also adds a 64 bit version.", "target": 0}
{"idx": 4050, "commit_message": "[PATCH] using int instead of size_t should be more efficient and\n range doesn't seem to be needed", "target": 1}
{"idx": 2000, "commit_message": "Implement flood pruning and make stack state changes more efficient.  If a non-root switch has multiple links towards the root, only propogate floods from the root, from one known good link (otherwise non-root connected hosts might receive more than one copy of a broadcast).  When processing a stack state port change, process all changed ports first before generating new flows to reduce number of flows sent.", "target": 1}
{"idx": 3340, "commit_message": "Big performance improvement for .award x Role", "target": 1}
{"idx": 678, "commit_message": "Many files: Fix sstream includes  arch/alpha/tlb.cc: base/cprintf.hh: base/cprintf_formats.hh: base/crc.cc: base/statistics.cc: base/statistics.hh: base/stats/text.cc: cpu/memtest/memtest.cc: cpu/simple/cpu.cc: dev/pcidev.cc: sim/eventq.cc:     Fix sstream includes  --HG-- extra : convert_revision : fd69937ea26b4961e92f1736fa44daa16f54698d", "target": 0}
{"idx": 2835, "commit_message": "Extension performance improvement  * Introduced Git repo stat TTL. This helps to avoid unnecessary fetch   requests to remote repository * Configuration file restructured. It's easier to have mapping for file   name in Git repository on resource rather then vise versa", "target": 1}
{"idx": 959, "commit_message": "Do the initial move of non-algorithm related classes to DataObjects  Currently nothing will compile. Refs #11209", "target": 0}
{"idx": 1381, "commit_message": "chore: add grunt configure to run on pre-commit hook (#1244)  **Short Description:**  Preventing us to open PR's like this - [URL]/dequelabs/axe-core/pull/1184    **Long Description:**  There has been several PR's in the past, where changes are done, but the `rule-descriptions` are not updated, because `build` was not run as a part of the development efforts.    These usually happen when the metadata of a rule spec or check spec is changed.     Overhead being unrelated changes show up on other work.    This PR adds `grunt configure`, which builds `doc/rule-descriptions.md` as a part of pre-commit hook. This should alleviate the above     Closes issue: NA    ## Reviewer checks    **Required fields, to be filled out by PR reviewer(s)**  - [x] Follows the commit message policy, appropriate for next version  - [x] Has documentation updated, a DU ticket, or requires no documentation change  - [x] Includes new tests, or was unnecessary  - [x] Code is reviewed for security by: @WilcoFiers", "target": 0}
{"idx": 1348, "commit_message": "optimization on asynchronous_request  on maps control", "target": 1}
{"idx": 1998, "commit_message": "Add test cache container to unit tests.  This is a memory-only Infinispan cache container.", "target": 0}
{"idx": 3536, "commit_message": "Reland \"Reland \"Change HeapObserverList to HeapObserverSet\"\"  This is a reland of 944fde321c86d9cdc9d9dfeb27519d8d4f646466. It was reverted because WebSocketChannelImpl::ProcessSendQueue() accessed an unbound HeapMojoRemote, which was guaranteed to be bound without this CL. The issue was fixed in another CL: [URL]/c/2362042  Original change's description: > Reland \"Change HeapObserverList to HeapObserverSet\" > > This is a reland of f29d2ae1e409a8b4596d5f3d2a707a0dbf790727 > > ExecutionContext::NotifyContextDestroyed() has relied on the > deterministic iteration order of ObserverList, so landing the original > CL caused a problem. It is fixed in another CL: > [URL]/c/2352588 > > Original change's description: > > Change HeapObserverList to HeapObserverSet > > > > The previous CL for HeapObserverList [URL]/c/2060348 > > addressed two things: changing HeapObserverList to HeapObserverSet and > > allowing removal while iteration, and was reverted for performance > > reasons. This CL only does the former and avoids performance > > implications of the latter. > > > > This CL is for migration of NewLinkedHashSet. > > See: [URL]/c/2134039 > > > > Bug: 1100257 > >", "target": 0}
{"idx": 777, "commit_message": "Monster planning : improved \"count\" calc for boss fights.", "target": 0}
{"idx": 290, "commit_message": "Updated RSB to permit enabling of RQ Performance Counters", "target": 0}
{"idx": 1985, "commit_message": "Merge pull request #13 from oksanagit/build_improve   suggest using RELEASE.local to avoid editing RELEASE file in two places", "target": 0}
{"idx": 3006, "commit_message": "sched: Implement smarter wake-affine logic  The wake-affine scheduler feature is currently always trying to pull the wakee close to the waker. In theory this should be beneficial if the waker's CPU caches hot data for the wakee, and it's also beneficial in the extreme ping-pong high context switch rate case.  Testing shows it can benefit hackbench up to 15%.  However, the feature is somewhat blind, from which some workloads such as pgbench suffer. It's also time-consuming algorithmically.  Testing shows it can damage pgbench up to 50% - far more than the benefit it brings in the best case.  So wake-affine should be smarter and it should realize when to stop its thankless effort at trying to find a suitable CPU to wake on.  This patch introduces 'wakee_flips', which will be increased each time the task flips (switches) its wakee target.  So a high 'wakee_flips' value means the task has more than one wakee, and the bigger the number, the higher the wakeup frequency.  Now when making the decision on whether to pull or not, pay attention to the wakee with a high 'wakee_flips', pulling such a task may benefit the wakee. Also imply that the waker will face cruel competition later, it could be very cruel or very fast depends on the story behind 'wakee_flips', waker therefore suffers.  Furthermore, if waker also has a high 'wakee_flips', that implies that multiple tasks rely on it, then waker's higher latency will damage all of them, so pulling wakee seems to be a bad deal.  Thus, when 'waker->wakee_flips / wakee->wakee_flips' becomes higher and higher, the cost of pulling seems to be worse and worse.  The patch therefore helps the wake-affine feature to stop its pulling work when:          wakee->wakee_flips > factor &&         waker->wakee_flips > (factor * wakee->wakee_flips) The 'factor' here is the number of CPUs in the current CPU's NUMA node, so a bigger node will lead to more pulling since the trial becomes more severe.  After applying the patch, pgbench shows up to 40% improvements and no regressions.  Tested with 12 cpu x86 server and tip 3.10.0-rc7.  The percentages in the final column highlight the areas with the biggest wins, all other areas improved as well:          pgbench                    base        smart          | db_size | clients |  tps  |        |  tps  |         +---------+---------+-------+   +-------+         | 22 MB   |       1 | 10598 |   | 10796 |         | 22 MB   |       2 | 21257 |   | 21336 |         | 22 MB   |       4 | 41386 |   | 41622 |         | 22 MB   |       8 | 51253 |   | 57932 |         | 22 MB   |      12 | 48570 |   | 54000 |         | 22 MB   |      16 | 46748 |   | 55982 | +19.75%         | 22 MB   |      24 | 44346 |   | 55847 | +25.93%         | 22 MB   |      32 | 43460 |   | 54614 | +25.66%         | 7484 MB |       1 |  8951 |   |  9193 |         | 7484 MB |       2 | 19233 |   | 19240 |         | 7484 MB |       4 | 37239 |   | 37302 |         | 7484 MB |       8 | 46087 |   | 50018 |         | 7484 MB |      12 | 42054 |   | 48763 |         | 7484 MB |      16 | 40765 |   | 51633 | +26.66%         | 7484 MB |      24 | 37651 |   | 52377 | +39.11%         | 7484 MB |      32 | 37056 |   | 51108 | +37.92%         | 15 GB   |       1 |  8845 |   |  9104 |         | 15 GB   |       2 | 19094 |   | 19162 |         | 15 GB   |       4 | 36979 |   | 36983 |         | 15 GB   |       8 | 46087 |   | 49977 |         | 15 GB   |      12 | 41901 |   | 48591 |         | 15 GB   |      16 | 40147 |   | 50651 | +26.16%         | 15 GB   |      24 | 37250 |   | 52365 | +40.58%         | 15 GB   |      32 | 36470 |   | 50015 | +37.14%", "target": 1}
{"idx": 16, "commit_message": "Merge pull request #2567 from nonifier/filter_journeys_before_fallback  Jormun: Filter journeys before streetnetwork fallback [Distributed]", "target": 0}
{"idx": 2214, "commit_message": "[1.4-devel] improved JDBC related performance and memory consumption; updated to latest Oracle libraries; reintegrated matching/merging tool as plugin", "target": 1}
{"idx": 559, "commit_message": "Use global memory for the various _str functions as much as possible", "target": 0}
{"idx": 150, "commit_message": "perf/x86/intel/uncore: Add Broadwell-U uncore IMC PMU support  This patch enables the uncore Memory Controller (IMC) PMU support for Intel Broadwell-U (Model 61) mobile processors. The IMC PMU enables measuring memory bandwidth.  To use with perf: $ perf stat -a -I 1000 -e uncore_imc/data_reads/,uncore_imc/data_writes/ sleep 10  Tested-by: Sonny Rao [URL]>", "target": 0}
{"idx": 1327, "commit_message": "When data is in memory, allocate & copy it in ospell rather than expect caller to keep track of it (which it usually doesn't)", "target": 0}
{"idx": 1439, "commit_message": "Refactor the garbage collector for BDD/ZBDD  Only the unique table is managed by the garbage collector. Other tables are treated as local containers, and cleaning is done by the functions that use them. The performance is mixed, but the memory consumptions is decreased by 2-10x.", "target": 1}
{"idx": 2083, "commit_message": "Fixing issue #5482: Port from desktop .NET: Performance improvement for XmlUTF8TextReader when reading invalid chars Perf comparison    Before                               After TestEFBytes             ~360 ms, 10 iterations   ~35 ms, 29 iterations TestAsciiBytes        ~7.x ms, 137 iterations   ~7.x ms, 123 iteration", "target": 1}
{"idx": 3179, "commit_message": "modifications to cache for loops to improve performance, see [URL]/js-for-loops-cached-vs-basic", "target": 1}
{"idx": 2058, "commit_message": "cpufreq: interactive: Make skipping delay for migration optional  Commit 92352c0a65bc (\"cpufreq: interactive: Ramp up directly if cpu_load exceeds 100\") and commit 594945e67031 (\"cpufreq: interactive: Skip delay in frequency changes due to migration\") allow interactive governor to skip above_hispeed_delay and min_sample_time if the frequency evaluation request comes from scheduler. Power and performance benefits of these two features are dependent on the behavior of each workload. Adverse load pattern may experience regression instead of improvement.  Make both features optional by introducing a sysfs file for each. Both features are disabled by default.", "target": 0}
{"idx": 3126, "commit_message": "Merge pull request #625 from vgteam/mapqz  continue improving aligner performance", "target": 1}
{"idx": 3170, "commit_message": "op_mod fails on many interesting corner cases [URL]/show_bug.cgi?id=81648  Source/JavaScriptCore:   Reviewed by Oliver Hunt.          Removed most strength reduction for op_mod, and fixed the integer handling to do the right thing for corner cases. Oddly, this revealed bugs in OSR, which this patch also fixes.          This patch is performance neutral on all of the major benchmarks we track.  * dfg/DFGOperations.cpp: * dfg/DFGOperations.h: * dfg/DFGSpeculativeJIT.cpp: (DFG): (JSC::DFG::SpeculativeJIT::compileSoftModulo): (JSC::DFG::SpeculativeJIT::compileArithMod): * jit/JIT.h: (JIT): * jit/JITArithmetic.cpp: (JSC): (JSC::JIT::emit_op_mod): (JSC::JIT::emitSlow_op_mod): * jit/JITArithmetic32_64.cpp: (JSC::JIT::emit_op_mod): (JSC::JIT::emitSlow_op_mod): * jit/JITOpcodes32_64.cpp: (JSC::JIT::privateCompileCTIMachineTrampolines): (JSC): * jit/JITStubs.h: (TrampolineStructure): (JSC::JITThunks::ctiNativeConstruct): * llint/LowLevelInterpreter64.asm: * wtf/Platform.h: * wtf/SimpleStats.h: (WTF::SimpleStats::variance):  LayoutTests:   Reviewed by Oliver Hunt.  * fast/js/integer-division-neg2tothe32-by-neg1-expected.txt: Added. * fast/js/integer-division-neg2tothe32-by-neg1.html: Added. * fast/js/script-tests/integer-division-neg2tothe32-by-neg1.js: Added. (myDiv): (myDivByNeg1): (myDivNeg2ToThe31): (myMod): (myModByNeg1): (myModNeg2ToThe31): (myOtherDiv): (myOtherDivByNeg1): (myOtherDivNeg2ToThe31): (myOtherMod): (myOtherModByNeg1): (myOtherModNeg2ToThe31):", "target": 0}
{"idx": 413, "commit_message": "Sync networks added in OOBE to first account.  Any networks that are added during OOBE should be considered to be owned by first user to log in for the purposes of sync.  Bug: 966270", "target": 0}
{"idx": 403, "commit_message": "disp: remove restart and reload  disp directory is dynamically loaded so no need to reload/restart", "target": 0}
{"idx": 2717, "commit_message": "io_uring: make CQ ring wakeups be more efficient  For batched IO, it's not uncommon for waiters to ask for more than 1 IO to complete before being woken up. This is a problem with wait_event() since tasks will get woken for every IO that completes, re-check condition, then go back to sleep. For batch counts on the order of what you do for high IOPS, that can result in 10s of extra wakeups for the waiting task.  Add a private wake function that checks for the wake up count criteria being met before calling autoremove_wake_function(). Pavel reports that one test case he has runs 40% faster with proper batching of wakeups.  Reported-by: Pavel Begunkov [URL]> Tested-by: Pavel Begunkov [URL]>", "target": 1}
{"idx": 983, "commit_message": "Metal: Support tri-fan & line-loop with primitive restart  Triangle fan: - If primitive restart is NOT enabled and there is no active render   pass, use Compute Shader to generate indices. - If primitive restart is enabled, use CPU to generate indices.  Line loop: - If draw non-instanced without primitive restart, generate and   draw only one additional last segment (fastest). - If draw instanced, primitive restart is NOT enabled, and there is no   active render pass, use Compute Shader to generate indices (OK). - Otherwise, use CPU to generate indices (slowest).  Also Disable OcclusionQueriesTest.ClearNotCounted failure on NVIDIA.  Bug: angleproject:2634 Bug: angleproject:5307", "target": 0}
{"idx": 3701, "commit_message": "GROOVY-7263: this patch will add new performance improvements to resolveVisitor to avoid problems casued by the GROOVY-5989 patch. The older performance patch had to be undone, since it broke the code example in GROOVY-7263", "target": 1}
{"idx": 954, "commit_message": "resolved memory leak issue in command and test files", "target": 0}
{"idx": 498, "commit_message": "Merge pull request #159 from opentable/release-build  [DX-457] Release build improvements and fixes", "target": 0}
{"idx": 2855, "commit_message": "Downgrade markdown-mode  This makes the syntax highlighting better, and fixes some performance regressions. I don't know what I'll do in the long run.", "target": 1}
{"idx": 2257, "commit_message": "improve proxy object transfer performance by autodetect if proxy object implements ICompare<T> interface", "target": 1}
{"idx": 1443, "commit_message": "service arg dynamic form in progress", "target": 0}
{"idx": 2230, "commit_message": "- Improved sensor performance by integrating normalization and feature detection.", "target": 1}
{"idx": 2010, "commit_message": "Merge pull request #171 from kamaci/fix/memory_inner_class  [ANY23-464] Performance improvement for inner classes", "target": 1}
{"idx": 3130, "commit_message": "Merge pull request #510 from mindjuice/patch-17  Minor help text improvements", "target": 0}
{"idx": 2394, "commit_message": "Improve write performance; Update READMEs and .travis.yml.", "target": 1}
{"idx": 2404, "commit_message": "Cache the window selector as 'viewport' in an attempt to improve performance.  (imported from commit 3e01382260938737fbee663f6a9e94ad495ef21e)", "target": 1}
{"idx": 1723, "commit_message": "Merge pull request #72 from TeamHG-Memex/fix-unhasher  InvertableHashingVectorizer: handle binary=True case properly. Fixes #71.", "target": 0}
{"idx": 1514, "commit_message": "Added new post. Improved Dated Files.", "target": 0}
{"idx": 1740, "commit_message": "am dbb26145: Merge \"Optimize shaders for dithered gradients\" into jb-mr1-dev  * commit 'dbb261455b1b8d2fdf4f0f8ad84ddb09dda1ed9b':   Optimize shaders for dithered gradients", "target": 1}
{"idx": 2524, "commit_message": "Cleanup use of Instance_List, Instance_List_Access and Instance_Array  (Script_Proxies): new package to encapsulate all the logic to associate  an Ada object with the same python instance, including cleaning up  references to the Ada object from python when the object is destroyed. Adapt to the new API in GNATCOLL.Scripts.Set, since we no longer need  to pass the scripting language when storing an instance in an  Instance_List (the language is known from the instance itself). We did not properly release instances for GPS.Bookmark. GPS.Bookmark  instances now store directly a Bookmark_Data_Access rather than the name  of the bookmark. This is slightly more efficient, and makes it possible  to use the Script_Proxies package. On the other hand, that makes that  calling GPS.Bookmark.name() after delete() no longer works.  OB19-005", "target": 1}
{"idx": 506, "commit_message": "OmeroShell : Improvements to the OmeroPy CLI   * Added sha1 and upload methods to omero.client  * Initial working uploade command  * Fixed preference handling from cli.py  * Added several sample files under examples/  * Updated bin/omero for production. Use bin/dev for development", "target": 0}
{"idx": 4109, "commit_message": "[PATCH] Removed debug code with would slow down mdrun when writing\n trajectories", "target": 1}
{"idx": 3385, "commit_message": "DbURL: improve constructor performance  When constructing a DbURL without an explicit username, /usr/bin/id was executed regardless of whether we needed its output or not. That seems excessive; let's only use it if the environment doesn't already have what we need.", "target": 1}
{"idx": 665, "commit_message": "sal: PVS-Studio V611 memory was allocated using 'new T[]' operator  ... but was released using the 'delete' operator", "target": 0}
{"idx": 3156, "commit_message": "Make Fusion-MPT much faster as module  From: \tMoore, Eric Dean [URL]>  Between the 3.01.16 and 3.01.18, we introduced new method to passing command line options to the driver.  Some of the command line options are used for fine tuning dv(domain validation) in the driver.  By accident, these command line options were wrapped around #ifdef MODULE in the 3.01.18 version of the driver. What this meant is when the driver is compiled built-in the kernel, the optimal settings for dv were ignored, thus poor performance.    There was actually a fix for this when I submitted SAS drivers to the mailing list back in November, however the SAS drivers was rejected, and later on I overlooked submitting a single patch to  solve this.", "target": 1}
{"idx": 2238, "commit_message": "sched/rt: Introduce power aware scheduling for real time tasks  Real Time task scheduling has historically been geared towards performance with a significant attempt to keep higher priority tasks on the same CPU. This is not optimal for power since the task CPU may not be the most power efficient CPU.  Also task movement via select_lowest_rq() gives CPU priority the primary consideration before looking at CPU topologies to find a CPU closest to the task CPU in terms of topology. This again is not optimal for power since the closest CPU may be significantly worse for power than CPUs further away.  This patch removes any bias for the task CPU. When the lowest priority CPUs in the system are found we give no consideration to the CPU topology. Instead we find the lowest power CPU within local_cpu_mask. This takes care of select_task_rq_rt() and push_task(). The pull model remains unaffected since we have no room for power optimization there.", "target": 1}
{"idx": 4031, "commit_message": "[PATCH] new, more efficient jacobian calculation for integrator", "target": 1}
{"idx": 3243, "commit_message": "[X86] Improved lowering of v4x32 build_vector dag nodes.  This patch improves the lowering of v4f32 and v4i32 build_vector dag nodes that are known to have at least two non-zero elements.  With this patch, a build_vector that performs a blend with zero is  converted into a shuffle. This is done to let the shuffle legalizer expand the dag node in a optimal way. For example, if we know that a build_vector performs a blend with zero, we can try to lower it as a movq/blend instead of always selecting an insertps.  This patch also improves the logic that lowers a build_vector into a insertps with zero masking. See for example the extra test cases added to test sse41.ll.  Differential Revision: [URL]/D6311", "target": 1}
{"idx": 521, "commit_message": "futex: Handle futex_pi OWNER_DIED take over correctly  Siddhesh analyzed a failure in the take over of pi futexes in case the owner died and provided a workaround. See: [URL]/bugzilla/show_bug.cgi?id=14076  The detailed problem analysis shows:  Futex F is initialized with PTHREAD_PRIO_INHERIT and PTHREAD_MUTEX_ROBUST_NP attributes.  T1 lock_futex_pi(F);  T2 lock_futex_pi(F);    --> T2 blocks on the futex and creates pi_state which is associated        to T1.  T1 exits    --> exit_robust_list() runs        --> Futex F userspace value TID field is set to 0 and            FUTEX_OWNER_DIED bit is set.  T3 lock_futex_pi(F);    --> Succeeds due to the check for F's userspace TID field == 0    --> Claims ownership of the futex and sets its own TID into the        userspace TID field of futex F    --> returns to user space  T1 --> exit_pi_state_list()        --> Transfers pi_state to waiter T2 and wakes T2 via        \t   rt_mutex_unlock(&pi_state->mutex)  T2 --> acquires pi_state->mutex and gains real ownership of the        pi_state    --> Claims ownership of the futex and sets its own TID into the        userspace TID field of futex F    --> returns to user space  T3 --> observes inconsistent state  This problem is independent of UP/SMP, preemptible/non preemptible kernels, or process shared vs. private. The only difference is that certain configurations are more likely to expose it.  So as Siddhesh correctly analyzed the following check in futex_lock_pi_atomic() is the culprit:  \tif (unlikely(ownerdied || !(curval & FUTEX_TID_MASK))) {  We check the userspace value for a TID value of 0 and take over the futex unconditionally if that's true.  AFAICT this check is there as it is correct for a different corner case of futexes: the WAITERS bit became stale.  Now the proposed change  -\tif (unlikely(ownerdied || !(curval & FUTEX_TID_MASK))) { +       if (unlikely(ownerdied || +                       !(curval & (FUTEX_TID_MASK | FUTEX_WAITERS)))) {  solves the problem, but it's not obvious why and it wreckages the \"stale WAITERS bit\" case.  What happens is, that due to the WAITERS bit being set (T2 is blocked on that futex) it enforces T3 to go through lookup_pi_state(), which in the above case returns an existing pi_state and therefor forces T3 to legitimately fight with T2 over the ownership of the pi_state (via pi_state->mutex). Probelm solved!  Though that does not work for the \"WAITERS bit is stale\" problem because if lookup_pi_state() does not find existing pi_state it returns -ERSCH (due to TID == 0) which causes futex_lock_pi() to return -ESRCH to user space because the OWNER_DIED bit is not set.  Now there is a different solution to that problem. Do not look at the user space value at all and enforce a lookup of possibly available pi_state. If pi_state can be found, then the new incoming locker T3 blocks on that pi_state and legitimately races with T2 to acquire the rt_mutex and the pi_state and therefor the proper ownership of the user space futex.  lookup_pi_state() has the correct order of checks. It first tries to find a pi_state associated with the user space futex and only if that fails it checks for futex TID value = 0. If no pi_state is available nothing can create new state at that point because this happens with the hash bucket lock held.  So the above scenario changes to:  T1 lock_futex_pi(F);  T2 lock_futex_pi(F);    --> T2 blocks on the futex and creates pi_state which is associated        to T1.  T1 exits    --> exit_robust_list() runs        --> Futex F userspace value TID field is set to 0 and            FUTEX_OWNER_DIED bit is set.  T3 lock_futex_pi(F);    --> Finds pi_state and blocks on pi_state->rt_mutex  T1 --> exit_pi_state_list()        --> Transfers pi_state to waiter T2 and wakes it via        \t   rt_mutex_unlock(&pi_state->mutex)  T2 --> acquires pi_state->mutex and gains ownership of the pi_state    --> Claims ownership of the futex and sets its own TID into the        userspace TID field of futex F    --> returns to user space  This covers all gazillion points on which T3 might come in between T1's exit_robust_list() clearing the TID field and T2 fixing it up. It also solves the \"WAITERS bit stale\" problem by forcing the take over.  Another benefit of changing the code this way is that it makes it less dependent on untrusted user space values and therefor minimizes the possible wreckage which might be inflicted.  As usual after staring for too long at the futex code my brain hurts so much that I really want to ditch that whole optimization of avoiding the syscall for the non contended case for PI futexes and rip out the maze of corner case handling code. Unfortunately we can't as user space relies on that existing behaviour, but at least thinking about it helps me to preserve my mental sanity. Maybe we should nevertheless :)  Reported-and-tested-by: Siddhesh Poyarekar [URL]> Link:   Acked-by: Darren Hart [URL]>", "target": 0}
{"idx": 3158, "commit_message": "enh: enabled Cython Pk setup, fixes #51  Tests indicate that this speeds up the creation by more than 200 times. However, the main part of computation is still in the eigh routines.  I have thoroughly tested the polarized setup of Hamiltonians and also one-time test of NC and SO. I thus suspect it to work as expected (but more tests are of course needed).  The test_hamiltonian has been updated to not do Hk several times. There may be remnants for these tests that eventually should be removed.  Changed a few Cython routines to return copies. I think this may be more memory efficient because then there are no references to too long arrays. I haven't checked this.", "target": 1}
{"idx": 3892, "commit_message": "JavaScriptCore:          Reviewed by Maciej Stachowiak.                  Fixed [URL]/show_bug.cgi?id=15683         Re-order declaration initialization to avoid calling hasProperty inside         VarDeclNode::processDeclaration                  .7% speedup on SunSpider.          * kjs/function.h:         * kjs/function.cpp: Merged parameter processing into FunctionBodyNode's         other processing of declared symbols, so the order of execution could          change.          * kjs/nodes.cpp:         (KJS::VarDeclNode::getDeclarations): Added special case for the          \"arguments\" property name, explained in the comment.          (KJS::VarDeclNode::processDeclaration): Removed call to hasProperty         in the case of function code, since we know the declared symbol         management will resolve conflicts between symbols. Yay!          (KJS::VarDeclListNode::getDeclarations): Now that VarDeclNode's          implementation of getDeclarations is non-trivial, we can't take a          short-cut here any longer -- we need to put the VarDecl node on the          stack so it gets processed normally.          (KJS::FunctionBodyNode::processDeclarations): Changed the order of          processing to enforce mutual exclusion rules.          * kjs/nodes.h:         (KJS::DeclarationStacks::DeclarationStacks): Structure includes an          ExecState now, for fast access to the \"arguments\" property name.  LayoutTests:          Layout tests for bugs that might result from changes like          [URL]/show_bug.cgi?id=15683          * fast/js/vardecl-preserve-parameters-expected.txt: Added.         * fast/js/vardecl-preserve-parameters.html: Added.         * fast/js/vardecl-preserve-vardecl-expected.txt: Added.         * fast/js/vardecl-preserve-vardecl.html: Added.", "target": 1}
{"idx": 4012, "commit_message": "[PATCH] Improved performance of interaction groups on CPU", "target": 1}
{"idx": 2499, "commit_message": "* Reworked software Bitmap engine:   - fixed 256x160 resolution.   - simpler and easier to use.   - improved performance.   - removed FF BMP engine (too complex, incomplete and not really useful after all).   - many others changes you will discover :) * Added \"Bitmap\" structure for better bitmap handling.   16 colors bitmap images are automatically converted to \"Bitmap\" by SGDK. * Major rewrite of Maths3D engine:   - added many 3D related structures (as matrix, transform..).   - more flexibility.   - improved performance. * removed useless VRAM table (eat rom space for minor speed boost). * added DMA capability to VDP_setHorizontalScrollxxx(..) / VDP_setVerticalScrollTile(..) functions. * refactored palette functions. * fixed QSort function. * minors fixes/tweaks in memset and memcpy functions. * minors tweaks on makefile. * others minors changes or improvements.", "target": 1}
{"idx": 1435, "commit_message": "Improve documentation of -fallow-store-data-races  2020-10-08  John Henning  [URL]>  gcc/  \tPR other/97309 \t* doc/invoke.texi: Improve documentation of \t-fallow-store-data-races.", "target": 0}
{"idx": 1806, "commit_message": "[tokenizer] improved handling of remaining data", "target": 0}
{"idx": 1470, "commit_message": "perf_counter, x86: make x86_pmu data a static struct  Instead of using a pointer to reference to the x86 pmu we now have one single data structure that is initialized at the beginning. This saves the pointer access when using this memory.  [ Impact: micro-optimization ]", "target": 1}
{"idx": 1259, "commit_message": "Improve the interactive shell app.  It now supports (and defaults to, when available) bpython. I also added support for python's default interactive console.", "target": 0}
{"idx": 3285, "commit_message": "git-svn: fix several small bugs, enable branch optimization  Share the repack counter between branches when doing multi-fetch.  Pass the -d flag to git repack by default.  That's the main reason we will want automatic pack generation, to save space and improve disk cache performance.  I won't add -a by default since it can generate extremely large packs that make RAM-starved systems unhappy.  We no longer generate the .git/svn/$GIT_SVN_ID/info/uuid file, either.  It was never read in the first place.  Check for and create .rev_db if we need to during fetch (in case somebody manually blew away their .rev_db and wanted to start over.  Mainly makes debugging easier).  Croak with $? instead of $! if there's an error closing pipes  Quiet down some of the chatter, too.", "target": 1}
{"idx": 3928, "commit_message": "[SYSTEMML-1683] Improved codegen row template (indexing, cbind)  This patch makes two improvements to the code generator row-wise template in order to further reduce the number of intermediates in scripts such as MLogreg as well as minor explain improvements):  (1) Column indexing support w/ unknown indexing expressions.  (2) Fusion of cbind with empty matrix after row-wise template (row aggregates).  (3) Extended explain to show the line numbers (of the original script) for generated operators.  For example, on MLogreg and a dense 100M x 10 scenario, this reduces the buffer pool writes from (76/30/1) to (60/30/1) and execution time from 282s to 256s (compared to the baseline w/ existing fused operators of 529s).   Note that there is substantial additional potential, which can be exploited to reduce the number evictions. However, this will be addressed in separate changes as it requires optimizer changes (e.g., considering multi-aggregates while considering materialization, and materialization points per consumer).", "target": 1}
{"idx": 3651, "commit_message": "A recent change for Bug 16249481 introduced compiler warnings on Windows 64 builds and a compiler error on Windows 32 builds. This patch contains typecasting in a few places to eliminate the WIN64 warnings along with a few nonfunctional cleanup changes.  The WIN32 compile error was fixed previously with a normal assert in os0atomic.h.  This patch enhances that fix by; 1) Rearrange macros so that they are in the order by lint, ulint,    uint32, uint64. 2) Deleted some unused macros. 3) Added C++-style casts for the Windows versions of atomic macros.    Used static_cast<> as a first choice, but used reinterpret_cast<>    where the Windows VS2010 compiler required it. 4) The return value for the win32 versions of os_atomic_increment_uint32    and os_atomic_decrement_uint32() were not returning the correct value.    They were returning the original value.  To be consistent with these    macros/functions on other OSes, they should return the new value.    This had no affect since the return value is not currently being checked. 5) HAVE_ATOMIC_BUILTINS_64 was not being defined for WIN64 as intended    because of an error.  The code used #ifndef _WIN32 to denote WIN64, but    actually, on WIN64, WIN32 is also defined.  So this patch changes it to    #ifdef _WIN64.  The macro that this activated is used by 64-bit monitor    integers, so it is not critical InnoDB code, but may improve performance    on WIN64 some intances.  Patch approved on RB#4181 by Marko", "target": 0}
{"idx": 2250, "commit_message": "Added news to the Cause ViewModel Fixed the API cause controller to use find_all_by_cause_id methods rather than loading the cause and walking the object graph, this should be more efficient. Tweaked the cause home view to be a bit more intelligent and use knockout to render sub-div's.", "target": 1}
{"idx": 3950, "commit_message": "Revert of net: merge two versions of SetTCPNoDelay() function into one (patchset #4 id:60001 of [URL]/1728853006/ )  Reason for revert: net-unittests failure on Mac. [URL]/p/chromium.mac/builders/Mac10.9%20Tests/builds/16976/steps/net_unittests%20on%20Mac-10.9/logs/CertVerifyProcTest.CybertrustGTERoot  Original issue's description: > net: merge DisableNagle() with two other SetTCPNoDelay() implementations > > This patch merges SetTCPNoDelay() function from tcp_socket_posix.cc, > SetTCPNoDelay() function from tcp_socket_util.cc and DisableNagle() function > from tcp_socket_win.cc, into a single slightly improved one in tcp_socket.cc > with the following prototype: > > bool SetTCPNoDelay(SocketDescriptor socket, bool no_delay); > > BUG=None > TEST=net_unittests > [URL] > > Committed: [URL]/2d1f2621d8e6dd10feba6cab380fb46d60cb3098 >", "target": 0}
{"idx": 1453, "commit_message": "[SPARK-13482][MINOR][CONFIGURATION] Make consistency of the configuraiton named in TransportConf.  `spark.storage.memoryMapThreshold` has two kind of the value, one is 2*1024*1024 as integer and the other one is '2m' as string. \"2m\" is recommanded in document but it will go wrong if the code goes into `TransportConf#memoryMapBytes`.  [URL]/jira/browse/SPARK-13482)  Author: huangzhaowei [URL]>  Closes #11360 from SaintBacchus/SPARK-13482.  (cherry picked from commit 264533b553be806b6c45457201952e83c028ec78)", "target": 0}
{"idx": 934, "commit_message": "Revert \"Minor block usage improvements\"  This reverts commit 1152f38d020df45a93147ad535b32d7c6d19faae.", "target": 0}
{"idx": 1473, "commit_message": "Merge pull request #79 from sctplab/master  Improve Windows support.", "target": 0}
{"idx": 3348, "commit_message": "CFG is made faster and more memory efficient.", "target": 1}
{"idx": 523, "commit_message": "improve multithread calling of llvm  call llvm multithread function instead of using a semaphore. also exit llvm multithread mode at the end of life.  v2: not call llvm::shutdown() if llvm is older than 3.4", "target": 1}
{"idx": 3368, "commit_message": "staging: android: lowmemorykiller: implement task's adj rbtree  Based on the current LMK implementation, LMK has to scan all processes to select the correct task to kill during low memory. The basic idea for the optimization is to : queue all tasks with oom_score_adj priority, and then LMK just selects the proper task from the queue(rbtree) to kill.  performance improvement: the current implementation: average time to find a task to kill : 1004us the optimized implementation: average time to find a task to kill: 43us", "target": 1}
{"idx": 1093, "commit_message": "Improved handling of the sidebars quicksearch snapin", "target": 0}
{"idx": 3808, "commit_message": "Use List instead of Map in Skyframe's intermediate eval results.  This CL is a no-op and only provides the necessary methods for Skyframe evaluation with Lists instead of Maps. Actual application will be done in subsequent CLs.  Constructing a Map<SkyKey, SkyValue> to store intermediate Skyframe evaluation result is wasteful since we don't make use of the look up capabilities of Maps, but rather just iterate over the key-value pairs. As an alternative, we can present the Skyframe evaluation result with a more space-efficient List<SkyValue>, then rely on the given order of the requested SkyKeys to iterate over it in various SkyFunctions.  Our benchmarks/profiles showed some reduction in GC and CPU time as a result of this switch.  RELNOTES: None PiperOrigin-RevId: 342917514", "target": 1}
{"idx": 130, "commit_message": "ipq40xx: wpj428: fix missing MDIO GPIO reset and pinmux  The bootloader does not always initialize the MDIO pins before booting Linux. E.g. on version \"U-Boot 2012.07 [Chaos Calmer 15.05.1,r35193] (Jul 25 2017 - 11:36:26)\" this is the case when booting automatically without activating the U-Boot console.  Without this change, the kernel boot will complain about missing PHYs:   libphy: ipq40xx_mdio: probed  ar40xx c000000.ess-switch: Probe failed - Missing PHYs!  libphy: Fixed MDIO Bus: probed  With this change it will work as expected:   libphy: ipq40xx_mdio: probed  ESS reset ok!  ESS reset ok!  libphy: Fixed MDIO Bus: probed  Ref: GH-2835 Tested-by: Fredrik Olofsson [URL]>", "target": 0}
{"idx": 2691, "commit_message": "Minor optimizations to speed up bgp and xmpp updates  Following changes are implemented:  - Cache string representation for BgpPeer ToString and ToUVEKey - Cache string representation for InetRoute and Inet6Route ToString - Cache string representation for XmppConnection ToUVEKey - Implement MacAddress::ToString more efficiently", "target": 1}
{"idx": 858, "commit_message": "Merge pull request #23534 from dimagi/speedup  use test plans for user line item tests", "target": 0}
{"idx": 4015, "commit_message": "[PATCH] Replaced Vertex_handle and Cell_handle by const & versions  \n in order to regain performance", "target": 1}
{"idx": 1795, "commit_message": "Improve handling of DESeq2 transformations, using `vst` and `rlog` arguments instead of `transformationLimit`", "target": 1}
{"idx": 2512, "commit_message": "[analyzer] Proper caching in CallDescription objects.  During the review of D29567 it turned out the caching in CallDescription is not implemented properly. In case an identifier does not exist in a translation unit, repeated identifier lookups will be done which might have bad impact on the performance. This patch guarantees that the lookup is only executed once. Moreover this patch fixes a corner case when the identifier of CallDescription does not exist in the translation unit and the called function does not have an identifier (e.g.: overloaded operator in C++).  Differential Revision: [URL]/D29884", "target": 1}
{"idx": 85, "commit_message": "Merge branch 'master' into e80  * master: (29 commits)   Parameters for e80   New script to update en-masse the master database   _check_equals has now a suicidal buddy: _assert_equals   Doc in the Example config files is up-to-date with the main file   bugfix: introduced a discrepancy in the species tree in the last commit   PhyloXMLWriter for GeneTreeNodes   Can also write GeneTreeNodes   Check that the given objects have the right type   fixed a typo on cyanidioschyzon_merolae   Added a few more plants species for EG 26_79 release   can_be_empty is only useful with wait_for rules   Only use semaphores, not wait_for rules   We can use semaphores because the funnel only has 1 job   trim_anchor_align sometimes needs more memory   Pipeline-wide parameters don't have to be redefined in the analysis   Unused at the moment   Connect branch #2 to pecan_high_mem   \"region\" is unused   New mlss-tags for the size of the blocks   make perlcritic happy   ...", "target": 0}
{"idx": 1150, "commit_message": "Merge pull request #3490 from degasus/singlecore  Fifo: Use SyncGPU timings for single core.", "target": 0}
{"idx": 1270, "commit_message": "GBE-438: Let dynamic configuration use a single datastore for all shapefile layers", "target": 0}
{"idx": 2461, "commit_message": "Fix for STS-111: Stripes with Spring doesn't work unless you go through an ActionBean first.  To fix this I added another interface method ActionResolver to be able to fetch the Class bound to a URL without having to instantiate it (and in the case of Spring, auto-wire it too).  Should fix the original problem and be more efficient too.", "target": 1}
{"idx": 2236, "commit_message": "- Patch #7458 by chx: merged the XML-RPC multicall support into xmlrpc() and use lazy-loading for the XML-RPC libraries.(performance improvement).", "target": 1}
{"idx": 2858, "commit_message": "fm10k: Add support for PF <-> VF mailbox  This patch adds support for the PF <-> VF mailbox.  It functions similar to the PF <-> SM mailbox however there are several modifications made to improve the reliability of the mailbox itself.  In addition the PF/VF mailbox is much smaller an only supports a total size of 16 DWORDs vs the 1024 DWORDS provided for the PF/SM mailbox.", "target": 1}
{"idx": 4090, "commit_message": "[PATCH] Disable CUDA textures on NVIDIA Volta\n\nThis has significant performance benefit for the nbnxm kernels with\ntabulated Ewald correction and it has negligible impact on the PME kernels.\n\nPartially addresses #3845", "target": 1}
{"idx": 4120, "commit_message": "[PATCH] added option to keep transpose to hybrid for better gpu\n performance", "target": 1}
{"idx": 3552, "commit_message": "[C] changed PokemonNameCorrector#guessBestPokemonByName() and #guessBestPokemonByNormalizedName() to stop guessing when the bestMatchPokemon has found, for improving performance.", "target": 1}
{"idx": 1193, "commit_message": "fixes most serious memory leak in web server component", "target": 1}
{"idx": 3713, "commit_message": "Adding some method swizzling for performance improvement", "target": 1}
{"idx": 3102, "commit_message": "Improved the way we generate mismatch descriptions. matches() methods can now return additional state that is used by describeMismatch(). This adds a small tax to the happy path, but makes the unhappy path quite a bit more efficient as well as providing better error messages.  Related to this, expect() can now be passed a verbose flag. Currently this is used by throwsA/returnsNormally to provide stack traces from the actual exception but could be used for other things too.  The tests for the Mock classes have been changed to be normal tests, not 'meta' tests.   A couple of other minor fixes. Review URL: [URL]//10832058", "target": 1}
{"idx": 35, "commit_message": "improve google/task.vim: timestamp check for tasklist (fix #82)", "target": 0}
{"idx": 3861, "commit_message": "FAB-4161 Run only patch sepecific unit test cases  Currently at CI, entire unit test cases were run which results significant long run jobs. This change will make sure only the changed packages unit test cases will be run at CI.  Merge patch set CI jobs will be still run the full unit test cases. Use go test -cover as opposed to gocov for improved performance Use git diff --name-only to find uncommitted changes Add 'verify' target to Makefile Add a test go source file to test the build generate html coverage report on merge job  Also covers FAB-4192 Makefile improvements  Refine the list of PROJECT_FILES omitting things that don't affect the build targets using that dependency Remove unnecessary dependencies  Have check_spelling.sh and check_license.sh only work on changed files. include last commit content for CI  Also addressed some spelling errors that slipped in.  address binh's comment re generated files", "target": 1}
{"idx": 3143, "commit_message": "Move to max iteration count breaker, gh-15  The previous breaker system was two-pronged: * break if the delta goes over 40~ years * break if the delta stays at 0 for more than 2 iteration  After considering tst/iteration_count.rb, setting a breaker at 1024 iteration looks cheap, efficient, simpler.  Now, on to fix the core of the gh-15 issue. That issue manifested itself as an endless loop, not intercepted by the previous break system because, the loop always seems to progress by 1 second.", "target": 1}
{"idx": 1264, "commit_message": "Interval: Modifyed the value of POS_INFINITY and NEG_INFINITY to correct some problem with is_bisectable() Optimizer: add some check to eliminate some unbounded interval", "target": 0}
{"idx": 3420, "commit_message": "duplicate small performance fixes made in ariande to arc/path", "target": 1}
{"idx": 2009, "commit_message": "net_sched: invoke ->attach() after setting dev->qdisc  [ Upstream commit 86e363dc3b50bfd50a1f315934583fbda673ab8d ]  For mq qdisc, we add per tx queue qdisc to root qdisc for display purpose, however, that happens too early, before the new dev->qdisc is finally set, this causes q->list points to an old root qdisc which is going to be freed right before assigning with a new one.  Fix this by moving ->attach() after setting dev->qdisc.  For the record, this fixes the following crash:   ------------[ cut here ]------------  WARNING: CPU: 1 PID: 975 at lib/list_debug.c:59 __list_del_entry+0x5a/0x98()  list_del corruption. prev->next should be ffff8800d1998ae8, but was 6b6b6b6b6b6b6b6b  CPU: 1 PID: 975 Comm: tc Not tainted 4.1.0-rc4+ #1019  Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011   0000000000000009 ffff8800d73fb928 ffffffff81a44e7f 0000000047574756   ffff8800d73fb978 ffff8800d73fb968 ffffffff810790da ffff8800cfc4cd20   ffffffff814e725b ffff8800d1998ae8 ffffffff82381250 0000000000000000  Call Trace:   [<ffffffff81a44e7f>] dump_stack+0x4c/0x65   [<ffffffff810790da>] warn_slowpath_common+0x9c/0xb6   [<ffffffff814e725b>] ? __list_del_entry+0x5a/0x98   [<ffffffff81079162>] warn_slowpath_fmt+0x46/0x48   [<ffffffff81820eb0>] ? dev_graft_qdisc+0x5e/0x6a   [<ffffffff814e725b>] __list_del_entry+0x5a/0x98   [<ffffffff814e72a7>] list_del+0xe/0x2d   [<ffffffff81822f05>] qdisc_list_del+0x1e/0x20   [<ffffffff81820cd1>] qdisc_destroy+0x30/0xd6   [<ffffffff81822676>] qdisc_graft+0x11d/0x243   [<ffffffff818233c1>] tc_get_qdisc+0x1a6/0x1d4   [<ffffffff810b5eaf>] ? mark_lock+0x2e/0x226   [<ffffffff817ff8f5>] rtnetlink_rcv_msg+0x181/0x194   [<ffffffff817ff72e>] ? rtnl_lock+0x17/0x19   [<ffffffff817ff72e>] ? rtnl_lock+0x17/0x19   [<ffffffff817ff774>] ? __rtnl_unlock+0x17/0x17   [<ffffffff81855dc6>] netlink_rcv_skb+0x4d/0x93   [<ffffffff817ff756>] rtnetlink_rcv+0x26/0x2d   [<ffffffff818544b2>] netlink_unicast+0xcb/0x150   [<ffffffff81161db9>] ? might_fault+0x59/0xa9   [<ffffffff81854f78>] netlink_sendmsg+0x4fa/0x51c   [<ffffffff817d6e09>] sock_sendmsg_nosec+0x12/0x1d   [<ffffffff817d8967>] sock_sendmsg+0x29/0x2e   [<ffffffff817d8cf3>] ___sys_sendmsg+0x1b4/0x23a   [<ffffffff8100a1b8>] ? native_sched_clock+0x35/0x37   [<ffffffff810a1d83>] ? sched_clock_local+0x12/0x72   [<ffffffff810a1fd4>] ? sched_clock_cpu+0x9e/0xb7   [<ffffffff810def2a>] ? current_kernel_time+0xe/0x32   [<ffffffff810b4bc5>] ? lock_release_holdtime.part.29+0x71/0x7f   [<ffffffff810ddebf>] ? read_seqcount_begin.constprop.27+0x5f/0x76   [<ffffffff810b6292>] ? trace_hardirqs_on_caller+0x17d/0x199   [<ffffffff811b14d5>] ? __fget_light+0x50/0x78   [<ffffffff817d9808>] __sys_sendmsg+0x42/0x60   [<ffffffff817d9838>] SyS_sendmsg+0x12/0x1c   [<ffffffff81a50e97>] system_call_fastpath+0x12/0x6f  ---[ end trace ef29d3fb28e97ae7 ]---  For long term, we probably need to clean up the qdisc_graft() code in case it hides other bugs like this.  Fixes: 95dc19299f74 (\"pkt_sched: give visibility to mq slave qdiscs\") Cc: Jamal Hadi Salim [URL]>", "target": 0}
{"idx": 1519, "commit_message": "[ARM] tegra: pinmux: add safe values, move tegra2, add suspend  - the reset values for some pin groups in the tegra pin mux can result in functional errors due to conflicting with actively-configured pin groups muxing from the same controller. this change adds a known safe, non- conflicting mux for every pin group, which can be used on platforms where the pin group is not routed to any peripheral  - also add each pin group's I/O voltage rail, to enable platform code to map from the pin groups used by each interface to the regulators used for dynamic voltage control  - add routines to individually configure the tristate, pin mux and pull- ups for a pingroup_config array, so that it is possible to program individual values at run-time without modifying other values. this allows driver power-management code to reprogram individual interfaces into lower power states during idle / suspend, or to reprogram the pin mux to support multiple physical busses per internal controller (e.g., sharing a single I2C or SPI controller across multiple pin groups)  - move chip-specific data like pingroups and drive-pingroups out of the common code and into chip-specific code  - fix debug output for group with no pullups  - add a TEGRA_MUX_SAFE function.  Setting a pingroup to TEGRA_MUX_SAFE will automatically select a mux setting that is guaranteed not to conflict with any of the hardware blocks.", "target": 1}
{"idx": 2849, "commit_message": "Had enough of a siesta - getting back into development beginning with a rewrite if the starter. added: made authentication a little smarter, using PROTOCOLINFO to autodetect authentication type and cookie location change: made 'blind mode' (disables connection queries) a startup option rather than flag in source (request by Sebastian) change: all log events (including arm) are now set via character flags, with TorCtl events log as their own toggleable type change: starting log label with runlevel events, condensing if logging a range change: simplifying command line parsing via getopt fix: blind mode now prevents all netstats (including connection counts and halting resolver thread), improving performance    svn:r21580", "target": 1}
{"idx": 3682, "commit_message": "mtd: fix: avoid race condition when accessing mtd->usecount  commit 073db4a51ee43ccb827f54a4261c0583b028d5ab upstream.  On A MIPS 32-cores machine a BUG_ON was triggered because some acesses to mtd->usecount were done without taking mtd_table_mutex. kernel: Call Trace: kernel: [<ffffffff80401818>] __put_mtd_device+0x20/0x50 kernel: [<ffffffff804086f4>] blktrans_release+0x8c/0xd8 kernel: [<ffffffff802577e0>] __blkdev_put+0x1a8/0x200 kernel: [<ffffffff802579a4>] blkdev_close+0x1c/0x30 kernel: [<ffffffff8022006c>] __fput+0xac/0x250 kernel: [<ffffffff80171208>] task_work_run+0xd8/0x120 kernel: [<ffffffff8012c23c>] work_notifysig+0x10/0x18 kernel: kernel:         Code: 2442ffff  ac8202d8  000217fe <00020336> dc820128  10400003                00000000  0040f809  00000000 kernel: ---[ end trace 080fbb4579b47a73 ]---  Fixed by taking the mutex in blktrans_open and blktrans_release.  Note that this locking is already suggested in include/linux/mtd/blktrans.h:  struct mtd_blktrans_ops { ... \t/* Called with mtd_table_mutex held; no race with add/remove */ \tint (*open)(struct mtd_blktrans_dev *dev); \tvoid (*release)(struct mtd_blktrans_dev *dev); ... };  But we weren't following it.  Originally reported by (and patched by) Zhang and Giuseppe, independently. Improved and rewritten.  Reported-by: Zhang Xingcai [URL]> Reported-by: Giuseppe Cantavenera [URL]> Tested-by: Giuseppe Cantavenera [URL]> Acked-by: Alexander Sverdlin [URL]>", "target": 0}
{"idx": 3960, "commit_message": "Merge pull request #114 from adimosh/dev  Performance improvement of PropertyChanged and CollectionChanged", "target": 1}
{"idx": 3252, "commit_message": "PM / OPP: Initialize regulator pointer to an error value  We are currently required to do two checks for regulator pointer: IS_ERR() and IS_NULL().  And multiple instances are reported, about both of these not being used consistently and so resulting in crashes.  Fix that by initializing regulator pointer with an error value and checking it only against an error.  This makes code more consistent and more efficient.  Fixes: 7d34d56ef334 (PM / OPP: Disable OPPs that aren't supported by the regulator) Reported-and-tested-by: Jon Hunter [URL]> Reported-and-tested-by: Tony Lindgren [URL]> Reported-and-tested-by: Guenter Roeck [URL]>", "target": 1}
{"idx": 4130, "commit_message": "[PATCH] Performance improvements for find_*_neighbors, and a new\n find_point_neighbors version for finding neighbors at just one point", "target": 1}
{"idx": 2235, "commit_message": "% fixed performance issues, when class names are getting parsed constantly + DOM.CSS.getClass method, returning actual class name for the element + Array.heapSort method", "target": 1}
{"idx": 3117, "commit_message": "zlib_deflate/deftree: remove bi_reverse()  Remove bi_reverse() and use generic bitrev32() instead - it should have better performance on some platforms.", "target": 1}
{"idx": 3018, "commit_message": "Improve performance of finding tree entries", "target": 1}
{"idx": 3572, "commit_message": "A number of smaller fixes and performance improvements:  - Implemented Get() directly instead of building on top of a full   merging iterator stack.  This speeds up the \"readrandom\" benchmark   by up to 15-30%.  - Fixed an opensource compilation problem.   Added --db=<name> flag to control where the database is placed.  - Automatically compact a file when we have done enough   overlapping seeks to that file.  - Fixed a performance bug where we would read from at least one   file in a level even if none of the files overlapped the key   being read.  - Makefile fix for Mac OSX installations that have XCode 4 without XCode 3.  - Unified the two occurrences of binary search in a file-list   into one routine.  - Found and fixed a bug where we would unnecessarily search the   last file when looking for a key larger than all data in the   level.  - A fix to avoid the need for trivial move compactions and   therefore gets rid of two out of five syncs in \"fillseq\".  - Removed the MANIFEST file write when switching to a new   memtable/log-file for a 10-20% improvement on fill speed on ext4.  - Adding a SNAPPY setting in the Makefile for folks who have   Snappy installed. Snappy compresses values and speeds up writes.", "target": 1}
{"idx": 2145, "commit_message": "Fix checkForBeanstalkErrors  The parser was dodgy for some reason, so I just replaced it with substring comparisons. Faster and easier, and equivalent. Previously, checkForBeanstalkErrors would sometimes raise an extraneous OutOfMemoryException.", "target": 1}
{"idx": 2823, "commit_message": "Improve EasyAdapter performance, onSetListeners() is now only called once when the ItemViewHolder is created. Refactor EasyAdapter moving some of the code to EasyAdapterUtil", "target": 1}
{"idx": 3923, "commit_message": "Gwent data from patch 0.8.50 and improved console messages.", "target": 0}
{"idx": 3869, "commit_message": "Loading a worker script should not be O(n^2) [URL]/show_bug.cgi?id=95518  Reviewed by Benjamin Poulain.  Previously, we would malloc a new buffer and memcpy the entire worker script every time we got another packet of data from the network. This patch uses StringBuilder to accumulate the buffer more efficiently.  * workers/WorkerScriptLoader.cpp: (WebCore::WorkerScriptLoader::WorkerScriptLoader): (WebCore::WorkerScriptLoader::didReceiveData): (WebCore::WorkerScriptLoader::didFinishLoading): (WebCore): (WebCore::WorkerScriptLoader::script): * workers/WorkerScriptLoader.h: (WorkerScriptLoader):", "target": 1}
{"idx": 861, "commit_message": "Added jquery script to dynamically collapse and expand sidebar menus.", "target": 0}
{"idx": 1108, "commit_message": "Improved a little bit the example and show how to compute the deps for all the files in QtCore.", "target": 0}
{"idx": 2538, "commit_message": "Configuration: increased \"mvrbtree.entryPoints\" from 16 to 64 as default value. This avoid the break of performance after the index optimization routine runs", "target": 1}
{"idx": 1880, "commit_message": "Merge pull request #52 from maurocolella/feature/improve-style-and-function  Improve style and function", "target": 0}
{"idx": 1084, "commit_message": "Some styling improvements.  Log In function is coming next", "target": 0}
{"idx": 3753, "commit_message": "exportfs: fix quadratic behavior in filehandle lookup  Suppose we're given the filehandle for a directory whose closest ancestor in the dcache is its Nth ancestor.  The main loop in reconnect_path searches for an IS_ROOT ancestor of target_dir, reconnects that ancestor to its parent, then recommences the search for an IS_ROOT ancestor from target_dir.  This behavior is quadratic in N.  And there's really no need to restart the search from target_dir each time: once a directory has been looked up, it won't become IS_ROOT again.  So instead of starting from target_dir each time, we can continue where we left off.  This simplifies the code and improves performance on very deep directory heirachies.  (I can't think of any reason anyone should need heirarchies a hundred or more deep, but the performance improvement may be valuable if only to limit damage in case of abuse.)", "target": 1}
{"idx": 736, "commit_message": "gnetworkmonitornetlink: Close the socket after disconnecting its GSources  `read_netlink_messages()` is the callback attached to the netlink socket (G_IO_IN). It calls `g_socket_receive_message()`. There is a race condition that if the socket is closed while there is a pending call, we will try to receive on a closed socket, which fails.  To avoid this, we switch the order of the operations around: first destroy the source and then close the socket.", "target": 0}
{"idx": 3516, "commit_message": "Improved performance of report* objects through queries", "target": 1}
{"idx": 3838, "commit_message": "ARROW-3321: [C++] Improve integer parsing performance  Before: ``` --------------------------------------------------------------------- Benchmark                              Time           CPU Iterations --------------------------------------------------------------------- BM_IntegerParsing<Int8Type>         1388 ns       1387 ns     502861   5.49911M items/s BM_IntegerParsing<Int16Type>        1475 ns       1475 ns     468724   5.17179M items/s BM_IntegerParsing<Int32Type>        1730 ns       1729 ns     405693   4.41194M items/s BM_IntegerParsing<Int64Type>        2131 ns       2131 ns     328192   3.58034M items/s BM_IntegerParsing<UInt8Type>        1238 ns       1238 ns     572573   6.16483M items/s BM_IntegerParsing<UInt16Type>       1302 ns       1301 ns     537960   5.86206M items/s BM_IntegerParsing<UInt32Type>       1391 ns       1391 ns     502859    5.4857M items/s BM_IntegerParsing<UInt64Type>       1637 ns       1637 ns     427832     4.661M items/s BM_FloatParsing<FloatType>          4437 ns       4436 ns     156887   1.71973M items/s BM_FloatParsing<DoubleType>         4593 ns       4592 ns     152459   1.66129M items/s ```  After: ``` --------------------------------------------------------------------- Benchmark                              Time           CPU Iterations --------------------------------------------------------------------- BM_IntegerParsing<Int8Type>           23 ns         23 ns   29800687   324.788M items/s BM_IntegerParsing<Int16Type>          27 ns         27 ns   26593165   287.438M items/s BM_IntegerParsing<Int32Type>          34 ns         34 ns   20689813   226.211M items/s BM_IntegerParsing<Int64Type>          49 ns         49 ns   14256379   155.424M items/s BM_IntegerParsing<UInt8Type>          17 ns         17 ns   42295211   454.911M items/s BM_IntegerParsing<UInt16Type>         16 ns         16 ns   42663172   464.397M items/s BM_IntegerParsing<UInt32Type>         21 ns         21 ns   33372432   363.209M items/s BM_IntegerParsing<UInt64Type>         33 ns         33 ns   21502295   234.255M items/s BM_FloatParsing<FloatType>          4554 ns       4553 ns     153207   1.67565M items/s BM_FloatParsing<DoubleType>         4579 ns       4578 ns     152304   1.66651M items/s ```  Author: Antoine Pitrou [URL]>  Closes #2619 from pitrou/ARROW-3321-faster-int-conversion and squashes the following commits:  9834b28e6 <Antoine Pitrou> ARROW-3321:  Improve integer parsing performance", "target": 1}
{"idx": 2960, "commit_message": "Separated all of the filters to make more readable and efficient", "target": 1}
{"idx": 474, "commit_message": "blkcg: don't call into policy draining if root_blkg is already gone  commit 0b462c89e31f7eb6789713437eb551833ee16ff3 upstream.  While a queue is being destroyed, all the blkgs are destroyed and its ->root_blkg pointer is set to NULL.  If someone else starts to drain while the queue is in this state, the following oops happens.    NULL pointer dereference at 0000000000000028   IP: [<ffffffff8144e944>] blk_throtl_drain+0x84/0x230   PGD e4a1067 PUD b773067 PMD 0   Oops: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC   Modules linked in: cfq_iosched(-) [last unloaded: cfq_iosched]   CPU: 1 PID: 537 Comm: bash Not tainted 3.16.0-rc3-work+ #2   Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011   task: ffff88000e222250 ti: ffff88000efd4000 task.ti: ffff88000efd4000   RIP: 0010:[<ffffffff8144e944>]  [<ffffffff8144e944>] blk_throtl_drain+0x84/0x230   RSP: 0018:ffff88000efd7bf0  EFLAGS: 00010046   RAX: 0000000000000000 RBX: ffff880015091450 RCX: 0000000000000001   RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000000000000000   RBP: ffff88000efd7c10 R08: 0000000000000000 R09: 0000000000000001   R10: ffff88000e222250 R11: 0000000000000000 R12: ffff880015091450   R13: ffff880015092e00 R14: ffff880015091d70 R15: ffff88001508fc28   FS:  00007f1332650740(0000) GS:ffff88001fa80000(0000) knlGS:0000000000000000   CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b   CR2: 0000000000000028 CR3: 0000000009446000 CR4: 00000000000006e0   Stack:    ffffffff8144e8f6 ffff880015091450 0000000000000000 ffff880015091d80    ffff88000efd7c28 ffffffff8144ae2f ffff880015091450 ffff88000efd7c58    ffffffff81427641 ffff880015091450 ffffffff82401f00 ffff880015091450   Call Trace:    [<ffffffff8144ae2f>] blkcg_drain_queue+0x1f/0x60    [<ffffffff81427641>] __blk_drain_queue+0x71/0x180    [<ffffffff81429b3e>] blk_queue_bypass_start+0x6e/0xb0    [<ffffffff814498b8>] blkcg_deactivate_policy+0x38/0x120    [<ffffffff8144ec44>] blk_throtl_exit+0x34/0x50    [<ffffffff8144aea5>] blkcg_exit_queue+0x35/0x40    [<ffffffff8142d476>] blk_release_queue+0x26/0xd0    [<ffffffff81454968>] kobject_cleanup+0x38/0x70    [<ffffffff81454848>] kobject_put+0x28/0x60    [<ffffffff81427505>] blk_put_queue+0x15/0x20    [<ffffffff817d07bb>] scsi_device_dev_release_usercontext+0x16b/0x1c0    [<ffffffff810bc339>] execute_in_process_context+0x89/0xa0    [<ffffffff817d064c>] scsi_device_dev_release+0x1c/0x20    [<ffffffff817930e2>] device_release+0x32/0xa0    [<ffffffff81454968>] kobject_cleanup+0x38/0x70    [<ffffffff81454848>] kobject_put+0x28/0x60    [<ffffffff817934d7>] put_device+0x17/0x20    [<ffffffff817d11b9>] __scsi_remove_device+0xa9/0xe0    [<ffffffff817d121b>] scsi_remove_device+0x2b/0x40    [<ffffffff817d1257>] sdev_store_delete+0x27/0x30    [<ffffffff81792ca8>] dev_attr_store+0x18/0x30    [<ffffffff8126f75e>] sysfs_kf_write+0x3e/0x50    [<ffffffff8126ea87>] kernfs_fop_write+0xe7/0x170    [<ffffffff811f5e9f>] vfs_write+0xaf/0x1d0    [<ffffffff811f69bd>] SyS_write+0x4d/0xc0    [<ffffffff81d24692>] system_call_fastpath+0x16/0x1b  776687bce42b (\"block, blk-mq: draining can't be skipped even if bypass_depth was non-zero\") made it easier to trigger this bug by making blk_queue_bypass_start() drain even when it loses the first bypass test to blk_cleanup_queue(); however, the bug has always been there even before the commit as blk_queue_bypass_start() could race against queue destruction, win the initial bypass test but perform the actual draining after blk_cleanup_queue() already destroyed all blkgs.  Fix it by skippping calling into policy draining if all the blkgs are already gone.", "target": 0}
{"idx": 1669, "commit_message": "Combine Ship rotation & linear movement  Now when a ship movement command is received by the manu subsytem it will create a new linear movement strategy for corresponding location w/ rotational parameters baked in.  Also sets stop_angle and stop_distance, and applies these changes to follow algorithm as well resulting in more concise/ cleaner movement.  Various other small tweaks to get things working, specs need to be updated to reflect new functionality", "target": 0}
{"idx": 3515, "commit_message": "All DFG nodes should have a mutable set of flags [URL]/show_bug.cgi?id=80779 <rdar://problem/11026218>  Reviewed by Gavin Barraclough.          Got rid of NodeId, and placed all of the flags that distinguished NodeId from NodeType into a separate Node::flags field. Combined what was previously ArithNodeFlags into Node::flags.          In the process of debugging, I found that the debug support in the virtual register allocator was lacking, so I improved it. I also realized that the virtual register allocator was assuming that the nodes in a basic block were contiguous, which is no longer the case. So I fixed that. The fix also made it natural to have more extreme assertions, so I added them. I suspect this will make it easier to catch virtual register allocation bugs in the future.          This is mostly performance neutral; if anything it looks like a slight speed-up.          This patch does leave some work for future refactorings; for example, Node::op is unencapsulated. This was already the case, though now it feels even more like it should be. I avoided doing that because this patch has already grown way bigger than I wanted.          Finally, this patch creates a DFGNode.cpp file and makes a slight effort to move some unnecessarily inline stuff out of DFGNode.h.  * CMakeLists.txt: * GNUmakefile.list.am: * JavaScriptCore.xcodeproj/project.pbxproj: * Target.pri: * dfg/DFGArithNodeFlagsInferencePhase.cpp: (JSC::DFG::ArithNodeFlagsInferencePhase::propagate): * dfg/DFGByteCodeParser.cpp: (JSC::DFG::ByteCodeParser::addToGraph): (JSC::DFG::ByteCodeParser::makeSafe): (JSC::DFG::ByteCodeParser::makeDivSafe): (JSC::DFG::ByteCodeParser::handleMinMax): (JSC::DFG::ByteCodeParser::handleIntrinsic): (JSC::DFG::ByteCodeParser::parseBlock): * dfg/DFGCFAPhase.cpp: (JSC::DFG::CFAPhase::performBlockCFA): * dfg/DFGCSEPhase.cpp: (JSC::DFG::CSEPhase::endIndexForPureCSE): (JSC::DFG::CSEPhase::pureCSE): (JSC::DFG::CSEPhase::clobbersWorld): (JSC::DFG::CSEPhase::impureCSE): (JSC::DFG::CSEPhase::setReplacement): (JSC::DFG::CSEPhase::eliminate): (JSC::DFG::CSEPhase::performNodeCSE): (JSC::DFG::CSEPhase::performBlockCSE): (CSEPhase): * dfg/DFGGraph.cpp: (JSC::DFG::Graph::opName): (JSC::DFG::Graph::dump): (DFG): * dfg/DFGNode.cpp: Added. (DFG): (JSC::DFG::arithNodeFlagsAsString): * dfg/DFGNode.h: (DFG): (JSC::DFG::nodeUsedAsNumber): (JSC::DFG::nodeCanTruncateInteger): (JSC::DFG::nodeCanIgnoreNegativeZero): (JSC::DFG::nodeMayOverflow): (JSC::DFG::nodeCanSpeculateInteger): (JSC::DFG::defaultFlags): (JSC::DFG::Node::Node): (Node): (JSC::DFG::Node::setOpAndDefaultFlags): (JSC::DFG::Node::mustGenerate): (JSC::DFG::Node::arithNodeFlags): (JSC::DFG::Node::setArithNodeFlag): (JSC::DFG::Node::mergeArithNodeFlags): (JSC::DFG::Node::hasResult): (JSC::DFG::Node::hasInt32Result): (JSC::DFG::Node::hasNumberResult): (JSC::DFG::Node::hasJSResult): (JSC::DFG::Node::hasBooleanResult): (JSC::DFG::Node::isJump): (JSC::DFG::Node::isBranch): (JSC::DFG::Node::isTerminal): (JSC::DFG::Node::child1): (JSC::DFG::Node::child2): (JSC::DFG::Node::child3): (JSC::DFG::Node::firstChild): (JSC::DFG::Node::numChildren): * dfg/DFGPredictionPropagationPhase.cpp: (JSC::DFG::PredictionPropagationPhase::propagate): (JSC::DFG::PredictionPropagationPhase::vote): (JSC::DFG::PredictionPropagationPhase::fixupNode): * dfg/DFGScoreBoard.h: (ScoreBoard): (JSC::DFG::ScoreBoard::~ScoreBoard): (JSC::DFG::ScoreBoard::assertClear): (JSC::DFG::ScoreBoard::use): * dfg/DFGSpeculativeJIT.cpp: (JSC::DFG::SpeculativeJIT::useChildren): * dfg/DFGSpeculativeJIT32_64.cpp: (JSC::DFG::SpeculativeJIT::compile): * dfg/DFGSpeculativeJIT64.cpp: (JSC::DFG::SpeculativeJIT::compile): * dfg/DFGVirtualRegisterAllocationPhase.cpp: (JSC::DFG::VirtualRegisterAllocationPhase::run):", "target": 0}
{"idx": 3670, "commit_message": "Update to use Reference Class OOP system  Instead of keeping data, registry, counter, etc, separate, they are now combined into a class using the Reference class system. The reference class system was chosen as opposed to an S3 or S4 class because it seems to be appropriate for objects that update themselves (they don't copy-on-modify), which hopefully will lead to performance improvements.  This change required major refactoring of most all functions, but will greatly simplify the workflow.", "target": 1}
{"idx": 3656, "commit_message": "Cost function and sequence execution implemented  Next steps: * Implement feasibility preserving function in case of system violations * Look into increasing performance (currently ~5 sec per restoration) * Create an optimization method evaluation methodology * Genetic optimization * Tree search optimization * Look for better computing resources", "target": 1}
{"idx": 3995, "commit_message": "[PATCH] Possible performance enhancement in Mesh::delete_elem. We use\n the passed Elems id() as a guess for the location of the Elem in the\n _elements vector. If the guess does not succeed, then we revert to the linear\n search.", "target": 1}
{"idx": 3051, "commit_message": "Cache hashcode for join node spec: performance improvement.", "target": 1}
{"idx": 2636, "commit_message": "Localize sonata_type_date_picker and sonata_type_datetime_picker form fields  Comment unneded format parts in MomentFormatConverter to improve performance", "target": 1}
{"idx": 3045, "commit_message": "Recreated temperature subsystem to use Fork/Join framework to improve performance", "target": 1}
{"idx": 1937, "commit_message": "msm: acpuclock-8960: Clean up krait rail voltage calculation  Previously, the krait rail voltage is calculated by the maximum of krait core voltage and the hfpll voltage given a freq level. However, the hfpll voltage has been taken into account when the hardware designers provide the krait core voltage value for each freq level, which means this voltage is good for the hfpll as well. Therefore, clean up the calculation by just using the krait core's voltage.", "target": 0}
{"idx": 1314, "commit_message": "Refs #1484/OFBIZ patch: renderer: targeted rendering: contains-expr: TODO: NOT doing this for the moment, because it's difficult optimization: STILL NEED TO IMPLEMENT WidgetRenderTargetExpr NORMALIZATION AND HANDLING FROM ContainsExpr SO THAT EXCLUDE OPTIMIZATIONS ARE FULLY HONORED", "target": 0}
{"idx": 3806, "commit_message": "Merge pull request #141 from dubek/set-union-performance  Optimize Set#union for better performance when receiver is small Set and arg is large Set", "target": 1}
{"idx": 3846, "commit_message": "python3-pillow: Upgrade 8.3.2 -> 9.0.0  Upgrade to release 9.0.0:  - Restrict builtins for ImageMath.eval() - Ensure JpegImagePlugin stops at the end of a truncated file - Fixed ImagePath.Path array handling - Remove consecutive duplicate tiles that only differ by their   offset - Removed redundant part of condition - Explicitly enable strip chopping for large uncompressed TIFFs - Use the Windows method to get TCL functions on Cygwin - Changed error type to allow for incremental WebP parsing - Improved I;16 operations on big endian - Ensure that BMP pixel data offset does not ignore palette - Limit quantized palette to number of colors - Use latin1 encoding to decode bytes - Fixed palette index for zeroed color in FASTOCTREE quantize - When saving RGBA to GIF, make use of first transparent palette   entry - Pass SAMPLEFORMAT to libtiff - Added rounding when converting P and PA - Improved putdata() documentation and data handling - Exclude carriage return in PDF regex to help prevent ReDoS - Image.NONE is only used for resampling and dithers - Fixed freeing pointer in ImageDraw.Outline.transform - Add Tidelift alignment action and badge - Replaced further direct invocations of setup.py - Added ImageShow support for xdg-open - Switched from deprecated \"setup.py install\" to \"pip install .\" - Support 16-bit grayscale ImageQt conversion - Fixed raising OSError in _safe_read when size is greater than   SAFEBLOCK - Convert subsequent GIF frames to RGB or RGBA - WebP: Fix memory leak during decoding on failure - Do not prematurely return in ImageFile when saving to stdout - Added support for top right and bottom right TGA orientations - Corrected ICNS file length in header - Block tile TIFF tags when saving - Added line width argument to ImageDraw polygon - Do not redeclare class each time when converting to NumPy - Only prevent repeated polygon pixels when drawing with   transparency - Fix pushes_fd method signature - Add support for pickling TrueType fonts - Only prefer command line tools SDK on macOS over default   MacOSX SDK - Fix compilation on 64-bit Termux - Replace 'setup.py sdist' with '-m build --sdist' - Use declarative package configuration - Use title for display in ImageShow - Fix for PyQt6 - Rename master to main", "target": 0}
{"idx": 2864, "commit_message": "SCSI: sd: fix array cache flushing bug causing performance problems  commit 39c60a0948cc06139e2fbfe084f83cb7e7deae3b upstream.  Some arrays synchronize their full non volatile cache when the sd driver sends a SYNCHRONIZE CACHE command.  Unfortunately, they can have Terrabytes of this and we send a SYNCHRONIZE CACHE for every barrier if an array reports it has a writeback cache.  This leads to massive slowdowns on journalled filesystems.  The fix is to allow userspace to turn off the writeback cache setting as a temporary measure (i.e. without doing the MODE SELECT to write it back to the device), so even though the device reported it has a writeback cache, the user, knowing that the cache is non volatile and all they care about is filesystem correctness, can turn that bit off in the kernel and avoid the performance ruinous (and safety irrelevant) SYNCHRONIZE CACHE commands.  The way you do this is add a 'temporary' prefix when performing the usual cache setting operations, so  echo temporary write through > /sys/class/scsi_disk/<disk>/cache_type  Reported-by: Ric Wheeler [URL]>", "target": 1}
{"idx": 2575, "commit_message": "Greatly improved performance - now all children are scanned for the closest hit.  Image look inverted, maybe my logic is inverted too ?", "target": 1}
{"idx": 1396, "commit_message": "Improve debugging experience: add global switch MSBuildDebugEngine; Inject binary logger from BuildManager; print static graph as .dot file (#6639)  ### Context  There's still a bit of friction when debugging MSBuild, especially under VS. You have to set multiple env vars, or search through temp, find all the obscure env var names, etc    ### Changes Made  - add one env var, `MSBuildDebugEngine` to turn everything on and also automatically pick `./MSBuild_Logs` as the debug log path for everything that spews out log files.  - in addition, when `MSBuildDebugEngine`:     - inject a binary logger directly from the build manager. This is super useful when running MSBuild in VS, as the build logging that VS gives is kind of lacking    - dump a `.dot` representation of the static graph, when one is available    This is how `MSBuild_Logs` looks like after doing a build (both VS and cmdline should produce this):  [URL]/2255729/123869003-4b74fa80-d8e5-11eb-8fef-bd0bea421411.png)", "target": 0}
{"idx": 1588, "commit_message": "Split SCTP initmsg test into two test cases  The original test allocates 65535 output streams which may fail on older kernels due to lack of memory. Split the test into two test cases: - allocate 10 output streams and accept no errors (functional test) - allocate 65535 output streams and accept ENOMEM (stress test)  Also clean up some unnecessary code and check that the test message is transferred correctly.", "target": 0}
{"idx": 2336, "commit_message": "- x86 back end: change code generation convention, so that instead of   dispatchers CALLing generated code which later RETs, dispatchers   jump to generated code and it jumps back to the dispatcher.  This   removes two memory references per translation run and by itself   gives a measureable performance improvement on P4.  As a result,   there is new plumbing so that the caller of LibVEX_Translate can   supply the address of the dispatcher to jump back to.    This probably breaks all other targets.  Do not update.  - Administrative cleanup: LibVEX_Translate has an excessive   number of arguments.  Remove them all and instead add a struct   by which the arguments are supplied.  Add further comments    about the meaning of some fields.", "target": 1}
{"idx": 188, "commit_message": "Improved documentation. Fix problem in which Admin Console doesn't send correct cookie when setting up cookie rule.", "target": 0}
{"idx": 3313, "commit_message": "[Java] Fixed InMemoryMulticastReceiverRegistry  * The idPattern which was generated here when a multicast got registered   was most likely a new object. If this was used as key for the   ConcurrentMap then we got a new map entry per call even for the same   multicastId.    Consequently the unregistry of entries failed because then newly   created Pattern object was not yet used as key part of the map.  * Now the multicastId is used as key of the Map (which remains the same   for registry / unregistry) and thus will be found.    Since the Pattern is still needed for matching (we don't want to   rebuild it all the time due to performance reasons) we store   an instance of new class PatternEntry as value, which contains   both the pattern and the set of participantIds (which was   previously the only value).  * Also made all methods synchronized in order to avoid race conditions.   ConcurrentMap got replaced by HashMap because synchronized already   covers concurrency protection.  * A test case has been added for multiple participants registering   for the same multicast id, using the real MulticastWildcardRegexFactory   which invokes the pattern creation from scratch on every invocation   thereby creating distinct objects.", "target": 1}
{"idx": 3859, "commit_message": "Merge branch 'master' into rails4  * master: (59 commits)   Unclustered hosts are missing from relationship tree when a cluster is present   Fixed HAML syntax.   Disable bundle install concurrency during kickstart of appliance.   Added check for VM view access on Service summary screen.   Only execute scheduled SCVMM ems_refresh if a SCVMM provider is present   Removed a leftover puts.   New service type for orchestration provisioning   UI: honor button groups order   Add tests.   Fix provision status issue.   Fix checked dynatree behavior.   Converted Advanced search pop up to Bootstrap   Added new images for stacks   @edit[:organizations] is nil for SAT5 and RHSM Hosted   UI: don't allow to add an empty ldap forest entry   Do not add a title to performance charts.   Fix configuration of LDAP authentication   Access to orchestration templates: view & modify   Fixed the cluster in datacenter issue for Host or VM Analysis/Compliance Check. (drop down issue in the UI)   Fixed Jasmine specs (again)   ... (transferred from ManageIQ/ )", "target": 0}
{"idx": 383, "commit_message": "e100: Fix ring parameter change handling regression.  When the PCI pool changes were added to fix resume failures:  commit 98468efddb101f8a29af974101c17ba513b07be1 e100: Use pci pool to work around GFP_ATOMIC order 5 memory allocation failu  and  commit 70abc8cb90e679d8519721e2761d8366a18212a6 e100: Fix broken cbs accounting due to missing memset.  This introduced a problem that can happen if the TX ring size is increased.  We need to size the PCI pool using cbs->max instead of the default cbs->count value.", "target": 0}
{"idx": 2888, "commit_message": "CCPR: Transform path points before parsing  Transforms a path's points into a local buffer up front, rather than transforming as we parse. This hopefully gets better vector performance as well as allowing us to skip the transformation step for paths that are known to be in device space already.  Introduces a test for parsing empty paths and does general cleanup.  Bug: skia:7190", "target": 1}
{"idx": 2685, "commit_message": "sched: Postpone actual migration disalbe to schedule  The migrate_disable() can cause a bit of a overhead to the RT kernel, as changing the affinity is expensive to do at every lock encountered. As a running task can not migrate, the actual disabling of migration does not need to occur until the task is about to schedule out.  In most cases, a task that disables migration will enable it before it schedules making this change improve performance tremendously.  [ Frank Rowand: UP compile fix ]", "target": 1}
{"idx": 1231, "commit_message": "[ImgBot] Optimize images  *Total -- 650.84kb -> 580.13kb (10.87%)  /Web Interface/img/wood_1.png -- 614.20kb -> 543.96kb (11.44%) /Web Interface/img/favicon.png -- 36.64kb -> 36.17kb (1.3%)", "target": 1}
{"idx": 3564, "commit_message": "app/crypto-perf: fix invalid latency for QAT  Fixes invalid latency result when using the performance application and hardware QAT PMD. It occurred when the number of processed packets was higher then the size of the internal QAT PMD ring buffer and the buffer was overflowed. Fixed by correcting the registration of the enqueued packets and freeing memory space for not enqueued packets.  Fixes: f8be1786b1b8 (\"app/crypto-perf: introduce performance test application\")", "target": 0}
{"idx": 898, "commit_message": "improve parsing, adding highlights to hot functions", "target": 0}
{"idx": 2546, "commit_message": "Refactor terrain border matching code for better performance and readability", "target": 1}
{"idx": 987, "commit_message": "Merge pull request #95 from quantumlib/io-split  Split io.h.", "target": 0}
{"idx": 478, "commit_message": "Fixes the crippled console output on PortuxG20.  In order to use the serial interface on the PortuxG20 we need to enable the level converter first by setting the PC9 pin to high. The level converter needs some time to settle so we have to use the mdelay() function to wait for some time. Unfortunately we have no timers available at board_early_init_f() so we enable the serial output early within board_postclk_init().  Now the U-Boot output looks fine:  | U-Boot 2012.07-00132-gaf1a3b0-dirty (Aug 16 2012 - 18:21:32) | | CPU: AT91SAM9G20 | Crystal frequency:   18.432 MHz | CPU clock        :  396.288 MHz | Master clock     :  132.096 MHz | DRAM:  64 MiB | WARNING: Caches not enabled | NAND:  128 MiB | In:    serial | Out:   serial | Err:   serial | Net:   macb0 | Hit any key to stop autoboot:  0", "target": 0}
{"idx": 2969, "commit_message": "kmix: Pass the signal for redrawing a single mixer right through to the KMixWindow.  This contains no functionality change, but it will allow us to redraw our window in a more efficient manner with some further development.  svn path=/trunk/KDE/kdemultimedia/kmix/; revision=1110904", "target": 0}
{"idx": 2441, "commit_message": "Reporting objectively bad reviews (#2038)  * Making clickable div show up as clickable.    Also laying in groundwork for ignoring and reporting reviews.    * No flagging highlighted reviews, gang.    * Simplified to one div for flag/edit icon.    Also, no flagging highlighted reviews.    * Simplifying review click dispatch.    * Added a class for reporting MALFEASANCE.    And calling it from flag click things.    * Don't report yourself, dummy.    * Whitespace.    * Reporting reviews should require confirmation.    Added UI bits to show/hide that.    * Are linebreaks at the end of imports needed?    I feel like I could be living in a state of sin otherwise.    * Building out click-to-really-report UI.    * My old eyes can't see the red on gray, but a different colored callout seems wrong?    * Theoretically, we can mark reviews as things to be ignored.    * Missing object in ctor.    * how method is invokd    * If we flag a user, we should ignore their other reviews.    * Fulfilling the API contract.    * Arrow function beats anonymous inline method.    * Supplying sync service to UserFilter.    * Touched changelog indicating flagging is here.    * Storage page will reflect how many ignored users you've got.    * SyncService is a promise, so we'll work within that for user filtering.    * You gotta be explicit about closing the flag context.    * Set the right key.    * Having a mechanism to empty out the ignored users list will be handy.    * Successfully emptying ignored users (in dev).    * Debug code oops'd.    * Linting fixes.    * Better styling on the review report buttons.    * Do the hamburger bars make it more obvious this is clickable?    * Improved styling of the callout div.    * Reporting a review shouldn't dismiss the popup.    * TIghtening up the click zone for the review workflow.    * Bonus styling on clickable elements - they should be links.    * Reviews are (hopefully) in vNext, not 4.6.0.    * Update CHANGELOG.md", "target": 0}
{"idx": 170, "commit_message": "disallow null subprograms in graphs package API  Most of the subprograms provided by the graph package that require an access to function/procedure parameter should never be run with a null access. This is now enforced by the API (and perhaps hints the compiler about a possible optimization).  (no-tn-check)  * gnat2why/flow/graphs.ads * gnat2why/flow/graphs.adb (BFS, DFS, Non_Trivial_Path_Exists, Shortest_Path, Conditional_Close,  Write_Dot_File, Write_Pdf_File): disallow calls with null access arguments.", "target": 0}
{"idx": 4001, "commit_message": "[PATCH] Use range for in dof_map.C\n\nWe can use more efficient iterators in a couple places here too.", "target": 1}
{"idx": 3780, "commit_message": "[ScheduleDAGInstrs / buildSchedGraph]  Clear subregister entries also.  In addPhysRegDeps, subregister entries of the defined register were previously not removed from Uses or Defs, which resulted in extra redundant edges for subregs around the register definition.  This is principally NFC (in very rare cases some node got a different height).  This makes the DAG more readable and efficient in some cases.  Review: Andy Trick [URL]/D46838", "target": 1}
{"idx": 1367, "commit_message": "Fixing import issue. Adding missing video field Optimize the query..  ECOM-7844", "target": 1}
{"idx": 1167, "commit_message": "[GeneratorBundle] Improve code style and code quality of generated classes", "target": 0}
{"idx": 3104, "commit_message": "Added character data buffering to pyexpat parser objects.  Setting the buffer_text attribute to true causes the parser to collect character data, waiting as long as possible to report it to the Python callback.  This can save an enormous number of callbacks from C to Python, which can be a substantial performance improvement.  buffer_text defaults to false.", "target": 1}
{"idx": 4017, "commit_message": "[PATCH] Improved ORB performance and memory usage on CUDA backend", "target": 1}
{"idx": 2900, "commit_message": "[Refactor] Remove OCMock dependency in ZMSyncStrategy tests (#1343)  * Remove usage of ZMObjectStrategyDirectory protocol  * Move request strategy creation into a factory  * Fix creation of ZMMissingUpdateEventsTranscoder filter request strategies correctly  * Fix ConversationStatusStrategy not being included in the list of change trackers  * Add missing strategy and remove duplicate strategy  * Revert scheme change  * Remove LocalNotificationDispatcher dependency from ZMSyncStrategy  * Replace OCMock objects with plain mocks  * Stop mocking the ApplicationStatusDirectory with OCMock  * Stop mocking the ZMUpdateEventsBuffer  * Remove OCMock import  * Delete ZMObjectStrategyDirectory  * Improve assertions in tests  * Revert \"Remove OCMock import\"  This reverts commit 1b6b1d4cfcfb0489943270fbd6e70ea01fbb1153.  * Use correct header", "target": 0}
{"idx": 1465, "commit_message": "Improved some combat animations of Kalenz and Konrad (as lord).", "target": 0}
{"idx": 3773, "commit_message": "First version of extracting RRULES from timeseries data, consecutive weeks are parsed out which now keeps about 25 percent of the events compared to the original timeseries list, improving on import and export (LOD) performance", "target": 1}
{"idx": 3937, "commit_message": "WL# 2094  This patch contains all that my previous patch (1.1814) contained, with the addition of using cli_fetch_lengths for handling binary data (Bar noted this on the review of 1.1814, Guilhem suggested using cli_fetch_lenghts by  making available via removal of static in method definition and declaration in mysql.h, but Konstantin had some reservations, but he said to commit the patch using this anyway, and I suppose this can be discussed. I abandoned 1.1814 because Monty made a couple fixes to my code as well as formatting changes, and I thought it would just be easier to hand-edit my changes into a fresh clone and then make a patch.   The reason for using cli_fetch_lengths is so that I can correctly get the length of the field I am setting into the field. I was previously using 'strlen' but Bar pointed out this won't correctly get the length of binary data and is also less effecient. Upon testing, it was in fact verified that binary data in a blob table was being inserted correctly, but not being retrieved correctly, all due to not having the correct value for the field:  (*field)->store(row[x], strlen(row[x]), &my_charset_bin);  was changed to:  (*field)->store(row[x], lengths[x], &my_charset_bin);  lengths being a unsigned long pointer to the values of the field lengths from a  MYSQL_ROW.  Since the server doesn't have the function \"mysql_fetch_lengths\" available, I tried  to use \"result->lengths\", but this isn't set, so I finally successfully used  cli_fetch_lenghts, which does give the correct lengths, and now the binary data gets retrieved correctly.  I've also run the code through indent-ex and am using Brian's vimrc to ensure correct formatting!  This code passes the entire test suite, without any errors or warning on both my  workstation and [URL]  --BZR-- revision-id: [URL]-20050206174007-15130 property-file-info: ld7:file_id60:sp1f-mysql.h-19700101030959-soi7hu6ji273nui3fm25jjf4m4362pcw7:message90:added cli_fetch_lengths to mysql.h in order to use this function in the federated handler property-file-info: 4:path15:include/mysql.hed7:file_id69:sp1f-federated.result-20041211200117-zbuxe4bh3vyrane2ehku7szsgbfbhkvd7:message135:- Moved countries to be created and inserted prior to federated test table property-file-info: - Added a test of inserting binary values into a blob table property-file-info: 4:path29:mysql-test/r/federated.resulted7:file_id67:sp1f-federated.test-20041211200119-aht6hujozcouca6joz5eaiq55jk6psb57:message124:- Moved order of countries table creation to prior to test table creation property-file-info: - Test insertion of binary values in a blob table property-file-info: 4:path27:mysql-test/t/federated.tested7:file_id61:sp1f-client.c-20030502160736-oraaciqy6jkfwygs6tqfoaxgjbi65yo77:message80:removed 'static' to allow cli_fetch_lengths to be used in the federated handler property-file-info: 4:path19:sql-common/client.ced7:file_id68:sp1f-ha_federated.cc-20041211200120-gu52ex5sicbua5vtoocuki3ltllsvm2c7:message1064:1. share->scheme that was created in parse_url was not being freed property-file-info: 2. HASH federated_open_tables was being deleted, but not freed property-file-info: 3. 'result' from mysql_store_result was not being free in several instances property-file-info: 4. Fixed the problem where a table scan was being performed after property-file-info: index_read_idx, which didn't cause a problem because the result set from property-file-info: idx_read_idx was not being freed, but once the result set was properly freed, property-file-info: it broke update_row. Now, I'm using the bool 'scan' to determine if I need to property-file-info: perform a table scan, which it magically is false when the query is an update property-file-info: with an index. property-file-info: 5. Changed all stings containing the query to perform in mysql_real_query property-file-info: calls from string.c_ptr_quick() to string.ptr() per Monty's suggestion property-file-info: (better performance) property-file-info: 6. Fixed various cast/type/truth compile warnings. property-file-info: 7. Removed 'load_conn_info' and just let 'parse_url' handle it. property-file-info: 8. Added the use of cli_fetch_lengths, needed to fix binary values being retrieved  property-file-info: from the database in rnd_next/convert_row_to_internal_format property-file-info: 9. Formatting changes by using indent-ex! property-file-info:  property-file-info:  property-file-info: 4:path19:sql/ha_federated.cced7:file_id67:sp1f-ha_federated.h-20041211200120-46qvxkyzym5wewxozk4xcbzljpbqxvlb7:message59:added scan flag, setting defaults for result and scan_flag property-file-info: 4:path18:sql/ha_federated.hee property-sp1-file-info:  |sql/ha_federated.h|20041211200120|30904|760656aa17e9340ee testament3-sha1: da79e5ce198fcc59a3bc3177fc96b6d4f52e4b64", "target": 1}
{"idx": 429, "commit_message": "[test] Remove an invalid check from the test ..  ..  RAR_Tests.SubsetListFinderVerifyEmptyInSubsetsToSearchForAndCaching  This is essentially checking if the the results of two different queries are two *different* empty array objects. This is an implementation detail and should not be relied upon. It is a legal optimization to return the same empty array object, which is what List.ToArray does on netcore and mono (on macOS). Full framework returns the same object, so this test passed on .net/windows.  So, remove that part of the test and reduce it to just ensuring that the method does not crash if it is passed empty string elements in the array. And rename to ..      RAR_Tests.SubsetListFinderVerifyEmptyInSubsetsToSearchFor", "target": 0}
{"idx": 2051, "commit_message": "f2fs: optimize fs_lock for better performance  There is a performance problem: when all sbi->fs_lock are holded, then all the following threads may get the same next_lock value from sbi->next_lock_num in function mutex_lock_op, and wait for the same lock(fs_lock[next_lock]), it may cause performance reduce. So we move the sbi->next_lock_num++ before getting lock, this will average the following threads if all sbi->fs_lock are holded.  v1-->v2: \tDrop the needless spin_lock as Jaegeuk suggested.  Suggested-by: Jaegeuk Kim [URL]>", "target": 1}
{"idx": 1655, "commit_message": "Fix initial track selection in ffmpeg demuxer  Current initial track selection logic is incorrect for files with unsupported audio/video streams. Those streams are included into detected_a/v_track_count, but we want only the first SUPPORTED audio and video tracks to be enabled initially.  Bug: 764330 Cq-Include-Trybots: master.tryserver.chromium.android:android_optional_gpu_tests_rel;master.tryserver.chromium.linux:linux_optional_gpu_tests_rel;master.tryserver.chromium.mac:mac_optional_gpu_tests_rel;master.tryserver.chromium.win:win_optional_gpu_tests_rel", "target": 0}
{"idx": 2961, "commit_message": "Merge pull request #14 from skangas/libxml-parse-xml-region  Use libxml when available to significantly improve performance", "target": 1}
{"idx": 40, "commit_message": "New: Add no-useless-backreference rule (fixes #12673) (#12690)  * New: Add no-useless-backreference rule (fixes #12673)    * Improve opening section in the docs, fix typo in a comment    * Reword the opening paragraph", "target": 0}
{"idx": 1747, "commit_message": "Improven even more the oAuth classes", "target": 0}
{"idx": 3575, "commit_message": "Improved the performance of the check for ignoring users  Fixes #2566", "target": 1}
{"idx": 3760, "commit_message": "Improve performance for buckets by using any cache  Before, everytime we computed buckets we did a full parse. Which is kindof useless", "target": 1}
{"idx": 668, "commit_message": "Roll src/third_party/skia 640898f:1864bfa  Summary of changes available at: [URL]/skia/+log/640898f..1864bfa  CQ_INCLUDE_TRYBOTS=tryserver.blink:linux_blink_rel [URL]  Commits in this roll: 1864bfa [URL] add radial gradient hard stop test 6b38eab [URL] add helper to create RSXform w/ anchorPt 6c72d57 [URL] Optimize RGB16 blitH functions with NEON for ARM platform.  Review URL: [URL]/1260163007", "target": 1}
{"idx": 1486, "commit_message": "Merge pull request #111 from bicpu/Malan", "target": 0}
{"idx": 3620, "commit_message": "Updated the function eval_h  Upon testing the code, I realized that the inner sum were going out of bounds. It is more efficient to only evaluate the sums needed within each case.", "target": 1}
{"idx": 1890, "commit_message": "cmd/compile: fix choice of phi building algorithm  The algorithm for placing a phi nodes in small functions now unreachable. This patch fix that.", "target": 0}
{"idx": 3757, "commit_message": "More efficient Note construction and Note.setAccidental()  First, we rewrite the musicxml.Note constructor so that it doesn't use getElementsByTagName anymore.  Secondly we define DOM editing code in Note.setAccidental.", "target": 1}
{"idx": 2068, "commit_message": "make check for existing keys more efficient", "target": 1}
{"idx": 1667, "commit_message": "bridge: fix parsing of MLDv2 reports  commit 47cc84ce0c2fe75c99ea5963c4b5704dd78ead54 upstream.  When more than a multicast address is present in a MLDv2 report, all but the first address is ignored, because the code breaks out of the loop if there has not been an error adding that address.  This has caused failures when two guests connected through the bridge tried to communicate using IPv6. Neighbor discoveries would not be transmitted to the other guest when both used a link-local address and a static address.  This only happens when there is a MLDv2 querier in the network.  The fix will only break out of the loop when there is a failure adding a multicast address.  The mdb before the patch:  dev ovirtmgmt port vnet0 grp ff02::1:ff7d:6603 temp dev ovirtmgmt port vnet1 grp ff02::1:ff7d:6604 temp dev ovirtmgmt port bond0.86 grp ff02::2 temp  After the patch:  dev ovirtmgmt port vnet0 grp ff02::1:ff7d:6603 temp dev ovirtmgmt port vnet1 grp ff02::1:ff7d:6604 temp dev ovirtmgmt port bond0.86 grp ff02::fb temp dev ovirtmgmt port bond0.86 grp ff02::2 temp dev ovirtmgmt port bond0.86 grp ff02::d temp dev ovirtmgmt port vnet0 grp ff02::1:ff00:76 temp dev ovirtmgmt port bond0.86 grp ff02::16 temp dev ovirtmgmt port vnet1 grp ff02::1:ff00:77 temp dev ovirtmgmt port bond0.86 grp ff02::1:ff00:def temp dev ovirtmgmt port bond0.86 grp ff02::1:ffa1:40bf temp  Fixes: 08b202b67264 (\"bridge br_multicast: IPv6 MLD support.\") Reported-by: Rik Theys < >", "target": 0}
{"idx": 3283, "commit_message": "- Patch #576302 by joachim | lambic: improved rewording of user admin help text.", "target": 0}
{"idx": 171, "commit_message": "Optimized boarding logic. Now it works correct. Adjust speed at the end to ensure that vehicles park closer to the cargo when carriers are in formation.", "target": 1}
{"idx": 1126, "commit_message": "Merge pull request #15189 from aeslaughter/find-exe-15017  Improve logic in mooseutils.find_moose_executable", "target": 0}
{"idx": 3258, "commit_message": "Simplify the NodeSet data structure as another look at performance indiciates it does not improve anything", "target": 0}
{"idx": 2813, "commit_message": "Try to improve the performance of the array_selection type", "target": 1}
{"idx": 2375, "commit_message": "BoneCP -> HikariCP, for better documentation and performance", "target": 1}
{"idx": 1863, "commit_message": "Moved the MultiDialog to a new class to allow us in other plugins.  Create an option to selectively clear results from memory.", "target": 0}
{"idx": 178, "commit_message": "New package: prelink - ELF prelinking utility to speed up dynamic linking.", "target": 1}
{"idx": 1622, "commit_message": "[IMP] account: Improve the report and add nodestroy in wizard  bzr revid: [URL]-20100729054345-akpfrt8kewvxoevu", "target": 0}
{"idx": 2935, "commit_message": "fix for bug introduced in Sinatra v1.4.4  This manually dups the options before they are passed to Sinatra's render method.  The new render method in v1.4.4 doesn't create a copy of the options hash anymore.  So when they delete things from the given options hash they are modifying the orig hash passed by the user.  This breaks how Deas renders the layouts.  In Deas' implementation, the same options hash is passed to all of the nested layouts.  So they first layout render gets the options, but any subsequent layout renders will have the modified options.  Specifically, the `:locals` option is removed.  This means the first layout render will get the locals - any subsequent will not get the locals.  Blargh.  Whatever.  This has Deas take responsibility for its own options since it is reusing for all nested layouts.  Deas takes responsibility for dup'ing the options for each layout render.  Why is the performance always the one to suffer?  This also improves the rack tests to actual render some layout view that use the locals.  This was needed to reproduce this error.", "target": 1}
{"idx": 3497, "commit_message": "transmission: Upgrade 2.94 -> 3.00  Upgrade to release 3.00:  - Allow the RPC server to listen on an IPv6 address - Change TR_CURL_SSL_VERIFY to TR_CURL_SSL_NO_VERIFY and enable   verification by default - Go back to using hash as base name for resume and torrent files   (those stored in configuration directory) - Handle \"fields\" argument in \"session-get\" RPC request; if   \"fields\" array is present in arguments, only return session   fields specified; otherwise return all the fields as before - Limit the number of incorrect authentication attempts in   embedded web server to 100 to prevent brute-force attacks - Set idle seed limit range to 1..40320 (4 weeks tops) in all   clients - Add Peer ID for Xfplay, PicoTorrent, Free Download Manager,   Folx, Baidu Netdisk torrent clients - Announce INT64_MAX as size left if the value is unknown   (helps with e.g. Amazon S3 trackers) - Add TCP_FASTOPEN support (should result in slight speedup) - Improve ToS handling on IPv6 connections - Abort handshake if establishing DH shared secret fails (leads   to crash) - Don't switch trackers while announcing (leads to crash) - Improve completion scripts execution and error handling; add   support for .cmd and .bat files on Windows - Maintain a \"session ID\" file (in temporary directory) to better   detect whether session is local or remote; return the ID as   part of \"session-get\" response - Change torrent location even if no data move is needed - Support CIDR-notated blocklists - Update the resume file before running scripts - Make multiscrape limits adaptive - Add labels support to libtransmission and transmission-remote - Parse session-id header case-insensitively - Sanitize suspicious path components instead of rejecting them - Load CA certs from system store on Windows / OpenSSL - Add support for mbedtls (formely polarssl) and wolfssl (formely   cyassl), LibreSSL - Fix building against OpenSSL 1.1.0+ - Fix quota support for uClibc-ng 1.0.18+ and DragonFly BSD - Fix a number of memory leaks (magnet loading, session shutdown,   bencoded data parsing) - Bump miniupnpc version to 2.0.20170509 - CMake-related improvements (Ninja generator, libappindicator,   systemd, Solaris and macOS) - Switch to submodules to manage (most of) third-party   dependencies - Fail installation on Windows if UCRT is not installed  License-Update: Bump copyright to 2020", "target": 0}
{"idx": 3674, "commit_message": "Some performance improvement  Adding some benchmarking, but also a tweak which gets rid of the exponential bottleneck. Pre-computes a unique hash per vector, stores that, and uses that for uniqing.  Still very experimental though...", "target": 1}
{"idx": 2854, "commit_message": "WIP: Use the stream struct when LZ4 is builtin.  This seems to improve performance on small systems, which suggests a latent bug elsewhere. (Perhaps involving data alignment, which matters on more on non-x86 architectures.)", "target": 1}
{"idx": 298, "commit_message": "Roll Catapult from 32ccf2128427 to 02439f647cbd (1 revision)  [URL]/catapult.git/+log/32ccf2128427..02439f647cbd  2021-12-06 [URL] CodeHealth: Run Pylint 2.7 in catapult/common/py_utils/  If this roll has caused a breakage, revert this CL and stop the roller using the controls here: [URL]/r/catapult-autoroll Please CC [URL] on the revert to ensure that a human is aware of the problem.  To file a bug in Chromium: [URL]/p/chromium/issues/entry  To report a problem with the AutoRoller itself, please file a bug: [URL]/p/skia/issues/entry?template=Autoroller+Bug  Documentation for the AutoRoller is here: [URL]/buildbot/+doc/main/autoroll/README.md  Cq-Include-Trybots: luci.chromium.try:android_optional_gpu_tests_rel;luci.chromium.try:chromeos-kevin-rel;luci.chromium.try:linux_optional_gpu_tests_rel;luci.chromium.try:mac_optional_gpu_tests_rel;luci.chromium.try:win_optional_gpu_tests_rel Bug: chromium:1262295 Tbr: [URL]", "target": 0}
{"idx": 3068, "commit_message": "[DataFrame] Fix equals and make it more efficient (#2186)  * Fixing equals    * Adding test fix    * Working on fix for equals and drop    * Fix equals and fix tests to use ray.dataframe.equals    * Addressing comments", "target": 1}
{"idx": 2384, "commit_message": "x86/reboot: Add ASRock Q1900DC-ITX mainboard reboot quirk  commit 80313b3078fcd2ca51970880d90757f05879a193 upstream.  The ASRock Q1900DC-ITX mainboard (Baytrail-D) hangs randomly in both BIOS and UEFI mode while rebooting unless reboot=pci is used. Add a quirk to reboot via the pci method.  The problem is very intermittent and hard to debug, it might succeed rebooting just fine 40 times in a row - but fails half a dozen times the next day. It seems to be slightly less common in BIOS CSM mode than native UEFI (with the CSM disabled), but it does happen in either mode. Since I've started testing this patch in late january, rebooting has been 100% reliable.  Most of the time it already hangs during POST, but occasionally it might even make it through the bootloader and the kernel might even start booting, but then hangs before the mode switch. The same symptoms occur with grub-efi, gummiboot and grub-pc, just as well as (at least) kernel 3.16-3.19 and 4.0-rc6 (I haven't tried older kernels than 3.16). Upgrading to the most current mainboard firmware of the ASRock Q1900DC-ITX, version 1.20, does not improve the situation.  ( Searching the web seems to suggest that other Bay Trail-D mainboards   might be affected as well. ) --", "target": 0}
{"idx": 2424, "commit_message": "Refactored Mesh internals and formats.  -Changed how mesh data is organized, hoping to make it more efficient on Vulkan and GLES. -Removed compression, it now always uses the most efficient format. -Added support for custom arrays (up to 8 custom formats) -Added support for 8 weights in skeleton data. -Added a simple optional versioning system for imported assets, to reimport if binary is newer -Fixes #43979 (I needed to test)  WARNING:  -NOT backwards compatible with previous 4.x-devel, will most likely never be, but it will force reimport scenes due to version change. -NOT backwards compatible with 3.x scenes, this will be eventually re-added. -Skeletons not working any longer, will fix in next PR.", "target": 1}
{"idx": 2885, "commit_message": "fetch less in queries to improve performance", "target": 1}
{"idx": 468, "commit_message": "Fixed memory leaks in savegame restoring  svn-id: r44863", "target": 0}
{"idx": 2343, "commit_message": "Add lists:mapfoldl/3 BIF  Make it more efficient by iterating rather than recursing as the lists.erl version does.", "target": 1}
{"idx": 1374, "commit_message": "Merge pull request #1389 from sanimej/ingress  For service name DNS resolution prioritize IP on user overlay network", "target": 0}
{"idx": 739, "commit_message": "- optimization of compiling speed when same modifier was used several times", "target": 1}
{"idx": 2190, "commit_message": "ACPI: Fix incompatibility with mcount-based function graph tracing  commit 61b79e16c68d703dde58c25d3935d67210b7d71b upstream.  Paul Menzel reported a warning:    WARNING: CPU: 0 PID: 774 at /build/linux-ROBWaj/linux-4.9.13/kernel/trace/trace_functions_graph.c:233 ftrace_return_to_handler+0x1aa/0x1e0   Bad frame pointer: expected f6919d98, received f6919db0     from func acpi_pm_device_sleep_wake return to c43b6f9d  The warning means that function graph tracing is broken for the acpi_pm_device_sleep_wake() function.  That's because the ACPI Makefile unconditionally sets the '-Os' gcc flag to optimize for size.  That's an issue because mcount-based function graph tracing is incompatible with '-Os' on x86, thanks to the following gcc bug:    [URL]/bugzilla/show_bug.cgi?id=42109  I have another patch pending which will ensure that mcount-based function graph tracing is never used with CONFIG_CC_OPTIMIZE_FOR_SIZE on x86.  But this patch is needed in addition to that one because the ACPI Makefile overrides that config option for no apparent reason.  It has had this flag since the beginning of git history, and there's no related comment, so I don't know why it's there.  As far as I can tell, there's no reason for it to be there.  The appropriate behavior is for it to honor CONFIG_CC_OPTIMIZE_FOR_{SIZE,PERFORMANCE} like the rest of the kernel.  Reported-by: Paul Menzel < >", "target": 0}
{"idx": 3407, "commit_message": "SONAR-4301 Improve performance when searching component children ids from specified component keys", "target": 1}
{"idx": 4105, "commit_message": "[PATCH] This commit introduces VariableGroups as an optimization when\n there are repeated variables of the same type inside a system.  Presently,\n these are only activated through the system.add_variables() API, but in the\n future there may be provisions for automatically identifying groups.\n\nThe memory usage for DofObjects now scales like\nN_sys+N_var_group_per_sys instead of N_sys+N_vars.  The DofMap\ndistribution code has been refactored to use VariableGroups.\n\nAll existing loops over Variables within a system will work unchanged,\nbut can be replaced with more efficient loops over VariableGroups.", "target": 1}
{"idx": 2165, "commit_message": "net: use __GFP_NORETRY for high order allocations  [ Upstream commit ed98df3361f059db42786c830ea96e2d18b8d4db ]  sock_alloc_send_pskb() & sk_page_frag_refill() have a loop trying high order allocations to prepare skb with low number of fragments as this increases performance.  Problem is that under memory pressure/fragmentation, this can trigger OOM while the intent was only to try the high order allocations, then fallback to order-0 allocations.  We had various reports from unexpected regressions.  According to David, setting __GFP_NORETRY should be fine, as the asynchronous compaction is still enabled, and this will prevent OOM from kicking as in :  CFSClientEventm invoked oom-killer: gfp_mask=0x42d0, order=3, oom_adj=0, oom_score_adj=0, oom_score_badness=2 (enabled),memcg_scoring=disabled CFSClientEventm  Call Trace:  [<ffffffff8043766c>] dump_header+0xe1/0x23e  [<ffffffff80437a02>] oom_kill_process+0x6a/0x323  [<ffffffff80438443>] out_of_memory+0x4b3/0x50d  [<ffffffff8043a4a6>] __alloc_pages_may_oom+0xa2/0xc7  [<ffffffff80236f42>] __alloc_pages_nodemask+0x1002/0x17f0  [<ffffffff8024bd23>] alloc_pages_current+0x103/0x2b0  [<ffffffff8028567f>] sk_page_frag_refill+0x8f/0x160  [<ffffffff80295fa0>] tcp_sendmsg+0x560/0xee0  [<ffffffff802a5037>] inet_sendmsg+0x67/0x100  [<ffffffff80283c9c>] __sock_sendmsg_nosec+0x6c/0x90  [<ffffffff80283e85>] sock_sendmsg+0xc5/0xf0  [<ffffffff802847b6>] __sys_sendmsg+0x136/0x430  [<ffffffff80284ec8>] sys_sendmsg+0x88/0x110  [<ffffffff80711472>] system_call_fastpath+0x16/0x1b Out of Memory: Kill process 2856 (bash) score 9999 or sacrifice child", "target": 1}
{"idx": 3522, "commit_message": "tdf#46738 Fix exporting .xlsx of coloured empty cells  When spreadsheet contains more that 84 cells, and these cells are empty, but contains additional data (border color, text color, specific formatting), the remaining rows are ignored during export to .xlsx and .xls As a result such empty rows are not saved during export. This patch is fixing most cases and make sure that at least first 84 empty cells will be preserved. It is not impacting the performance as it is still notchecking next columns when the visible cells are more that 84 characters. This patch improve exporting empty cells, but not impacts performance.", "target": 0}
{"idx": 3044, "commit_message": "drm/i915: Adjust CDCLK accordingly to our DBuf bw needs  According to BSpec max BW per slice is calculated using formula Max BW = CDCLK * 64. Currently when calculating min CDCLK we account only per plane requirements, however in order to avoid FIFO underruns we need to estimate accumulated BW consumed by all planes(ddb entries basically) residing on that particular DBuf slice. This will allow us to put CDCLK lower and save power when we don't need that much bandwidth or gain additional performance once plane consumption grows.  v2: - Fix long line warning     - Limited new DBuf bw checks to only gens >= 11  v3: - Lets track used Dbuf bw per slice and per crtc in bw state       (or may be in DBuf state in future), that way we don't need       to have all crtcs in state and those only if we detect if       are actually going to change cdclk, just same way as we       do with other stuff, i.e intel_atomic_serialize_global_state       and co. Just as per Ville's paradigm.     - Made dbuf bw calculation procedure look nicer by introducing       for_each_dbuf_slice_in_mask - we often will now need to iterate       slices using mask.     - According to experimental results CDCLK * 64 accounts for       overall bandwidth across all dbufs, not per dbuf.  v4: - Fixed missing const(Ville)     - Removed spurious whitespaces(Ville)     - Fixed local variable init(reduced scope where not needed)     - Added some comments about data rate for planar formats     - Changed struct intel_crtc_bw to intel_dbuf_bw     - Moved dbuf bw calculation to intel_compute_min_cdclk(Ville)  v5: - Removed unneeded macro  v6: - Prevent too frequent CDCLK switching back and forth:       Always switch to higher CDCLK when needed to prevent bandwidth       issues, however don't switch to lower CDCLK earlier than once       in 30 minutes in order to prevent constant modeset blinking.       We could of course not switch back at all, however this is       bad from power consumption point of view.  v7: - Fixed to track cdclk using bw_state, modeset will be now       triggered only when CDCLK change is really needed.  v8: - Lock global state if bw_state->min_cdclk is changed.     - Try getting bw_state only if there are crtcs in the commit       (need to have read-locked global state)  v9: - Do not do Dbuf bw check for gens < 9 - triggers WARN       as ddb_size is 0.  v10: - Lock global state for older gens as well.  v11: - Define new bw_calc_min_cdclk hook, instead of using        a condition(Manasi Navare)  v12: - Fixed rebase conflict  v13: - Added spaces after declarations to make checkpatch happy.", "target": 1}
{"idx": 4127, "commit_message": "[PATCH] Unroll dynamic indexing in SYCL gather kernel\n\nThread ID-based dynamic indexing of constant memory data in the SYCL\ngather kernel caused a large amount of register spills and poor\nperformance of the gather kernel on AMD. Avoiding dynamic indexing\neliminates spills and improves performance of this kernel >10x.\n\nRefs #3927", "target": 1}
{"idx": 537, "commit_message": "Improve connection handling and recovery in general, and specifically to address Issue #877:  - On servers with very short timeouts set the wait_timeout for the session as well as the interactive_timeout to prevent the connection from dropping frequently  - Improve recovery from connection errors, correctly restoring the connection if appropriate and possible  - Allow reconnections to occur recursively by altering the internal tracking mechanism  - Fix some edge cases where the connection would remain locked incorrectly  - Improve error messaging for the \"MySQL Server has gone away\" network case", "target": 1}
{"idx": 1680, "commit_message": "Merge pull request #321 from mumuki/chore-improve-backwards-compatibility  Chore improve backwards compatibility", "target": 0}
{"idx": 3161, "commit_message": "Lazy evaluate enterprise status for finch study filtering.  The previous CL [URL]/c/1789926 introduced filtering finch studies by enterprise status. However, computing enterprise status negatively affects performance. This CL only computes enterprise status if at least 1 study is filtering by enterprise.  Bug: 1001649", "target": 1}
{"idx": 3287, "commit_message": "Performance improvement: FIRE-140 thanks Nicky Dasmijn", "target": 1}
{"idx": 2049, "commit_message": "Honor windows.devicePixelRatio by default  Cesium now honors `window.devicePixelRatio` by default, which greatly improving performance on mobile devices and high DPI displays by rendering at the browser-recommended resolution.  This change also decreases bandwidth usage because we request far fewer tiles when rendering at lower resolutions.", "target": 1}
{"idx": 3968, "commit_message": "add some handy shell scripts for performance profiling and debugging", "target": 0}
{"idx": 2245, "commit_message": "Update dartdoc to 1.0.0 (#85549)  This includes some major internal changes that should improve performance (the AOT template compiler) and the new lookup code. The big changes noticeable for Flutter will be resolution of field formal parameters, extension method support, and more consistent disambiguation in comment reference lookups.    While a vast net improvement, this PR will change a few links to point to the wrong place. #85484 will address that after this lands, as there was no good way to specify what the user wanted unambiguously before dartdoc 1.0.0 in a few cases. That PR includes more details on the introduced regressions and link changes.", "target": 1}
{"idx": 3881, "commit_message": "sched: Implement smarter wake-affine logic  The wake-affine scheduler feature is currently always trying to pull the wakee close to the waker. In theory this should be beneficial if the waker's CPU caches hot data for the wakee, and it's also beneficial in the extreme ping-pong high context switch rate case.  Testing shows it can benefit hackbench up to 15%.  However, the feature is somewhat blind, from which some workloads such as pgbench suffer. It's also time-consuming algorithmically.  Testing shows it can damage pgbench up to 50% - far more than the benefit it brings in the best case.  So wake-affine should be smarter and it should realize when to stop its thankless effort at trying to find a suitable CPU to wake on.  This patch introduces 'wakee_flips', which will be increased each time the task flips (switches) its wakee target.  So a high 'wakee_flips' value means the task has more than one wakee, and the bigger the number, the higher the wakeup frequency.  Now when making the decision on whether to pull or not, pay attention to the wakee with a high 'wakee_flips', pulling such a task may benefit the wakee. Also imply that the waker will face cruel competition later, it could be very cruel or very fast depends on the story behind 'wakee_flips', waker therefore suffers.  Furthermore, if waker also has a high 'wakee_flips', that implies that multiple tasks rely on it, then waker's higher latency will damage all of them, so pulling wakee seems to be a bad deal.  Thus, when 'waker->wakee_flips / wakee->wakee_flips' becomes higher and higher, the cost of pulling seems to be worse and worse.  The patch therefore helps the wake-affine feature to stop its pulling work when:  \twakee->wakee_flips > factor && \twaker->wakee_flips > (factor * wakee->wakee_flips) The 'factor' here is the number of CPUs in the current CPU's NUMA node, so a bigger node will lead to more pulling since the trial becomes more severe.  After applying the patch, pgbench shows up to 40% improvements and no regressions.  Tested with 12 cpu x86 server and tip 3.10.0-rc7.  The percentages in the final column highlight the areas with the biggest wins, all other areas improved as well:  \tpgbench\t\t    base\tsmart  \t| db_size | clients |  tps  |\t|  tps  | \t+---------+---------+-------+   +-------+ \t| 22 MB   |       1 | 10598 |   | 10796 | \t| 22 MB   |       2 | 21257 |   | 21336 | \t| 22 MB   |       4 | 41386 |   | 41622 | \t| 22 MB   |       8 | 51253 |   | 57932 | \t| 22 MB   |      12 | 48570 |   | 54000 | \t| 22 MB   |      16 | 46748 |   | 55982 | +19.75% \t| 22 MB   |      24 | 44346 |   | 55847 | +25.93% \t| 22 MB   |      32 | 43460 |   | 54614 | +25.66% \t| 7484 MB |       1 |  8951 |   |  9193 | \t| 7484 MB |       2 | 19233 |   | 19240 | \t| 7484 MB |       4 | 37239 |   | 37302 | \t| 7484 MB |       8 | 46087 |   | 50018 | \t| 7484 MB |      12 | 42054 |   | 48763 | \t| 7484 MB |      16 | 40765 |   | 51633 | +26.66% \t| 7484 MB |      24 | 37651 |   | 52377 | +39.11% \t| 7484 MB |      32 | 37056 |   | 51108 | +37.92% \t| 15 GB   |       1 |  8845 |   |  9104 | \t| 15 GB   |       2 | 19094 |   | 19162 | \t| 15 GB   |       4 | 36979 |   | 36983 | \t| 15 GB   |       8 | 46087 |   | 49977 | \t| 15 GB   |      12 | 41901 |   | 48591 | \t| 15 GB   |      16 | 40147 |   | 50651 | +26.16% \t| 15 GB   |      24 | 37250 |   | 52365 | +40.58% \t| 15 GB   |      32 | 36470 |   | 50015 | +37.14%", "target": 1}
{"idx": 2373, "commit_message": "sh: Optimise FDE/CIE lookup by using red-black trees  Now that the DWARF unwinder is being used to provide perf callstacks unwinding speed is an issue. It is no longer being used in exceptional circumstances where we don't care about runtime performance, e.g. when panicing, so it makes sense improve performance is possible.  With this patch I saw a 42% improvement in unwind time when calling return_address(1). Greater improvements will be seen as the number of levels unwound increases as each unwind is now cheaper.  Note that insertion time has doubled but that's just the price we pay for keeping the trees balanced. However, this is a one-time cost for kernel boot/module load and so the improvements in lookup time dominate the extra time we spend keeping the trees balanced.", "target": 1}
{"idx": 3962, "commit_message": "random: Add performance improvements for the DRBG.  * random/random-drbg.c (struct drbg_state_ops_s): New function pointers 'crypto_init' and 'crypto-fini'. (struct drbg_state_s): New fields 'priv_data', 'ctr_handle', and 'ctr_null'. (drbg_hash_init, drbg_hash_fini): New. (drbg_hmac_init, drbg_hmac_setkey): New. (drbg_sym_fini, drbg_sym_init, drbg_sym_setkey): New. (drbg_sym_ctr): New. (drbg_ctr_bcc): Set the key. (drbg_ctr_df): Ditto. (drbg_hmac_update): Ditto. (drbg_hmac_generate): Replace drgb_hmac by drbg_hash. (drbg_hash_df): Ditto. (drbg_hash_process_addtl): Ditto. (drbg_hash_hashgen): Ditto. (drbg_ctr_update): Rework. (drbg_ctr_generate): Rework. (drbg_ctr_ops): Init new functions pointers. (drbg_uninstantiate): Call fini function. (drbg_instantiate): Call init function.  -- The performance improvements can be categorized as follows:  * Initialize the cipher handle of the backend ciphers once and re-use   them for subsequent cipher invocations.  * Limit the invocation of setkey to the cases when the key is newly   created.  * Use the AES CTR mode and rip out the counter maintenance in the DRBG   code. This allows the use of accelerated CTR AES implementations. To   use the CTR AES mode, a NULL buffer is created that is used as the   \"plaintext\" to the CTR mode, because the DRBG CTR AES operation is the   result of the encryption of the CTR (i.e. the NULL buffer makes the   final XOR of the CTR AES mode a noop).  The following timing measurements are made. The measurement do not use a precise timing operation and should rather serve as a general hint to the performance improvements.   On a Broadwell i7 CPU:  \tblock size\t4096\t\t1024\t\t128\t\t32\t\t16  aes256 old\t\t28MB/s\t27MB/s\t19MB/s\t11MB/s\t6MB/s  aes128 old\t\t29MB/s\t32MB/s\t23MB/s\t15MB/s\t9MB/s  sha256 old\t\t48MB/s\t48MB/s\t33MB/s\t16MB/s\t8MB/s  hmac sha256 old\t15MB/s\t15MB/s\t10MB/s\t5MB/s\t2MB/s   aes256 new\t\t180MB/s\t169MB/s\t93MB/s\t37MB/s\t20MB/s  aes128 new\t\t240MB/s\t221MB/s\t125MB/s\t51MB/s\t27MB/s  sha256 new\t\t75MB/s\t69MB/s\t48MB/s\t23MB/s\t11MB/s  hmac sha256 new\t37MB/s\t34MB/s\t21MB/s\t8MB/s\t4MB/s", "target": 1}
{"idx": 2557, "commit_message": "Use REMS instead of RES in the ICH SPI default opcode table  RES is Read Electronic Signature (1 Byte, identical for different chips) REMS is Read Electronic Manufacturer Signature (2 Bytes, mostly unique) RDID is Read JEDEC ID (3 bytes, unique)  Of the chips which don't support RDID, a sizable portion supports REMS which gives us both a manufacturer ID and a device ID. This is clearly superior to having only a device ID (the RES case) which has multiple documented collisions.  The RES/REMS problem is aggravated by inconsistent naming in vendor data sheets. What's in a name? Considering that we have 1-byte IDs, 2-byte IDs and 3+byte IDs with varying names but mostly consistent opcodes, it makes sense to set our own standard about how the opcodes are called.  The best way forward would be to have the ICH SPI driver reprogram the opcode menu on the fly if the opcode menu doesn't contain the requested opcode and the opcode menu is not locked. Until that happens, this patch improves detection accuracy by a factor of 256 for some chips.  Corresponding to flashrom svn r549.", "target": 0}
{"idx": 2714, "commit_message": "add some more thaw/freeze uses  to try and squeeze out a little more performance.  Its plausible that disconnecting the model from treeview with gtk_tree_view_set_model(..., nullptr) no longer improves times.  If we didn't do that, then we could thaw/freeze without losing what nodes are expanded and the current scroll pos.", "target": 1}
{"idx": 328, "commit_message": "DynamicString::insert : fixing the nasty bug with heap corruption", "target": 0}
{"idx": 2007, "commit_message": "Performance improvements to the individual profile's mappers and reducers.", "target": 1}
{"idx": 3049, "commit_message": "Merge pull request #14696 from pveentjer/v3.12/performance/write-through-final  Write through optimization", "target": 1}
{"idx": 299, "commit_message": "Improved type safety of policy consequence value check", "target": 0}
{"idx": 3561, "commit_message": "helpers: Don't clean path twice  Join calls Clean as it says in docs.  Minor performance improvement: Before: Average time per operation: 432ms Average memory allocated per operation: 127322kB Average allocations per operation: 2138137  After: Average time per operation: 428ms Average memory allocated per operation: 127350kB Average allocations per operation: 2137892", "target": 1}
{"idx": 3868, "commit_message": "improve logging set up to survive multiple command executions  This patch improves geogit cli logging set up to properly resolve the logging file and current dir upon multiple command executions and makes geogit-console batch mode (runFile()) to set up logging too, and also avoids code duplication in cli exception handling between cli and console.", "target": 0}
{"idx": 2258, "commit_message": "[merge-m52] Do not SchedulePaint() inside views::Label::OnPaint()  View::SchedulePaint() shouldn't be called inside an OnPaint() method. At best it wastes computation doing a follow-up, redundant paint. On Mac it's causing a weird interaction with transparent backgrounds for strings of particular lengths on retina screens.  For performance, MaybeBuildRenderTextLines() is always deferred until a Paint. It calls RecalculateColors() to apply colors to the lines it newly creates, and that schedules a paint. But MaybeBuildRenderTextLines() just needs to apply the colors that have already been calculated.  So, to fix, split RecalculateColors() into the color calculation and ApplyTextColors(), which can be called from OnPaint().  BUG=604092 TEST=On a retina-screen Mac with a fresh profile, navigate (e.g. to chrome://version), then press Backspace, The \"Press <key> to go back\" popup should appear and it should have a consistent, transparent background.  Review-Url: [URL]/2065003002", "target": 1}
{"idx": 1696, "commit_message": "cpu/stm32: improvement of USB driver selection  There are STM32 families where all models use only the Synopsys DWC2 USB OTG core while others completely use only the USB Device FS core. For these families then either the driver `drivers/usbdev_synopsys_dwc2` or the driver `cpu/stm32/periph/usbdev` is used depending on the respective family. However, the STM32 families F1 and L4 use both cores. The correct driver must therefore be selected depending on the CPU line or CPU model.", "target": 0}
{"idx": 3646, "commit_message": "- Performance improvements in Number `is_lucas_carmichael(n)`.  If `lucas_factor()` finds some prime factors and some composites factors, we now check the prime factors for p+1 | n+1, so we can return early if the condition is not met, without factoring the composite factors. This is much faster for large `n` that are not Lucas-Carmichael.  The trial division is also improved, checking for small factors first and stopping early if `n` has no small factors (<= 5*10^4).", "target": 1}
{"idx": 1378, "commit_message": "intel_idle: Don't register CPU notifier if we are not running.  commit 6f8c2e7933679f54b6478945dc72e59ef9a3d5e0 upstream.  The 'intel_idle_probe' probes the CPU and sets the CPU notifier. But if later on during the module initialization we fail (say in cpuidle_register_driver), we stop loading, but we neglect to unregister the CPU notifier.  This means that during CPU hotplug events the system will fail:  calling  intel_idle_init+0x0/0x326 @ 1 intel_idle: MWAIT substates: 0x1120 intel_idle: v0.4 model 0x2A intel_idle: lapic_timer_reliable_states 0xffffffff intel_idle: intel_idle yielding to none initcall intel_idle_init+0x0/0x326 returned -19 after 14 usecs  ... some time later, offlining and onlining a CPU:  cpu 3 spinlock event irq 62 BUG: unable to ] __cpuidle_register_device+0x1c/0x120 PGD 99b8b067 PUD 99b95067 PMD 0 Oops: 0000 [#1] SMP Modules linked in: xen_evtchn nouveau mxm_wmi wmi radeon ttm i915 fbcon tileblit font atl1c bitblit softcursor drm_kms_helper video xen_blkfront xen_netfront fb_sys_fops sysimgblt sysfillrect syscopyarea xenfs xen_privcmd mperf CPU 0 Pid: 2302, comm: udevd Not tainted 3.8.0-rc3upstream-00249-g09ad159 #1 MSI MS-7680/H61M-P23 (MS-7680) RIP: e030:[<ffffffff814d956c>]  [<ffffffff814d956c>] __cpuidle_register_device+0x1c/0x120 RSP: e02b:ffff88009dacfcb8  EFLAGS: 00010286 RAX: 0000000000000000 RBX: ffff880105380000 RCX: 000000000000001c RDX: 0000000000000000 RSI: 0000000000000055 RDI: ffff880105380000 RBP: ffff88009dacfce8 R08: ffffffff81a4f048 R09: 0000000000000008 R10: 0000000000000008 R11: 0000000000000000 R12: ffff880105380000 R13: 00000000ffffffdd R14: 0000000000000000 R15: ffffffff81a523d0 FS:  00007f37bd83b7a0(0000) GS:ffff880105200000(0000) knlGS:0000000000000000 CS:  e033 DS: 0000 ES: 0000 CR0: 0000000080050033 CR2: 0000000000000008 CR3: 00000000a09ea000 CR4: 0000000000042660 DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000 DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400 Process udevd (pid: 2302, threadinfo ffff88009dace000, task ffff88009afb47f0) Stack:  ffffffff8107f2d0 ffffffff810c2fb7 ffff88009dacfce8 00000000ffffffea  ffff880105380000 00000000ffffffdd ffff88009dacfd08 ffffffff814d9882  0000000000000003 ffff880105380000 ffff88009dacfd28 ffffffff81340afd Call Trace:  [<ffffffff8107f2d0>] ? collect_cpu_info_local+0x30/0x30  [<ffffffff810c2fb7>] ? __might_sleep+0xe7/0x100  [<ffffffff814d9882>] cpuidle_register_device+0x32/0x70  [<ffffffff81340afd>] intel_idle_cpu_init+0xad/0x110  [<ffffffff81340bc8>] cpu_hotplug_notify+0x68/0x80  [<ffffffff8166023d>] notifier_call_chain+0x4d/0x70  [<ffffffff810bc369>] __raw_notifier_call_chain+0x9/0x10  [<ffffffff81094a4b>] __cpu_notify+0x1b/0x30  [<ffffffff81652cf7>] _cpu_up+0x103/0x14b  [<ffffffff81652e18>] cpu_up+0xd9/0xec  [<ffffffff8164a254>] store_online+0x94/0xd0  [<ffffffff814122fb>] dev_attr_store+0x1b/0x20  [<ffffffff81216404>] sysfs_write_file+0xf4/0x170  [<ffffffff811a1024>] vfs_write+0xb4/0x130  [<ffffffff811a17ea>] sys_write+0x5a/0xa0  [<ffffffff816643a9>] system_call_fastpath+0x16/0x1b Code: 03 18 00 c9 c3 66 2e 0f 1f 84 00 00 00 00 00 55 48 89 e5 48 83 ec 30 48 89 5d e8 4c 89 65 f0 48 89 fb 4c 89 6d f8 e8 84 08 00 00 <48> 8b 78 08 49 89 c4 e8 f8 7f c1 ff 89 c2 b8 ea ff ff ff 84 d2 RIP  [<ffffffff814d956c>] __cpuidle_register_device+0x1c/0x120  RSP <ffff88009dacfcb8>  This patch fixes that by moving the CPU notifier registration as the last item to be done by the module.", "target": 0}
{"idx": 584, "commit_message": "IB/hfi1: Fix an out-of-bounds access in get_hw_stats  When running with KASAN, the following trace is produced:  [   62.535888]  ================================================================== [   62.544930] BUG: KASAN: slab-out-of-bounds in gut_hw_stats+0x122/0x230 [hfi1] [   62.553856] Write of size 8 at addr ffff88080e8d6330 by task kworker/0:1/14  [   62.565333] CPU: 0 PID: 14 Comm: kworker/0:1 Not tainted 4.19.0-test-build-kasan+ #8 [   62.575087] Hardware name: Intel Corporation S2600KPR/S2600KPR, BIOS SE5C610.86B.01.01.0019.101220160604 10/12/2016 [   62.587951] Workqueue: events work_for_cpu_fn [   62.594050] Call Trace: [   62.598023]  dump_stack+0xc6/0x14c [   62.603089]  ? dump_stack_print_info.cold.1+0x2f/0x2f [   62.610041]  ? kmsg_dump_rewind_nolock+0x59/0x59 [   62.616615]  ? get_hw_stats+0x122/0x230 [hfi1] [   62.622985]  print_address_description+0x6c/0x23c [   62.629744]  ? get_hw_stats+0x122/0x230 [hfi1] [   62.636108]  kasan_report.cold.6+0x241/0x308 [   62.642365]  get_hw_stats+0x122/0x230 [hfi1] [   62.648703]  ? hfi1_alloc_rn+0x40/0x40 [hfi1] [   62.655088]  ? __kmalloc+0x110/0x240 [   62.660695]  ? hfi1_alloc_rn+0x40/0x40 [hfi1] [   62.667142]  setup_hw_stats+0xd8/0x430 [ib_core] [   62.673972]  ? show_hfi+0x50/0x50 [hfi1] [   62.680026]  ib_device_register_sysfs+0x165/0x180 [ib_core] [   62.687995]  ib_register_device+0x5a2/0xa10 [ib_core] [   62.695340]  ? show_hfi+0x50/0x50 [hfi1] [   62.701421]  ? ib_unregister_device+0x2e0/0x2e0 [ib_core] [   62.709222]  ? __vmalloc_node_range+0x2d0/0x380 [   62.716131]  ? rvt_driver_mr_init+0x11f/0x2d0 [rdmavt] [   62.723735]  ? vmalloc_node+0x5c/0x70 [   62.729697]  ? rvt_driver_mr_init+0x11f/0x2d0 [rdmavt] [   62.737347]  ? rvt_driver_mr_init+0x1f5/0x2d0 [rdmavt] [   62.744998]  ? __rvt_alloc_mr+0x110/0x110 [rdmavt] [   62.752315]  ? rvt_rc_error+0x140/0x140 [rdmavt] [   62.759434]  ? rvt_vma_open+0x30/0x30 [rdmavt] [   62.766364]  ? mutex_unlock+0x1d/0x40 [   62.772445]  ? kmem_cache_create_usercopy+0x15d/0x230 [   62.780115]  rvt_register_device+0x1f6/0x360 [rdmavt] [   62.787823]  ? rvt_get_port_immutable+0x180/0x180 [rdmavt] [   62.796058]  ? __get_txreq+0x400/0x400 [hfi1] [   62.802969]  ? memcpy+0x34/0x50 [   62.808611]  hfi1_register_ib_device+0xde6/0xeb0 [hfi1] [   62.816601]  ? hfi1_get_npkeys+0x10/0x10 [hfi1] [   62.823760]  ? hfi1_init+0x89f/0x9a0 [hfi1] [   62.830469]  ? hfi1_setup_eagerbufs+0xad0/0xad0 [hfi1] [   62.838204]  ? pcie_capability_clear_and_set_word+0xcd/0xe0 [   62.846429]  ? pcie_capability_read_word+0xd0/0xd0 [   62.853791]  ? hfi1_pcie_init+0x187/0x4b0 [hfi1] [   62.860958]  init_one+0x67f/0xae0 [hfi1] [   62.867301]  ? hfi1_init+0x9a0/0x9a0 [hfi1] [   62.873876]  ? wait_woken+0x130/0x130 [   62.879860]  ? read_word_at_a_time+0xe/0x20 [   62.886329]  ? strscpy+0x14b/0x280 [   62.891998]  ? hfi1_init+0x9a0/0x9a0 [hfi1] [   62.898405]  local_pci_probe+0x70/0xd0 [   62.904295]  ? pci_device_shutdown+0x90/0x90 [   62.910833]  work_for_cpu_fn+0x29/0x40 [   62.916750]  process_one_work+0x584/0x960 [   62.922974]  ? rcu_work_rcufn+0x40/0x40 [   62.928991]  ? __schedule+0x396/0xdc0 [   62.934806]  ? __sched_text_start+0x8/0x8 [   62.941020]  ? pick_next_task_fair+0x68b/0xc60 [   62.947674]  ? run_rebalance_domains+0x260/0x260 [   62.954471]  ? __list_add_valid+0x29/0xa0 [   62.960607]  ? move_linked_works+0x1c7/0x230 [   62.967077]  ? trace_event_raw_event_workqueue_execute_start+0x140/0x140 [   62.976248]  ? mutex_lock+0xa6/0x100 [   62.982029]  ? __mutex_lock_slowpath+0x10/0x10 [   62.988795]  ? __switch_to+0x37a/0x710 [   62.994731]  worker_thread+0x62e/0x9d0 [   63.000602]  ? max_active_store+0xf0/0xf0 [   63.006828]  ? __switch_to_asm+0x40/0x70 [   63.012932]  ? __switch_to_asm+0x34/0x70 [   63.019013]  ? __switch_to_asm+0x40/0x70 [   63.025042]  ? __switch_to_asm+0x34/0x70 [   63.031030]  ? __switch_to_asm+0x40/0x70 [   63.037006]  ? __schedule+0x396/0xdc0 [   63.042660]  ? kmem_cache_alloc_trace+0xf3/0x1f0 [   63.049323]  ? kthread+0x59/0x1d0 [   63.054594]  ? ret_from_fork+0x35/0x40 [   63.060257]  ? __sched_text_start+0x8/0x8 [   63.066212]  ? schedule+0xcf/0x250 [   63.071529]  ? __wake_up_common+0x110/0x350 [   63.077794]  ? __schedule+0xdc0/0xdc0 [   63.083348]  ? wait_woken+0x130/0x130 [   63.088963]  ? finish_task_switch+0x1f1/0x520 [   63.095258]  ? kasan_unpoison_shadow+0x30/0x40 [   63.101792]  ? __init_waitqueue_head+0xa0/0xd0 [   63.108183]  ? replenish_dl_entity.cold.60+0x18/0x18 [   63.115151]  ? _raw_spin_lock_irqsave+0x25/0x50 [   63.121754]  ? max_active_store+0xf0/0xf0 [   63.127753]  kthread+0x1ae/0x1d0 [   63.132894]  ? kthread_bind+0x30/0x30 [   63.138422]  ret_from_fork+0x35/0x40  [   63.146973] Allocated by task 14: [   63.152077]  kasan_kmalloc+0xbf/0xe0 [   63.157471]  __kmalloc+0x110/0x240 [   63.162804]  init_cntrs+0x34d/0xdf0 [hfi1] [   63.168883]  hfi1_init_dd+0x29a3/0x2f90 [hfi1] [   63.175244]  init_one+0x551/0xae0 [hfi1] [   63.181065]  local_pci_probe+0x70/0xd0 [   63.186759]  work_for_cpu_fn+0x29/0x40 [   63.192310]  process_one_work+0x584/0x960 [   63.198163]  worker_thread+0x62e/0x9d0 [   63.203843]  kthread+0x1ae/0x1d0 [   63.208874]  ret_from_fork+0x35/0x40  [   63.217203] Freed by task 1: [   63.221844]  __kasan_slab_free+0x12e/0x180 [   63.227844]  kfree+0x92/0x1a0 [   63.232570]  single_release+0x3a/0x60 [   63.238024]  __fput+0x1d9/0x480 [   63.242911]  task_work_run+0x139/0x190 [   63.248440]  exit_to_usermode_loop+0x191/0x1a0 [   63.254814]  do_syscall_64+0x301/0x330 [   63.260283]  entry_SYSCALL_64_after_hwframe+0x44/0xa9  [   63.270199] The buggy address belongs to the object at ffff88080e8d5500  which belongs to the cache kmalloc-4096 of size 4096 [   63.287247] The buggy address is located 3632 bytes inside of  4096-byte region [ffff88080e8d5500, ffff88080e8d6500) [   63.303564] The buggy address belongs to the page: [   63.310447] page:ffffea00203a3400 count:1 mapcount:0 mapping:ffff88081380e840 index:0x0 compound_mapcount: 0 [   63.323102] flags: 0x2fffff80008100(slab|head) [   63.329775] raw: 002fffff80008100 0000000000000000 0000000100000001 ffff88081380e840 [   63.340175] raw: 0000000000000000 0000000000070007 00000001ffffffff 0000000000000000 [   63.350564] page dumped because: kasan: bad access detected  [   63.361974] Memory state around the buggy address: [   63.369137]  ffff88080e8d6200: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 [   63.379082]  ffff88080e8d6280: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 [   63.389032] >ffff88080e8d6300: 00 00 00 00 00 00 fc fc fc fc fc fc fc fc fc fc [   63.398944]                                      ^ [   63.406141]  ffff88080e8d6380: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc [   63.416109]  ffff88080e8d6400: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc [   63.426099] ==================================================================  The trace happens because get_hw_stats() assumes there is room in the memory allocated in init_cntrs() to accommodate the driver counters. Unfortunately, that routine only allocated space for the device counters.  Fix by insuring the allocation has room for the additional driver counters.  Cc: [URL]> # v4.14+ Fixes: b7481944b06e9 (\"IB/hfi1: Show statistics counters under IB stats interface\")", "target": 1}
{"idx": 243, "commit_message": "major improvements to the scale bracelet visualization", "target": 0}
{"idx": 1244, "commit_message": "Merge \"msm: kgsl: Add the entire memory range of certain objects in snapshot", "target": 0}
{"idx": 3591, "commit_message": "For floppies call disk_close() only when the floppy MOTOR_TIMEOUT expired. Otherwise call fsync(). This improves floppy performance, particularly when using kernel 2.6.", "target": 1}
{"idx": 3889, "commit_message": "Improve FileNodeIndex.  Use off-heap memory buffer to hold unsorted nodes until flushed to disk. Makes for an overall performance improvement (about 50% faster with large indexes) and reduces the number of temporary files by about 5 times, further improving the node iteration that uses in-process merge sort from the different files.", "target": 1}
{"idx": 3399, "commit_message": "Optimization Attempt: We now start a separate VoltProcedureListener per partition in an HStoreSite, as well as separate thread to process ForwardTxn requests in HStoreMessenger. The former allows us to saturate a single-node much better while the second was an attempt to keep a cluster saturdated. This still requires a ton of tweaking to get good performance numbers.", "target": 1}
{"idx": 2992, "commit_message": "Change internal _headers attribute to be a dictionary of columns instead of a numpy structured array.  This should make a lot of the header manipulations more efficient, since the majority of them are column-based.", "target": 1}
{"idx": 199, "commit_message": "sched: export cpu_clock  the rcutorture module relies on cpu_clock.", "target": 0}
{"idx": 2515, "commit_message": "NFS: Adapt readdirplus to application usage patterns  While the use of READDIRPLUS is significantly more efficient than READDIR followed by many LOOKUP calls, it is still less efficient than just READDIR if the attributes are not required.  This patch tracks when lookups are attempted on the directory, and uses that information to selectively disable READDIRPLUS on that directory. The first 'readdir' call is always served using READDIRPLUS. Subsequent calls only use READDIRPLUS if there was a successful lookup or revalidation on a child in the mean time.  Credit for the original idea should go to Neil Brown. See:       [URL]/lists/linux-nfs/msg19996.html However, the implementation in this patch differs from Neil's in that it focuses on tracking lookups rather than calls to stat().", "target": 1}
{"idx": 2311, "commit_message": "fixed performance tab when process exits", "target": 0}
{"idx": 1664, "commit_message": "[test-ui] Implement support for dynamic sources", "target": 0}
{"idx": 2347, "commit_message": "Improved performance when .mo is read in I18n::__loadMo()", "target": 1}
{"idx": 341, "commit_message": ":  remco | 2007-02-16 14:09:32 +0100  improve test", "target": 0}
{"idx": 3882, "commit_message": "Bug#14633008 MISLEADING ERROR WHEN TRYING TO UPDATE NON-EXISTING P_S TABLES  Before this change, INSERT / UPDATE / DELETE / LOCK TABLES performed on unknown performance_schema tables would fail with errors such as ER_TABLEACCESS_DENIED_ERROR.  For users with the proper grants, the error message for similar cases with non performance_schema tables is simply ER_NO_SUCH_TABLE.  While this behavior is correct (the performance_schema has some extra security privileges checks that are built in), it is also confusing.  This fix relaxes the built in privilege checks for the performance schema, so that DML on tables that do not exist simply fails with ER_NO_SUCH_TABLE.  This is mostly cosmetic, to improve ease of use.", "target": 0}
{"idx": 3801, "commit_message": "USB: OHCI: avoid conflicting platform drivers  Like the EHCI driver, OHCI supports a large number of different platform glue drivers by directly including them, which causes problems with conflicting macro definitions in some cases. As more ARM architecture specific back-ends are required to coexist in a single build, we should split those out into separate drivers. Unfortunately, the infrastructure for that is still under development, so to give us more time, this uses a separate *_PLATFORM_DRIVER macro for each ARM specific OHCI backend, just like we already do on PowerPC and some of the other ARM platforms.  In linux-3.10, only the SPEAr and CNS3xxx back-ends would actually conflict without this patch, but over time we would get more of them, so this is a way to avoid having to patch the driver every time it breaks. We should still split out all back-ends into separate loadable modules, but that work is only needed to improve code size and cleanliness after this patch, not for correctness.  While we're here, this fixes the incorrectly sorted error path for the OMAP1 and OMAP3 backends to ensure we always unregister the exact set of drivers that were registered before erroring out.", "target": 0}
{"idx": 3219, "commit_message": "Patch from Simon Hyde to improve the aspect ratio settings, and allow 16x9 content to be properly letterboxed on 4x3 TVs.", "target": 0}
{"idx": 3987, "commit_message": "S32A_Blend_BlitRow32: for ARM without NEON  The S32A_Blend_BlitRow32 function was written and unrolled in ARM assembly to improve the rendering performance on ARM cores lacking NEON.  Added in SkBlitRow_opts_arm.cpp.  Performance improvement about ~18% on micro benchmarking.  Patch-by: Vassillis", "target": 1}
{"idx": 3162, "commit_message": "Removed all the lazy joins. This should improve performance.", "target": 1}
{"idx": 4114, "commit_message": "[PATCH] rocSPARSE does not require sorted columns for csrgemm\n\nThis is specific to the rocSPARSE CSR implementation of SpGEMM.\nBut this is a substantial performance savings.", "target": 1}
{"idx": 2246, "commit_message": "[SPARK-15764][SQL] Replace N^2 loop in BindReferences  BindReferences contains a n^2 loop which causes performance issues when operating over large schemas: to determine the ordinal of an attribute reference, we perform a linear scan over the `input` array. Because input can sometimes be a `List`, the call to `input(ordinal).nullable` can also be O(n).  Instead of performing a linear scan, we can convert the input into an array and build a hash map to map from expression ids to ordinals. The greater up-front cost of the map construction is offset by the fact that an expression can contain multiple attribute references, so the cost of the map construction is amortized across a number of lookups.  Perf. benchmarks to follow. /cc ericl  Author: Josh Rosen [URL]>  Closes #13505 from JoshRosen/bind-references-improvement.", "target": 1}
{"idx": 3933, "commit_message": "Breaks API: Refactor, performance and security fixes for APathQuery.", "target": 1}
{"idx": 1006, "commit_message": "Improved experience on Windows XP users", "target": 0}
{"idx": 2554, "commit_message": "Merge pull request #3 from Mike-Bal/merge_perf  Improve performance when mergin overlapping timed data series", "target": 1}
{"idx": 824, "commit_message": "Changes test and makes it run a real algorithm", "target": 0}
{"idx": 982, "commit_message": "RequestBody and Response examples generator. Minor code improvements.", "target": 0}
{"idx": 3298, "commit_message": "Improve performance of Path.Line() constructor.  Passing an array is much faster than using arguments directly.", "target": 1}
{"idx": 1631, "commit_message": "The claimid is no longer used to determine the address of the startd. This means that the schedd and shadow now honor the startd's published PrivateNetworkIpAddr as one would expect.  It also means that we can simplify the rules for rewriting published IP addresses; that is my primary motivation, because the rewriting of the claimid at publication made the claimid --> security session logic needlessly complicated.", "target": 0}
{"idx": 3417, "commit_message": "Add images without xdebug  Most CLI tools display warnings regarding serious performance impact when ran with xdebug enabled. For CI purposes there is no need to have xdebug enabled as you are not able to connect to the debugger anyway.", "target": 0}
{"idx": 306, "commit_message": "vasikka.py : soften stops algorithm added to text to phoneme mapping phase just before sound generation; tamilvu_ngram : use trigram, bigram and unigram data saving phases; tvu bigram probability data collected for TVU dictionary", "target": 0}
{"idx": 3174, "commit_message": "return arrays instead of lists in specific commands   - to get better performance and make it similar to structures    properties", "target": 1}
{"idx": 3119, "commit_message": "improve performance of DOM.watch - drop _.some call", "target": 1}
{"idx": 2769, "commit_message": "Use Picasso for loading images on settings screen to improve performance", "target": 1}
{"idx": 772, "commit_message": "am 44fdcf26: Merge \"Update no wifi networks string\" into mnc-dev  * commit '44fdcf26421c4c2a59888739fa003a14e09e8391':   Update no wifi networks string", "target": 0}
{"idx": 2929, "commit_message": "Improved server performance by reducing the amount of redundant data sent to the network thread.", "target": 1}
{"idx": 4037, "commit_message": "[PATCH] Reduced the cost of the pull communication\n\nWith more than 32 ranks, a sub-communicator will be used\nfor the pull communication. This reduces the pull communication\nsignificantly with small pull groups. With large pull groups the total\nsimulation performance might not improve much, because ranks\nthat are not in the sub-communicator will later wait for the pull\nranks during the communication for the constraints.\n\nAdded a pull_comm_t struct to separate the data used for communication.\n\nChange-Id: I92b64d098b508b11718ef3ae175b771032ad7be2", "target": 1}
{"idx": 673, "commit_message": "mmap: Provide own mprotect() implementation.  This implementation calls LIBC mprotect() under the hood but in a controlled manner that doesn't break functionality of memory mappings created with mmap().", "target": 0}
{"idx": 2746, "commit_message": "get_permalink() performance improvement from arnee. fixes #2463", "target": 1}
{"idx": 1999, "commit_message": "Merge branch 'master' of [URL]/zendframework/zf2 into cache_filesystemSpeedup", "target": 0}
{"idx": 654, "commit_message": "Be more relaxed about performance of map on fast iterator with slow function", "target": 0}
{"idx": 2494, "commit_message": "Make the inert flag independently inherit  Improve performance of changing inertness.  Bug: 1360404", "target": 1}
{"idx": 1559, "commit_message": "Sparse buffer test: allocate memory in one big chunk  The test made excessive small memory allocations breaking the maxMemoryAllocationCount limit.  Affects:  dEQP-VK.sparse_resources.buffer.transfer.sparse_binding.buffer_size_2_24  Components: Vulkan VK-GL-CTS issue: 592", "target": 0}
{"idx": 2904, "commit_message": "perf, bpf: Introduce PERF_RECORD_BPF_EVENT  For better performance analysis of BPF programs, this patch introduces PERF_RECORD_BPF_EVENT, a new perf_event_type that exposes BPF program load/unload information to user space.  Each BPF program may contain up to BPF_MAX_SUBPROGS (256) sub programs. The following example shows kernel symbols for a BPF program with 7 sub programs:      ffffffffa0257cf9 t bpf_prog_b07ccb89267cf242_F     ffffffffa02592e1 t bpf_prog_2dcecc18072623fc_F     ffffffffa025b0e9 t bpf_prog_bb7a405ebaec5d5c_F     ffffffffa025dd2c t bpf_prog_a7540d4a39ec1fc7_F     ffffffffa025fcca t bpf_prog_05762d4ade0e3737_F     ffffffffa026108f t bpf_prog_db4bd11e35df90d4_F     ffffffffa0263f00 t bpf_prog_89d64e4abf0f0126_F     ffffffffa0257cf9 t bpf_prog_ae31629322c4b018__dummy_tracepoi  When a bpf program is loaded, PERF_RECORD_KSYMBOL is generated for each of these sub programs. Therefore, PERF_RECORD_BPF_EVENT is not needed for simple profiling.  For annotation, user space need to listen to PERF_RECORD_BPF_EVENT and gather more information about these (sub) programs via sys_bpf.", "target": 0}
{"idx": 2242, "commit_message": "igb: Make Tx budget for NAPI user adjustable  This change is to make the NAPI budget limits for transmit adjustable.  Currently they are only set to 128, and when the changes/improvements to NAPI occur to allow for adjustability, it would be possible to tune the value for optimal performance with applications such as routing.  v2: remove tie between NAPI and interrupt moderation     fix work limit define name (s/IXGBE/IGB/)     Update patch description to better reflect patch", "target": 0}
{"idx": 964, "commit_message": "Fix a regression is plist parser  last_file cannot be anymore a pointer given that previous line is not kept in memory anymore", "target": 0}
{"idx": 2880, "commit_message": "Improve label query performance  By not using IN, but a VALUES list for treenode and connector IDs so we can join them to the label query, reduces query time by 50% in my tests.", "target": 1}
{"idx": 3392, "commit_message": "Small hack to get better performance on data_cleaning", "target": 1}
{"idx": 3446, "commit_message": "R_ShowStats() was rewritten. Now this function is faster and more universal. There is no more a static array and copying of memory.", "target": 1}
{"idx": 3738, "commit_message": "Set the preface/postface from the parser into the multipart object.  2000-11-04  Not Zed  [URL]>          * camel-mime-part-utils.c         (camel_mime_part_construct_content_from_parser): Set the         preface/postface from the parser into the multipart object.          * camel-multipart.c (camel_multipart_set_postface): Function to         set the postface text on a multipart.         (camel_multipart_set_preface): Similarly for preface text.          * camel-mime-parser.c (folder_scan_content): If we scan until a         boundary, then we do not include the   that starts the boundary         line in the content.         (struct _header_scan_stack): Added a ByteArray to store the         multipart pre/post-text as we're scanning.         (folder_pull_part): Free pre/posttext if they are allocated.         (folder_scan_step): Build into the pre/posttext arrays as we         encounter data.         (camel_mime_parser_preface): REturn the multipart preface text, if         there is any scanned.         (camel_mime_parser_postface): Likewise for postface text.         (byte_array_to_string): helper function for above.          * providers/mbox/camel-mbox-folder.c (mbox_append_message): Change         the from line to be \" From ...\" always, so no need to         check/append a   to messages.         (mbox_append_message): Open the output stream with append mode         [assuming this is more efficient than seeking to the end]         And dont prepend    on the From line if its the first in the         mbox.         (mbox_append_message): Pass the offset of the real start of the         \"From \" line when we perform the update (which may != 'seek')          * camel-mime-filter-charset.c (complete): Removed the terminating         NUL 'fix'.          * camel-stream-filter.c (do_read): Added some debug.         (do_flush): And here.         (do_write): And here too.         (do_write): ARGH!!! ARGH!  Ok, so the filter stream was writing a         different number of bytes than the requester was asking it to         write (because of filtering, of course!).  So instead of returning         the true number of written bytes, we'll return what they asked us         to write - unless there is an error in which case we return -1.          * camel-mime-utils.c (base64_encode_close): Sigh, forgot to make         it unsigned.  I think this is actually a gcc bug as (48 >> 2)         somehow ended up negative, when it obviously should not, even if         the data load was signed.", "target": 0}
{"idx": 2446, "commit_message": "Merge pull request #94 from MelvinTo/master  main-run performance improvement", "target": 1}
{"idx": 3320, "commit_message": "Daniel R. Roe: CPPTRAJ - Alpha Version Intial Revision Cpptraj is a trajectory analysis tool in the spirit of ptraj. It consists of an entirely new codebase written in C++. It does not yet include the complete functionality of ptraj but is a bit faster and more efficient. This initial release is an ALPHA version.", "target": 1}
{"idx": 3136, "commit_message": "Add flags/precision arguments to String::number(double) to allow fine-grained control over the result string [URL]/show_bug.cgi?id=72793  Reviewed by Zoltan Herczeg.  Source/JavaScriptCore:   This new code will be used in follow-up patches to replace the String::format(\"%.2f\") usage in platform/text/TextStream.cpp, and String::format(\"%.6lg\") usage in svg/SVGPathStringBuilder.cpp.  The String::number(double) currently calls String::format(\"%.6lg\") in trunk. In order to replace this by a variant that properly rounds to six significant figures, JSC code could be refactored. JSCs Number.toPrecision/toFixed uses wtf/dtoa/double-conversion which provides all features we need, except truncating trailing zeros, needed to mimic the \"g\" format, which is either f or e but with trailing zeros removed, producing shorter results. Changed the default signature to:  \"static String number(double, unsigned = ShouldRoundSignificantFigures | ShouldTruncateTrailingZeros, unsigned precision = 6);\".  In WebCore we can now replace String::format() calls like this: String::format(\"%.2f\", f) -> String::number(f, ShouldRoundDecimalPlaces, 2) String::format(\"%.6lg\", f) -> String::number(f)  The default parameters for precison & flags exactly match the format of the string produced now, except that the result is rounded according to the rounding mode / formatting mode and precision. This paves the way towards reliable results in the d=\"\" attribute dumps of SVG paths  across platforms. The dtoa rounding code enforces a unique zero, resolving all 0.0 vs. -0.0 issues currently seen on Windows, and some Gtk/Qt bots.  This patch needs a rebaseline of svg/dom/length-list-parser.html as we don't perfecly mimic the String::format() \"lg\" mode result for exponentials, we used to return eg. \"e-7\" and now return \"e-07\" - the trailing zero truncation hasn't been implemented for exponentials, as this really affects only this test and thus wasn't worth the trouble - in contrary the trailing zero truncation is needed for thousands of other results in \"f\" notation, and thus needed to match the DRT results.  Here's a performance comparision using a JSC release build and some arbitary numbers: Converting 123.456 using old approach took 95.527100ms. avg 0.000955ms/call. Converting 123.456 using new approach took 28.126953ms. avg 0.000281ms/call.  Converting 123 using old approach took 85.411133ms. avg 0.000854ms/call. Converting 123 using new approach took 24.190186ms. avg 0.000242ms/call.  Converting 0.1 using old approach took 92.622803ms. avg 0.000926ms/call. Converting 0.1 using new approach took 23.317871ms. avg 0.000233ms/call.  Converting 1/i using old approach took 106.893066ms. avg 0.001069ms/call. Converting 1/i using new approach took 27.164062ms. avg 0.000272ms/call.  For all numbers I've tested in RoundingSignificantFigures mode and 6 digit precision the speedup was at least 250%.  * JavaScriptCore.exp: Change String::number(double) signature. * JavaScriptCore.vcproj/JavaScriptCore/JavaScriptCore.def: Ditto. * runtime/NumberPrototype.cpp: (JSC::numberProtoFuncToFixed): Refactor this into numberToFixedPrecisionString(), move to wtf/dtoa.cpp. (JSC::numberProtoFuncToPrecision): Ditto, refactor this into numberToFixedWidthString. * wtf/dtoa.cpp: Moved fixedWidth/Precision helpers into dtoa, extend numberToFixedPrecisionString(). Add a mode which allows to truncate trailing zeros/decimal point.                 to make it possible to use them to generate strings that match the output from String::format(\"%6.lg\"), while using our dtoas rounding facilities. * wtf/dtoa.h: * wtf/dtoa/utils.h: Expose new helper method, which allows us to truncate the result, before generating the output const char*. (WTF::double_conversion::StringBuilder::SetPosition): * wtf/text/WTFString.cpp: (WTF::String::number): Remove String::format(\"%6.lg\") usage! Switch to rounding to six significant figures, while matching the output of String::format. * wtf/text/WTFString.h:  LayoutTests:   Rebaseline one test result, after the String::number(double) changes. Trailing zeros are no longer removed in the exponential form of the string: e-07 is reported instead of e-7 now. It was decided to leave it as-is and not introduce trailing zero removal for the exponential formatting, as it only affects this test.  I'll rebaseline other platforms once results are available.  * svg/dom/length-list-parser-expected.txt:", "target": 1}
{"idx": 3164, "commit_message": "drm/panel: add S6E8AA0 driver  The patch adds MIPI-DSI based S6E8AA0 AMOLED LCD panel driver. Driver uses mipi_dsi bus to communicate with panel and exposes drm_panel interface.  v2 - added bus error handling, - set maxmimum DSI packet size on init, - removed unsupported brightness drm_panel callbacks, - minor improvements  v3 - switched to gpiod framework, - minor fixes in error handling", "target": 0}
{"idx": 1710, "commit_message": "[core] remove redundant check for max_conns  network_server_handle_fdevent() checks max_conns and is the only callers of connection_accept(), so connection_accept() does not need to repeat the check.", "target": 1}
{"idx": 3880, "commit_message": "Map values directly from the JSON nodes  Not only is it more efficient without converting to an intermediate String, using JsonNode.toString() may not even produce valid JSON according to its Javadoc (ObjectMapper.writeValueAsString() should be used).", "target": 1}
{"idx": 2886, "commit_message": "Used Buffer<byte> when deserializing to improve performance.", "target": 1}
{"idx": 715, "commit_message": "Improvements for the container building process  - Clarifying variable definitions - Adding a minor version tag to all built images - Adding checksum verification of the downloaded JARs  PiperOrigin-RevId: 489179538", "target": 0}
{"idx": 2150, "commit_message": "MAGMA 2.1 release 2016-08-30  MAGMA 2.1 for CUDA is now available. New features and updates include:  * Variable size batched routines (gemm, gemv, syrk, syr2k).  * Improved SVD performance for tall (m >> n) or wide (m << n) matrices.  * Preconditioned QMR.  * Expanded doxygen documentation.  * For MAGMA v1 compatability, initializes default queue for each GPU on    first use, instead of in magma_init.  Please take [this [URL]/r/2016DenseLinearAlgebra) to help improve MAGMA, LAPACK, and other dense linear algebra libraries. We estimate that it should take 10 minutes to fill it out.  Thank you very much.", "target": 1}
{"idx": 3477, "commit_message": "Merge branch 'next' of [URL]/pub/scm/linux/kernel/git/benh/powerpc  Pull main powerpc updates from Ben Herrenschmidt:  \"This time around, the powerpc merges are going to be a little bit more   complicated than usual.    This is the main pull request with most of the work for this merge   window.  I will describe it a bit more further down.    There is some additional cpuidle driver work, however I haven't   included it in this tree as it depends on some work in tip/timer-core   which Thomas accidentally forgot to put in a topic branch.  Since I   didn't want to carry all of that tip timer stuff in powerpc -next, I   setup a separate branch on top of Thomas tree with just that cpuidle   driver in it, and Stephen has been carrying that in next separately   for a while now.  I'll send a separate pull request for it.    Additionally, two new pieces in this tree add users for a sysfs API   that Tejun and Greg have been deprecating in drivers-core-next.   Thankfully Greg reverted the patch that removes the old API so this   merge can happen cleanly, but once merged, I will send a patch   adjusting our new code to the new API so that Greg can send you the   removal patch.    Now as for the content of this branch, we have a lot of perf work for   power8 new counters including support for our new \"nest\" counters   (also called 24x7) under pHyp (not natively yet).    We have new functionality when running under the OPAL firmware   (non-virtualized or KVM host), such as access to the firmware error   logs and service processor dumps, system parameters and sensors, along   with a hwmon driver for the latter.    There's also a bunch of bug fixes accross the board, some LE fixes,   and a nice set of selftests for validating our various types of copy   loops.    On the Freescale side, we see mostly new chip/board revisions, some   clock updates, better support for machine checks and debug exceptions,   etc...\"  * 'next' of [URL]/pub/scm/linux/kernel/git/benh/powerpc: (70 commits)   powerpc/book3s: Fix CFAR clobbering issue in machine check handler.   powerpc/compat: 32-bit little endian machine name is ppcle, not ppc   powerpc/le: Big endian arguments for ppc_rtas()   powerpc: Use default set of netfilter modules (CONFIG_NETFILTER_ADVANCED=n)   powerpc/defconfigs: Enable THP in pseries defconfig   powerpc/mm: Make sure a local_irq_disable prevent a parallel THP split   powerpc: Rate-limit users spamming kernel log buffer   powerpc/perf: Fix handling of L3 events with bank == 1   powerpc/perf/hv_{gpci, 24x7}: Add documentation of device attributes   powerpc/perf: Add kconfig option for hypervisor provided counters   powerpc/perf: Add support for the hv 24x7 interface   powerpc/perf: Add support for the hv gpci (get performance counter info) interface   powerpc/perf: Add macros for defining event fields & formats   powerpc/perf: Add a shared interface to get gpci version and capabilities   powerpc/perf: Add 24x7 interface headers   powerpc/perf: Add hv_gpci interface header   powerpc: Add hvcalls for 24x7 and gpci (Get Performance Counter Info)   sysfs: create bin_attributes under the requested group   powerpc/perf: Enable BHRB access for EBB events   powerpc/perf: Add BHRB constraint and IFM MMCRA handling for EBB   ...", "target": 0}
{"idx": 3731, "commit_message": "Once VG_(maybe_add_context) starts ignoring errors, ignore them right up front, in the VG_(record_*_error) functions.  This is an attempt to avoid excessive performance problems with programs which have excessive numbers of errors.", "target": 1}
{"idx": 2260, "commit_message": "CacheStorage: Remove CacheStorageSequence feature and virtual test suite.  This feature launched to 100% on windows, mac, and android in M80.  It was just enabled by default on ChromeOS in ToT after an extended period investigating performance regressions.  Bug: 960012", "target": 0}
{"idx": 1287, "commit_message": "lcoking/barriers, arch: Use smp barriers in smp_store_release()  With commit b92b8b35a2e (\"locking/arch: Rename set_mb() to smp_store_mb()\") it was made clear that the context of this call (and thus set_mb) is strictly for CPU ordering, as opposed to IO. As such all archs should use the smp variant of mb(), respecting the semantics and saving a mandatory barrier on UP.", "target": 0}
{"idx": 1198, "commit_message": "some improvements for the repl  - running \"tests\" no longer fails silently and lists individual tests - repl file is removed from the model after execution - repl can run private functions (again)", "target": 0}
{"idx": 2188, "commit_message": "BAP-9860: Error during loading related entities by EntitySerializer on PosgreSQL. Remove redundant sql queries in EntitySerializer if requested only related entity id. Add some caching to improve performance of EntitySerializer.", "target": 1}
{"idx": 1478, "commit_message": "ARM: 7877/1: use built-in byte swap function  Enable the compiler intrinsic for byte swapping on arch ARM. This allows the compiler to detect and be able to optimize out byte swappings, and has a very modest benefit on vmlinux size (Linaro gcc 4.8):  text data bss dec hex filename 2840310 123932 61960 3026202 2e2d1a vmlinux-lart #orig 2840152 123932 61960 3026044 2e2c7c vmlinux-lart #builtin-bswap  6473120 314840 5616016 12403976 bd4508 vmlinux-mxs #orig 6472586 314848 5616016 12403450 bd42fa vmlinux-mxs #builtin-bswap  7419872 318372 379556 8117800 7bde28 vmlinux-imx_v6_v7 #orig 7419170 318364 379556 8117090 7bdb62 vmlinux-imx_v6_v7 #builtin-bswap", "target": 1}
{"idx": 3353, "commit_message": "128-bit block cipher modes consolidation. As consolidated functions rely on indirect call to block functions, they are not as fast as non-consolidated routines. However, performance loss(*) is within measurement error and consolidation advantages are considered to outweigh it.  (*) actually one can observe performance *improvement* on e.g.     CBC benchmarks thanks to optimization, which also becomes     shared among ciphers.", "target": 1}
{"idx": 389, "commit_message": "Retire Windows native TurboVNC Viewer ...  ... in favor of the Java TurboVNC Viewer, which has similar performance and more features.  This commit also allows MinGW to be used for Windows builds.", "target": 0}
{"idx": 2518, "commit_message": "Make project structure more efficient and use new SBT build structure  Part of ia-toki/judgels#100", "target": 0}
{"idx": 752, "commit_message": "Fix for bug Blades/BLD-152. Added test for bugfix. Optimized bug fix.", "target": 1}
{"idx": 3025, "commit_message": "Improve performance of time_in_state event query am: f35e50b0e8 am: 13d088bbb5 am: 7308d0be17 am: dceb2ec262 am: b18aa0d2f5  Original change: [URL]/c/platform/external/perfetto/+/1336401", "target": 1}
{"idx": 3, "commit_message": "Added method ImageFromByte in TfpgBaseImgAnim. Now animation can be loaded from memory, not only from filename", "target": 0}
{"idx": 2152, "commit_message": "grouping works now, performance improvements for array iteration, fix for tree not working when no scrollbar present,", "target": 1}
{"idx": 3570, "commit_message": "Check appear and disappear more efficiently.  Erasing and adding entries from sets is more expensive than doing a sorted iteration comparison.", "target": 1}
{"idx": 1212, "commit_message": "C6X: early boot code  Original port to early 2.6 kernel using TI COFF toolchain. Brought up to date by Mark Salter [URL]>  This patch provides the early boot code for C6X architecture. There is a 16 entry vector table which is used to direct reset and interrupt events. The vector table entries contain a small amount of code (maximum of 8 opcodes) which simply branches to the actual event handling code.  The head.S code simply clears BSS, setups up a few control registers, and calls machine_init followed by start_kernel. The machine_init code in setup.c does the early flat tree parsing (memory, commandline, etc). At setup_arch time, the code does the usual memory setup and minimally scans the devicetree for any needed information.", "target": 0}
{"idx": 424, "commit_message": "f2fs: avoid to use a NULL point in destroy_segment_manager  A NULL point should avoid to be used in destroy_segment_manager after allocating memory fail for f2fs_sm_info.", "target": 0}
{"idx": 3668, "commit_message": "Check SecurityChanges when ensuring currency data feeds  A performance improvement to the way we process currency conversion data began saving the security reference instead of just the symbol. When added via universe selection (not AddSecurity) the security doesn't exist in the security manager until it's added in the algorithm manager. This was caused key not found exceptions when attempting to retrieve the security from the security manager.  The fix here is to also check SecurityChanges when resolving the data feed. A future improvement might be to decouple the cash object from the currency feed required to provide it conversions to the account currency.  Fixes #1635", "target": 1}
{"idx": 1136, "commit_message": "Merge pull request #50 from amazeeio/AMAZEEIO-926-improve-error-message-when-ssh-key-not-authorized  Improve error message when SSH key not authorized", "target": 0}
{"idx": 187, "commit_message": "Enable/Disable some actions correctely.  svn path=/trunk/kdenetwork/kmail/; revision=124461", "target": 0}
{"idx": 2497, "commit_message": "Simplification to mask and activity array indexing in CFPRF_DotProduct_opt. Has no effect on performance, and allows OpenMP optimization (to be committed in the future). Implemented and tested By Marco Elver.", "target": 0}
{"idx": 182, "commit_message": "interfaces/hardware-observe: allow lsmem and sysfs memory status and ranges", "target": 0}
{"idx": 526, "commit_message": "Don't install into a subdirectory  Now the install happens in the current directory, with logs in a 'logs' subdirectory.  Other improvements: curl now fails if the Vagrantfile can't be downloaded, because the RELEASE value is invalid.  Curl also doesn't print as large a progress bar.  The script fails early if there's no RELEASE specified.  (cherry picked from commit 66a25250e5310c6ed2cf1ee2bd3f7ca3224a5749)", "target": 0}
{"idx": 2070, "commit_message": "updated the node stack to make direct output writes instead of buffering  * simpler and more efficient for now * buffered output no longer necessary b/c the stack itself inherently buffers (doesn't output a node until the next node is pushed)", "target": 1}
{"idx": 3677, "commit_message": "enlarge the file-chunk-size for performance  On a 1 GB file this saves us roughly 50% in terms of CPU time (on my machine). We could probably investigate if other crypto libraries are faster and/or if it'd make sense to only calculate the hash that's required (where feasible, such as, e.g., in the Cuckoo Scheduler).", "target": 1}
{"idx": 3115, "commit_message": "HETS-609 - Owner search - Equipment count should not include archived Improved performance of owner search by reducing values returned in API call", "target": 1}
{"idx": 4067, "commit_message": "[PATCH] Sparse refactored readers: Better vectorization for tile\n bitmaps calculations. (#2711) (#2734)\n\n* Sparse unordered with duplicates: Better vectorization for tile bitmaps.\n\nWhen computing tile bitmaps, there are a few places where we were not\nvectorizing properly and it caused performance impacts on some customer\nscenario. Fixing the use of covered/overlap in the dimension class to\nenable proper vectorization.", "target": 1}
{"idx": 1494, "commit_message": "Adjusted the input module to use raster stacks rather than bricks.  Turns out that memory/disk usage is of greater concern than initially thought.", "target": 0}
{"idx": 1179, "commit_message": "(Matt & Sherm) Fix testExampleOptimization so that failures during execution actually cause the test to fail! (We were getting spurious passes before.)", "target": 0}
{"idx": 3168, "commit_message": "x86/hpeldsp: Fix author attribution  This also fixes the project name  Original authors fabrice and nick go back to the initial ffmpeg commit Others for example contributed in: (for a complete list please use git blame / show / log)  commit e9c0a38ff0a9d4754220ae3432b2cdebe5a1c781 Author: Zdenek Kabelac < > Date:   Tue May 28 16:35:58 2002 +0000      * optimized avg_* functions (except xy2)     * minor speedup for put_pixels_x2 & cleanup      Originally committed as revision 619 to [URL]/ffmpeg/trunk  commit 607dce96c0225e30ae2e7f3b8de2d00b4f064805 Author: Michael Niedermayer < > Date:   Fri May 17 01:04:14 2002 +0000      hopefully faster mmx2&3dnow MC      Originally committed as revision 506 to [URL]/ffmpeg/trunk", "target": 1}
{"idx": 768, "commit_message": "plugins/rpc: fix a couple of memory leaks  Always free response, in the worst case we are freeing NULL which is a NOP. Reported by Coverity as CID #1231246, #1231245", "target": 0}
{"idx": 1660, "commit_message": "Clean up log search results.  Took the previous color/layout ideas for logging types and improved.      * Errors now pop and are the only log type with different font-coloring.     * Removed the lone td with error level and moved everything into one td.     * Added semantic markup for log listings to reduce br's and simplify     layout.     *", "target": 0}
{"idx": 2748, "commit_message": "genirq: Add a helper to spread an affinity mask for MSI/MSI-X vectors  This is lifted from the blk-mq code and adopted to use the affinity mask concept just introduced in the irq handling code.  It tries to keep the algorithm the same as the one current used by blk-mq, but improvements like assining vectors on a per-node basis instead of just per sibling are possible with this simple move and refactoring.", "target": 0}
{"idx": 3941, "commit_message": "Added some padding to the peak regions for __call_peak2 -- peaks cannot be called within padding but it improves the filter performance. If peaks fail to be found, then we will fall back on __call_peak. Removed valley enforcement and instead use \"peakyness\" enforcement (see cSignal)", "target": 1}
{"idx": 3369, "commit_message": "Fix renderSectionHeader/Footer There are some [bs] annotations so that there's no currying (for better performance)", "target": 1}
{"idx": 3531, "commit_message": "upgrade in the base library (strings::Join now supports int and int64 vectors), file operations uses status; improve the code on symmetries; API for assumptions on sat", "target": 0}
{"idx": 847, "commit_message": "Improve legends for charts.  This CL improves the styling of legends by using black text to improve readablity and adding colored graphics to denote labels. It also increases the size of the chart and the size of the legend area to make use of available whitespace in results.vue, reducing the chance of text going off chart.  Bug: chromium:866423", "target": 0}
{"idx": 2806, "commit_message": "Various changes to improve the ability to find routes and make better looking, more efficient routes.", "target": 1}
{"idx": 2778, "commit_message": "4 of 4 commit (sorry my svn clinet is crazy for moment) Commit w3seek patch from bug 1609 : file attachment (id=910)  The attached patch implements QueueUserWorkItem()/RtlQueueWorkItem() (lacks optimizations!!!). WINE's latest rpcrt4 relies on it.  1. Implement QueueUserWorkItem()/RtlQueueWorkItem() : 2. A slightly optimized  3. Supports WT_TRANSFER_IMPERSONATION 4. Slightly improved handling of growing/shrinking the pool by assuming work items with WT_EXECUTELONGFUNCTION run longer 5. Fixes a hack that made a worker thread always terminate if there were at least one more thread available", "target": 1}
{"idx": 3641, "commit_message": "Two inter-related changes:  1. fixed bug where Search Manager would load incorrect objects because state had been changed in between calls (i.e. $params object may use Search Manager, changing its state before $results object can be created -- to avoid, we need more explicit calls to setSearchClassId())  2. refactored record drivers in preparation for plugin manager (moved constructor parameter to setRawData method).  This allowed more common functionality to be moved to the abstract base class.  Renamed getAllFields() to getRawData() for consistency.  Small bonus change: turned off highlighting/spellchecking/recommendations in BrowseController for improved performance.", "target": 0}
{"idx": 2654, "commit_message": "[REF] sale,sale_expense: clean and optimize reinvoice code  In the previous commit the analytic entries generation when posting a move was optimized to be done in batch. The performance is break when sale module is installed. Indeed, in case of reinvoicing a analytic line, AAL creation will trigger a sale.line creation.  This mecanism is very inefficient because 1/ AAL creation and Sales line creation are not batched 2/ sale line creation is done after the AAL creation, and then linked with a `write` operation. So one `create` and one `write` per AAL to reinvoice. 3/ To determine on which Sales Order to reinvoice, many `search` can be performed per AAL.  Also, this looks strange that AAL creation might result into a sales line creation.  This commit changes this in order to optimize and clean the code: - the account.move.line (that creates the AAL) will also create the Sales lines - SO lines creation will be done in batch - minimize the number of `search` done during the process - the SO line will be linked to the AAL by passing the SO line id in the create values of AAL (no `write` operation one AAL and SOL are created).  This was the last part of legacy code of 'sale_analytic.py' that we need to get rid of. There are still work to do, but I think now, the business case handled here can now breathe and have a peacefull life.  Task-1911898  closes odoo/odoo#28939", "target": 1}
{"idx": 2966, "commit_message": "A small improvement to the height querying performance", "target": 1}
{"idx": 3459, "commit_message": "use type_hierarchical_dictionary to store couplings; improved performance of dictionary type", "target": 1}
{"idx": 3754, "commit_message": "[Mac] Implement ResourceBundle::GetNativeImageNamed() to load directly into an NSImage.  This should have marginal performance gains for Mac. Instead of loading into a Skia-backed gfx::Image, which then converts to get an NSImage representation, this will load directly to an NSImage-backed gfx::Image.  BUG=carnitas TEST=All UI images load and look correct.  Review URL: [URL]/6543016", "target": 1}
{"idx": 2597, "commit_message": "PR middle-end/105874: Use EXPAND_MEMORY to fix ada bootstrap.  Many thanks to Tamar Christina for filing PR middle-end/105874 indicating that SPECcpu 2017's Leela is failing on x86_64 due to a miscompilation of FastBoard::is_eye.  This function is much smaller and easier to work with than my previous hunt for the cause of the Ada bootstrap failures due to miscompilation somewhere in GCC (or one of the 131 places that the problematic form of optimization triggers during an ada bootstrap).  It turns out the source of the miscompilation introduced by my recent patch is the distinction (during RTL expansion) of l-values and r-values. According to the documentation above expand_modifier, EXPAND_MEMORY should be used for lvalues (when a memory is required), and EXPAND_NORMAL for rvalues when a constant is permissible.  In what I'd like to consider a latent bug, the recursive call to expand_expr_real on line 11188 of expr.cc, in the case handling ARRAY_REF, COMPONENT_REF, BIT_FIELD_REF and ARRARY_RANGE_REF was passing EXPAND_NORMAL when it really required (the semantics of) EXPAND_MEMORY.  All the time that VAR_DECLs were being returned as memory this was fine, but as soon as we're able to optimize sort arrays into immediate constants, bad things happen.  In the test case from Leela, we notice that the array s_eyemask always has DImode constant value { 4, 64 }, which is useful as an rvalue, but not when we need to index it as an lvalue, as in s_eyemask[color].  This also explains why everything being accepted by immediate_const_ctor_p (during an ada bootstrap) looks reasonable, what's incorrect is that we don't know how these structs/arrays are to be used.  The fix is to ensure that we call expand_expr with EXPAND_MEMORY when processing the VAR_DECL's returned by get_inner_reference.  2022-06-08  Roger Sayle  [URL]>  gcc/ChangeLog         PR middle-end/105874         * expr.cc (expand_expr_real_1) <normal_inner_ref>:  New local         variable tem_modifier for calculating the expand_modifier enum to         use for expanding tem.  If tem is a VAR_DECL, use EXPAND_MEMORY.  gcc/testsuite/ChangeLog         PR middle-end/105874         * g++.dg/opt/pr105874.C: New test case.", "target": 0}
{"idx": 239, "commit_message": "Linux build fix  GCC does not allow local functor classes to be used with template algorithms, because template arguments must refer to an entity with external linkage.", "target": 0}
{"idx": 1844, "commit_message": "Slightly improved some methods in the WorldManager", "target": 0}
{"idx": 1500, "commit_message": "msm: ipc: Possible memory corruption due to Sign Conversion  msm_ipc_router_skb_to_buf() takes an unsigned argument and assigns the same to a signed local variable. This might cause issues when the value of the argument is too high.  Change the datatype of the local variable to unsigned.  CRs-Fixed: 550606", "target": 0}
{"idx": 2113, "commit_message": "8036860: Pad and cache-align the BiasedMappedArray Summary: Pad and cache-align BiasedMappedArray instances by default to avoid performance variability problems due to false sharing, as instances of this data structures are typically used for performance sensitive code.", "target": 1}
{"idx": 579, "commit_message": "ASoC: msm: qdsp6v2: Correct buffer size alignment while memory map  Buffer size needs to be aligned at 4K byte boundary while sending memory map command to the Q6 DSP, otherwise DSP would return failure as response to the memory map command failing audio session.  CRs-fixed: 830118", "target": 0}
{"idx": 2931, "commit_message": "Enable indexes in models to improve performance", "target": 1}
{"idx": 1293, "commit_message": "mm: hugetlbfs: close race during teardown of hugetlbfs shared page tables  If a process creates a large hugetlbfs mapping that is eligible for page table sharing and forks heavily with children some of whom fault and others which destroy the mapping then it is possible for page tables to get corrupted.  Some teardowns of the mapping encounter a \"bad pmd\" and output a message to the kernel log.  The final teardown will trigger a BUG_ON in mm/filemap.c.  This was reproduced in 3.4 but is known to have existed for a long time and goes back at least as far as 2.6.37.  It was probably was introduced in 2.6.20 by [39dde65c: shared page table for hugetlb page].  The messages look like this;  [  ..........] Lots of bad pmd messages followed by this [  127.164256] mm/memory.c:391: bad pmd ffff880412e04fe8(80000003de4000e7). [  127.164257] mm/memory.c:391: bad pmd ffff880412e04ff0(80000003de6000e7). [  127.164258] mm/memory.c:391: bad pmd ffff880412e04ff8(80000003de0000e7). [  127.186778] ------------[ cut here ]------------ [  127.186781] kernel BUG at mm/filemap.c:134! [  127.186782] invalid opcode: 0000 [#1] SMP [  127.186783] CPU 7 [  127.186784] Modules linked in: af_packet cpufreq_conservative cpufreq_userspace cpufreq_powersave acpi_cpufreq mperf ext3 jbd dm_mod coretemp crc32c_intel usb_storage ghash_clmulni_intel aesni_intel i2c_i801 r8169 mii uas sr_mod cdrom sg iTCO_wdt iTCO_vendor_support shpchp serio_raw cryptd aes_x86_64 e1000e pci_hotplug dcdbas aes_generic container microcode ext4 mbcache jbd2 crc16 sd_mod crc_t10dif i915 drm_kms_helper drm i2c_algo_bit ehci_hcd ahci libahci usbcore rtc_cmos usb_common button i2c_core intel_agp video intel_gtt fan processor thermal thermal_sys hwmon ata_generic pata_atiixp libata scsi_mod [  127.186801] [  127.186802] Pid: 9017, comm: hugetlbfs-test Not tainted 3.4.0-autobuild #53 Dell Inc. OptiPlex 990/06D7TR [  127.186804] RIP: 0010:[<ffffffff810ed6ce>]  [<ffffffff810ed6ce>] __delete_from_page_cache+0x15e/0x160 [  127.186809] RSP: 0000:ffff8804144b5c08  EFLAGS: 00010002 [  127.186810] RAX: 0000000000000001 RBX: ffffea000a5c9000 RCX: 00000000ffffffc0 [  127.186811] RDX: 0000000000000000 RSI: 0000000000000009 RDI: ffff88042dfdad00 [  127.186812] RBP: ffff8804144b5c18 R08: 0000000000000009 R09: 0000000000000003 [  127.186813] R10: 0000000000000000 R11: 000000000000002d R12: ffff880412ff83d8 [  127.186814] R13: ffff880412ff83d8 R14: 0000000000000000 R15: ffff880412ff83d8 [  127.186815] FS:  00007fe18ed2c700(0000) GS:ffff88042dce0000(0000) knlGS:0000000000000000 [  127.186816] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b [  127.186817] CR2: 00007fe340000503 CR3: 0000000417a14000 CR4: 00000000000407e0 [  127.186818] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000 [  127.186819] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400 [  127.186820] Process hugetlbfs-test (pid: 9017, threadinfo ffff8804144b4000, task ffff880417f803c0) [  127.186821] Stack: [  127.186822]  ffffea000a5c9000 0000000000000000 ffff8804144b5c48 ffffffff810ed83b [  127.186824]  ffff8804144b5c48 000000000000138a 0000000000001387 ffff8804144b5c98 [  127.186825]  ffff8804144b5d48 ffffffff811bc925 ffff8804144b5cb8 0000000000000000 [  127.186827] Call Trace: [  127.186829]  [<ffffffff810ed83b>] delete_from_page_cache+0x3b/0x80 [  127.186832]  [<ffffffff811bc925>] truncate_hugepages+0x115/0x220 [  127.186834]  [<ffffffff811bca43>] hugetlbfs_evict_inode+0x13/0x30 [  127.186837]  [<ffffffff811655c7>] evict+0xa7/0x1b0 [  127.186839]  [<ffffffff811657a3>] iput_final+0xd3/0x1f0 [  127.186840]  [<ffffffff811658f9>] iput+0x39/0x50 [  127.186842]  [<ffffffff81162708>] d_kill+0xf8/0x130 [  127.186843]  [<ffffffff81162812>] dput+0xd2/0x1a0 [  127.186845]  [<ffffffff8114e2d0>] __fput+0x170/0x230 [  127.186848]  [<ffffffff81236e0e>] ? rb_erase+0xce/0x150 [  127.186849]  [<ffffffff8114e3ad>] fput+0x1d/0x30 [  127.186851]  [<ffffffff81117db7>] remove_vma+0x37/0x80 [  127.186853]  [<ffffffff81119182>] do_munmap+0x2d2/0x360 [  127.186855]  [<ffffffff811cc639>] sys_shmdt+0xc9/0x170 [  127.186857]  [<ffffffff81410a39>] system_call_fastpath+0x16/0x1b [  127.186858] Code: 0f 1f 44 00 00 48 8b 43 08 48 8b 00 48 8b 40 28 8b b0 40 03 00 00 85 f6 0f 88 df fe ff ff 48 89 df e8 e7 cb 05 00 e9 d2 fe ff ff <0f> 0b 55 83 e2 fd 48 89 e5 48 83 ec 30 48 89 5d d8 4c 89 65 e0 [  127.186868] RIP  [<ffffffff810ed6ce>] __delete_from_page_cache+0x15e/0x160 [  127.186870]  RSP <ffff8804144b5c08> [  127.186871] ---[ end trace 7cbac5d1db69f426 ]---  The bug is a race and not always easy to reproduce.  To reproduce it I was doing the following on a single socket I7-based machine with 16G of RAM.  $ hugeadm --pool-pages-max DEFAULT:13G $ echo $((18*1048576*1024)) > /proc/sys/kernel/shmmax $ echo $((18*1048576*1024)) > /proc/sys/kernel/shmall $ for i in `seq 1 9000`; do ./hugetlbfs-test; done  On my particular machine, it usually triggers within 10 minutes but enabling debug options can change the timing such that it never hits. Once the bug is triggered, the machine is in trouble and needs to be rebooted.  The machine will respond but processes accessing proc like \"ps aux\" will hang due to the BUG_ON.  shutdown will also hang and needs a hard reset or a sysrq-b.  The basic problem is a race between page table sharing and teardown.  For the most part page table sharing depends on i_mmap_mutex.  In some cases, it is also taking the mm->page_table_lock for the PTE updates but with shared page tables, it is the i_mmap_mutex that is more important.  Unfortunately it appears to be also insufficient. Consider the following situation  Process A\t\t\t\t\tProcess B ---------\t\t\t\t\t--------- hugetlb_fault\t\t\t\t\tshmdt   \t\t\t\t\t\tLockWrite(mmap_sem)     \t\t\t\t\t\t  do_munmap \t\t\t\t\t\t    unmap_region \t\t\t\t\t\t      unmap_vmas \t\t\t\t\t\t        unmap_single_vma \t\t\t\t\t\t          unmap_hugepage_range       \t\t\t\t\t\t            Lock(i_mmap_mutex) \t\t\t\t\t\t\t    Lock(mm->page_table_lock) \t\t\t\t\t\t\t    huge_pmd_unshare/unmap tables <--- (1) \t\t\t\t\t\t\t    Unlock(mm->page_table_lock)       \t\t\t\t\t\t            Unlock(i_mmap_mutex)   huge_pte_alloc\t\t\t\t      ...     Lock(i_mmap_mutex)\t\t\t\t      ...     vma_prio_walk, find svma, spte\t\t      ...     Lock(mm->page_table_lock)\t\t\t      ...     share spte\t\t\t\t\t      ...     Unlock(mm->page_table_lock)\t\t\t      ...     Unlock(i_mmap_mutex)\t\t\t      ...   hugetlb_no_page\t\t\t\t\t\t\t\t\t  <--- (2) \t\t\t\t\t\t      free_pgtables \t\t\t\t\t\t        unlink_file_vma \t\t\t\t\t\t\thugetlb_free_pgd_range \t\t\t\t\t\t    remove_vma_list  In this scenario, it is possible for Process A to share page tables with Process B that is trying to tear them down.  The i_mmap_mutex on its own does not prevent Process A walking Process B's page tables.  At (1) above, the page tables are not shared yet so it unmaps the PMDs.  Process A sets up page table sharing and at (2) faults a new entry.  Process B then trips up on it in free_pgtables.  This patch fixes the problem by adding a new function __unmap_hugepage_range_final that is only called when the VMA is about to be destroyed.  This function clears VM_MAYSHARE during unmap_hugepage_range() under the i_mmap_mutex.  This makes the VMA ineligible for sharing and avoids the race.  Superficially this looks like it would then be vunerable to truncate and madvise issues but hugetlbfs has its own truncate handlers so does not use unmap_mapping_range() and does not support madvise(DONTNEED).  This should be treated as a -stable candidate if it is merged.  Test program is as follows. The test case was mostly written by Michal Hocko with a few minor changes to reproduce this bug.  ==== CUT HERE ====  static size_t huge_page_size = (2UL << 20); static size_t nr_huge_page_A = 512; static size_t nr_huge_page_B = 5632;  unsigned int get_random(unsigned int max) { \tstruct timeval tv;  \tgettimeofday(&tv, NULL); \tsrandom(tv.tv_usec); \treturn random() % max; }  static void play(void *addr, size_t size) { \tunsigned char *start = addr, \t\t      *end = start + size, \t\t      *a; \tstart += get_random(size/2);  \t/* we could itterate on huge pages but let's give it more time. */ \tfor (a = start; a < end; a += 4096) \t\t*a = 0; }  int main(int argc, char **argv) { \tkey_t key = IPC_PRIVATE; \tsize_t sizeA = nr_huge_page_A * huge_page_size; \tsize_t sizeB = nr_huge_page_B * huge_page_size; \tint shmidA, shmidB; \tvoid *addrA = NULL, *addrB = NULL; \tint nr_children = 300, n = 0;  \tif ((shmidA = shmget(key, sizeA, IPC_CREAT|SHM_HUGETLB|0660)) == -1) { \t\tperror(\"shmget:\"); \t\treturn 1; \t}  \tif ((addrA = shmat(shmidA, addrA, SHM_R|SHM_W)) == (void *)-1UL) { \t\tperror(\"shmat\"); \t\treturn 1; \t} \tif ((shmidB = shmget(key, sizeB, IPC_CREAT|SHM_HUGETLB|0660)) == -1) { \t\tperror(\"shmget:\"); \t\treturn 1; \t}  \tif ((addrB = shmat(shmidB, addrB, SHM_R|SHM_W)) == (void *)-1UL) { \t\tperror(\"shmat\"); \t\treturn 1; \t}  fork_child: \tswitch(fork()) { \t\tcase 0: \t\t\tswitch (n%3) { \t\t\tcase 0: \t\t\t\tplay(addrA, sizeA); \t\t\t\tbreak; \t\t\tcase 1: \t\t\t\tplay(addrB, sizeB); \t\t\t\tbreak; \t\t\tcase 2: \t\t\t\tbreak; \t\t\t} \t\t\tbreak; \t\tcase -1: \t\t\tperror(\"fork:\"); \t\t\tbreak; \t\tdefault: \t\t\tif (++n < nr_children) \t\t\t\tgoto fork_child; \t\t\tplay(addrA, sizeA); \t\t\tbreak; \t} \tshmdt(addrA); \tshmdt(addrB); \tdo { \t\twait(NULL); \t} while (--n > 0); \tshmctl(shmidA, IPC_RMID, NULL); \tshmctl(shmidB, IPC_RMID, NULL); \treturn 0; }  [URL]: name the declaration's args, fix CONFIG_HUGETLBFS=n build]", "target": 0}
{"idx": 2315, "commit_message": "Aesthetic patch.  *Slightly* improve the clickable transitions at the configuration page.", "target": 0}
{"idx": 902, "commit_message": "0.3.0  Lot's of refactorings, optimizations, bugfixes, new features", "target": 1}
{"idx": 1716, "commit_message": "drm/msm/a5xx: Add support for Adreno 508, 509, 512 GPUs  The Adreno 508/509/512 GPUs are stripped versions of the Adreno 5xx found in the mid-end SoCs such as SDM630, SDM636, SDM660 and SDA variants; these SoCs are usually provided with ZAP firmwares, but they have no available GPMU.", "target": 0}
{"idx": 2337, "commit_message": "mm: compaction: trace compaction begin and end  commit 0eb927c0ab789d3d7d69f68acb850f69d4e7c36f upstream.  The broad goal of the series is to improve allocation success rates for huge pages through memory compaction, while trying not to increase the compaction overhead.  The original objective was to reintroduce capturing of high-order pages freed by the compaction, before they are split by concurrent activity.  However, several bugs and opportunities for simple improvements were found in the current implementation, mostly through extra tracepoints (which are however too ugly for now to be considered for sending).  The patches mostly deal with two mechanisms that reduce compaction overhead, which is caching the progress of migrate and free scanners, and marking pageblocks where isolation failed to be skipped during further scans.  Patch 1 (from mgorman) adds tracepoints that allow calculate time spent in         compaction and potentially debug scanner pfn values.  Patch 2 encapsulates the some functionality for handling deferred compactions         for better maintainability, without a functional change         type is not determined without being actually needed.  Patch 3 fixes a bug where cached scanner pfn's are sometimes reset only after         they have been read to initialize a compaction run.  Patch 4 fixes a bug where scanners meeting is sometimes not properly detected         and can lead to multiple compaction attempts quitting early without         doing any work.  Patch 5 improves the chances of sync compaction to process pageblocks that         async compaction has skipped due to being !MIGRATE_MOVABLE.  Patch 6 improves the chances of sync direct compaction to actually do anything         when called after async compaction fails during allocation slowpath.  The impact of patches were validated using mmtests's stress-highalloc benchmark with mmtests's stress-highalloc benchmark on a x86_64 machine with 4GB memory.  Due to instability of the results (mostly related to the bugs fixed by patches 2 and 3), 10 iterations were performed, taking min,mean,max values for success rates and mean values for time and vmstat-based metrics.  First, the default GFP_HIGHUSER_MOVABLE allocations were tested with the patches stacked on top of v3.13-rc2.  Patch 2 is OK to serve as baseline due to no functional changes in 1 and 2.  Comments below.  stress-highalloc                              3.13-rc2              3.13-rc2              3.13-rc2              3.13-rc2              3.13-rc2                               2-nothp               3-nothp               4-nothp               5-nothp               6-nothp Success 1 Min          9.00 (  0.00%)       10.00 (-11.11%)       43.00 (-377.78%)       43.00 (-377.78%)       33.00 (-266.67%) Success 1 Mean        27.50 (  0.00%)       25.30 (  8.00%)       45.50 (-65.45%)       45.90 (-66.91%)       46.30 (-68.36%) Success 1 Max         36.00 (  0.00%)       36.00 (  0.00%)       47.00 (-30.56%)       48.00 (-33.33%)       52.00 (-44.44%) Success 2 Min         10.00 (  0.00%)        8.00 ( 20.00%)       46.00 (-360.00%)       45.00 (-350.00%)       35.00 (-250.00%) Success 2 Mean        26.40 (  0.00%)       23.50 ( 10.98%)       47.30 (-79.17%)       47.60 (-80.30%)       48.10 (-82.20%) Success 2 Max         34.00 (  0.00%)       33.00 (  2.94%)       48.00 (-41.18%)       50.00 (-47.06%)       54.00 (-58.82%) Success 3 Min         65.00 (  0.00%)       63.00 (  3.08%)       85.00 (-30.77%)       84.00 (-29.23%)       85.00 (-30.77%) Success 3 Mean        76.70 (  0.00%)       70.50 (  8.08%)       86.20 (-12.39%)       85.50 (-11.47%)       86.00 (-12.13%) Success 3 Max         87.00 (  0.00%)       86.00 (  1.15%)       88.00 ( -1.15%)       87.00 (  0.00%)       87.00 (  0.00%)              3.13-rc2    3.13-rc2    3.13-rc2    3.13-rc2    3.13-rc2              2-nothp     3-nothp     4-nothp     5-nothp     6-nothp User         6437.72     6459.76     5960.32     5974.55     6019.67 System       1049.65     1049.09     1029.32     1031.47     1032.31 Elapsed      1856.77     1874.48     1949.97     1994.22     1983.15                                3.13-rc2    3.13-rc2    3.13-rc2    3.13-rc2    3.13-rc2                                2-nothp     3-nothp     4-nothp     5-nothp     6-nothp Minor Faults                 253952267   254581900   250030122   250507333   250157829 Major Faults                       420         407         506         530         530 Swap Ins                             4           9           9           6           6 Swap Outs                          398         375         345         346         333 Direct pages scanned            197538      189017      298574      287019      299063 Kswapd pages scanned           1809843     1801308     1846674     1873184     1861089 Kswapd pages reclaimed         1806972     1798684     1844219     1870509     1858622 Direct pages reclaimed          197227      188829      298380      286822      298835 Kswapd efficiency                  99%         99%         99%         99%         99% Kswapd velocity                953.382     970.449     952.243     934.569     922.286 Direct efficiency                  99%         99%         99%         99%         99% Direct velocity                104.058     101.832     153.961     143.200     148.205 Percentage direct scans             9%          9%         13%         13%         13% Zone normal velocity           347.289     359.676     348.063     339.933     332.983 Zone dma32 velocity            710.151     712.605     758.140     737.835     737.507 Zone dma velocity                0.000       0.000       0.000       0.000       0.000 Page writes by reclaim         557.600     429.000     353.600     426.400     381.800 Page writes file                   159          53           7          79          48 Page writes anon                   398         375         345         346         333 Page reclaim immediate             825         644         411         575         420 Sector Reads                   2781750     2769780     2878547     2939128     2910483 Sector Writes                 12080843    12083351    12012892    12002132    12010745 Page rescued immediate               0           0           0           0           0 Slabs scanned                  1575654     1545344     1778406     1786700     1794073 Direct inode steals               9657       10037       15795       14104       14645 Kswapd inode steals              46857       46335       50543       50716       51796 Kswapd skipped wait                  0           0           0           0           0 THP fault alloc                     97          91          81          71          77 THP collapse alloc                 456         506         546         544         565 THP splits                           6           5           5           4           4 THP fault fallback                   0           1           0           0           0 THP collapse fail                   14          14          12          13          12 Compaction stalls                 1006         980        1537        1536        1548 Compaction success                 303         284         562         559         578 Compaction failures                702         696         974         976         969 Page migrate success           1177325     1070077     3927538     3781870     3877057 Page migrate failure                 0           0           0           0           0 Compaction pages isolated      2547248     2306457     8301218     8008500     8200674 Compaction migrate scanned    42290478    38832618   153961130   154143900   159141197 Compaction free scanned       89199429    79189151   356529027   351943166   356326727 Compaction cost                   1566        1426        5312        5156        5294 NUMA PTE updates                     0           0           0           0           0 NUMA hint faults                     0           0           0           0           0 NUMA hint local faults               0           0           0           0           0 NUMA hint local percent            100         100         100         100         100 NUMA pages migrated                  0           0           0           0           0 AutoNUMA cost                        0           0           0           0           0  Observations:  - The \"Success 3\" line is allocation success rate with system idle   (phases 1 and 2 are with background interference).  I used to get stable   values around 85% with vanilla 3.11.  The lower min and mean values came   with 3.12.  This was bisected to commit 81c0a2bb (\"mm: page_alloc: fair   zone allocator policy\") As explained in comment for patch 3, I don't   think the commit is wrong, but that it makes the effect of compaction   bugs worse.  From patch 3 onwards, the results are OK and match the 3.11   results.  - Patch 4 also clearly helps phases 1 and 2, and exceeds any results   I've seen with 3.11 (I didn't measure it that thoroughly then, but it   was never above 40%).  - Compaction cost and number of scanned pages is higher, especially due   to patch 4.  However, keep in mind that patches 3 and 4 fix existing   bugs in the current design of compaction overhead mitigation, they do   not change it.  If overhead is found unacceptable, then it should be   decreased differently (and consistently, not due to random conditions)   than the current implementation does.  In contrast, patches 5 and 6   (which are not strictly bug fixes) do not increase the overhead (but   also not success rates).  This might be a limitation of the   stress-highalloc benchmark as it's quite uniform.  Another set of results is when configuring stress-highalloc t allocate with similar flags as THP uses:  (GFP_HIGHUSER_MOVABLE|__GFP_NOMEMALLOC|__GFP_NORETRY|__GFP_NO_KSWAPD)  stress-highalloc                              3.13-rc2              3.13-rc2              3.13-rc2              3.13-rc2              3.13-rc2                                 2-thp                 3-thp                 4-thp                 5-thp                 6-thp Success 1 Min          2.00 (  0.00%)        7.00 (-250.00%)       18.00 (-800.00%)       19.00 (-850.00%)       26.00 (-1200.00%) Success 1 Mean        19.20 (  0.00%)       17.80 (  7.29%)       29.20 (-52.08%)       29.90 (-55.73%)       32.80 (-70.83%) Success 1 Max         27.00 (  0.00%)       29.00 ( -7.41%)       35.00 (-29.63%)       36.00 (-33.33%)       37.00 (-37.04%) Success 2 Min          3.00 (  0.00%)        8.00 (-166.67%)       21.00 (-600.00%)       21.00 (-600.00%)       32.00 (-966.67%) Success 2 Mean        19.30 (  0.00%)       17.90 (  7.25%)       32.20 (-66.84%)       32.60 (-68.91%)       35.70 (-84.97%) Success 2 Max         27.00 (  0.00%)       30.00 (-11.11%)       36.00 (-33.33%)       37.00 (-37.04%)       39.00 (-44.44%) Success 3 Min         62.00 (  0.00%)       62.00 (  0.00%)       85.00 (-37.10%)       75.00 (-20.97%)       64.00 ( -3.23%) Success 3 Mean        66.30 (  0.00%)       65.50 (  1.21%)       85.60 (-29.11%)       83.40 (-25.79%)       83.50 (-25.94%) Success 3 Max         70.00 (  0.00%)       69.00 (  1.43%)       87.00 (-24.29%)       86.00 (-22.86%)       87.00 (-24.29%)              3.13-rc2    3.13-rc2    3.13-rc2    3.13-rc2    3.13-rc2                2-thp       3-thp       4-thp       5-thp       6-thp User         6547.93     6475.85     6265.54     6289.46     6189.96 System       1053.42     1047.28     1043.23     1042.73     1038.73 Elapsed      1835.43     1821.96     1908.67     1912.74     1956.38                                3.13-rc2    3.13-rc2    3.13-rc2    3.13-rc2    3.13-rc2                                  2-thp       3-thp       4-thp       5-thp       6-thp Minor Faults                 256805673   253106328   253222299   249830289   251184418 Major Faults                       395         375         423         434         448 Swap Ins                            12          10          10          12           9 Swap Outs                          530         537         487         455         415 Direct pages scanned             71859       86046      153244      152764      190713 Kswapd pages scanned           1900994     1870240     1898012     1892864     1880520 Kswapd pages reclaimed         1897814     1867428     1894939     1890125     1877924 Direct pages reclaimed           71766       85908      153167      152643      190600 Kswapd efficiency                  99%         99%         99%         99%         99% Kswapd velocity               1029.000    1067.782    1000.091     991.049     951.218 Direct efficiency                  99%         99%         99%         99%         99% Direct velocity                 38.897      49.127      80.747      79.983      96.468 Percentage direct scans             3%          4%          7%          7%          9% Zone normal velocity           351.377     372.494     348.910     341.689     335.310 Zone dma32 velocity            716.520     744.414     731.928     729.343     712.377 Zone dma velocity                0.000       0.000       0.000       0.000       0.000 Page writes by reclaim         669.300     604.000     545.700     538.900     429.900 Page writes file                   138          66          58          83          14 Page writes anon                   530         537         487         455         415 Page reclaim immediate             806         655         772         548         517 Sector Reads                   2711956     2703239     2811602     2818248     2839459 Sector Writes                 12163238    12018662    12038248    11954736    11994892 Page rescued immediate               0           0           0           0           0 Slabs scanned                  1385088     1388364     1507968     1513292     1558656 Direct inode steals               1739        2564        4622        5496        6007 Kswapd inode steals              47461       46406       47804       48013       48466 Kswapd skipped wait                  0           0           0           0           0 THP fault alloc                    110          82          84          69          70 THP collapse alloc                 445         482         467         462         539 THP splits                           6           5           4           5           3 THP fault fallback                   3           0           0           0           0 THP collapse fail                   15          14          14          14          13 Compaction stalls                  659         685        1033        1073        1111 Compaction success                 222         225         410         427         456 Compaction failures                436         460         622         646         655 Page migrate success            446594      439978     1085640     1095062     1131716 Page migrate failure                 0           0           0           0           0 Compaction pages isolated      1029475     1013490     2453074     2482698     2565400 Compaction migrate scanned     9955461    11344259    24375202    27978356    30494204 Compaction free scanned       27715272    28544654    80150615    82898631    85756132 Compaction cost                    552         555        1344        1379        1436 NUMA PTE updates                     0           0           0           0           0 NUMA hint faults                     0           0           0           0           0 NUMA hint local faults               0           0           0           0           0 NUMA hint local percent            100         100         100         100         100 NUMA pages migrated                  0           0           0           0           0 AutoNUMA cost                        0           0           0           0           0  There are some differences from the previous results for THP-like allocations:  - Here, the bad result for unpatched kernel in phase 3 is much more   consistent to be between 65-70% and not related to the \"regression\" in   3.12.  Still there is the improvement from patch 4 onwards, which brings   it on par with simple GFP_HIGHUSER_MOVABLE allocations.  - Compaction costs have increased, but nowhere near as much as the   non-THP case.  Again, the patches should be worth the gained   determininsm.  - Patches 5 and 6 somewhat increase the number of migrate-scanned pages.    This is most likely due to __GFP_NO_KSWAPD flag, which means the cached   pfn's and pageblock skip bits are not reset by kswapd that often (at   least in phase 3 where no concurrent activity would wake up kswapd) and   the patches thus help the sync-after-async compaction.  It doesn't   however show that the sync compaction would help so much with success   rates, which can be again seen as a limitation of the benchmark   scenario.  This patch (of 6):  Add two tracepoints for compaction begin and end of a zone.  Using this it is possible to calculate how much time a workload is spending within compaction and potentially debug problems related to cached pfns for scanning.  In combination with the direct reclaim and slab trace points it should be possible to estimate most allocation-related overhead for a workload.", "target": 1}
{"idx": 2811, "commit_message": "Release 1.1, many new features and performance improvements. See README.md", "target": 1}
{"idx": 3375, "commit_message": "Dramatically improve watch mode performance. (#8201)  ## Summary    Resolves #7341     This PR dramatically improves watch mode performance, bringing it in line with single run mode performance. It accomplishes that by:  - Workers previously initialized a new `ModuleMap` and `Resolver` for every test in watch mode. Now, those objects are only initialized once when the worker is setup.  - In the main thread, caching the conversion of `ModuleMap` to a JSON-friendly object.  - Allowing watch mode to use the same number of CPUs as single run mode.    ## Benchmarks    I benchmarked against Jest's own test suite, excluding e2e tests which don't provide good signal because they individually take a long time (so startup time for the test is marginalized). The numbers show that running in Watch mode previously added an extra 35%~ of runtime to the tests but that has now been reduced to almost nothing.    Watch mode should now just be paying a one-time initial cost for each worker when the haste map changes instead of paying that same cost for _every_ test run.    ### branch: master    `yarn jest ./packages`  Run time: 15.091s    `yarn jest ./packages --watch`  Run time: 23.234s    ### branch: watch-performance    `yarn jest ./packages`  Run time: 14.973s    `yarn jest ./packages --watch`  Run time: 15.196s      ## Test plan    - All tests pass.  - Benchmarked to verify the performance wins.  - Verified that when the haste map is updated, the update is propagated out to all workers.", "target": 1}
{"idx": 2014, "commit_message": "- Minor bug-fixes and performance improvements. - Added more Sidef scripts.", "target": 1}
{"idx": 3687, "commit_message": "Rollback of rL355585.  Introduces memory leak in FunctionTest.GetPointerAlignment that breaks sanitizer buildbots:  ``` ================================================================= ==2453==ERROR: LeakSanitizer: detected memory leaks  Direct leak of 128 byte(s) in 1 object(s) allocated from:     #0 0x610428 in operator new(unsigned long) /b/sanitizer-x86_64-linux-bootstrap/build/llvm/projects/compiler-rt/lib/asan/asan_new_delete.cc:105     #1 0x16936bc in llvm::User::operator new(unsigned long) /b/sanitizer-x86_64-linux-bootstrap/build/llvm/lib/IR/User.cpp:151:19     #2 0x7c3fe9 in Create /b/sanitizer-x86_64-linux-bootstrap/build/llvm/include/llvm/IR/Function.h:144:12     #3 0x7c3fe9 in (anonymous namespace)::FunctionTest_GetPointerAlignment_Test::TestBody() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/unittests/IR/FunctionTest.cpp:136     #4 0x1a836a0 in HandleExceptionsInMethodIfSupported<testing::Test, void> /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc     #5 0x1a836a0 in testing::Test::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2474     #6 0x1a85c55 in testing::TestInfo::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2656:11     #7 0x1a870d0 in testing::TestCase::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2774:28     #8 0x1aa5b84 in testing::internal::UnitTestImpl::RunAllTests() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:4649:43     #9 0x1aa4d30 in HandleExceptionsInMethodIfSupported<testing::internal::UnitTestImpl, bool> /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc     #10 0x1aa4d30 in testing::UnitTest::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:4257     #11 0x1a6b656 in RUN_ALL_TESTS /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/include/gtest/gtest.h:2233:46     #12 0x1a6b656 in main /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/UnitTestMain/TestMain.cpp:50     #13 0x7f5af37a22e0 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x202e0)  Indirect leak of 40 byte(s) in 1 object(s) allocated from:     #0 0x610428 in operator new(unsigned long) /b/sanitizer-x86_64-linux-bootstrap/build/llvm/projects/compiler-rt/lib/asan/asan_new_delete.cc:105     #1 0x151be6b in make_unique<llvm::ValueSymbolTable> /b/sanitizer-x86_64-linux-bootstrap/build/llvm/include/llvm/ADT/STLExtras.h:1349:29     #2 0x151be6b in llvm::Function::Function(llvm::FunctionType*, llvm::GlobalValue::LinkageTypes, unsigned int, llvm::Twine const&, llvm::Module*) /b/sanitizer-x86_64-linux-bootstrap/build/llvm/lib/IR/Function.cpp:241     #3 0x7c4006 in Create /b/sanitizer-x86_64-linux-bootstrap/build/llvm/include/llvm/IR/Function.h:144:16     #4 0x7c4006 in (anonymous namespace)::FunctionTest_GetPointerAlignment_Test::TestBody() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/unittests/IR/FunctionTest.cpp:136     #5 0x1a836a0 in HandleExceptionsInMethodIfSupported<testing::Test, void> /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc     #6 0x1a836a0 in testing::Test::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2474     #7 0x1a85c55 in testing::TestInfo::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2656:11     #8 0x1a870d0 in testing::TestCase::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2774:28     #9 0x1aa5b84 in testing::internal::UnitTestImpl::RunAllTests() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:4649:43     #10 0x1aa4d30 in HandleExceptionsInMethodIfSupported<testing::internal::UnitTestImpl, bool> /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc     #11 0x1aa4d30 in testing::UnitTest::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:4257     #12 0x1a6b656 in RUN_ALL_TESTS /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/include/gtest/gtest.h:2233:46     #13 0x1a6b656 in main /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/UnitTestMain/TestMain.cpp:50     #14 0x7f5af37a22e0 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x202e0)  SUMMARY: AddressSanitizer: 168 byte(s) leaked in 2 allocation(s). ```  See [URL]:8011/builders/sanitizer-x86_64-linux-bootstrap/builds/11358/steps/check-llvm%20asan/logs/stdio for more information.  Also introduces use-of-uninitialized-value in ConstantsTest.FoldGlobalVariablePtr: ``` ==7070==WARNING: MemorySanitizer: use-of-uninitialized-value     #0 0x14e703c in User /b/sanitizer-x86_64-linux-fast/build/llvm/include/llvm/IR/User.h:79:5     #1 0x14e703c in Constant /b/sanitizer-x86_64-linux-fast/build/llvm/include/llvm/IR/Constant.h:44     #2 0x14e703c in llvm::GlobalValue::GlobalValue(llvm::Type*, llvm::Value::ValueTy, llvm::Use*, unsigned int, llvm::GlobalValue::LinkageTypes, llvm::Twine const&, unsigned int) /b/sanitizer-x86_64-linux-fast/build/llvm/include/llvm/IR/GlobalValue.h:78     #3 0x14e5467 in GlobalObject /b/sanitizer-x86_64-linux-fast/build/llvm/include/llvm/IR/GlobalObject.h:34:9     #4 0x14e5467 in llvm::GlobalVariable::GlobalVariable(llvm::Type*, bool, llvm::GlobalValue::LinkageTypes, llvm::Constant*, llvm::Twine const&, llvm::GlobalValue::ThreadLocalMode, unsigned int, bool) /b/sanitizer-x86_64-linux-fast/build/llvm/lib/IR/Globals.cpp:314     #5 0x6938f1 in llvm::(anonymous namespace)::ConstantsTest_FoldGlobalVariablePtr_Test::TestBody() /b/sanitizer-x86_64-linux-fast/build/llvm/unittests/IR/ConstantsTest.cpp:565:18     #6 0x1a240a1 in HandleExceptionsInMethodIfSupported<testing::Test, void> /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc     #7 0x1a240a1 in testing::Test::Run() /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc:2474     #8 0x1a26d26 in testing::TestInfo::Run() /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc:2656:11     #9 0x1a2815f in testing::TestCase::Run() /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc:2774:28     #10 0x1a43de8 in testing::internal::UnitTestImpl::RunAllTests() /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc:4649:43     #11 0x1a42c47 in HandleExceptionsInMethodIfSupported<testing::internal::UnitTestImpl, bool> /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc     #12 0x1a42c47 in testing::UnitTest::Run() /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc:4257     #13 0x1a0dfba in RUN_ALL_TESTS /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/include/gtest/gtest.h:2233:46     #14 0x1a0dfba in main /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/UnitTestMain/TestMain.cpp:50     #15 0x7f2081c412e0 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x202e0)     #16 0x4dff49 in _start (/b/sanitizer-x86_64-linux-fast/build/llvm_build_msan/unittests/IR/IRTests+0x4dff49)  SUMMARY: MemorySanitizer: use-of-uninitialized-value /b/sanitizer-x86_64-linux-fast/build/llvm/include/llvm/IR/User.h:79:5 in User ```  See [URL]:8011/builders/sanitizer-x86_64-linux-fast/builds/30222/steps/check-llvm%20msan/logs/stdio for more information.", "target": 0}
{"idx": 1402, "commit_message": "bbexample-lt: Correct location of local tarball", "target": 0}
{"idx": 2851, "commit_message": "Attempt to improve study list performance", "target": 1}
{"idx": 3611, "commit_message": "Right... just a few changes. Here we go: - Increased default math library precision - Modified math_raw_be_to_long() to increase performance - Removed unused math_slong_to_bits() function - Removed unnecessary parenthesis - Renamed math_is_whole_number() to is_int() and re-wrote to function over all possible double precision floating point values - Added is_Nan() - Added is_infinite() - Re-wrote ceil() to use functionality provided by floor() - Re-wrote floor to behave well with NaN's, +/-infinity, +/- 0 and subnormals (still relies on type cast to long though so breaks above 2^32) - Added IEEEremainder() - Modified sqrt() to behave well with NaN's, +/-infinity and 0 and limited to max 1000 refinements - Re-wrote fast_inv_sqrt() to function with a double as input - Modified fast_sqrt() to function with a double as input - Moved test_error() to test_math.axi - Wrote math library test suite (still needs a bit more work) - Misc commenting improvements - Removed trailing whitespace - Set svn:ignore properties for /test", "target": 1}
{"idx": 1992, "commit_message": "make height of script output somewhat dynamic  this lets it take up a lot less space when the output is short.", "target": 0}
{"idx": 342, "commit_message": "Improve the Information component to better support model changes", "target": 0}
{"idx": 960, "commit_message": "Skip undefined/bool children and allow onClick, onCreate, etc. event names.  * Don't createElement from null/bool child nodes. Fix #94. Fix #95. * Allow events to be written in camelCase. * Support options.reducers in favor of options.update (to be deprecated in 0.6.0). * Improve documentation, move portions of previous build boilerplates to the user guide (WIP).", "target": 0}
{"idx": 1757, "commit_message": "TST: added EAB and Dual Boundary tests  Added EAB and Dual Boundary tests for the pysat functions.  Also specified the `max_sdiff` kwarg and improved style consistency.", "target": 0}
{"idx": 2356, "commit_message": "refactor timer code to be much cleaner and more efficient", "target": 1}
{"idx": 3109, "commit_message": "Merge pull request #1921 from lafranceinsoumise/gdp/try-to-improve-vpr-matching-script-performances  Try to improve `match_available_proxies_with_requests` query time", "target": 1}
{"idx": 2486, "commit_message": "A number of performance improvements in the loader.  Reviewed by me.", "target": 1}
{"idx": 2565, "commit_message": "Performance report fix for common data", "target": 0}
{"idx": 598, "commit_message": "Updates to run_cmd to avoid hanging, config adds /usr/local/include, improved test_harness support.", "target": 1}
{"idx": 48, "commit_message": "mm, vmstat: Fix CPU hotplug callback registration  Subsystems that want to register CPU hotplug callbacks, as well as perform initialization for the CPUs that are already online, often do it as shown below:          get_online_cpus();          for_each_online_cpu(cpu)                 init_cpu(cpu);          register_cpu_notifier(&foobar_cpu_notifier);          put_online_cpus();  This is wrong, since it is prone to ABBA deadlocks involving the cpu_add_remove_lock and the cpu_hotplug.lock (when running concurrently with CPU hotplug operations).  Instead, the correct and race-free way of performing the callback registration is:          cpu_notifier_register_begin();          for_each_online_cpu(cpu)                 init_cpu(cpu);          /* Note the use of the double underscored version of the API */         __register_cpu_notifier(&foobar_cpu_notifier);          cpu_notifier_register_done();  Fix the vmstat code in the MM subsystem by using this latter form of callback registration.  Cc: Andrew Morton [URL]> Cc: Rik van Riel [URL]> Cc: Johannes Weiner [URL]> Cc: Cody P Schafer [URL]> Cc: Toshi Kani [URL]> Cc: Dave Hansen [URL]> Cc: Ingo Molnar [URL]> Cc: [URL] Acked-by: Christoph Lameter [URL]>", "target": 0}
{"idx": 39, "commit_message": "Add both IPv4 and IPv6 DHCP options if interface has both  It is possible that an interface has both IPv4 and IPv6 addresses, primarily when using SLAAC with OpenStack Neutron.  When this is the case, it is very likely that the first fixed IP would be a SLAAC assigned port and the second IP is the IPv4 address.  In an environment where you are looking to boot via IPv4, no DHCPv6 infrastructure exists as IPv6 connectivity is provided via SLAAC, you would not be able to use this network to boot off of.  This patch instead grabs all the fixed IP addresses, then inserts the options that match the IP versions which are attached to the interface, potentially resulting in both IPv4 and IPv6 options being included (though the IPv6 ones would be largely omitted).  In environments where only IPv4 or IPv6 is in use on the port, it will still only insert the options for those specific IP versions.  Story #2008660 Task #41933", "target": 0}
{"idx": 2891, "commit_message": "- Patch #777728 by Jeff Burnz: improve formatting of default search block.", "target": 0}
{"idx": 3411, "commit_message": "net: fec: Add software TSO support  Add software TSO support for FEC. This feature allows to improve outbound throughput performance.  Tested on imx6dl sabresd board, running iperf tcp tests shows: - 16.2% improvement comparing with FEC SG patch - 82% improvement comparing with NO SG & TSO patch  $ ethtool -K eth0 tso on $ iperf -c 10.192.242.167 -t 3 & [  3] local 10.192.242.108 port 35388 connected with 10.192.242.167 port 5001 [ ID] Interval       Transfer     Bandwidth [  3]  0.0- 3.0 sec   181 MBytes   506 Mbits/sec  During the testing, CPU loading is 30%. Since imx6dl FEC Bandwidth is limited to SOC system bus bandwidth, the performance with SW TSO is a milestone.  CC: Ezequiel Garcia [URL]> CC: Eric Dumazet [URL]> CC: David Laight < > CC: Li Frank [URL]>", "target": 1}
{"idx": 3986, "commit_message": "- fixed performance issue on small matrix inversion for SPD matrices", "target": 1}
{"idx": 263, "commit_message": "Merge pull request #244 from ladybug-tools/test_coverage_improvement  Added test for Radiance trans material", "target": 0}
{"idx": 3794, "commit_message": "Performance optimization for displaying earlier script version", "target": 1}
{"idx": 1727, "commit_message": "statistics: draw legend as a QSGNode  In order not to waste CPU by constantly rerendering the chart, we must use these weird OpenGL QSGNode things. The interface is appallingly low-level and unfriendly.  As a first test, try to convert the legend. Create a wrapper class that represents a rectangular item with a texture and that will certainly need some (lots of) optimization.  Make sure that all low-level QSG-objects are only accessed in the rendering thread. This means that the wrapper has to maintain a notion of \"dirtiness\" of the state. I.e. which part of the QSG-objects have to be modified.  From the low-level wrapper derive a class that draws a rounded rectangle for every resize. The child class of that must then paint on the rectangle after every resize.  That looks all not very fortunate, but it displays a legend and will make it possible to move the legend without and drawing operations, only shifting around an OpenGL surface.  The render thread goes through all chart-items and rerenders them if dirty. Currently, on deletion of these items, this list is not reset. I.e. currently it is not supported to remove individual items. Only the full scene can be cleared!", "target": 0}
{"idx": 1312, "commit_message": "[PATCH] remove ide_cmd_type_parser() logic  Set ide_task_t fields (command_type, handler and prehandler) directly. Remove unused ide_task_t->posthandler and all ide_cmd_type_parser() logic.  ide_cmd_type_parser() was meant to be used for ioctls but ended up checking validity of kernel generated requests (doh!).  Rationale for removal: - it can't be used for existing ioctls (changes the way they work) - kernel shouldn't check validity of (root only) user-space requests   (it can and should be done in user-space) - it wastes CPU cycles on going through parsers - it makes code harder to understand/follow   (now info about request is localized)", "target": 0}
{"idx": 3351, "commit_message": "Performance Budget large header fix--thanks Stan", "target": 0}
{"idx": 2411, "commit_message": "Avoid filtering messages query by empty in-predicate.  Doing db_session.query(Message).filter(Message.id.in_(ids)) when ids is empty causes ``` /usr/local/lib/python2.7/dist-packages/sqlalchemy/sql/default_comparator.py:33: SAWarning: The IN-predicate on \"message.id\" was invoked with an empty sequence. This results in a contradiction, which nonetheless can be expensive to evaluate.  Consider alternative strategies for improved performance.```  But we can simply short-circuit instead of doing the query.", "target": 1}
{"idx": 272, "commit_message": "Update [2.3.3]  -App startup optimized -First run errors fixed -Image Size checking added (before flash) -Blocksize argument added on flash -Progress on creating backups -Blocksize checking added -Startup notification fixed", "target": 1}
{"idx": 1034, "commit_message": "[ui] Sort processes by slice count as a fallback  When processes have no heap profiles, perf sample, or cpu scheduling info, we now sort processes by slice count instead. This is indended to display processes more prominently if the contain more events from the tracing categories the user requested.  Testing: Record a trace that contains system wide trace events without cpu scheduling data, but that also includes data from the forground app: \"./tools/record_android_trace view binder_driver\"  Verify the forground app appears at, or near the top of of the trace when opened", "target": 0}
{"idx": 2611, "commit_message": "[BEAM-9268] SpannerIO: Add more documentation and warnings for unknown tables. (#10690)  * Add more documentation and warnings for unknown tables.    When a table is not known to SpannerIO, this causes performance issues  because the Mutations can not be sorted by primary key.    This change adds more information to the javadoc, and logs a warning  for every 10K mutations referencing an unknown table.    * Fix Checkstyle errors", "target": 0}
{"idx": 1748, "commit_message": "Merge branch 'master' of [URL]:acidgenomics/basejump into develop", "target": 0}
{"idx": 999, "commit_message": "Use self-hosted Github Actions runner on glpi-network repository", "target": 0}
{"idx": 639, "commit_message": "Pure network functions don't generate tasks any more.", "target": 0}
{"idx": 4049, "commit_message": "[PATCH] Adds a URIManager to manage all URIs within an array\n directory. This introduces several performance improvements, especially\n around redundant URI listings, parallelizing URI listings, etc. Also makes\n VFS::ls a noop for POSIX and HDFS when the listed directory does not exist\n instead of throwing an error, matching the functionality of the object\n stores. Finally, it removes partial vacuuming, as that leads to incorrect\n behavior with time traveling.", "target": 1}
{"idx": 614, "commit_message": "Merge pull request #278 from andir/to_dict_speedup  Speedup to_dict with sqlalchemy.inspection", "target": 1}
{"idx": 89, "commit_message": "sched: window-stats: adjust RQ curr, prev sums on task migration  Adjust cpu's busy time in its recent and previous window upon task migration. This would enable scheduler to provide better inputs to cpufreq governor on a cpu's busy time in a given window.", "target": 0}
{"idx": 4024, "commit_message": "[PATCH] Fix performance problems for large molecular systems", "target": 1}
{"idx": 3322, "commit_message": "Add memoisation to improve performance on clinical summary", "target": 1}
{"idx": 1081, "commit_message": "Improve maven-shade-plugin filter, and move to parent pom.  - Removes 223 build warnings (out of 562 for building non-test code)", "target": 0}
{"idx": 856, "commit_message": "Improve support for Python3 in Mac, iOS build  - Decode the result of subprocess.Popen() so that the stdout/stderr   result is str, not bytes. - Use dict.items() instead of dict.iteritems(). - If the return of map() needs to be a list, use list comprehension. - Use range() instead of xrange(). - Tuple parameter unpacking is removed on Python3, refactor its usage. - struct.pack() doesn't accept str, convert arguments as bytes. - plistlib has several API changes. Replace removed.   functions (readPlistFromString). Still have some warnings like this:   \"The readPlist function is deprecated, use load() instead\" - _GetOutputNoError() in tweak_info_plist.py has no usage. Removed.  No intended behavior change.  Bug: 941669", "target": 0}
{"idx": 3453, "commit_message": "Fix a fairly major performance problem.  If a PHI node had a constant as an incoming value from a block, the selector would evaluate the constant at the TOP of the block instead of at the end of the block.  This made the live range for the constant span the entire block, increasing register pressure needlessly.", "target": 1}
{"idx": 1190, "commit_message": "- Split the text writer routine to limit the CPU load.", "target": 1}
{"idx": 1046, "commit_message": "gnu: abjad: Improve description.  * gnu/packages/music.scm (abjad)[description]: Improve abjad's description.", "target": 0}
{"idx": 810, "commit_message": "xwgir-call-method invoke function on an xwidget dynamically", "target": 0}
{"idx": 3655, "commit_message": "Redis: Don't use keys, port to scan for better performance", "target": 1}
{"idx": 1595, "commit_message": "Improve navigation flow of image viewer when \"start in gallery mode\" is on (#439)", "target": 0}
{"idx": 867, "commit_message": "tcp: Fix integer-overflow in TCP vegas  [ Upstream commit 1f74e613ded11517db90b2bd57e9464d9e0fb161 ]  In vegas we do a multiplication of the cwnd and the rtt. This may overflow and thus their result is stored in a u64. However, we first need to cast the cwnd so that actually 64-bit arithmetic is done.  Then, we need to do do_div to allow this to be used on 32-bit arches.  Cc: Stephen Hemminger [URL]> Cc: Neal Cardwell [URL]> Cc: Eric Dumazet [URL]> Cc: David Laight < > Cc: Doug Leith < > Fixes: 8d3a564da34e (tcp: tcp_vegas cong avoid fix)", "target": 0}
{"idx": 3959, "commit_message": "* samtools-0.1.5-34 (r451)  * applied the patch by John  * improved the help message a little bit", "target": 0}
{"idx": 435, "commit_message": "Improve private room support  It's now possible to convert between secret and hidden rooms without first making the room public. 'Secret room' is now the official name for private rooms that aren't affected by global moderation, and a new alias /secretroom has been introduced to reflect that.", "target": 0}
{"idx": 2501, "commit_message": "net: remove skb_orphan_try()  [ Upstream commit 62b1a8ab9b3660bb820d8dfe23148ed6cda38574 ]  Orphaning skb in dev_hard_start_xmit() makes bonding behavior unfriendly for applications sending big UDP bursts : Once packets pass the bonding device and come to real device, they might hit a full qdisc and be dropped. Without orphaning, the sender is automatically throttled because sk->sk_wmemalloc reaches sk->sk_sndbuf (assuming sk_sndbuf is not too big)  We could try to defer the orphaning adding another test in dev_hard_start_xmit(), but all this seems of little gain, now that BQL tends to make packets more likely to be parked in Qdisc queues instead of NIC TX ring, in cases where performance matters.  Reverts commits : fc6055a5ba31 net: Introduce skb_orphan_try() 87fd308cfc6b net: skb_tx_hash() fix relative to skb_orphan_try() and removes SKBTX_DRV_NEEDS_SK_REF flag  Reported-and-bisected-by: Jean-Michel Hautbois [URL]>", "target": 0}
{"idx": 3539, "commit_message": "sparc: perf: Make counting mode actually work  [ Upstream commit d51291cb8f32bfae6b331e1838651f3ddefa73a5 ]  Currently perf-stat (aka, counting mode) does not work:  $ perf stat ls ...  Performance counter stats for 'ls':            1.585665      task-clock (msec)         #    0.580 CPUs utilized                 24      context-switches          #    0.015 M/sec                  0      cpu-migrations            #    0.000 K/sec                 86      page-faults               #    0.054 M/sec    <not supported>      cycles    <not supported>      stalled-cycles-frontend    <not supported>      stalled-cycles-backend    <not supported>      instructions    <not supported>      branches    <not supported>      branch-misses         0.002735100 seconds time elapsed  The reason is that state is never reset (stays with PERF_HES_UPTODATE set). Add a call to sparc_pmu_enable_event during the added_event handling. Clean up the encoding since pmu_start calls sparc_pmu_enable_event which does the same. Passing PERF_EF_RELOAD to sparc_pmu_start means the call to sparc_perf_event_set_period can be removed as well.  With this patch:  $ perf stat ls ...  Performance counter stats for 'ls':            1.552890      task-clock (msec)         #    0.552 CPUs utilized                 24      context-switches          #    0.015 M/sec                  0      cpu-migrations            #    0.000 K/sec                 86      page-faults               #    0.055 M/sec          5,748,997      cycles                    #    3.702 GHz    <not supported>      stalled-cycles-frontend:HG    <not supported>      stalled-cycles-backend:HG          1,684,362      instructions:HG           #    0.29  insns per cycle            295,133      branches:HG               #  190.054 M/sec             28,007      branch-misses:HG          #    9.49% of all branches         0.002815665 seconds time elapsed", "target": 0}
{"idx": 646, "commit_message": "gpu: Arm: Smoothen GPU throttling levels", "target": 1}
{"idx": 2008, "commit_message": "[p6object] Refactor ACCEPTS to better handle non-P6 objects and maybe a little performance win too.", "target": 0}
{"idx": 2710, "commit_message": "perf: update textwrap to version 0.7.0  This version of textwrap uses a new wrapping algorithm that allocates fewer strings on the heap.  The 05_ripgrep benchmarks shows a performance improvement of 3-15%. The build_help_long benchmark benefits the most since it uses longer help texts.", "target": 1}
{"idx": 2330, "commit_message": "OK this is important. So read it carefully.  This checkin implements route matching of comments so that they are only accepted from the same route as the top-level post they are attached to. This way there should be no mis-match of permissions between any posts in the thread. It may not be completely compatible with comments posted in the past (though I've tried to be, there may be some minor issues). In addition it seems that relaying was invoked more often than necessary - especially when a duplicate post arrived which was not processed because the edited time hadn't changed - it still invoked relaying. This fix should improve site performance considerably for comments cross-posted to forums; which got bounced around a bit and delivered redundantly for no reason.  Roll this back *only* if it causes a meltdown or comment loss is \"serious\" (as in OMG people are dying, make it stop!). If we can get past 24 hours without serious issue we need to get everybody onto this code. There may be some minor comment loss (mostly affecting new comments to older posts or likes of older comments) until the majority of sites have moved to the new code.  It may be difficult or impossible to deliver comments to posts that pre-date the addition of source routes (April 1, 2014) to anybody but the top-level post author at his/her primary hub. We may wish to close comments on these posts, but let's see how we go before doing that.", "target": 1}
{"idx": 556, "commit_message": "habanalabs: prevent CPU soft lockup on Palladium  Unmapping ptes in the device MMU on Palladium can take a long time, which can cause a kernel BUG of CPU soft lockup.  This patch minimize the chances for this bug by sleeping a little between unmapping ptes.", "target": 1}
{"idx": 2630, "commit_message": "AP_ADSB: delete furthest when buffer is full  - added lowest/highest_threat tracking. This is currently defined as 2D distance. Room for improvement to make it 3D and be flight vector based instead of distance - when trying to add a vehicle but  the buffer is full, overwrite the lowest_threat/furthest - added basic THREAT enum of high/low which means in or our of the 200m radius. Room for improvement here.", "target": 0}
{"idx": 3271, "commit_message": "Use CSS3 2D Transforms for better performance", "target": 1}
{"idx": 3443, "commit_message": "Fix some bugs in StructTreeRoot parsing of parent tree  - Add support for parsing child nodes in the number tree - Number tree keys do not have to be consecutive numbers. Use   map instead of vector for parentTree. - Due to performance impact of iterating a map instead of   vector in parentTreeAdd, add a reverse mapping from Ref   to parentTree. - Add mcid parameter to findParentElement() to enable finding   the parent when there are multiple MCIDs on the same page. - Move RefCompare from pdfinfo.cc to Object.h so it can be   used by other files.  Bug #103912", "target": 0}
{"idx": 3146, "commit_message": "[TASK] Improve and fix ThumbnailController  The ThumbnailController outputs raw data of image files as a response to a file process request. This is a massive and unnecessary performance hit, when using a remote storage, as the files need to get downloaded from the remote to be then delivered by TYPO3.  This is now changed to simply redirect to the file URL.  Also the mime-type check for images is replaced with an isImage() call to the processed file, in order to also properly deliver thumbnails of PDF files.  Also clarify in code, that ProcessedFile::CONTEXT_IMAGEPREVIEW isn't capable of handling any other processing instruction than \"width\" and \"height\".  Also fix delivering an icon as thumbnail, when the processed file isn't an image.  Last but not least, fix the 404 response by using a HtmlResponse instead of a plain Response object, because the plain Response object needs a resource and cannot deal with plain strings.  Releases: master, 10.4, 9.5 Resolves: #91976", "target": 1}
{"idx": 3578, "commit_message": "Merge pull request #172 from halkyon/performance_improvements  BUG Performance improvements of SubmittedFormField queries.", "target": 1}
{"idx": 3782, "commit_message": "Fixed performance regression in RecursiveBinMapper, added warning that w_kinetics matrix is experimental.", "target": 1}
{"idx": 679, "commit_message": "re PR middle-end/40084 (Revision 147294 failed 483.xalancbmk in SPEC CPU 2006 at -O3)  \tPR middle-end/40084 \t* cgraph.c (cgraph_update_edges_for_call_stmt_node): Take old_call argument; \trewrite. \t(cgraph_update_edges_for_call_stmt): Take old_decl argument. \t* cgraph.h (cgraph_update_edges_for_call_stmt): Update prototype. \t* tree-inline.c (copy_bb): Set frequency correctly. \t(fold_marked_statements): Update call of cgraph_update_edges_for_call_stmt.  From-SVN: r147337", "target": 0}
{"idx": 1512, "commit_message": "Don't give the heap execute permission - the linux kernel doesn't normally give execute permission to memory allocated from the heap with sbrk.  This also required fixing the smc1 test for amd64 to use mmap to allocate memory so that it can have execute permission.", "target": 0}
{"idx": 1990, "commit_message": "More improvements to the _Command_ object.  Actually removed the 'more flexible' magic __get & __set options, this was never a good idea.  Also, built an Abstract class with which to extend into concrete classes. The _Dispatch_ object should know completely what it is being passed.", "target": 0}
{"idx": 324, "commit_message": "RECOVER: When we pull databases during recovery, we used to reallocate the databuffer for each entry added. This would normally not be an issue, but for cases where memory is fragmented, this could start to cost significant cpu if we need to reallocate and move to a different region.  Change this to instead preallocate , by default, 10MByte chunks to the data buffer. This significantly reduces the number of potential reallocate and move  operations that may be required.  Create a tunable to override/change how much preallocation should be used.  (This used to be ctdb commit 1f262deaad0818f159f9c68330f7fec121679023)", "target": 1}
{"idx": 3992, "commit_message": "[PATCH] s390x: Use new sgemm kernel also for strmm on Z14 and newer\n\nEmploy the newly added GEMM kernel also for STRMM on Z14. The\nimplementation in C with vector intrinsics exploits FP32 SIMD operations\nand thereby gains performance over the existing assembly code. Extend\nthe implementation for handling triangular matrix multiplication,\naccordingly. As added benefit, the more flexible C code enables us to\nadjust register blocking in the subsequent commit.\n\nTested via make -C test / ctest / utest and by a couple of additional\nunit tests that exercise blocking.\n\nSigned-off-by: Marius Hillenbrand <mhillen@linux.ibm.com>", "target": 1}
{"idx": 816, "commit_message": "drm/i915: fix pch pci device enumeration  pci_get_class(class, from) drops the refcount for 'from', so the extra pci_dev_put we do on it will result in a use after free bug starting with the WARN below.  Regression introduced in  commit 6a9c4b35e6696a63805b6da5e4889c6986e9ee1b Author: Rui Guo [URL]> Date:   Wed Jun 19 21:10:23 2013 +0800      drm/i915: Fix PCH detect with multiple ISA bridges in VM  [  164.338460] WARNING: CPU: 1 PID: 2094 at include/linux/kref.h:47 klist_next+0xae/0x110() [  164.347731] CPU: 1 PID: 2094 Comm: modprobe Tainted: G           O 3.13.0-imre+ #354 [  164.356468] Hardware name: Intel Corp. VALLEYVIEW B0 PLATFORM/NOTEBOOK, BIOS BYTICRB1.X64.0062.R70.1310112051 10/11/2013 [  164.368796] Call Trace: [  164.371609]  [<ffffffff816a32a6>] dump_stack+0x4e/0x7a [  164.377447]  [<ffffffff8104f75d>] warn_slowpath_common+0x7d/0xa0 [  164.384238]  [<ffffffff8104f83a>] warn_slowpath_null+0x1a/0x20 [  164.390851]  [<ffffffff8169aeae>] klist_next+0xae/0x110 [  164.396777]  [<ffffffff8130a110>] ? pci_do_find_bus+0x70/0x70 [  164.403286]  [<ffffffff813cb4a9>] bus_find_device+0x89/0xc0 [  164.409719]  [<ffffffff8130a373>] pci_get_dev_by_id+0x63/0xa0 [  164.416238]  [<ffffffff8130a4e4>] pci_get_class+0x44/0x50 [  164.422433]  [<ffffffffa034821f>] intel_dsm_detect+0x16f/0x1f0 [i915] [  164.429801]  [<ffffffffa03482ae>] intel_register_dsm_handler+0xe/0x10 [i915] [  164.437831]  [<ffffffffa02d30fe>] i915_driver_load+0xafe/0xf30 [i915] [  164.445126]  [<ffffffff8158a150>] ? intel_alloc_coherent+0x110/0x110 [  164.452340]  [<ffffffffa0148c07>] drm_dev_register+0xc7/0x150 [drm] [  164.459462]  [<ffffffffa014b23f>] drm_get_pci_dev+0x11f/0x1f0 [drm] [  164.466554]  [<ffffffff816abb81>] ? _raw_spin_unlock_irqrestore+0x51/0x70 [  164.474287]  [<ffffffffa02cf7a6>] i915_pci_probe+0x56/0x60 [i915] [  164.481185]  [<ffffffff8130a028>] pci_device_probe+0x78/0xf0 [  164.487603]  [<ffffffff813cd495>] driver_probe_device+0x155/0x350 [  164.494505]  [<ffffffff813cd74e>] __driver_attach+0x6e/0xa0 [  164.500826]  [<ffffffff813cd6e0>] ? __device_attach+0x50/0x50 [  164.507333]  [<ffffffff813cb2be>] bus_for_each_dev+0x6e/0xc0 [  164.513752]  [<ffffffff813ccefe>] driver_attach+0x1e/0x20 [  164.519870]  [<ffffffff813cc958>] bus_add_driver+0x138/0x260 [  164.526289]  [<ffffffffa0188000>] ? 0xffffffffa0187fff [  164.532116]  [<ffffffff813cde78>] driver_register+0x98/0xe0 [  164.538558]  [<ffffffffa0188000>] ? 0xffffffffa0187fff [  164.544389]  [<ffffffff813087b0>] __pci_register_driver+0x60/0x70 [  164.551336]  [<ffffffffa014b37d>] drm_pci_init+0x6d/0x120 [drm] [  164.558040]  [<ffffffffa0188000>] ? 0xffffffffa0187fff [  164.563928]  [<ffffffffa018806a>] i915_init+0x6a/0x6c [i915] [  164.570363]  [<ffffffff810002da>] do_one_initcall+0xaa/0x160 [  164.576783]  [<ffffffff8103b140>] ? set_memory_nx+0x40/0x50 [  164.583100]  [<ffffffff810ce7f5>] load_module+0x1fb5/0x2550 [  164.589410]  [<ffffffff810caab0>] ? store_uevent+0x40/0x40 [  164.595628]  [<ffffffff810cee7d>] SyS_init_module+0xed/0x100 [  164.602048]  [<ffffffff816b3c52>] system_call_fastpath+0x16/0x1b  v2: simplify the loop further (Chris)", "target": 0}
{"idx": 2724, "commit_message": "The \"buffer\" trick to store wavefunctions in memory has been upgraded with  Lorenzo's new code that 1) does not require knowledge of the maximum number of records when opening the buffer, and 2) deals with more than a single memory buffer. The interface with QE remains the same and nothing changes, but it becomes possible to keep everything (not only wavefunctions) in  memory, store to file at the end, or when max time is reached, or a soft  exit required. This will become the default behavior in the future.  Also fixed a recently introduced bug: close_buffer(unit,'keep') wasn't saving the data.   No idea about performance hits, but there shouldn't be any.  Beware (and report) memory leaks, though.", "target": 0}
{"idx": 3621, "commit_message": "Use ContainerNode instead of Node where possible [URL]/show_bug.cgi?id=87220  Reviewed by Geoffrey Garen.  It's better to use a more specific type; in some cases we even generate more efficient code if we have a more specific type. Also, we want any type casts to be as close as possible to the corresponding type checks, so eliminating these uses of toContainerNode is a plus, also.  * dom/ContainerNodeAlgorithms.h: Changed insertionPoint to be a ContainerNode instead of a Node. Fixed spelling error \"inseretions\". Changed (WebCore::ChildFrameDisconnector::Target::Target): Changed type of frame owner element to HTMLFrameOwnerElement from Node.  * dom/DocumentType.cpp: (WebCore::DocumentType::insertedInto): (WebCore::DocumentType::removedFrom): * dom/DocumentType.h: * dom/Element.cpp: (WebCore::Element::insertedInto): (WebCore::Element::removedFrom): * dom/Element.h: * dom/Node.cpp: (WebCore::Node::insertedInto): (WebCore::Node::removedFrom): * dom/Node.h: * dom/ProcessingInstruction.cpp: (WebCore::ProcessingInstruction::insertedInto): (WebCore::ProcessingInstruction::removedFrom): * dom/ProcessingInstruction.h: * dom/ScriptElement.cpp: (WebCore::ScriptElement::insertedInto): * dom/ScriptElement.h: * html/FormAssociatedElement.cpp: (WebCore::FormAssociatedElement::insertedInto): (WebCore::FormAssociatedElement::removedFrom): * html/FormAssociatedElement.h: * html/HTMLBaseElement.cpp: (WebCore::HTMLBaseElement::insertedInto): (WebCore::HTMLBaseElement::removedFrom): * html/HTMLBaseElement.h: * html/HTMLBodyElement.cpp: (WebCore::HTMLBodyElement::insertedInto): (WebCore::HTMLBodyElement::didNotifyDescendantInsertions): * html/HTMLBodyElement.h: * html/HTMLFormControlElement.cpp: (WebCore::HTMLFormControlElement::insertedInto): (WebCore::HTMLFormControlElement::removedFrom): * html/HTMLFormControlElement.h: * html/HTMLFormElement.cpp: (WebCore::HTMLFormElement::insertedInto): (WebCore::HTMLFormElement::didNotifyDescendantInsertions): (WebCore::HTMLFormElement::removedFrom): * html/HTMLFormElement.h: * html/HTMLFrameElementBase.cpp: (WebCore::HTMLFrameElementBase::insertedInto): (WebCore::HTMLFrameElementBase::didNotifyDescendantInsertions): * html/HTMLFrameElementBase.h: * html/HTMLFrameSetElement.cpp: (WebCore::HTMLFrameSetElement::insertedInto): (WebCore::HTMLFrameSetElement::removedFrom): * html/HTMLFrameSetElement.h: * html/HTMLIFrameElement.cpp: (WebCore::HTMLIFrameElement::insertedInto): (WebCore::HTMLIFrameElement::removedFrom): * html/HTMLIFrameElement.h: * html/HTMLImageElement.cpp: (WebCore::HTMLImageElement::insertedInto): (WebCore::HTMLImageElement::removedFrom): * html/HTMLImageElement.h: * html/HTMLInputElement.cpp: (WebCore::HTMLInputElement::insertedInto): (WebCore::HTMLInputElement::removedFrom): * html/HTMLInputElement.h: * html/HTMLLinkElement.cpp: (WebCore::HTMLLinkElement::insertedInto): (WebCore::HTMLLinkElement::removedFrom): * html/HTMLLinkElement.h: * html/HTMLMapElement.cpp: (WebCore::HTMLMapElement::insertedInto): (WebCore::HTMLMapElement::removedFrom): * html/HTMLMapElement.h: * html/HTMLMediaElement.cpp: (WebCore::HTMLMediaElement::insertedInto): (WebCore::HTMLMediaElement::removedFrom): * html/HTMLMediaElement.h: * html/HTMLMetaElement.cpp: (WebCore::HTMLMetaElement::insertedInto): * html/HTMLMetaElement.h: * html/HTMLObjectElement.cpp: (WebCore::HTMLObjectElement::insertedInto): (WebCore::HTMLObjectElement::removedFrom): * html/HTMLObjectElement.h: * html/HTMLOptionElement.cpp: (WebCore::HTMLOptionElement::insertedInto): * html/HTMLOptionElement.h: * html/HTMLQuoteElement.cpp: (WebCore::HTMLQuoteElement::insertedInto): * html/HTMLQuoteElement.h: * html/HTMLScriptElement.cpp: (WebCore::HTMLScriptElement::insertedInto): * html/HTMLScriptElement.h: * html/HTMLSelectElement.cpp: (WebCore::HTMLSelectElement::insertedInto): * html/HTMLSelectElement.h: * html/HTMLSourceElement.cpp: (WebCore::HTMLSourceElement::insertedInto): (WebCore::HTMLSourceElement::removedFrom): * html/HTMLSourceElement.h: * html/HTMLStyleElement.cpp: (WebCore::HTMLStyleElement::insertedInto): (WebCore::HTMLStyleElement::removedFrom): * html/HTMLStyleElement.h: * html/HTMLTextFormControlElement.cpp: (WebCore::HTMLTextFormControlElement::insertedInto): * html/HTMLTextFormControlElement.h: * html/HTMLTitleElement.cpp: (WebCore::HTMLTitleElement::insertedInto): (WebCore::HTMLTitleElement::removedFrom): * html/HTMLTitleElement.h: * html/HTMLTrackElement.cpp: (WebCore::HTMLTrackElement::insertedInto): (WebCore::HTMLTrackElement::removedFrom): * html/HTMLTrackElement.h: * mathml/MathMLMathElement.cpp: (WebCore::MathMLMathElement::insertedInto): * mathml/MathMLMathElement.h: * svg/SVGElement.cpp: (WebCore::SVGElement::removedFrom): * svg/SVGElement.h: * svg/SVGFEImageElement.cpp: (WebCore::SVGFEImageElement::insertedInto): (WebCore::SVGFEImageElement::removedFrom): * svg/SVGFEImageElement.h: * svg/SVGFontFaceElement.cpp: (WebCore::SVGFontFaceElement::insertedInto): (WebCore::SVGFontFaceElement::removedFrom): * svg/SVGFontFaceElement.h: * svg/SVGFontFaceUriElement.cpp: (WebCore::SVGFontFaceUriElement::insertedInto): * svg/SVGFontFaceUriElement.h: * svg/SVGGlyphElement.cpp: (WebCore::SVGGlyphElement::insertedInto): (WebCore::SVGGlyphElement::removedFrom): * svg/SVGGlyphElement.h: * svg/SVGHKernElement.cpp: (WebCore::SVGHKernElement::insertedInto): (WebCore::SVGHKernElement::removedFrom): * svg/SVGHKernElement.h: * svg/SVGImageElement.cpp: (WebCore::SVGImageElement::insertedInto): * svg/SVGImageElement.h: * svg/SVGSVGElement.cpp: (WebCore::SVGSVGElement::insertedInto): (WebCore::SVGSVGElement::removedFrom): * svg/SVGSVGElement.h: * svg/SVGScriptElement.cpp: (WebCore::SVGScriptElement::insertedInto): * svg/SVGScriptElement.h: * svg/SVGStyleElement.cpp: (WebCore::SVGStyleElement::insertedInto): (WebCore::SVGStyleElement::removedFrom): * svg/SVGStyleElement.h: * svg/SVGStyledElement.cpp: (WebCore::SVGStyledElement::insertedInto): (WebCore::SVGStyledElement::removedFrom): * svg/SVGStyledElement.h: * svg/SVGTRefElement.cpp: (WebCore::SVGTRefElement::insertedInto): (WebCore::SVGTRefElement::removedFrom): * svg/SVGTRefElement.h: * svg/SVGTextPathElement.cpp: (WebCore::SVGTextPathElement::insertedInto): * svg/SVGTextPathElement.h: * svg/SVGTitleElement.cpp: (WebCore::SVGTitleElement::insertedInto): (WebCore::SVGTitleElement::removedFrom): * svg/SVGTitleElement.h: * svg/SVGUseElement.cpp: (WebCore::SVGUseElement::insertedInto): (WebCore::SVGUseElement::removedFrom): * svg/SVGUseElement.h: * svg/SVGVKernElement.cpp: (WebCore::SVGVKernElement::insertedInto): (WebCore::SVGVKernElement::removedFrom): * svg/SVGVKernElement.h: * svg/animation/SVGSMILElement.cpp: (WebCore::SVGSMILElement::insertedInto): (WebCore::SVGSMILElement::removedFrom): * svg/animation/SVGSMILElement.h: Changed arguments of insertedInto and removedFrom to ContainerNode instead of Node. Did the same with didNotifyDescendantInsertions, while fixing the typo in its name.  * editing/ReplaceSelectionCommand.cpp: (WebCore::ReplaceSelectionCommand::doApply): Put a typecast toHTMLElement here. The check for isListElement and isLegacyAppleStyleSpan takes care of the type checking. (WebCore::ReplaceSelectionCommand::insertAsListItems): Changed this function to take an HTMLElement instead of a Node, then we can drop use of the toContainerNode function. * editing/ReplaceSelectionCommand.h:  * editing/TextIterator.cpp: Fixed a typo in a comment.", "target": 0}
{"idx": 2160, "commit_message": "Merge branch 'Sleepable local storage'  KP Singh says:  ====================  Local storage is currently unusable in sleepable helpers. One of the important use cases of local_storage is to attach security (or performance) contextual information to kernel objects in LSM / tracing programs to be used later in the life-cyle of the object.  Sometimes this context can only be gathered from sleepable programs (because it needs accesing __user pointers or helpers like bpf_ima_inode_hash). Allowing local storage to be used from sleepable programs allows such context to be managed with the benefits of local_storage.  # v2 -> v3  * Fixed some RCU issues pointed by Martin * Added Martin's ack  # v1 -> v2  * Generalize RCU checks (will send a separate patch for updating   non local storage code where this can be used). * Add missing RCU lock checks from v1 ====================", "target": 0}
{"idx": 797, "commit_message": "x86/VPMU: Clear last_vcpu when destroying VPMU  We need to make sure that last_vcpu is not pointing to VCPU whose VPMU is being destroyed. Otherwise we may try to dereference it in the future, when VCPU is gone.  We have to do this via IPI since otherwise there is a (somewheat theoretical) chance that between test and subsequent clearing of last_vcpu the remote processor (i.e. vpmu->last_pcpu) might do both vpmu_load() and then vpmu_save() for another VCPU. The former will clear last_vcpu and the latter will set it to something else.  Performing this operation via IPI will guarantee that nothing can happen on the remote processor between testing and clearing of last_vcpu.  We should also check for VPMU_CONTEXT_ALLOCATED in vpmu_destroy() to avoid unnecessary percpu tests and arch-specific destroy ops. Thus checks in AMD and Intel routines are no longer needed.", "target": 0}
{"idx": 899, "commit_message": "Improve default mail service implementation  Allow provide custom sender depending on the current message and related entity.", "target": 0}
{"idx": 2805, "commit_message": "Synchronized to hipl--userspace--2.6--patch-2346 Patches applied:   * [URL]--hipl/hipl--esp--2.6--patch-595    Synchronized to hipl--userspace--2.6--patch-2236   * [URL]--hipl/hipl--esp--2.6--patch-596    Synchronized to hipl--userspace--2.6--patch-2240   * [URL]--hipl/hipl--esp--2.6--patch-597    Synchronized to hipl--userspace--2.6--patch-2272   * [URL]--hipl/hipl--esp--2.6--patch-598    sender part of cumulative auth   * [URL]--hipl/hipl--esp--2.6--patch-599    cumulative auth verification part1   * [URL]--hipl/hipl--esp--2.6--patch-600    receiver offset corrected   * [URL]--hipl/hipl--esp--2.6--patch-601    cumulative auth verification part2 - done   * [URL]--hipl/hipl--esp--2.6--patch-602    current cumulative auth   * [URL]--hipl/hipl--esp--2.6--patch-603    Synchronized to hipl--userspace--2.6--patch-2289   * [URL]--hipl/hipl--esp--2.6--patch-604    remove debug-assert   * [URL]--hipl/hipl--esp--2.6--patch-605    fixed signature verification bug in hipfw   * [URL]--hipl/hipl--esp--2.6--patch-606    Synchronized to hipl--userspace--2.6--patch-2291   * [URL]--hipl/hipl--nat--2.6--patch-462    Interoperability fixes (updating structures up-to-date).   * [URL]--hipl/hipl--nat--2.6--patch-463    Interop fixes (relay registration with ice)   * [URL]--hipl/hipl--nat--2.6--patch-464    minor change   * [URL]--hipl/hipl--nat--2.6--patch-465    Disabled a registration server check to support rebooting registration clients.   * [URL]--hipl/hipl--nat--2.6--patch-466    Cherrypicked hipl--pjsip--2.6--patch-13   * [URL]--hipl/hipl--nat--2.6--patch-467    Cherrypicked hipl--pjsip--2.6--patch-14   * [URL]--hipl/hipl--nat--2.6--patch-468    some fix for priority, but not complete   * [URL]--hipl/hipl--nat--2.6--patch-469    fix for priority   * [URL]--hipl/hipl--nat--2.6--patch-470    make variance for priority   * [URL]--hipl/hipl--nat--2.6--patch-471    Bug fix to LSI prefix checks   * [URL]--hipl/hipl--nat--2.6--patch-472    fix ice priority and some bug in handle_locator   * [URL]--hipl/hipl--nat--2.6--patch-473    fix kind in outgoing locator   * [URL]--hipl/hipl--nat--2.6--patch-474    fix outgoing locator type for server reflexive and update kind in handle locator   * [URL]--hipl/hipl--nat--2.6--patch-475    ice retransmission added   * [URL]--hipl/hipl--nat--2.6--patch-476    ice retransmission fixed   * [URL]--hipl/hipl--nat--2.6--patch-477    Synchronized to hipl--userspace--2.6--patch-2292   * [URL]--hipl/hipl--nat--2.6--patch-478    Relay/rvs addresses have now HIP_LOCATOR_TRAFFIC_TYPE_SIGNAL as traffic type   * [URL]--hipl/hipl--nat--2.6--patch-479    A bug fix to registration   * [URL]--hipl/hipl--nat--2.6--patch-480    Fix to ICE role   * [URL]--hipl/hipl--nat--2.6--patch-481    A bug fix to priorities as suggested by Xiang   * [URL]--hipl/hipl--nat--2.6--patch-482    ice retransmission fixed again in maintainence.c   * [URL]--hipl/hipl--nat--2.6--patch-483    Reverted patch 471   * [URL]--hipl/hipl--nat--2.6--patch-484    Removed retransmission support for ice (bug id 826)   * [URL]--hipl/hipl--nat--2.6--patch-485    Bug fixes   * [URL]--hipl/hipl--nat--2.6--patch-486    Cleaning up a bloated function in the nat code   * [URL]--hipl/hipl--nat--2.6--patch-487    Cleaning up a bloated function in the nat code   * [URL]--hipl/hipl--nat--2.6--patch-488    Compilation fix   * [URL]--hipl/hipl--nat--2.6--patch-489    minor change   * [URL]--hipl/hipl--nat--2.6--patch-490    Nat code error handling   * [URL]--hipl/hipl--nat--2.6--patch-491    fix bug in filling i2 context   * [URL]--hipl/hipl--nat--2.6--patch-492    STUN messages should be now transmitted faster. Untested.   * [URL]--hipl/hipl--nat--2.6--patch-493    Excluded relay server of the localhost from the list of local candidates   * [URL]--hipl/hipl--nat--2.6--patch-494    Commented out a debug statement   * [URL]--hipl/hipl--nat--2.6--patch-495    Bug fix to ice maintenance loop   * [URL]--hipl/hipl--nat--2.6--patch-496    Added debug info for null op   * [URL]--hipl/hipl--nat--2.6--patch-497    Removed a debug statement   * [URL]--hipl/hipl--nat--2.6--patch-498    Synchronized to hipl--userspace--2.6--patch-2293   * [URL]--hipl/hipl--nat--2.6--patch-499    Synchronized to hipl--userspace--2.6--patch-2294   * [URL]--hipl/hipl--nat--2.6--patch-500    Fixed to ICE priorities network byte ordering   * [URL]--hipl/hipl--nat--2.6--patch-501    bug fix in priority and modify some logs   * [URL]--hipl/hipl--nat--2.6--patch-502    a small fix in handle locator   * [URL]--hipl/hipl--nat--2.6--patch-503    a small fix in PJ   * [URL]--hipl/hipl--nat--2.6--patch-504    Bug fix to ice priorities   * [URL]--hipl/hipl--nat--2.6--patch-505    Commenting   * [URL]--hipl/hipl--nat--2.6--patch-506    Synchronized to hipl--userspace--2.6--patch-2297   * [URL]--hipl/hipl--nat--2.6--patch-507    nat tfm negotiation for responder   * [URL]--hipl/hipl--nat--2.6--patch-508    RTO value   * [URL]--hipl/hipl--nat--2.6--patch-509    RTO value   * [URL]--hipl/hipl--nat--2.6--patch-510    Synchronized to hipl--userspace--2.6--patch-2307   * [URL]--hipl/hipl--nat--2.6--patch-511    Synchronized to hipl--pjsip--2.6--patch-15   * [URL]--hipl/hipl--nat--2.6--patch-512    polish priority logs   * [URL]--hipl/hipl--nat--2.6--patch-513    Synchronized to hipl--userspace--2.6--patch-2308   * [URL]--hipl/hipl--pjsip--2.6--base-0    tag of [URL]--hipl/hipl--nat--2.6--patch-451   * [URL]--hipl/hipl--pjsip--2.6--patch-1    Upgraded to pjproject 1.1. Rewrote all old changes   * [URL]--hipl/hipl--pjsip--2.6--patch-2    Added untagged files from previous commit   * [URL]--hipl/hipl--pjsip--2.6--patch-3    Reapplied basic pjproject changes.   * [URL]--hipl/hipl--pjsip--2.6--patch-4    Readded new pjproject files to configure.ac in top dir   * [URL]--hipl/hipl--pjsip--2.6--patch-5    Readded Xiang's hacks to the ICE code   * [URL]--hipl/hipl--pjsip--2.6--patch-6    Synchronized to hipl--nat--2.6--patch-452   * [URL]--hipl/hipl--pjsip--2.6--patch-7    Synchronized to hipl--nat--2.6--patch-464   * [URL]--hipl/hipl--pjsip--2.6--patch-8    fix interface   * [URL]--hipl/hipl--pjsip--2.6--patch-9    fix interface 2   * [URL]--hipl/hipl--pjsip--2.6--patch-10    Fixed one problem in pjnat unit tests   * [URL]--hipl/hipl--pjsip--2.6--patch-11    disable old stun dump   * [URL]--hipl/hipl--pjsip--2.6--patch-12    add transport ID in ice stun out inteface   * [URL]--hipl/hipl--pjsip--2.6--patch-13    draft fix for retransission bug   * [URL]--hipl/hipl--pjsip--2.6--patch-14    fix for retransission bug   * [URL]--hipl/hipl--pjsip--2.6--patch-15    Synchronized to hipl--nat--2.6--patch-510   * [URL]--hipl/hipl--update--2.6--patch-185    Synchronized to hipl--userspace--2.6--patch-2249   * [URL]--hipl/hipl--update--2.6--patch-186    Partial fix to 801   * [URL]--hipl/hipl--update--2.6--patch-187    Continuing shotgun   * [URL]--hipl/hipl--update--2.6--patch-188    Shotgun stuff   * [URL]--hipl/hipl--update--2.6--patch-189    Synchronized to hipl--userspace--2.6--patch-2289   * [URL]--hipl/hipl--userspace--2.6--patch-2285    Synchronized to hipl--fix--2.6--patch-399   * [URL]--hipl/hipl--userspace--2.6--patch-2286    Cleaned up a debug statement   * [URL]--hipl/hipl--userspace--2.6--patch-2287    Updated bamboo v4 packaging script   * [URL]--hipl/hipl--userspace--2.6--patch-2288    Synchronized to hipl--nat--2.6--patch-465   * [URL]--hipl/hipl--userspace--2.6--patch-2289    Updated howto. Currently felwood is not running Bamboo because it has problems in 64-bit machines   * [URL]--hipl/hipl--userspace--2.6--patch-2290    Synchronized to hipl--update--2.6--patch-189   * [URL]--hipl/hipl--userspace--2.6--patch-2291    Cherrypicked hipl--nat--2.6--patch-471   * [URL]--hipl/hipl--userspace--2.6--patch-2292    Synchronized to hipl--esp--2.6--patch-606   * [URL]--hipl/hipl--userspace--2.6--patch-2293    Added null pointer checks to hipfw conntrack.c to solve a problem with close acks   * [URL]--hipl/hipl--userspace--2.6--patch-2294    A bug fix to previous commit   * [URL]--hipl/hipl--userspace--2.6--patch-2295    A potential bug fix to the problem reported by Robert   * [URL]--hipl/hipl--userspace--2.6--patch-2296    Increased release version number   * [URL]--hipl/hipl--userspace--2.6--patch-2297    Fixed a package compilation error   * [URL]--hipl/hipl--userspace--2.6--patch-2298    Synchronized to hipl--nat--2.6--patch-506   * [URL]--hipl/hipl--userspace--2.6--patch-2299    Synchronized to hipl--nat--2.6--patch-509   * [URL]--hipl/hipl--userspace--2.6--patch-2300    Increased release version number   * [URL]--hipl/hipl--userspace--2.6--patch-2301    A bug fix to userspace ipsec (un)locking   * [URL]--hipl/hipl--userspace--2.6--patch-2302    fixed kernelspace-userspace incompatibility issue   * [URL]--hipl/hipl--userspace--2.6--patch-2303    Increased release version number   * [URL]--hipl/hipl--userspace--2.6--patch-2304    Registration to an LSI works now.   * [URL]--hipl/hipl--userspace--2.6--patch-2305    Increased release version number   * [URL]--hipl/hipl--userspace--2.6--patch-2306    Updated baz/tla selection in package building script   * [URL]--hipl/hipl--userspace--2.6--patch-2307    Added support for telling the port to be used in dhtservers file, see manual for extra info   * [URL]--hipl/hipl--userspace--2.6--patch-2308    Changed couple of comments and default text in hipd_config   * [URL]--hipl/hipl--userspace--2.6--patch-2309    Updated Bamboo references to Openlookup in the HOWTO   * [URL]--hipl/hipl--userspace--2.6--patch-2310    Synchronized to hipl--nat--2.6--patch-513   * [URL]--hipl/hipl--userspace--2.6--patch-2311    Reserved field is now zero in r1 generation counter   * [URL]--hipl/hipl--userspace--2.6--patch-2312    Bug id 812   * [URL]--hipl/hipl--userspace--2.6--patch-2313    Increased release version number   * [URL]--hipl/hipl--userspace--2.6--patch-2314    Upgraded libipsec from 0.6.6 to 0.7.2   * [URL]--hipl/hipl--userspace--2.6--patch-2315    Small fix to previous commit   * [URL]--hipl/hipl--userspace--2.6--patch-2316    Bug fix to --enable-pfkey compilation   * [URL]--hipl/hipl--userspace--2.6--patch-2317    Include pjproject depend files to 'make clean' target   * [URL]--hipl/hipl--userspace--2.6--patch-2318    Bug fix to --enable-pfkey compilation   * [URL]--hipl/hipl--userspace--2.6--patch-2319    HIPL libipsec overrides ipsec-tools. Renamed binary library name to 'libhipsec'   * [URL]--hipl/hipl--userspace--2.6--patch-2320    Decreased release number   * [URL]--hipl/hipl--userspace--2.6--patch-2321    Increased release version number   * [URL]--hipl/hipl--userspace--2.6--patch-2322    'make dist' works again   * [URL]--hipl/hipl--userspace--2.6--patch-2323    'make bin' target works again   * [URL]--hipl/hipl--userspace--2.6--patch-2324    Extended the opendht receive buffer in netdev.c   * [URL]--hipl/hipl--userspace--2.6--patch-2325    Fixed few memory leaks   * [URL]--hipl/hipl--userspace--2.6--patch-2326    Increased release version number   * [URL]--hipl/hipl--userspace--2.6--patch-2327    seg fault fix and some memory leaks   * [URL]--hipl/hipl--userspace--2.6--patch-2328    leaks...   * [URL]--hipl/hipl--userspace--2.6--patch-2329    Added some constants for buddy certificates   * [URL]--hipl/hipl--userspace--2.6--patch-2330    Increased release version number   * [URL]--hipl/hipl--userspace--2.6--patch-2331    removed useless free   * [URL]--hipl/hipl--userspace--2.6--patch-2332    Increased release version number   * [URL]--hipl/hipl--userspace--2.6--patch-2333    Fixed a potential bug in OpenDHT code.   * [URL]--hipl/hipl--userspace--2.6--patch-2334    Updated vlc instructions.   * [URL]--hipl/hipl--userspace--2.6--patch-2335    Increased release version number   * [URL]--hipl/hipl--userspace--2.6--patch-2336    Updated vlc instructions (copy-paste mistake)   * [URL]--hipl/hipl--userspace--2.6--patch-2337    Minor update to vlc instructions   * [URL]--hipl/hipl--userspace--2.6--patch-2338    Bug fix to DHT code   * [URL]--hipl/hipl--userspace--2.6--patch-2339    Increased release version number   * [URL]--hipl/hipl--userspace--2.6--patch-2340    Comment   * [URL]--hipl/hipl--userspace--2.6--patch-2341    removed q1 from dnsproxy.py:hip_lookup   * [URL]--hipl/hipl--userspace--2.6--patch-2342    dnsproxy.py cleanup   * [URL]--hipl/hipl--userspace--2.6--patch-2343    Added tools/DNS/Serialization.py   * [URL]--hipl/hipl--userspace--2.6--patch-2344    Adding asynchronous requests and responses to dnsproxy.py. Now only in no-HIP requests   * [URL]--hipl/hipl--userspace--2.6--patch-2345    Clean old queries   * [URL]--hipl/hipl--userspace--2.6--patch-2346    DNS/__init__.py needed Serialization imports", "target": 0}
{"idx": 224, "commit_message": "Added test for MacBook Pro Retina display. See [URL]/two/discussion/2162/how-to-use-retina-displays-a-little-overview-and-performance-report- for results.", "target": 0}
{"idx": 3480, "commit_message": "Changed \"frequencies\" to \"distinct\" in error diversity computations. Means more what we mean, and might be more efficient.", "target": 0}
{"idx": 250, "commit_message": "Merge changes I3e936c7e,I105abad2,I545cb46f,I50507afe into jb_chocolate  * changes:   msm: display: remove framebuffer memory associated with fb1 and fb2   msm: rotator: Add Rotator device & bus scale data for 8064/8960/8930   msm: display: Use local HDMI as primary flags for 8960/8064 targets   msm: board: Guard HDMI regulator_get for errors.", "target": 0}
{"idx": 4014, "commit_message": "[PATCH] wmkdep: Added path string substitution support\n\nto avoid the need for sed'ing the output.  This improves performance by avoiding\nthe need for calling additional commands and generating a temporary file.", "target": 1}
{"idx": 1454, "commit_message": "Improve the `Support` section from `README.md`", "target": 0}
{"idx": 3409, "commit_message": "Add \"performance\" folders into binary build (to help fix broken tests)", "target": 0}
{"idx": 2758, "commit_message": "Fix EGPRS PUAN encoding: use correct urbb_len  Earlier there was an incorrect encoding of PUAN when VQ is not equal VR case for EGPRS UL RLC window. The PCU was encoding the same PUAN message always irrespective of radio condition. This was a bottle neck for performance testing. Which has been fixed in this patch.  Related: OS#1793  unit test assertion in the previous commit is fixed in this patch.", "target": 1}
{"idx": 2029, "commit_message": "Many improvements to `curry` based on #147 #150 #155 #159  1. Idempotent such that `curry(curry(f))` is equivalent to `curry(f)`; see #147 2. Comparable via equality and hashable based on `func`, `args`, and `keywords`; see #159 3. `func`, `args`, and `keywords` attributes are readonly 4. `__name__` and `__doc__` attributes are writable 5. More efficient implementation using `partial`; see #150 6. Curried objects never transmogrigy into `partial` objects; see #155", "target": 1}
{"idx": 2305, "commit_message": "[operators] make LincombOperator.apply more memory efficient", "target": 1}
{"idx": 3961, "commit_message": "'context' method for inductive graphs  This could be implemented in terms of match, but it feels more efficient to have it on its own.", "target": 0}
{"idx": 2167, "commit_message": "Avoid regex in the common case  Escaped characters in field names are highly unusual. We can quickly test for their presence and if none are found do the path splitting using the more efficient binary module instead of regular expressions. A microbenchmark shows this approach to be a little more than twice as fast as the original.", "target": 1}
{"idx": 1120, "commit_message": "Init information (e.g. system_cpu_info and package_version) should be sent for every process_group that starts dynamically.", "target": 0}
{"idx": 1862, "commit_message": "DigitalReadOut.qml: optimize getPosition() calculation  reduce recursive position calculation from 3 iterations to 1 by replacing g5xOffset, g92Offset, and toolOffset with status.motion.*", "target": 1}
{"idx": 1836, "commit_message": "stmhal: Make stm.mem* support large integers.  With these you can now do things like:  stm.mem32[0x20000000] = 0x80000000  and read 32-bit values. You can also read all the way to the end of memory using either stm.mem32[0xfffffffc] or stm.mem32[-4].  IRQs shouldn't use mem32 at all since they'd fail if the top 2 bits weren't equal, so IRQs should be using 16-bit I/O.", "target": 0}
{"idx": 1354, "commit_message": "fixed a memory leak when no features are extracted from the scene", "target": 0}
{"idx": 3589, "commit_message": "nohz/s390: fix arch_needs_cpu() return value on offline cpus  commit 398812159e328478ae49b4bd01f0d71efea96c39 upstream.  This fixes the same problem as described in the patch \"nohz: fix printk_needs_cpu() return value on offline cpus\" for the arch_needs_cpu() primitive:  arch_needs_cpu() may return 1 if called on offline cpus. When a cpu gets offlined it schedules the idle process which, before killing its own cpu, will call tick_nohz_stop_sched_tick(). That function in turn will call arch_needs_cpu() in order to check if the local tick can be disabled. On offline cpus this function should naturally return 0 since regardless if the tick gets disabled or not the cpu will be dead short after. That is besides the fact that __cpu_disable() should already have made sure that no interrupts on the offlined cpu will be delivered anyway.  In this case it prevents tick_nohz_stop_sched_tick() to call select_nohz_load_balancer(). No idea if that really is a problem. However what made me debug this is that on 2.6.32 the function get_nohz_load_balancer() is used within __mod_timer() to select a cpu on which a timer gets enqueued. If arch_needs_cpu() returns 1 then the nohz_load_balancer cpu doesn't get updated when a cpu gets offlined. It may contain the cpu number of an offline cpu. In turn timers get enqueued on an offline cpu and not very surprisingly they never expire and cause system hangs.  This has been observed 2.6.32 kernels. On current kernels __mod_timer() uses get_nohz_timer_target() which doesn't have that problem. However there might be other problems because of the too early exit tick_nohz_stop_sched_tick() in case a cpu goes offline.  This specific bug was indrocuded with 3c5d92a0 \"nohz: Introduce arch_needs_cpu\".  In this case a cpu hotplug notifier is used to fix the issue in order to keep the normal/fast path small. All we need to do is to clear the condition that makes arch_needs_cpu() return 1 since it is just a performance improvement which is supposed to keep the local tick running for a short period if a cpu goes idle. Nothing special needs to be done except for clearing the condition.  Acked-by: Peter Zijlstra < >", "target": 1}
{"idx": 2495, "commit_message": "mm: compaction: partially revert capture of suitable high-order page  Eric Wong reported on 3.7 and 3.8-rc2 that ppoll() got stuck when waiting for POLLIN on a local TCP socket.  It was easier to trigger if there was disk IO and dirty pages at the same time and he bisected it to commit 1fb3f8ca0e92 (\"mm: compaction: capture a suitable high-order page immediately when it is made available\").  The intention of that patch was to improve high-order allocations under memory pressure after changes made to reclaim in 3.6 drastically hurt THP allocations but the approach was flawed.  For Eric, the problem was that page->pfmemalloc was not being cleared for captured pages leading to a poor interaction with swap-over-NFS support causing the packets to be dropped.  However, I identified a few more problems with the patch including the fact that it can increase contention on zone->lock in some cases which could result in async direct compaction being aborted early.  In retrospect the capture patch took the wrong approach.  What it should have done is mark the pageblock being migrated as MIGRATE_ISOLATE if it was allocating for THP and avoided races that way.  While the patch was showing to improve allocation success rates at the time, the benefit is marginal given the relative complexity and it should be revisited from scratch in the context of the other reclaim-related changes that have taken place since the patch was first written and tested.  This patch partially reverts commit 1fb3f8ca0e92 (\"mm: compaction: capture a suitable high-order page immediately when it is made available\").", "target": 0}
{"idx": 3917, "commit_message": "many modification in python scripts  * mapping.py.in verifies pep8 * emf2fasta much shorter and more efficient * extractbackground files were fused and now use argparse", "target": 1}
{"idx": 1133, "commit_message": "Merge pull request #5 from chef-buddy/add_logging  fixed bug in food compound normalization algorithm", "target": 0}
{"idx": 43, "commit_message": "Try a more straightforward use of tiling  Rather than retiling for every node, defer tiling until the end. This dramatically improves the startup time for a moderate number of systems.", "target": 1}
{"idx": 2530, "commit_message": "Integration performance tests: fix in tests for compilation  GitOrigin-RevId: f4275a212bddb7911e02eaa7c80337bef4f7172f", "target": 0}
{"idx": 1662, "commit_message": "Add tutorial/Optimize.C which shows how to use Miunite2 to optimize a lens shape.", "target": 0}
{"idx": 3185, "commit_message": "- greatly improved performance of InmemoryCache; - fixed minor bug in some cache tests.", "target": 1}
{"idx": 1545, "commit_message": "Port all VBO drawing other than PIE model and terrain to GFX class. This also fixes GPU memory leak bug when changing skybox, hence closing ticket:3842.", "target": 0}
{"idx": 3491, "commit_message": "added a AddRange method to FullyObservableCollection  more efficient collection updating - it only raises 1 event for the whole batch", "target": 1}
{"idx": 2954, "commit_message": "Bug 1519718 - WR mix-blend rewrite r=gw  This is a new implementation of mix-blend compositing that is meant to be more idiomatic to WR and efficient.  Previously, mix-blend mode was composed in the following way:   1. parent stacking context was forced to isolate   2. source picture is also isolated   3. when rendering the isolated context, the framebuffer is read upon reaching the source. Both the readback and the source are placed in the RT cache.   4. a mix-blend draw call is issued to read from those cache segments and blend on top of the backdrop  The new implementation works by using the picture cutting (intruduced for preserve-3D contexts earlier) and some bits of magic:   1. backdrop stacking context is isolated with a special composition mode that prevents it from actually rendeing unless the suorce stacking context is invisible.   2. source stacking context is isolated with mix-blend composition mode that has a pointer to the backdrop picture   3. the instance of the backdrop picture is placed as a peer of the source picture (not a child)   4. if the backdrop is invisible, the source is drawn as a simple blit   5. otherwise, it's a draw call that reads from the isolated backdrop and source textures  Note the differences:   - parent stacking context is not isolated, but backdrop is   - no framebuffer readback is involved   - the source and backdrop pictures are rendered in parallel in a pass, improving the batching   - we don't blend onto the backdrop while reading from the backdrop copy at the same time   - the depth of the render pass tree is reduced: previously the parent and the source were isolated, now the source and the backdrop, which are siblings  Differential Revision: [URL]/D20608  [wrupdater] From [URL]/mozilla-central/rev/b5b2ecf454b0d34845098e13a186532469021ad0", "target": 1}
{"idx": 1485, "commit_message": "Add wrap mw, optimizing watch and time mw", "target": 1}
{"idx": 3173, "commit_message": "[scopes] Optimize the performance of looking up the generated binding for a mapped original location (#5919)", "target": 1}
{"idx": 566, "commit_message": "Sketch out first steps of main algorithm.", "target": 0}
{"idx": 918, "commit_message": "reduce material, closer to MK2s version, improve selective infill", "target": 0}
{"idx": 3971, "commit_message": "- Change all FAT*FindAvailableCluster functions to new functions   FAT*FindAndMarkAvailableCluster which have incorporated the setting of   EOF marker in the File Allocation Table for the returned cluster.  - Rewritten FAT32CountAvailableClusters, FAT32FindAndMarkAvailableCluster,   FAT16CountAvailableClusters and FAT16FindAndMarkAvailableCluster for   better performance. These functions were using one big loop for traversing   the FAT and had a block of code in the loop for requesting cache manger   for next chunk of FAT *if necessary* (which commonly wasn't the case).   Now it's changed to request always a whole FAT chunk and process it at once   in a nested loop.  - Cache last offset + cluster pair while reading/writing from/to file. This   ensures almost linear times when doing sequential reads/writes, because the   whole FAT traversing for the file is not done again for every request.   Previously there was code for this, but it was neither correctly used   nor working. It stored the last offset + cluster pair in file CCB structure   (that is unique for each opened file handle) and not FCB structure (which   is shared among all instances of the same file). This resulted in   inconsistent cluster + offset number when the file allocation chain was   changed (eg. by enlarging/shrinking the file), but since the cached offsets   weren't actully used it went unnoticed.  - Remove old hack from NextCluster and fix the call to it in VfatAddEntry.   Not much to say about it, there was an temporary hack in NextCluster and   with fixed VfatAddEntry it's now no longer needed.  - Add pointers to WriteCluster, FindAndMarkAvailableCluster and   GetNextCluster functions to device extension (set during mount) and use   them at appropriate locations. This avoids some nasty if's in the code   and causes some unnoticable performance improvment in the low-level   FAT code.  - Lock the directory FCB in VfatAddEntry while modifying it. This should   propably be done on more places, but it needs more investigations.  - Increase the file cache allocation size in VfatRead/VfatWrite. It boosts   the overall speed of the driver a lot.", "target": 1}
{"idx": 3478, "commit_message": "Cache corona occlusion buffer  Rather than creating and destroying the occlusion buffer every frame, cache it. This improves performance slightly.  From: Alex Goins [URL]>", "target": 1}
{"idx": 2876, "commit_message": "performance optimizations of foreseeing agent; decision strategy mechanism improvement;", "target": 1}
{"idx": 3947, "commit_message": "modifications to cache for loops to improve performance, see [URL]/js-for-loops-cached-vs-basic", "target": 1}
{"idx": 2789, "commit_message": "Merge \"Remove overlay view for better performance\" into mnc-ub-dev", "target": 1}
{"idx": 3569, "commit_message": "Merge pull request #30 from viniciusfbb/patch-1  Improve firemonkey support", "target": 0}
{"idx": 105, "commit_message": "Use _routeDepth instead of activeRefs  The _routeDepth property mimics React's own _mountDepth property and gives <ActiveRouteHandler> the ability to dynamically lookup its Match as needed.  Also, keeping the element (was component) on the match object means we can avoid passing around the router instance.", "target": 0}
{"idx": 2075, "commit_message": "Working on speed analysis. Made some functions more efficient", "target": 1}
{"idx": 2673, "commit_message": "- Improve performance of bhget, by increased CHUNK-size and supporting parallell requests inFlight.", "target": 1}
{"idx": 2256, "commit_message": "small performance improvement: check if logging is enabled before calculating the log info (Coord.toOSMURL() is costly)", "target": 1}
{"idx": 2941, "commit_message": "Improved performance of BitVector#reverse by replacing byte level reversal computation with a lookup table", "target": 1}
{"idx": 3789, "commit_message": "[Wallet] Improve performance when listing mints", "target": 1}
{"idx": 3327, "commit_message": "BZ-1155852 - Performance improvement suggestion for getRuntimeEngine()", "target": 1}
{"idx": 438, "commit_message": "FROM_UPSTREAM [VPG]: drm/i915: Plumb drm_device through page tables operations  The next patch in the series will require it for alloc_pt_single.", "target": 0}
{"idx": 2468, "commit_message": "Introduce a SEARCH_AFTER index pagination type  Current Paginated interface only allows to restart a query from a given offset. Update it to also allow restarting queries using a searchAfter key. searchAfter can help with performance of queries such as [1] where the visibility is being queried for an account that cannot see most/all changes. [1] finishes in ~45 mins with OFFSET and ~10 mins with SEARCH_AFTER when the site has around 1M abandoned changes.  Index config has been updated to add a paginationType entry with OFFSET and SEARCH_AFTER as supported values. The default is set to OFFSET to keep the current pagination type unchanged.  Gerrit's Lucene index implementation has been updated to support this new pagination type with search-after[2]. Elasticsearch index implementation has also been updated to paginate using search-after[3] and can be further improved to use PIT[4]. Lucene and Elasticsearch tests have been updated to run with both pagination types. Also, Elasticsearch tests now use the official docker image as it can handle running tests with multiple index config suites.  Note that, searchAfter will not impact using offsets in Gerrit query APIs.  [1] gerrit query 'status:abandoned visibleto:guest' [2] [URL]/core/6_6_5/core/org/apache/lucene/search/IndexSearcher.html#search-org.apache.lucene.search.Query-int-org.apache.lucene.search.Sort-boolean-boolean- [3] https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html#search-after [4] https://www.elastic.co/guide/en/elasticsearch/reference/current/point-in-time-api.html  Release-Notes: Index searches now support search-after pagination", "target": 1}
{"idx": 2844, "commit_message": "Added collision cache feature Performance improvements for pools deletion and all keys deletion API change for nvm_kv_open New API nvm_kv_batch_get added Enhanced benchmarking tool to dump data on media", "target": 1}
{"idx": 2453, "commit_message": "Essentially commented out dbAvailable() until performance problems fixed.  tracks internal commit dd02669266d327f1fb70d62919ebfc3e5c787b66", "target": 1}
{"idx": 815, "commit_message": "Improve parsing of verslagen algemeen overleg csv source", "target": 0}
{"idx": 3834, "commit_message": "Add expression evaluation to ddc for google3  - Move expression evaluation to ddc in preparation for google3 - Added server to ddc to handle update and compileExpression requests - Added tests - Added 'experimental-output-compiled-kernel' option to ddc to generate   full kernel files only for compiled libraries, and store with   '.full.dill' extension - Added AssetFileSystem to communicate to the asset server in the   debugger - Made expression_compiler_worker work with full kernel files,   so removed invalidation of current file to improve performance - Made expression_compiler_worker reuse already loaded imports   to avoid reading them from source in the incremental compiler - Updated tests to work with DDC (for simulating webdev) - Disabled tests that work with bazel kernel worker for now   as it does not generate full dill files yet - Addressed code review comments from the prototype version:   [URL]/c/sdk/+/157005  Details:  Currently, in flutter tools, expression evaluation is supported via expression compilation, which is done by the incremental compiler in the frontend server. The same incremental compiler is used for initial application compilation, incremental code compilation for hot reload, and any number of expression compilation requests.  In google3, the apps are typically too large to be compiled as a whole in memory by the frontend server. Build in google3 is currently done by blaze, as a distributed build using a task dependency graph. Build tasks output kernel outline files as an interface between components produced by individual tasks.  We are proposing an implementation of the expression compilation in google3 that is taking advantage of full kernel files produced by the build (supporting build changes to follow). This change introduces a small server based on dev_compiler, which can handle following requests:  - update: load full kernel for given modules (done on app start) - compileExpression: compile expression in a given library and module   (done when paused on a breakpoint)  Expression compilation uses previously loaded kernel files for the application component and its dependencies to compile an expression.", "target": 1}
{"idx": 2740, "commit_message": "daemon/logger/fluentd: fix missing host, remove urlutil.IsTransportURL()  pkg/urlutil (despite its poorly chosen name) is not really intended as a generic utility to handle URLs, and should only be used by the builder to handle (remote) build contexts.  This patch:  - fix some cases where the host was ignored for valid addresses. - removes a redundant use of urlutil.IsTransportURL(); instead adding code to   check if the given scheme (protocol) is supported. - improve port validation for out of range ports. - fix some missing validation: the driver was silently ignoring path elements,   but expected a host (not an URL)", "target": 0}
{"idx": 3845, "commit_message": "improved performance by using flexible double buffer strings", "target": 1}
{"idx": 602, "commit_message": "- Fix SheetCount count error; - Optimize deserialization operations; - README updated, add go version required notice", "target": 1}
{"idx": 4084, "commit_message": "[PATCH] Adjusted scheduling, removed slow atomic section", "target": 1}
{"idx": 1935, "commit_message": "drm/i915: Defer rc6 shutdown to suspend_late  Currently we shutdown rc6 during i915_gem_resume() but this is called during the preparation phase (i915_drm_prepare) for all suspend paths, but we only want to shutdown rc6 for S3+. Move the actual shutdown to i915_gem_suspend_late().  We then need to differentiate between suspend targets, to distinguish S0 (s2idle) where the device is kept awake but needs to be in a low power mode (the same as runtime suspend) from the device suspend levels where we lose control of HW and so must disable any HW access to dangling memory.  Bugzilla: [URL]/show_bug.cgi?id=111909 Fixes: c113236718e8 (\"drm/i915: Extract GT render sleep (rc6) management\") Testcase: igt/gem_exec_suspend/power-S0", "target": 0}
{"idx": 1812, "commit_message": "tests: Do not build tests for AVX2 and FMA on CPUs without these exts", "target": 0}
{"idx": 1786, "commit_message": "[FREELDR] - Massively refactor the winldr code - move common parts of LoadReactOSSetup and LoadAndBootWindows into LoadAndBootWindowsCommon - Combine architecture specific code into 2 functions: WinLdrSetupMachineDependent prepares the main stuff and WinLdrSetProcessorContext is the last thing done before transferring control to the kernel. - rename WinLdrTunOnPaging to WinLdrSetupMemoryLayout - Stop wasting stack space by decreasing the number of huge text buffers used - Don't handle x86 specific data like Tss in portable code - Add the progressbar for reactos setup as well - Add missing DPRINT_PELOADER to DEBUG_ALL", "target": 0}
{"idx": 2516, "commit_message": "Merge pull request #298 from veidenbaums/performance-update  Improve performance", "target": 1}
{"idx": 3341, "commit_message": "Optimize intersection detection.  By unioning the features for the \"other\", self's features can be compared to a single giant blob of geometry instead of many individual rows. This improved performance 3x in testing when intersecting Sites onto TslAreas.", "target": 1}
{"idx": 3172, "commit_message": "6484956: G1: improve evacuation pause efficiency  A bunch of performance optimizations to decrease GC pause times in G1.", "target": 1}
{"idx": 3324, "commit_message": "Improving performance when logging while filter is active Other minor improvements and refactoring", "target": 1}
{"idx": 1965, "commit_message": "FAQ module - improve display (accordions)", "target": 0}
{"idx": 1323, "commit_message": "Changed forkMode for Surefire plugin to try to reduce memory usage in CI", "target": 1}
{"idx": 2395, "commit_message": "Minor change to HTTPRequest that should improve performance.", "target": 1}
{"idx": 65, "commit_message": "Enable log for mixint moo optimizer (#131)  * Update legacy tests    * Add test for segmoomoe    * Enable logging for segmoomoe", "target": 0}
{"idx": 2187, "commit_message": "X11: Improve performance of `Window::set_cursor_icon` (#1116)  * X11: Fix performance issue with rapidly resetting cursor icon    * When setting cursor icon, if the new icon value is the same as the    current value, no messages are sent the X server.    * X11: Cache cursor objects in XConnection    * Add changelog entry", "target": 1}
{"idx": 1156, "commit_message": "Remote driver & daemon impl of new event API  This wires up the remote driver to handle the new events APIs. The public API allows an application to request a callback filters events to a specific domain object, and register multiple callbacks for the same event type. On the wire there are two strategies for this   - Register multiple callbacks with the remote daemon, each    with filtering as needed  - Register only one callback per event type, with no filtering  Both approaches have potential inefficiency. In the first scheme, the same event gets sent over the wire many times if multiple callbacks are registered. With the second scheme, unneccessary events get sent over the wire if a per-domain filter is set on the client. The second scheme is far easier to implement though, so this patch takes that approach.  * daemon/dispatch.h: Don't export remoteRelayDomainEvent since it   is no longer needed for unregistering callbacks, instead the   unique callback ID is used * daemon/libvirtd.c, daemon/libvirtd.h: Track and unregister   callbacks based on callback ID, instead of function pointer * daemon/remote.c: Switch over to using virConnectDomainEventRegisterAny   instead of legacy virConnectDomainEventRegister function. Refactor   remoteDispatchDomainEventSend() to cope with arbitrary event types * src/driver.h, src/driver.c: Move verify() call into source file   instead of header, to avoid polluting the global namespace with   the verify function name * src/remote/remote_driver.c: Implement new APIs for event   registration. Refactor processCallDispatchMessage() to cope   with arbitrary incoming event types. Merge remoteDomainQueueEvent()   into processCallDispatchMessage() to avoid duplication of code.   Rename remoteDomainReadEvent() to remoteDomainReadEventLifecycle() * src/remote/remote_protocol.x: Define wire format for the new   virConnectDomainEventRegisterAny and virConnectDomainEventDeregisterAny   functions", "target": 0}
{"idx": 3708, "commit_message": "mm, compaction: defer each zone individually instead of preferred zone  When direct sync compaction is often unsuccessful, it may become deferred for some time to avoid further useless attempts, both sync and async. Successful high-order allocations un-defer compaction, while further unsuccessful compaction attempts prolong the compaction deferred period.  Currently the checking and setting deferred status is performed only on the preferred zone of the allocation that invoked direct compaction.  But compaction itself is attempted on all eligible zones in the zonelist, so the behavior is suboptimal and may lead both to scenarios where 1) compaction is attempted uselessly, or 2) where it's not attempted despite good chances of succeeding, as shown on the examples below:  1) A direct compaction with Normal preferred zone failed and set    deferred compaction for the Normal zone.  Another unrelated direct    compaction with DMA32 as preferred zone will attempt to compact DMA32    zone even though the first compaction attempt also included DMA32 zone.     In another scenario, compaction with Normal preferred zone failed to    compact Normal zone, but succeeded in the DMA32 zone, so it will not    defer compaction.  In the next attempt, it will try Normal zone which    will fail again, instead of skipping Normal zone and trying DMA32    directly.  2) Kswapd will balance DMA32 zone and reset defer status based on    watermarks looking good.  A direct compaction with preferred Normal    zone will skip compaction of all zones including DMA32 because Normal    was still deferred.  The allocation might have succeeded in DMA32, but    won't.  This patch makes compaction deferring work on individual zone basis instead of preferred zone.  For each zone, it checks compaction_deferred() to decide if the zone should be skipped.  If watermarks fail after compacting the zone, defer_compaction() is called.  The zone where watermarks passed can still be deferred when the allocation attempt is unsuccessful.  When allocation is successful, compaction_defer_reset() is called for the zone containing the allocated page.  This approach should approximate calling defer_compaction() only on zones where compaction was attempted and did not yield allocated page.  There might be corner cases but that is inevitable as long as the decision to stop compacting dues not guarantee that a page will be allocated.  Due to a new COMPACT_DEFERRED return value, some functions relying implicitly on COMPACT_SKIPPED = 0 had to be updated, with comments made more accurate.  The did_some_progress output parameter of __alloc_pages_direct_compact() is removed completely, as the caller actually does not use it after compaction sets it - it is only considered when direct reclaim sets it.  During testing on a two-node machine with a single very small Normal zone on node 1, this patch has improved success rates in stress-highalloc mmtests benchmark.  The success here were previously made worse by commit 3a025760fc15 (\"mm: page_alloc: spill to remote nodes before waking kswapd\") as kswapd was no longer resetting often enough the deferred compaction for the Normal zone, and DMA32 zones on both nodes were thus not considered for compaction.  On different machine, success rates were improved with __GFP_NO_KSWAPD allocations.  [URL]: fix CONFIG_COMPACTION=n build]", "target": 1}
{"idx": 1525, "commit_message": "some experiments with BSP for algorithms", "target": 0}
{"idx": 82, "commit_message": "61184: SystemML Engine Enhancements - Performance and memory consumption scalar operations (sparsesafe ==, !=,  to , <), incl tests", "target": 1}
{"idx": 3167, "commit_message": "arm64: perf: Add cap_user_time aarch64  It is useful to get the running time of a thread.  Doing so in an efficient manner can be important for performance of user applications. Avoiding system calls in `clock_gettime` when handling CLOCK_THREAD_CPUTIME_ID is important.  Other clocks are handled in the VDSO, but CLOCK_THREAD_CPUTIME_ID falls back on the system call.  CLOCK_THREAD_CPUTIME_ID is not handled in the VDSO since it would have costs associated with maintaining updated user space accessible time offsets.  These offsets have to be updated everytime the a thread is scheduled/descheduled.  However, for programs regularly checking the running time of a thread, this is a performance improvement.  This patch takes a middle ground, and adds support for cap_user_time an optional feature of the perf_event API.  This way costs are only incurred when the perf_event api is enabled.  This is done the same way as it is in x86.  Ultimately this allows calculating the thread running time in userspace on aarch64 as follows (adapted from perf_event_open manpage):  u32 seq, time_mult, time_shift; u64 running, count, time_offset, quot, rem, delta; struct perf_event_mmap_page *pc; pc = buf;  // buf is the perf event mmaped page as documented in the API.  if (pc->cap_usr_time) {     do {         seq = pc->lock;         barrier();         running = pc->time_running;          count = readCNTVCT_EL0();  // Read ARM hardware clock.         time_offset = pc->time_offset;         time_mult   = pc->time_mult;         time_shift  = pc->time_shift;          barrier();     } while (pc->lock != seq);      quot = (count >> time_shift);     rem = count & (((u64)1 << time_shift) - 1);     delta = time_offset + quot * time_mult +             ((rem * time_mult) >> time_shift);      running += delta;     // running now has the current nanosecond level thread time. }  Summary of changes in the patch:  For aarch64 systems, make arch_perf_update_userpage update the timing information stored in the perf_event page.  Requiring the following calculations:   - Calculate the appropriate time_mult, and time_shift factors to convert     ticks to nano seconds for the current clock frequency.   - Adjust the mult and shift factors to avoid shift factors of 32 bits.     (possibly unnecessary)   - The time_offset userspace should apply when doing calculations:     negative the current sched time (now), because time_running and     time_enabled fields of the perf_event page have just been updated. Toggle bits to appropriate values:   - Enable cap_user_time", "target": 1}
{"idx": 1777, "commit_message": "Mark some strings for translations (the can't create, g_error and the  Fri May 12 16:18:23 2000  George Lebl [URL]>  \t* memload.c,cpuload.c,netload.c,swapload.c: Mark some strings for \t  translations (the can't create, g_error and the tooltip)", "target": 0}
{"idx": 3784, "commit_message": "bonding: add support for numa awareness  This patch enables bonding numa awareness on multi-socket server working in active-backeup mode. The VPP adds capability for automatically preferring slave with local numa node in order to reduces the load on the QPI-bus and improve system overall performance in multi-socket use cases. Users doesn't need to add any extra operation as usual.", "target": 1}
{"idx": 3373, "commit_message": "cache performance and thread safety issues fixed.", "target": 1}
{"idx": 3829, "commit_message": "mm: mempolicy: Let vma_merge and vma_split handle vma->vm_policy linkages  commit 05f144a0d5c2207a0349348127f996e104ad7404 upstream.  Dave Jones' system call fuzz testing tool \"trinity\" triggered the following bug error with slab debugging enabled      =============================================================================     BUG numa_policy (Not tainted): Poison overwritten     -----------------------------------------------------------------------------      INFO: 0xffff880146498250-0xffff880146498250. First byte 0x6a instead of 0x6b     INFO: Allocated in mpol_new+0xa3/0x140 age=46310 cpu=6 pid=32154      __slab_alloc+0x3d3/0x445      kmem_cache_alloc+0x29d/0x2b0      mpol_new+0xa3/0x140      sys_mbind+0x142/0x620      system_call_fastpath+0x16/0x1b     INFO: Freed in __mpol_put+0x27/0x30 age=46268 cpu=6 pid=32154      __slab_free+0x2e/0x1de      kmem_cache_free+0x25a/0x260      __mpol_put+0x27/0x30      remove_vma+0x68/0x90      exit_mmap+0x118/0x140      mmput+0x73/0x110      exit_mm+0x108/0x130      do_exit+0x162/0xb90      do_group_exit+0x4f/0xc0      sys_exit_group+0x17/0x20      system_call_fastpath+0x16/0x1b     INFO: Slab 0xffffea0005192600 objects=27 used=27 fp=0x          (null) flags=0x20000000004080     INFO: Object 0xffff880146498250 @offset=592 fp=0xffff88014649b9d0  This implied a reference counting bug and the problem happened during mbind().  mbind() applies a new memory policy to a range and uses mbind_range() to merge existing VMAs or split them as necessary.  In the event of splits, mpol_dup() will allocate a new struct mempolicy and maintain existing reference counts whose rules are documented in Documentation/vm/numa_memory_policy.txt .  The problem occurs with shared memory policies.  The vm_op->set_policy increments the reference count if necessary and split_vma() and vma_merge() have already handled the existing reference counts. However, policy_vma() screws it up by replacing an existing vma->vm_policy with one that potentially has the wrong reference count leading to a premature free.  This patch removes the damage caused by policy_vma().  With this patch applied Dave's trinity tool runs an mbind test for 5 minutes without error.  /proc/slabinfo reported that there are no numa_policy or shared_policy_node objects allocated after the test completed and the shared memory region was deleted.", "target": 0}
{"idx": 497, "commit_message": "[release/3.0-preview7] Update dependencies from 2 repositories (#11831)  * Update dependencies from [URL]/aspnet/EntityFrameworkCore build 20190702.14    - Microsoft.EntityFrameworkCore.Tools - 3.0.0-preview7.19352.14  - Microsoft.EntityFrameworkCore.SqlServer - 3.0.0-preview7.19352.14  - dotnet-ef - 3.0.0-preview7.19352.14  - Microsoft.EntityFrameworkCore - 3.0.0-preview7.19352.14  - Microsoft.EntityFrameworkCore.InMemory - 3.0.0-preview7.19352.14  - Microsoft.EntityFrameworkCore.Relational - 3.0.0-preview7.19352.14  - Microsoft.EntityFrameworkCore.Sqlite - 3.0.0-preview7.19352.14    * Update dependencies from [URL]/aspnet/AspNetCore-Tooling build 20190702.12    - Microsoft.NET.Sdk.Razor - 3.0.0-preview7.19352.12  - Microsoft.CodeAnalysis.Razor - 3.0.0-preview7.19352.12  - Microsoft.AspNetCore.Razor.Language - 3.0.0-preview7.19352.12  - Microsoft.AspNetCore.Mvc.Razor.Extensions - 3.0.0-preview7.19352.12    * Dependency coherency updates    - Microsoft.AspNetCore.Analyzer.Testing - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.AspNetCore.BenchmarkRunner.Sources - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.ActivatorUtilities.Sources - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Caching.Abstractions - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Caching.Memory - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Caching.SqlServer - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Caching.StackExchangeRedis - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.CommandLineUtils.Sources - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration.Abstractions - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration.AzureKeyVault - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration.Binder - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration.CommandLine - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration.EnvironmentVariables - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration.FileExtensions - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration.Ini - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration.Json - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration.KeyPerFile - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration.UserSecrets - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration.Xml - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Configuration - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.DependencyInjection.Abstractions - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.DependencyInjection - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.DiagnosticAdapter - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Diagnostics.HealthChecks.Abstractions - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Diagnostics.HealthChecks - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.FileProviders.Abstractions - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.FileProviders.Composite - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.FileProviders.Embedded - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.FileProviders.Physical - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.FileSystemGlobbing - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.HashCodeCombiner.Sources - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Hosting.Abstractions - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Hosting - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.HostFactoryResolver.Sources - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Http - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Localization.Abstractions - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Localization - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Logging.Abstractions - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Logging.AzureAppServices - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Logging.Configuration - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Logging.Console - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Logging.Debug - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Logging.EventSource - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Logging.EventLog - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Logging.TraceSource - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Logging.Testing - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.ObjectPool - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Options.ConfigurationExtensions - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Options.DataAnnotations - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Options - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.ParameterDefaultValue.Sources - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.Primitives - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.TypeNameHelper.Sources - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.ValueStopwatch.Sources - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.WebEncoders - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Internal.Extensions.Refs - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.JSInterop - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Mono.WebAssembly.Interop - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.Extensions.DependencyModel - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Ref - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - NETStandard.Library.Ref - 2.1.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.NETCore.App.Runtime.win-x64 - 3.0.0-preview7-27902-11 (parent: Microsoft.Extensions.Logging)  - Microsoft.Extensions.Logging - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Internal.AspNetCore.Analyzers - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)  - Microsoft.AspNetCore.Testing - 3.0.0-preview7.19352.9 (parent: Microsoft.EntityFrameworkCore)", "target": 0}
{"idx": 2948, "commit_message": "[Defect / Enhancement / New Feature]     New Feature      [Problem]     Extend the V3D kernel driver to report Performance Register and its values      [Solution]     Extended v3d driver with \"V3D_PERF_SUPPORT\" flag. Added Performance Counter enable and disable and Read IOCTL's      [Reviewers]                 Nikhil, Tuukka, DavidX     [Testing]         [Test Cases]         Test Perforamance Register and its values with Spy tool (Debugging and Performance measuring UI tool)          [Label/CL# Synced To]         sdb-rhea-android-ics          [Platform]         lmp_rheastone_00", "target": 0}
{"idx": 3500, "commit_message": "tdb: always open internal databases with incompatible hash.  This makes them more efficient due to better distribution of keys across hash chains.", "target": 1}
{"idx": 2432, "commit_message": "Allocated buffer for first_comment only if needed  Minor performance improvement to reduce the number of calls to malloc()", "target": 1}
{"idx": 2379, "commit_message": "Improve performance for calculating memory allocation Extend interface for 'show variables' with current scope", "target": 1}
{"idx": 3361, "commit_message": "Performance Improvement for background images (#8448)  * Remove image canvas scaling and use imagedata to draw    * Bring back light mode for the tilemap and image editor", "target": 1}
{"idx": 3680, "commit_message": "fixes to the customizeable.jsm and some performance fixes", "target": 1}
{"idx": 2993, "commit_message": "swap: add per-partition lock for swapfile  swap_lock is heavily contended when I test swap to 3 fast SSD (even slightly slower than swap to 2 such SSD).  The main contention comes from swap_info_get().  This patch tries to fix the gap with adding a new per-partition lock.  Global data like nr_swapfiles, total_swap_pages, least_priority and swap_list are still protected by swap_lock.  nr_swap_pages is an atomic now, it can be changed without swap_lock.  In theory, it's possible get_swap_page() finds no swap pages but actually there are free swap pages.  But sounds not a big problem.  Accessing partition specific data (like scan_swap_map and so on) is only protected by swap_info_struct.lock.  Changing swap_info_struct.flags need hold swap_lock and swap_info_struct.lock, because scan_scan_map() will check it.  read the flags is ok with either the locks hold.  If both swap_lock and swap_info_struct.lock must be hold, we always hold the former first to avoid deadlock.  swap_entry_free() can change swap_list.  To delete that code, we add a new highest_priority_index.  Whenever get_swap_page() is called, we check it.  If it's valid, we use it.  It's a pity get_swap_page() still holds swap_lock().  But in practice, swap_lock() isn't heavily contended in my test with this patch (or I can say there are other much more heavier bottlenecks like TLB flush).  And BTW, looks get_swap_page() doesn't really need the lock.  We never free swap_info[] and we check SWAP_WRITEOK flag.  The only risk without the lock is we could swapout to some low priority swap, but we can quickly recover after several rounds of swap, so sounds not a big deal to me. But I'd prefer to fix this if it's a real problem.  \"swap: make each swap partition have one address_space\" improved the swapout speed from 1.7G/s to 2G/s.  This patch further improves the speed to 2.3G/s, so around 15% improvement.  It's a multi-process test, so TLB flush isn't the biggest bottleneck before the patches.", "target": 1}
{"idx": 189, "commit_message": "Finishing improvements to the JSON files", "target": 0}
{"idx": 3999, "commit_message": "[PATCH] Deprecate version of BoundaryInfo::boundary_ids(const Node*)\n that returns a vector.\n\nAdd new version that must be passed a std::set.  The new version\nshould be more efficient for making repeated calls to boundary_ids(),\nsince the container does not need to be created and destroyed\nrepeatedly...", "target": 1}
{"idx": 3662, "commit_message": "Minor performance improvement for search requests", "target": 1}
{"idx": 2786, "commit_message": "ARM: 7178/1: fault.c: Port OOM changes into do_page_fault  Commit d065bd810b6deb67d4897a14bfe21f8eb526ba99 (mm: retry page fault when blocking on disk transfer) and commit 37b23e0525d393d48a7d59f870b3bc061a30ccdb (x86,mm: make pagefault killable)  The above commits introduced changes into the x86 pagefault handler for making the page fault handler retryable as well as killable.  These changes reduce the mmap_sem hold time, which is crucial during OOM killer invocation.  Port these changes to ARM.  Without these changes, my ARM board encounters many hang and livelock scenarios. After applying this patch, OOM feature performance improves according to my testing.", "target": 1}
{"idx": 794, "commit_message": "Tweaks and bugfixes.  Most of this code will be replaced this week, but hey...  * subversion/libsvn_delta/diff.c    (svn_diff__tree_insert_token): Minor optimization.  We already know the     ordering of the tokens will be incremental when we get them, so we can     safely remove the test to see if there is an offset larger than the     one we are inserting already at the beginning of the list.    (svn_diff__lcs_reverse): Typo in comment.    (svn_diff__lcs): 2 bugfixes.  Correct the determination of 'k'.  Actually     reuse the lcs nodes that aren't needed anymore.  A new node was being     allocated all the time since the pointer to the node to be reused was     being NULL'd.", "target": 0}
{"idx": 1703, "commit_message": "Added description regarding GPU/cupy.  Updated some minor descriptions following updates of scripts.", "target": 0}
{"idx": 292, "commit_message": "Silence compiler  lib/company/company.el:3221:1: Warning: Lexical argument     shadows the dynamic variable right-margin-width", "target": 0}
{"idx": 2365, "commit_message": "Tidied up the flags in NakedObjectField and NakedObjectSpecification to more efficiently indicate whether a field is for a collection, object or value.  Added isCollection to NOSpec.", "target": 1}
{"idx": 3394, "commit_message": "Adding indexes to campaignitem to improve performance for generating campaign items", "target": 1}
{"idx": 2062, "commit_message": "Fix two just-introduced regressions in the ZFS states:  * a \"filesystem.present\" or \"volume.present\" state that specified no   properties would fail because it would execute \"zfs get\" with no property   argument.  Fix this (and improve performance too) by skipping the \"zfs   get\" if the user does not request any property values.  * A \"volume.present\" state that specified volume_size but no properties   would fail to check the volsize.  Also, make the properties argument of _dataset_properties a mandatory argument rather than a keyword argument.  All callers already specify this argument, making the default value a red herring.", "target": 1}
{"idx": 3442, "commit_message": "Improve efficiency of Seq, Map, and IntMap Align instances  Use builtin primitives to make Seq, Map, and IntMap instances of Align more efficient and inlinable. Also, add Crosswalk instances for Seq and Vector, as those are isomorphic to lists.", "target": 1}
{"idx": 544, "commit_message": "aws_route: Retry if route not found after creating it (#13747)  Output from acceptance testing:    ```  --- PASS: TestAccAWSRoute_basic (56.69s)  --- PASS: TestAccAWSRoute_changeCidr (43.84s)  --- PASS: TestAccAWSRoute_changeRouteTable (48.75s)  --- PASS: TestAccAWSRoute_disappears (29.82s)  --- PASS: TestAccAWSRoute_doesNotCrashWithVPCEndpoint (40.48s)  --- PASS: TestAccAWSRoute_ipv6Support (41.10s)  --- PASS: TestAccAWSRoute_ipv6ToInstance (101.37s)  --- PASS: TestAccAWSRoute_ipv6ToInternetGateway (35.51s)  --- PASS: TestAccAWSRoute_ipv6ToNetworkInterface (122.20s)  --- PASS: TestAccAWSRoute_ipv6ToPeeringConnection (38.36s)  --- PASS: TestAccAWSRoute_noopdiff (72.92s)  --- PASS: TestAccAWSRoute_TransitGatewayID_DestinationCidrBlock (259.74s)  ```", "target": 0}
{"idx": 2650, "commit_message": "[SEC][NEW] Password blacklist: template warnings fixed, PHP 7.0 compatibility, re-wrote file generation for better performance, minor UI enhancements. More UI to come.", "target": 1}
{"idx": 3326, "commit_message": "Merge branch 'appropos-watchCollection'  Performance optimization for collection.", "target": 1}
{"idx": 3543, "commit_message": "Reworked electricity standby analysis based on cache with significantly improved performance", "target": 1}
{"idx": 3306, "commit_message": "Improve 10G PHY TX timing performance", "target": 1}
{"idx": 698, "commit_message": "Add note on why we use -dynamic for Mac. Switch to LTS-3", "target": 0}
{"idx": 3444, "commit_message": "First step in making stubs cleaner + more efficient.  Rather than using individual addParameter()/addFault()/etc calls in each method, statically build up an array of OperationDescs which contains all the metadata, and simply reference those in the methods.  This avoids a lot of code (and object creations for ParameterDescs / QNames / etc) each time around.  Add a few convenience methods (constructors, etc) to make this look a little nicer.", "target": 1}
{"idx": 3241, "commit_message": "Merge pull request #111 from cloudfoundry/shalako-patch-1  improve instructions for instrumentation", "target": 0}
{"idx": 2168, "commit_message": "Chore: refactor config hash caching in CLIEngine (#9260)  Previously, CLIEngine would store the last config object when executing on multiple files, as a performance optimization to avoid rehashing configs if the same config was used for multiple files.    This can be better implemented by using a WeakMap to map config objects to hash results.", "target": 1}
{"idx": 2310, "commit_message": "directaccess: optimize performance  Summary: The directaccess extension could be smarter to avoid walking through public commits when marking ancestors as visible.  Reported by simpkins.  Reviewed By: DurhamG  Differential Revision: D12814546  fbshipit-source-id: 712db5b77afbb5108b696e1721d15c26c3a51176", "target": 1}
{"idx": 1070, "commit_message": "Auto merge of #84205 - workingjubilee:more-simd-intrin, r=bjorn3  Add simd_{round,trunc} intrinsics  LLVM supports many functions from math.h in its IR. Many of these have SIMD instructions on various platforms. So, let's add round and trunc so std::arch can use them.  Yes, exact comparison is intentional: rounding must always return a valid integer-equal value, except for inf/NAN.", "target": 1}
{"idx": 1560, "commit_message": "Merge \"Cisco N1kv: Remove vmnetwork delete REST call on last port delete", "target": 0}
{"idx": 2281, "commit_message": "Add a couple of %rflags spec rules which improve performance of amd64 FP comparisons.", "target": 1}
{"idx": 3099, "commit_message": "x86, hpet: Restrict read back to affected ATI chipsets  After programming the HPET, we do a readback as a workaround for ATI/SBx00 chipsets as a synchronization.  Unfortunately this triggers an erratum in newer ICH chipsets (ICH9+) where reading the comparator immediately after the write returns the old value.  Furthermore, as always, I/O reads are bad for performance.  Therefore, restrict the readback to the chipsets that need it, or, for debugging purposes, when we are running with hpet=verbose.", "target": 0}
{"idx": 3634, "commit_message": "git-gui: More performance improvements to rescan logic.  Removed as much as possible from the merge_state proc, which is where we spent most of our time before UI update.  This change makes our running time match that of git status, except that we then need about 7 additional seconds to draw 6900 files on screen.  Apparently the [array names a -exact $v] operator in Tcl is O(n) rather than O(1), which is really quite disappointing given that each array can only have one entry for a given value.  Switching to a lookup with a catch (whose error we ignore) runs in O(1) time and bought us most of that improvement.", "target": 1}
{"idx": 2619, "commit_message": "swap: change block allocation algorithm for SSD  I'm using a fast SSD to do swap.  scan_swap_map() sometimes uses up to 20~30% CPU time (when cluster is hard to find, the CPU time can be up to 80%), which becomes a bottleneck.  scan_swap_map() scans a byte array to search a 256 page cluster, which is very slow.  Here I introduced a simple algorithm to search cluster.  Since we only care about 256 pages cluster, we can just use a counter to track if a cluster is free.  Every 256 pages use one int to store the counter.  If the counter of a cluster is 0, the cluster is free.  All free clusters will be added to a list, so searching cluster is very efficient.  With this, scap_swap_map() overhead disappears.  This might help low end SD card swap too.  Because if the cluster is aligned, SD firmware can do flash erase more efficiently.  We only enable the algorithm for SSD.  Hard disk swap isn't fast enough and has downside with the algorithm which might introduce regression (see below).  The patch slightly changes which cluster is choosen.  It always adds free cluster to list tail.  This can help wear leveling for low end SSD too. And if no cluster found, the scan_swap_map() will do search from the end of last cluster.  So if no cluster found, the scan_swap_map() will do search from the end of last free cluster, which is random.  For SSD, this isn't a problem at all.  Another downside is the cluster must be aligned to 256 pages, which will reduce the chance to find a cluster.  I would expect this isn't a big problem for SSD because of the non-seek penality.  (And this is the reason I only enable the algorithm for SSD).", "target": 1}
{"idx": 2467, "commit_message": "Theme: full classnames to improve performance. Cleaned up some comments.", "target": 1}
{"idx": 2759, "commit_message": "Bytecode should not have responsibility for determining how to perform non-local resolves [URL]/show_bug.cgi?id=99349  Reviewed by Gavin Barraclough.  This patch removes lexical analysis from the bytecode generation.  This allows us to delay lookup of a non-local variables until the lookup is actually necessary, and simplifies a lot of the resolve logic in BytecodeGenerator.  Once a lookup is performed we cache the lookup information in a set of out-of-line buffers in CodeBlock.  This allows subsequent lookups to avoid unnecessary hashing, etc, and allows the respective JITs to recreated optimal lookup code.  This is currently still a performance regression in LLInt, but most of the remaining regression is caused by a lot of indirection that I'll remove in future work, as well as some work necessary to allow LLInt to perform in line instruction repatching. We will also want to improve the behaviour of the baseline JIT for some of the lookup operations, however this patch was getting quite large already so I'm landing it now that we've reached the bar of \"performance-neutral\".  * GNUmakefile.list.am: * JavaScriptCore.vcproj/JavaScriptCore/JavaScriptCore.vcproj: * JavaScriptCore.xcodeproj/project.pbxproj: * bytecode/CodeBlock.cpp: (JSC::CodeBlock::printStructures): (JSC::CodeBlock::dump): (JSC::CodeBlock::CodeBlock): (JSC::CodeBlock::visitStructures): (JSC): (JSC::CodeBlock::finalizeUnconditionally): (JSC::CodeBlock::shrinkToFit): * bytecode/CodeBlock.h: (JSC::CodeBlock::addResolve): (JSC::CodeBlock::addPutToBase): (CodeBlock): (JSC::CodeBlock::resolveOperations): (JSC::CodeBlock::putToBaseOperation): (JSC::CodeBlock::numberOfResolveOperations): (JSC::CodeBlock::numberOfPutToBaseOperations): (JSC::CodeBlock::addPropertyAccessInstruction): (JSC::CodeBlock::globalObjectConstant): (JSC::CodeBlock::setGlobalObjectConstant): * bytecode/GlobalResolveInfo.h: Removed. * bytecode/Opcode.h: (JSC): (JSC::padOpcodeName): * bytecode/ResolveGlobalStatus.cpp: (JSC::computeForStructure): (JSC::ResolveGlobalStatus::computeFor): * bytecode/ResolveGlobalStatus.h: (JSC): (ResolveGlobalStatus): * bytecode/ResolveOperation.h: Added.   The new types and logic we use to perform the cached lookups. (JSC): (ResolveOperation): (JSC::ResolveOperation::getAndReturnScopedVar): (JSC::ResolveOperation::checkForDynamicEntriesBeforeGlobalScope): (JSC::ResolveOperation::getAndReturnGlobalVar): (JSC::ResolveOperation::getAndReturnGlobalProperty): (JSC::ResolveOperation::resolveFail): (JSC::ResolveOperation::skipTopScopeNode): (JSC::ResolveOperation::skipScopes): (JSC::ResolveOperation::returnGlobalObjectAsBase): (JSC::ResolveOperation::setBaseToGlobal): (JSC::ResolveOperation::setBaseToUndefined): (JSC::ResolveOperation::setBaseToScope): (JSC::ResolveOperation::returnScopeAsBase): (JSC::PutToBaseOperation::PutToBaseOperation): * bytecompiler/BytecodeGenerator.cpp: (JSC::ResolveResult::checkValidity): (JSC): (JSC::BytecodeGenerator::BytecodeGenerator): (JSC::BytecodeGenerator::resolve): (JSC::BytecodeGenerator::resolveConstDecl): (JSC::BytecodeGenerator::shouldAvoidResolveGlobal): (JSC::BytecodeGenerator::emitResolve): (JSC::BytecodeGenerator::emitResolveBase): (JSC::BytecodeGenerator::emitResolveBaseForPut): (JSC::BytecodeGenerator::emitResolveWithBaseForPut): (JSC::BytecodeGenerator::emitResolveWithThis): (JSC::BytecodeGenerator::emitGetLocalVar): (JSC::BytecodeGenerator::emitInitGlobalConst): (JSC::BytecodeGenerator::emitPutToBase): * bytecompiler/BytecodeGenerator.h: (JSC::ResolveResult::registerResolve): (JSC::ResolveResult::dynamicResolve): (ResolveResult): (JSC::ResolveResult::ResolveResult): (JSC): (NonlocalResolveInfo): (JSC::NonlocalResolveInfo::NonlocalResolveInfo): (JSC::NonlocalResolveInfo::~NonlocalResolveInfo): (JSC::NonlocalResolveInfo::resolved): (JSC::NonlocalResolveInfo::put): (BytecodeGenerator): (JSC::BytecodeGenerator::getResolveOperations): (JSC::BytecodeGenerator::getResolveWithThisOperations): (JSC::BytecodeGenerator::getResolveBaseOperations): (JSC::BytecodeGenerator::getResolveBaseForPutOperations): (JSC::BytecodeGenerator::getResolveWithBaseForPutOperations): (JSC::BytecodeGenerator::getPutToBaseOperation): * bytecompiler/NodesCodegen.cpp: (JSC::ResolveNode::isPure): (JSC::FunctionCallResolveNode::emitBytecode): (JSC::PostfixNode::emitResolve): (JSC::PrefixNode::emitResolve): (JSC::ReadModifyResolveNode::emitBytecode): (JSC::AssignResolveNode::emitBytecode): (JSC::ConstDeclNode::emitCodeSingle): (JSC::ForInNode::emitBytecode): * dfg/DFGAbstractState.cpp: (JSC::DFG::AbstractState::execute): * dfg/DFGByteCodeParser.cpp: (ByteCodeParser): (InlineStackEntry): (JSC::DFG::ByteCodeParser::handleGetByOffset): (DFG): (JSC::DFG::ByteCodeParser::parseResolveOperations): (JSC::DFG::ByteCodeParser::parseBlock): (JSC::DFG::ByteCodeParser::InlineStackEntry::InlineStackEntry): * dfg/DFGCapabilities.h: (JSC::DFG::canCompileResolveOperations): (DFG): (JSC::DFG::canCompilePutToBaseOperation): (JSC::DFG::canCompileOpcode): (JSC::DFG::canInlineOpcode): * dfg/DFGGraph.h: (ResolveGlobalData): (ResolveOperationData): (DFG): (PutToBaseOperationData): (Graph): * dfg/DFGNode.h: (JSC::DFG::Node::hasIdentifier): (JSC::DFG::Node::resolveOperationsDataIndex): (Node): * dfg/DFGNodeType.h: (DFG): * dfg/DFGOSRExit.cpp: (JSC::DFG::OSRExit::OSRExit): * dfg/DFGOSRExit.h: (OSRExit): * dfg/DFGOSRExitCompiler.cpp: * dfg/DFGOSRExitCompiler32_64.cpp: (JSC::DFG::OSRExitCompiler::compileExit): * dfg/DFGOSRExitCompiler64.cpp: (JSC::DFG::OSRExitCompiler::compileExit): * dfg/DFGOperations.cpp: * dfg/DFGOperations.h: * dfg/DFGPredictionPropagationPhase.cpp: (JSC::DFG::PredictionPropagationPhase::propagate): * dfg/DFGRepatch.cpp: (JSC::DFG::tryCacheGetByID): * dfg/DFGSpeculativeJIT.cpp: (JSC::DFG::SpeculativeJIT::convertLastOSRExitToForward): * dfg/DFGSpeculativeJIT.h: (JSC::DFG::SpeculativeJIT::resolveOperations): (SpeculativeJIT): (JSC::DFG::SpeculativeJIT::putToBaseOperation): (JSC::DFG::SpeculativeJIT::callOperation): * dfg/DFGSpeculativeJIT32_64.cpp: (JSC::DFG::SpeculativeJIT::compile): * dfg/DFGSpeculativeJIT64.cpp: (JSC::DFG::SpeculativeJIT::compile): * dfg/DFGStructureCheckHoistingPhase.cpp: (JSC::DFG::StructureCheckHoistingPhase::run): * jit/JIT.cpp: (JSC::JIT::privateCompileMainPass): (JSC::JIT::privateCompileSlowCases): * jit/JIT.h: (JIT): * jit/JITOpcodes.cpp: (JSC::JIT::emit_op_put_to_base): (JSC): (JSC::JIT::emit_resolve_operations): (JSC::JIT::emitSlow_link_resolve_operations): (JSC::JIT::emit_op_resolve): (JSC::JIT::emitSlow_op_resolve): (JSC::JIT::emit_op_resolve_base): (JSC::JIT::emitSlow_op_resolve_base): (JSC::JIT::emit_op_resolve_with_base): (JSC::JIT::emitSlow_op_resolve_with_base): (JSC::JIT::emit_op_resolve_with_this): (JSC::JIT::emitSlow_op_resolve_with_this): (JSC::JIT::emitSlow_op_put_to_base): * jit/JITOpcodes32_64.cpp: (JSC::JIT::emit_op_put_to_base): (JSC): * jit/JITPropertyAccess.cpp: (JSC::JIT::emit_op_init_global_const): (JSC::JIT::emit_op_init_global_const_check): (JSC::JIT::emitSlow_op_init_global_const_check): * jit/JITPropertyAccess32_64.cpp: (JSC::JIT::emit_op_init_global_const): (JSC::JIT::emit_op_init_global_const_check): (JSC::JIT::emitSlow_op_init_global_const_check): * jit/JITStubs.cpp: (JSC::DEFINE_STUB_FUNCTION): (JSC): * jit/JITStubs.h: * llint/LLIntSlowPaths.cpp: (LLInt): (JSC::LLInt::LLINT_SLOW_PATH_DECL): * llint/LLIntSlowPaths.h: (LLInt): * llint/LowLevelInterpreter.asm: * llint/LowLevelInterpreter32_64.asm: * llint/LowLevelInterpreter64.asm: * runtime/JSScope.cpp: (JSC::LookupResult::base): (JSC::LookupResult::value): (JSC::LookupResult::setBase): (JSC::LookupResult::setValue): (LookupResult): (JSC): (JSC::setPutPropertyAccessOffset): (JSC::executeResolveOperations): (JSC::JSScope::resolveContainingScopeInternal): (JSC::JSScope::resolveContainingScope): (JSC::JSScope::resolve): (JSC::JSScope::resolveBase): (JSC::JSScope::resolveWithBase): (JSC::JSScope::resolveWithThis): (JSC::JSScope::resolvePut): (JSC::JSScope::resolveGlobal): * runtime/JSScope.h: (JSScope): * runtime/JSVariableObject.cpp: (JSC): * runtime/JSVariableObject.h: (JSVariableObject): * runtime/Structure.h: (JSC::Structure::propertyAccessesAreCacheable): (Structure):", "target": 0}
{"idx": 206, "commit_message": "Added stack testing program pushpop.s Added char view for memory, use 'mb' at prompt. Added support for labels in DATA to put a symbol in the table but not save anything. Fixed bug in STRB,STRH trying to save words instead of their respective sizes.", "target": 0}
{"idx": 2548, "commit_message": "Merge branch 'improve-notification-settings-migrations' into 'master'    Remove notification settings in batches    ## What does this MR do?    This improves the performance of the migration `db/migrate/20160603180330_remove_duplicated_notification_settings.rb` by removing duplicate rows in batches instead of using a single big `DELETE FROM` query.    ## Why was this MR needed?    The original migration would locally take 45 minutes to complete, possibly up to hours on [URL] and similar setups.    ## What are the relevant issue numbers?    #18289    See merge request !4529", "target": 1}
{"idx": 3202, "commit_message": "Improve chunkloading performance, prevent provideChunk from returning a newly generated chunk before populating it.", "target": 1}
{"idx": 1039, "commit_message": "Magicolor: Fix SNMP detection with multiple snmp agents in the network.  So far, the snmp detection would stop working after the first response, because libsnmp haved like that if we return 1 in the callback. Since we want multiple responses to one broadcast query, we don't tell libsnmp that the response has answered our query. As a drawback, libsnmp will send the same query in 1-second-intervals, and each device will answer again. So, we have to keep a list of all devices already detected.", "target": 0}
{"idx": 1451, "commit_message": "ixgbe: Add 82599 device id's, hook it up into the main driver.  With the hardware-specific code in place, add all supported device id's, along with base driver changes to enable 82599 devices.  The devices being enabled are:  8086:10f7: 82599EB 10 Gigabit KX4 Network Connection 8086:10fb: 82599EB 10 Gigabit Network Connection  The device 8086:10fb is a fully-pluggable SFP+ NIC.", "target": 0}
{"idx": 369, "commit_message": "qemu_cpu.cfg: We don't need any image processing  The qemu_cpu test case doesn't use any disk image, so we don't need any image processing when running the tests cases.  This should make the tests run much faster.", "target": 1}
{"idx": 2041, "commit_message": "Update XSSImageCheck.py (#475)  refactoring code with List Comprehension which is more pythonic, concise and efficient;", "target": 1}
{"idx": 1871, "commit_message": "Cult Overhaul  Cult is awful, so let's try to improve it. Idea by KorPhaeron. I also took some inspiration from adrix89's sacrifice cult, so credits to him. Also thanks a lot specially to MrPerson and Iamgoofball for helping me brainstorm this, and Joan for the sprites for the summoning orb, the large nar-sie shell, and the new cult antag hud.  Basically, we remove conversion, and turn cult into a magic version of nuke, with a small team of stealth elite cultists that have to build a base in the station and sacrifice people in order to build an army of constructs and get materials to eventually summon Nar-Sie.  Stun talismans and conversion are gone. Nar-Sie is now the only objective. Sacrifice runes now provide summoning orbs, which you can use to drop a large shell. Insert enough orbs in the shell and you trigger a Delta. Defend the shell for 3 minutes and Nar-sie will arise. This shell is bombproof and singularityproof. It may be summoned up to three times if destroyed, but you will have to start from the beginning sac-wise.  Runes are now RNG. Each cultist only gets 50% of the runes. Inspiration is basically The Binding of Isaac here (thank you MrPerson for this!). Furthermore, many old runes were merged/removed and other new ones were added. Almost all were massively rebalanced. Cult now also has a stealthy ritual dagger with high bleeding and throw effects.", "target": 0}
{"idx": 3452, "commit_message": "Improve performance of dedupe command by only caling prune method once.", "target": 1}
{"idx": 2667, "commit_message": "IPDatabase uses more efficient unordered_map instead", "target": 1}
{"idx": 2953, "commit_message": "remove useless millisleep  reduces time to service requests improving performance", "target": 1}
{"idx": 3756, "commit_message": "i965/fs: Improve performance of copy/constant propagation.  Use a simple chaining hash table for the ACP.  This is not really very good, because we still do a full walk of the tree per destination write, but it still reduces fp-long-alu runtime from 5.3 to 3.9s.", "target": 1}
{"idx": 3228, "commit_message": "BACKPORT: audit: fix a double fetch in audit_log_single_execve_arg()  (cherry picked from commit 43761473c254b45883a64441dd0bc85a42f3645c)  There is a double fetch problem in audit_log_single_execve_arg() where we first check the execve(2) argumnets for any \"bad\" characters which would require hex encoding and then re-fetch the arguments for logging in the audit record[1].  Of course this leaves a window of opportunity for an unsavory application to munge with the data.  This patch reworks things by only fetching the argument data once[2] into a buffer where it is scanned and logged into the audit records(s).  In addition to fixing the double fetch, this patch improves on the original code in a few other ways: better handling of large arguments which require encoding, stricter record length checking, and some performance improvements (completely unverified, but we got rid of some strlen() calls, that's got to be a good thing).  As part of the development of this patch, I've also created a basic regression test for the audit-testsuite, the test can be tracked on GitHub at the following link:   * [URL]/linux-audit/audit-testsuite/issues/25  [1] If you pay careful attention, there is actually a triple fetch problem due to a strnlen_user() call at the top of the function.  [2] This is a tiny white lie, we do make a call to strnlen_user() prior to fetching the argument data.  I don't like it, but due to the way the audit record is structured we really have no choice unless we copy the entire argument at once (which would require a rather wasteful allocation).  The good news is that with this patch the kernel no longer relies on this strnlen_user() value for anything beyond recording it in the log, we also update it with a trustworthy value whenever possible.  Reported-by: Pengfei Wang [URL]> Cc: [URL]>", "target": 1}
{"idx": 154, "commit_message": "2007-05-15  H.J. Lu  [URL]> \t    Alan Modra  [URL].au>  \tPR ld/4504 \t* elf-bfd.h (_bfd_elf_adjust_dynamic_copy): New. \t* elflink.c (_bfd_elf_adjust_dynamic_copy): New.  \t* elf-m10300.c (_bfd_mn10300_elf_adjust_dynamic_symbol): Call \t_bfd_elf_adjust_dynamic_copy to adjust for the copy in dynamic \tbss section. \t* elf32-arm.c (elf32_arm_adjust_dynamic_symbol): Likewise. \t* elf32-cris.c (elf_cris_adjust_dynamic_symbol): Likewise. \t* elf32-hppa.c (elf32_hppa_adjust_dynamic_symbol): Likewise. \t* elf32-i370.c (i370_elf_adjust_dynamic_symbol): Likewise. \t* elf32-i386.c (elf_i386_adjust_dynamic_symbol): Likewise. \t* elf32-m32r.c (m32r_elf_adjust_dynamic_symbol): Likewise. \t* elf32-m68k.c (elf_m68k_adjust_dynamic_symbol): Likewise. \t* elf32-ppc.c (ppc_elf_adjust_dynamic_symbol): Likewise. \t* elf32-s390.c (elf_s390_adjust_dynamic_symbol): Likewise. \t* elf32-sh.c (sh_elf_adjust_dynamic_symbol): Likewise. \t* elf32-vax.c (elf_vax_adjust_dynamic_symbol): Likewise. \t* elf64-ppc.c (ppc64_elf_adjust_dynamic_symbol): Likewise. \t* elf64-s390.c (elf_s390_adjust_dynamic_symbol): Likewise. \t* elf64-sh64.c (sh64_elf64_adjust_dynamic_symbol): Likewise. \t* elf64-x86-64.c (elf64_x86_64_adjust_dynamic_symbol): Likewise. \t* elfxx-mips.c (_bfd_mips_vxworks_adjust_dynamic_symbol): Likewise. \t* elfxx-sparc.c (_bfd_sparc_elf_adjust_dynamic_symbol): Likewise.", "target": 0}
{"idx": 1048, "commit_message": "ARM: dts: msm: Add default prefetching size for secure playback  Prefetching for heaps designated for secure playback provides a good performance boost. Add the optimized default prefetching size for clients to use.", "target": 1}
{"idx": 2514, "commit_message": "[MERGE] view form: reduce the number of result in 'search more' view opening to 160 records (performances improvement, not filtering every possible record) (opw 593963)", "target": 1}
{"idx": 2533, "commit_message": "+ improve performance: Matrix.rotateM() allocates memory, so avoid it (use RenderHelper)  this greatly decreases the need to collect garbage during the game this also increases the frame rate by about 15%", "target": 1}
{"idx": 1251, "commit_message": "change check params to allow for slightly flakier network (?); updae conf's;", "target": 0}
{"idx": 4057, "commit_message": "[PATCH] NumericVector::add_vector refactoring\n\nSimilar to #411 and #413\n\nThis was originally intended to be just another additional T* API plus\na refactoring; however, the new PetscVector::add_vector(DenseVector)\ncode path should be a performance improvement as well.", "target": 1}
{"idx": 1155, "commit_message": "Improved per-host data savings estimate for NoScript Previews  Uses NoScript inflation_percent from optimization guide hints if not 0.  Bug: 807662", "target": 0}
{"idx": 2125, "commit_message": "improved performance of restore by generating hash on backup (#72)", "target": 1}
{"idx": 3837, "commit_message": "Merge pull request #87 from matthewhesketh/patch-3  Improved English", "target": 0}
{"idx": 2681, "commit_message": "ACPI: Be in TS_POLLING state during mwait based C-state entry  ACPI deep C-state entry had a long standing bug/missing feature, wherein we were sending resched IPIs when an idle CPU is in mwait based deep C-state. Only mwait based C1 was using the write to the monitored address to wake up mwait'ing CPU.  This patch changes the code to retain TS_POLLING bit if we are entering an mwait based deep C-state.  The patch has been verified to reduce the number of resched IPIs in general and also improves the performance/power on workloads with low system utilization (i.e., when mwait based deep C-states are being used).  Fixes \"netperf ~50% regression with 2.6.33-rc1, bisect to 1b9508f\" [URL]/?l=linux-kernel&m=126441481427331&w=4  Reported-by: Lin Ming [URL]> Tested-by: Alex Shi [URL]>", "target": 1}
{"idx": 2283, "commit_message": "sessions.data as jsonb rather than text, which will be more efficient on read", "target": 1}
{"idx": 2860, "commit_message": "Bug 26048: Use ErrorDocument middleware for Plack HTTP errors  This patch uses the ErrorDocument middleware to use Koha's custom error pages instead of generic Plack error responses  Test plan: 0. Apply patch 1. vi /usr/sbin/koha-plack (and change \"development\" to \"deployment\") 2. vi ./opac/opac-main.pl 3. Add \"die\" to line 2 4. vi ./mainpage.pl 5. Add \"die\" to line 2 6. cp ./debian/templates/plack.psgi /etc/koha/sites/kohadev/plack.psgi 7. koha-plack --restart kohadev 8. Go to http://localhost:8080/cgi-bin/koha/opac-main.pl 9. See a beautiful OPAC 500 error instead of \"Internal Server Error\" 10. Go to http://localhost:8080/cgi-bin/koha/blah.pl 11. See a beautiful OPAC 404 error instead of \"not found\" 12. Go to http://localhost:8081/cgi-bin/koha/mainpage.pl 13. See a beautiful Staff interface 500 error instead of \"Internal Server Error\" 14. Go to http://localhost:8081/cgi-bin/koha/blah.pl 15. See a beautiful Staff interface 404 error instead of \"not found\"  For bonus points: 16. koha-plack --disable kohadev 17. koha-plack --stop kohadev 18. service apache restart 19. Repeat the above test plan to show CGI still works for 404 (although 500 will show \"Software Error\" due to C4::Context needing some improvements) 20. Using the \"Network\" tab on your developer tools, make sure 404 and 500 are returned by the appropriate error pages", "target": 0}
{"idx": 2039, "commit_message": "Improve performance of the TopReferrers plugin by ignoring blank referrers.", "target": 1}
{"idx": 3792, "commit_message": "Insert TRACE_EVENT macros for the sampling profiler into not performance-sensitive places  - Implement TraceEvent::SamplingState0Scope.  - Insert TraceEvent::SamplingState0Scope into where performance is not sensitive. I'll insert the macros to performance-sensitive places in a follow-up CL.  - Replace \"TraceEventAPIAtomicWord\" with \"long\", since it's implemented as long in the Chromium side. \"TraceEventAPIAtomicWord\" is confusing since it gives us an impression that it's already implemented as a thread-safe and atomic word.  R=abarth BUG=241743  Review URL: [URL]/17377006", "target": 0}
{"idx": 2222, "commit_message": "Unreviewed, rolling out r101202. [URL]/changeset/101202 [URL]/show_bug.cgi?id=71244  Caused performance regressions when painting collapsed borders  Source/WebCore:  * rendering/RenderTableCell.cpp: (WebCore::compareBorders): (WebCore::RenderTableCell::collapsedStartBorder): (WebCore::RenderTableCell::collapsedEndBorder): (WebCore::RenderTableCell::collapsedBeforeBorder): (WebCore::RenderTableCell::collapsedAfterBorder): * rendering/style/CollapsedBorderValue.h: (WebCore::CollapsedBorderValue::CollapsedBorderValue): (WebCore::CollapsedBorderValue::operator==): * rendering/style/RenderStyleConstants.h:  LayoutTests:  * css2.1/20110323/border-conflict-element-001.htm: Removed. * css2.1/20110323/border-conflict-element-001a.htm: Removed. * css2.1/20110323/border-conflict-element-001b.htm: Removed. * css2.1/20110323/border-conflict-element-001c.htm: Removed. * css2.1/20110323/border-conflict-element-001d.htm: Removed. * css2.1/20110323/border-conflict-element-003.htm: Removed. * css2.1/20110323/border-conflict-element-004.htm: Removed. * css2.1/20110323/border-conflict-element-005.htm: Removed. * css2.1/20110323/border-conflict-element-006.htm: Removed. * css2.1/20110323/border-conflict-element-007.htm: Removed. * css2.1/20110323/border-conflict-element-008.htm: Removed. * css2.1/20110323/border-conflict-element-009.htm: Removed. * css2.1/20110323/border-conflict-element-010.htm: Removed. * css2.1/20110323/border-conflict-element-011.htm: Removed. * css2.1/20110323/border-conflict-element-012.htm: Removed. * css2.1/20110323/border-conflict-element-013.htm: Removed. * css2.1/20110323/border-conflict-element-014.htm: Removed. * css2.1/20110323/border-conflict-element-015.htm: Removed. * css2.1/20110323/border-conflict-element-016.htm: Removed. * css2.1/20110323/border-conflict-element-017.htm: Removed. * css2.1/20110323/border-conflict-element-018.htm: Removed. * css2.1/20110323/border-conflict-element-019.htm: Removed. * css2.1/20110323/border-conflict-element-020.htm: Removed. * css2.1/20110323/border-conflict-element-021.htm: Removed. * css2.1/20110323/border-conflict-element-022.htm: Removed. * css2.1/20110323/border-conflict-element-023.htm: Removed. * css2.1/20110323/border-conflict-element-024.htm: Removed. * css2.1/20110323/border-conflict-element-025.htm: Removed. * css2.1/20110323/border-conflict-element-026.htm: Removed. * css2.1/20110323/border-conflict-element-027.htm: Removed. * css2.1/20110323/border-conflict-element-028.htm: Removed. * css2.1/20110323/border-conflict-element-029.htm: Removed. * css2.1/20110323/border-conflict-element-030.htm: Removed. * css2.1/20110323/border-conflict-element-031.htm: Removed. * css2.1/20110323/border-conflict-element-032.htm: Removed. * css2.1/20110323/border-conflict-element-033.htm: Removed. * css2.1/20110323/border-conflict-element-034.htm: Removed. * css2.1/20110323/border-conflict-element-035.htm: Removed. * css2.1/20110323/border-conflict-element-036.htm: Removed. * css2.1/20110323/border-conflict-element-037.htm: Removed. * css2.1/20110323/border-conflict-element-038.htm: Removed. * css2.1/20110323/border-conflict-element-039.htm: Removed. * css2.1/20110323/support/swatch-blue.png: Removed. * css2.1/20110323/support/swatch-green.png: Removed. * css2.1/20110323/support/swatch-lime.png: Removed. * css2.1/20110323/support/swatch-orange.png: Removed. * css2.1/20110323/support/swatch-red.png: Removed. * css2.1/20110323/support/swatch-teal.png: Removed. * css2.1/20110323/support/swatch-white.png: Removed. * css2.1/20110323/support/swatch-yellow.png: Removed. * fast/css/border-conflict-element-002.htm: Removed. * platform/chromium-linux/css2.1/20110323/border-conflict-style-079-expected.png: * platform/chromium-linux/css2.1/20110323/border-conflict-style-088-expected.png: * platform/chromium-linux/css2.1/20110323/floating-replaced-height-008-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-05-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-06-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-07-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-08-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-15-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-16-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-17-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-18-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-25-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-26-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-27-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-28-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-35-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-36-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-37-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-38-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-45-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-46-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-47-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-48-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-51-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-52-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-53-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-54-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-55-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-56-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-57-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-58-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-59-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-61-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-62-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-63-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-64-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-65-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-66-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-67-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-68-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-69-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-71-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-72-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-73-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-74-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-75-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-76-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-77-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-78-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-79-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-81-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-82-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-83-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-84-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-85-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-86-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-87-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-88-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-89-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-95-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-96-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-97-d-expected.png: * platform/chromium-linux/css2.1/t170602-bdr-conflct-w-98-d-expected.png: * platform/chromium-linux/fast/borders/border-antialiasing-expected.png: * platform/chromium-linux/tables/mozilla/collapsing_borders/bug41262-4-expected.png: * platform/chromium-linux/tables/mozilla/marvin/table_rules_all-expected.png: * platform/chromium-linux/tables/mozilla/marvin/table_rules_none-expected.png: * platform/chromium-linux/tables/mozilla_expected_failures/marvin/table_rules_cols-expected.png: * platform/chromium-linux/tables/mozilla_expected_failures/marvin/table_rules_rows-expected.png: * platform/chromium/css2.1/20110323/border-conflict-element-001-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-001-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-001a-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-001a-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-001b-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-001b-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-001c-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-001c-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-001d-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-001d-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-003-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-003-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-004-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-004-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-005-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-005-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-006-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-006-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-007-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-007-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-008-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-008-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-009-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-009-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-010-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-010-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-011-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-011-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-012-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-012-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-013-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-013-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-014-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-014-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-015-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-015-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-016-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-016-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-017-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-017-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-018-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-018-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-019-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-019-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-020-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-020-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-021-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-021-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-022-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-022-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-023-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-023-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-024-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-024-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-025-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-025-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-026-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-026-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-027-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-027-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-028-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-028-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-029-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-029-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-030-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-030-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-031-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-031-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-032-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-032-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-033-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-033-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-034-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-034-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-035-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-035-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-036-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-036-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-037-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-037-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-038-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-038-expected.txt: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-039-expected.png: Removed. * platform/chromium/css2.1/20110323/border-conflict-element-039-expected.txt: Removed. * platform/chromium/fast/css/border-conflict-element-002-expected.png: Removed. * platform/chromium/fast/css/border-conflict-element-002-expected.txt: Removed.", "target": 0}
{"idx": 2912, "commit_message": "Extend performance_browser_tests watchdog timeout to 2 minutes.  According to the perf bot builder logs, the first of 8 tests is flaky in that it simply takes much longer to start up. This only happens in approx. 1 out of 5 runs. When examining the build logs, it seems that the test does start running successfully. However, because it took so long to start up, the test launcher watchdog kills the test before it finishes its 15-second performance sampling period.  As a short-term fix, I am increasing the watchdog timeout to eliminate the flakes. In the long-term, I plan to revisit and try to figure out whether this is a problem with the test, or an environmental issue (i.e., it very much \"smells\" like it's related to [URL]/416072).  Bug: 759866", "target": 0}
{"idx": 4098, "commit_message": "[PATCH] Improved performance mostly by using hints to insert to the\n status line.", "target": 1}
{"idx": 3514, "commit_message": "VM: Always start switchable calls with IC stub.  This generalizes the use of switchable calls to the case where the number of arguments checked is > 1 and improves performance of calls to the various operator methods.  BUG= [URL]  Review URL: [URL]/1888783002 .", "target": 1}
{"idx": 2344, "commit_message": "Local music performance improvements and bugfixes", "target": 0}
{"idx": 2153, "commit_message": "tweak the examples/parser-to-lexer-communication-test.jison example a bit to better measure impact of some lexer/parser code changes on parser execution performance (measured and observed via the build/run command `make examples/parser-to-lexer-communication-test--profiling`)", "target": 1}
{"idx": 1269, "commit_message": "Implements loading of bzip2 file content into memory.", "target": 0}
{"idx": 2777, "commit_message": "COLLECT performance improvement  Use lower-level FUNC* instead of higher-level FUNC", "target": 1}
{"idx": 2191, "commit_message": "Only pump messages during a cookie query if it results in a user prompt.  Note: I left LocalStorage intact.  I want to first confirm that this CL resolves the Intl2 performance regression.  If so, then I'll follow-up with a CL to add similar treatment for LocalStorage.  R=jam BUG=36310 TEST=none  Review URL: [URL]/657074", "target": 0}
{"idx": 3121, "commit_message": "Fix frame timing issue in performance page (#2802)  * Fix frame timing issue in performance page", "target": 0}
{"idx": 161, "commit_message": "SWITCHYARD-1314 Message Validator improvement  Contains:  - [URL]/browse/SWITCHYARD-1315 - Return Details of Message Validation Error    -- validate() method returns ValidationResult object, which has getDetail() method to return error details when validation fails  - [URL]/browse/SWITCHYARD-1257 - Support multiple Schemas in XmlValidator    -- added SchemaFiles element in validate.xml to specify multiple schema files and removed schemaFile attribute    -- XmlValidator now supports namespace aware validation as well with setting 'namespaceAware' attribute as true  - [URL]/browse/SWITCHYARD-1312 - Add XML Catalog support to XML Validator    -- added SchemaCatalogs element in validate.xml to specify multiple schema catalogs", "target": 0}
{"idx": 2796, "commit_message": "constexpr\"-ized Matrix and Vector classes.  It should improve performance, because what can be computed at compile time is now computed at compile time. In addition these things have been changed or improved:   * Removed constructors from T*, as they cannot be AFAIK written using    constexpr functions only and they only do unnecessary data copying    most of the time. The functionality is now provided using static    functions Matrix*::from() and Vector*::from() which returns either    const or non-const reference to original data, so no copy is    performed. These functions also have explicit warning about unsafe    operations.  * Defaulted copy constructors and assignment operators, using    \"default initialization\" for arrays instead of memsetting it with    zeros. It should behave the same and this way we don't need any    memcpy(), memset() etc. from <cstring>, which is good.", "target": 1}
{"idx": 669, "commit_message": "Run msvc analysis with single CPU  Hopefully this avoids out of heap memory errors.", "target": 0}
{"idx": 1450, "commit_message": "optimizations and corrections to study and response views", "target": 1}
{"idx": 3659, "commit_message": "Moved some things around in the crawler for slightly better performance", "target": 1}
{"idx": 3848, "commit_message": "Switched to my own combination monitor which is much more efficient.", "target": 1}
{"idx": 2800, "commit_message": "Performance improvement. Not the last one. We still have much work here I think.  svn path=/trunk/KDE/kdelibs/; revision=750741", "target": 1}
{"idx": 4045, "commit_message": "[PATCH] Replace vpermpd with vpermilpd in the Haswell DTRMM kernel\n\nto improve performance on AMD Zen (#2180) applying wjc404's improvement of the DGEMM kernel from #2186", "target": 1}
{"idx": 293, "commit_message": "improve ticket followup for new doc (add 'filename')", "target": 0}
{"idx": 1142, "commit_message": "improved the layout of the GUI remote, now using a progress bar for example.  New class CurrentTrackMonitor.", "target": 0}
{"idx": 2890, "commit_message": "Improve core attack rate capacity  This commit addresses three performance bottlenecks that were preventing attacks with high rates to complete in the specified duration.", "target": 1}
{"idx": 2939, "commit_message": "cifs: set ra_pages in backing_dev_info  commit 2b6c26a0a62cc0bab0ad487533d5581d7c293fef upstream.  Commit 522440ed made cifs set backing_dev_info on the mapping attached to new inodes. This change caused a fairly significant read performance regression, as cifs started doing page-sized reads exclusively.  By virtue of the fact that they're allocated as part of cifs_sb_info by kzalloc, the ra_pages on cifs BDIs get set to 0, which prevents any readahead. This forces the normal read codepaths to use readpage instead of readpages causing a four-fold increase in the number of read calls with the default rsize.  Fix it by setting ra_pages in the BDI to the same value as that in the default_backing_dev_info.  Fixes [URL]/show_bug.cgi?id=31662  Reported-and-Tested-by: Till < >", "target": 1}
{"idx": 2955, "commit_message": "Bug 1491: initial work on improving the flag writer's performance.", "target": 1}
{"idx": 1182, "commit_message": "Fix Bug 5330 to handle OVSDB disconnect from VTN Manager  Whenever a new OVSDB node gets connected, odl-vtn-manager-neutron feature will create a OVS bridge which can be controlled using Openflow to provide networking to Openstack instances. This patch deletes the bridge node entry from config DS when the OVS disconnects.The patch also removes some data change handling code that were not required by VTN and modifies access levels on some existing methods.", "target": 0}
{"idx": 3057, "commit_message": "Source code -- lights for deferred shading, more gbuffer is now 4x more memory efficient,  first work on collision callbacks,", "target": 1}
{"idx": 340, "commit_message": "lobby: Improve filter CSS loading to avoid ugly flashing on first load", "target": 0}
{"idx": 3553, "commit_message": "Performance improvements to optimise database access  - Ensure queries made after object construction   do not make additional queries to the database - Add assertions to test suite formalising expected performance  This tweak ensures we should never need to make more than 3 DB queries for any series of method calls.", "target": 1}
{"idx": 3339, "commit_message": "library: improve \"browse\" performance with more efficient queries", "target": 1}
{"idx": 3642, "commit_message": "2010-10-06  Nikolas Zimmermann  [URL]>          Reviewed by Dirk Schulze.          Only execute first SVG text layout phase if needed         [URL]/show_bug.cgi?id=47254          The first SVG text layout phase which computes the per-character metrics and extracts         the x/y/dx/dy/rotate values from the SVG DOM is currently executed upon every RenderSVGText::layout() call.          Optimize this, by only calling it:         - if x/y/dx/dy/rotate value lists change         - the style of a RenderSVGInlineText changes (eg. font-size changes influence metrics)         - the text content of any of the children in the <text> subtree change          No change in layout tests, a pure performance change - covered by existing tests.          * rendering/RenderSVGResourceGradient.cpp:         (WebCore::createMaskAndSwapContextForTextGradient): Adapt to renames, use RenderSVGText::locateRenderSVGTextAncestor().         (WebCore::clipToTextMask): Ditto.         * rendering/SVGRenderSupport.cpp:         * rendering/SVGRenderSupport.h: Move findTreeRootObject to RenderSVGText::locateRenderSVGTextAncestor().         * rendering/svg/RenderSVGInline.cpp:         (WebCore::RenderSVGInline::objectBoundingBox): adapt to renames, use RenderSVGText::locateRenderSVGTextAncestor().         (WebCore::RenderSVGInline::strokeBoundingBox): Ditto.         (WebCore::RenderSVGInline::repaintRectInLocalCoordinates): Ditto.         (WebCore::RenderSVGInline::absoluteQuads): Ditto.         * rendering/svg/RenderSVGInlineText.cpp:         (WebCore::RenderSVGInlineText::styleDidChange): Call setNeedsPositioningValuesUpdate() on the RenderSVGText root object, if diff == StyleDifferenceLayout.         * rendering/svg/RenderSVGText.cpp:         (WebCore::RenderSVGText::RenderSVGText): Initialize m_needsPositioningValuesUpdate.         (WebCore::RenderSVGText::locateRenderSVGTextAncestor): New helper function, moved from SVGRenderSupport, to a more sensible place.         (WebCore::RenderSVGText::layout): Only execute the first SVG text layout phase, if m_needsPositioningValuesUpdate=true.         * rendering/svg/RenderSVGText.h:         (WebCore::RenderSVGText::setNeedsPositioningValuesUpdate):         (WebCore::toRenderSVGText): Add new helper casting methods, like most other renderers have.         * svg/SVGTextPositioningElement.cpp:         (WebCore::updatePositioningValuesInRenderer):         (WebCore::SVGTextPositioningElement::svgAttributeChanged): If x/y/dx/dy/rotate changes, call setNeedsPositioningValuesUpdate on the RenderSVGText root object.         (WebCore::SVGTextPositioningElement::childrenChanged): If any children changes (addition, removal), do the same.         * svg/SVGTextPositioningElement.h:", "target": 1}
{"idx": 1842, "commit_message": "Added Tests/HistoricalReferenceOutput/PerformanceDump-v2.0a114-x86-ReleaseU.txt (very slight speedups except sharedptr slower - cuz actually deleting more I'm guessing) - maybe nothing significant", "target": 0}
{"idx": 3471, "commit_message": "msm: Enable bus scaling for h/w crypto driver.  Adding bus bandwidth options for the crypto driver improves the performance. The driver requests for bus bandwidth when loaded.", "target": 1}
{"idx": 4048, "commit_message": "[PATCH] sbgemm: cooperlake: reorder ptr increase for performance", "target": 1}
{"idx": 2112, "commit_message": "Merge pull request #38 from loudnate/loudnate/performance  Insulin effect performance improvements", "target": 1}
{"idx": 2382, "commit_message": "Minor performance improvement. Use an (unsynchronized) ArrayList instead of a Vector as the container for the strings in the DOMStringList.", "target": 1}
{"idx": 3489, "commit_message": "refactor: apply FxCop analyzers (#86)  * style: use FxCop analyzers    Mostly ignored diagnostics, to enable one by one in future    * style: sort out Tests-only FxCop issues    * build: update SourceLink package    * style: fix XML FxCop warnings    * style: fix Dispose warnigns from FxCop    * style: fix FxCop performance warnings    * style: fix FxCop naming issues    * style: fix FxCop globalization issues    * style: fix FxCop design issues    * docs: add changelog entries    for #85", "target": 0}
{"idx": 2304, "commit_message": "Cache Manager is now much more efficient, and manages the cache more appropriately. Clean compile of all FullFAT modules on VS2008", "target": 1}
{"idx": 1780, "commit_message": "Improve behavior of marathon.json.mustache rendering to return an error if `.labels` isn't Map[String, String] (#306)", "target": 0}
{"idx": 277, "commit_message": "Moved zone-related threads into the zone  The action, motion, and update threads all really belonged in the zone object, so they and all their baggage were moved there.  As a result, three files (action.cc, motion_worker.cc, and update.cc) were able to be removed.  The dynamic library handling which was being done by hand everywhere became its own class, located in library.h and library.cc.  Handling of individual libraries is now able to be done much closer to where it is used; for example, the actions library loading and registering is now done inside the zone itself.  The zone_interface files are a relic of when we were trying to keep the base C server stuff and the C++ classes separate, and the original reasoning is no longer valid, so we will begin moving as much as possible out of those files, for their eventual removal.  There were some smaller updates in order to get everything within the classes and actions directories to compile.  Linking is still a problem, though it may be a result of the differences between the Mac (current dev platform) and Linux (previous dev platform) linkers.  Some of the problems may be resolved with the eventual removal of the zone_interface.", "target": 0}
{"idx": 3822, "commit_message": "Performance improvements and adding minimal debug tool", "target": 1}
{"idx": 3733, "commit_message": "Improve network compression performance by gzipping at best speed", "target": 1}
{"idx": 379, "commit_message": "[Telemetry] Fix --cold-load-percent.  Previously, we didn't properly clear all the network caches. 1. DNS and predictor caches were left in tact. This was fixed by calling the    net benchmarking extension methods. 2. Live resources in the memory cache were left in tact. This is fixed by    navigating to about:blank to destroy the old renderer.  Also, --enable-net-benchmarking is supported on the stable channel, so we can remove the workaround.  With this, cold loads are consistent on Android:  *RESULT cold_times: page_load_time= [4637,4493,4479,4564,4611,4549] ms Avg cold_times: 4555.500000ms Sd  cold_times: 62.602716ms RESULT warm_times_by_url: http___www.youtube.com_watch?v_LIJOhk6FscY= [2122,2104,2079,2094] ms Avg warm_times_by_url: 2099.750000ms Sd  warm_times_by_url: 18.043928ms  BUG=  Review URL: [URL]/165193002", "target": 0}
{"idx": 3212, "commit_message": "Made some types of nested update queries very slightly more efficient at the database level. Also worked around the fact that MySQL (and maybe other backends we don't know about) cannot select from the table they're updating.  Fixed #7095.  --HG-- extra : convert_revision : svn%3Abcc190cf-cafb-0310-a4f2-bffc1f526a37/django/trunk%407496", "target": 1}
{"idx": 3129, "commit_message": "Rewrote src/possible-selectors to be way more efficient", "target": 1}
{"idx": 3981, "commit_message": "Use hash set storage for MCS generation  The performance of the generation is improved. However, the minimization has suffered because of the loss of optimizations with ordered structures. Several performance tests are broken with mixed results.", "target": 1}
{"idx": 3079, "commit_message": "mlv_rec: improved writing performance  --HG-- branch : unified", "target": 1}
{"idx": 374, "commit_message": "bump guardian  [#171307969]  Submodule src/guardian ed7e94a2..b9bba44a:   > Consider cpu entitlement when setting bad cgroup shares", "target": 0}
{"idx": 2220, "commit_message": "Some twiks  EstimateA_L1_logistic - corrected NaN issues when lambda=x=0 on some components GetStat - removed \"throw away stats with low amount of measurement heuristic\". There seem to be no affect construct_bal_weights - modified script to remove \"unobserved neurons\", and make network with circular boundary conditions construct_block_weights_lognormal.m - added a function that generarte blocks from a lognormal distribution. Sometimes this gives better performance", "target": 1}
{"idx": 1676, "commit_message": "Constraint for network-uri and removed preliminary logo", "target": 0}
{"idx": 2001, "commit_message": "Merge pull request #21 from eauland/patch-1  Improve ergonomics", "target": 0}
{"idx": 2978, "commit_message": "Merge pull request #597 from Microsoft/cacheFileLookups  Cache unsuccessful file lookups for improved performance.", "target": 1}
{"idx": 2651, "commit_message": "make SortedArrayCluster.remove_members a lot faster by using a list instead of a generator (~100x speedup, but now uses more memory)", "target": 1}
{"idx": 3864, "commit_message": "APNs: set MaxIdleConnsPerHost as same as core.worker_num.  As worker_num is typically larger than MaxIdleConnsPerHost, the performance should be improved.", "target": 1}
{"idx": 903, "commit_message": "[INTERNAL] Interaction: Improve semantic step name detection  If closest Element to actual browserEvent provides a semantic step name we use it and will not try to find a better match. With this idea MenuItems could be handled correctly.", "target": 0}
{"idx": 2833, "commit_message": "Improved the performance and memory usage of parsing individual selectors.", "target": 1}
{"idx": 995, "commit_message": "[POWERPC] bootwrapper: Add find_node_by_alias and dt_fixup_mac_address_by_alias  Add the ability to set the mac address given the alias for the device. Removes the need for having a linux,network-index property.", "target": 0}
{"idx": 1954, "commit_message": "internal/graphicscommand: Bug fix: memory leak at q.commands  Apparently, the part of a slice between len and cap-1 still holds references. Release them explicitly.  Closes #1803", "target": 0}
{"idx": 4042, "commit_message": "[PATCH] Improving performance of BigInt/BigFloat routines (such as\n Cholesky) by more than a factor of three by avoiding allocations within the\n templated BLAS routines", "target": 1}
{"idx": 2872, "commit_message": "arm64: create an option to use simple spinlocks  The ticket based spin locks may reduce the worst case latency  in use cases where there is a lot of contention for a lock. However, they require more overhead than a simple lock in the case that there is no contention.  This implements a simple spinlock which improves performance in the use cases where there is not much contention and fairness is not a big problem.  Also, the implementation of the ticket based lock for the arm64 architecture does not use the WFE instruction optimally. It uses the idiom: \tsevl 1:\twfe \tldaxr \tcmp \tbne 1b  This is not ideal in the contested or uncontested case because it delays executing the ldaxr instruction. It executes potentially slow WFE and SEVL instructions.  Further, this idiom is incompatible with __raw_spin_lock which uses:  while (!raw_spin_can_lock(lock) && (lock)->break_lock) arch_spin_relax(&lock->raw_lock);  The problem is that there is no place to put the SEVL outside the loop. This results in the CPU busy spinning anytime there is contention for a spinlock.  A better idiom in all cases is something like:  1:\tldaxr \tcmp \tbne 2f \twfe \tb 1b 2:  With this idiom, the load is executed immediately instead of executing the potentially slow no-op SEVL+WFE.  This idiom fits nicely into the __raw_spin_lock loop allowing the CPU to go to sleep while waiting for the lock.  Bug 1440840", "target": 1}
{"idx": 2502, "commit_message": "Merge pull request #377 from imzhenyu/improve-private-log  improve performance for private log", "target": 1}
{"idx": 2628, "commit_message": "Merge pull request #1 from Wilfred/patch-1  Improve example in README.md", "target": 0}
{"idx": 3520, "commit_message": "rtlwifi: rtl8192se: Fix connection problems  Changes in the vendor driver were added to rtlwifi, but some updates to rtl8192se were missed, and the driver could neither scan nor connect. There are other changes that will enhance performance, but this minimal set fix the basic functionality.", "target": 0}
{"idx": 3527, "commit_message": "Add scan plan system  This can improve performance now and will be useful for the future transcoder system.", "target": 1}
{"idx": 2874, "commit_message": "Improved SerpentDeep gen, CoordPacker bugfixes  SerpentDeepMapGenerator now produces far less extraneous staircases, which should makethe intended goal of forcing up and down movement more interesting. CoordPacker.translate always produced off-by-one bugs, and it wasn't caught by the existing test; this has been fixed and tests confirm it. Changing to use AND NOT instead of changing the operands should help differencePacked be faster. negate() called twice will no longer append garbage to the end. Added xorPacked and a variant on rectangle that has a starting x and y.", "target": 0}
{"idx": 3755, "commit_message": "WinGui: - Hopefully a significant performance improvement in the Parser ReadLine() Function. This should help when the CLI is throwing out huge amounts of read errors / logging data.", "target": 1}
{"idx": 2795, "commit_message": "Double the screen repaint delay  Greatly improves performance when a lot of output is being generated.", "target": 1}
{"idx": 1040, "commit_message": "It turns out that now that the propagator definition macrology is worked out (and do-apply-prop no longer tries to wrap a direct propagator constructor in a with-network-group), the basic tests of the metadata facility just pass again.", "target": 0}
{"idx": 2493, "commit_message": "Merge branch '2.3' into 2.4  * 2.3:   [Process] minor fixes   Improve performance of getNextEmbedBlock by removing unnecessary preg_match and function calls.   Avoid unnecessary line indentation calculation.   Optimise Inline::evaluateScalar() for parsing strings.   fixed CS   fixed parsing Mongo DSN and added Test for it   () is also a valid delimiter   Adding PHP 5.6 to travis-ci tests   Update BCryptPasswordEncoder.php   [Validator] Removed PHP <5.3.3 specific code which is not officially supported.   Fixed wrong redirect url if path contains some query parameters", "target": 1}
{"idx": 3281, "commit_message": "hugetlb: support file_region coalescing again  An earlier patch in this series disabled file_region coalescing in order to hang the hugetlb_cgroup uncharge info on the file_region entries.  This patch re-adds support for coalescing of file_region entries. Essentially everytime we add an entry, we call a recursive function that tries to coalesce the added region with the regions next to it.  The worst case call depth for this function is 3: one to coalesce with the region next to it, one to coalesce to the region prev, and one to reach the base case.  This is an important performance optimization as private mappings add their entries page by page, and we could incur big performance costs for large mappings with lots of file_region entries in their resv_map.  [URL]: fix CONFIG_CGROUP_HUGETLB ifdefs]   Link: [URL] [URL]: remove check_coalesce_bug debug code]   Link: [URL]", "target": 1}
{"idx": 2159, "commit_message": "Replace std::map with std::unordered_map for better performance", "target": 1}
{"idx": 1982, "commit_message": "improve UI and fix typos errors", "target": 0}
{"idx": 2213, "commit_message": "Improving performance of migration add_line_item_id_to_spree_inventory_units  I noticed when I ran these commands on the console that the line      shipments = Spree::Shipment.includes(:inventory_units, :order)  would load a tremendous amount of stuff from the database, negating the performance savings by the `find_each` method. This may even be a Rails bug. Putting the `includes` and the `find_each` into the same line fixed performance issues immediately.", "target": 1}
{"idx": 1424, "commit_message": "padd dynamic_id to process.   \t* operations/file-io/exr-load.cpp: padd dynamic_id to process.", "target": 0}
{"idx": 1266, "commit_message": "Merge pull request #5528 from zhuoshuguo/fix_header_include_guard  CPU: Fixed include guards", "target": 0}
{"idx": 931, "commit_message": "INTEGRATION: CWS swobjpos03 (1.22.56); FILE MERGED 2004/02/16 10:02:40 od 1.22.56.3: RESYNC: (1.22-1.24); FILE MERGED resolve merge conflicts. 2003/11/10 13:31:07 od 1.22.56.2: #113049# - further improvements to the isolated object positioning algorithms 2003/10/27 13:04:03 od 1.22.56.1: merging changes from swobjpos02", "target": 0}
{"idx": 4072, "commit_message": "[PATCH] QN update is now in Base class - subclasses onla compute the\n update. Changed computation of QN-Update for MVQN: use QR decomposition of\n matrix V, instead of LU decomposition of VTV. More efficient and more robust\n implementation", "target": 1}
{"idx": 2111, "commit_message": "Reduce strength of PT relative to HPT  This change is intended to provide a bit more incentive to make peace with the Human race, because the neutral PT was barely worse than the HPT (being only -5 damage).  Photon Torpedo => -1% accuracy Human Photon Torpedo => +1% accuracy, -5 damage  The efficiency of the HPT remains the same, and the efficiency of the PT drops a little bit (it is now the least efficient P3 neutral).  We swap 5 damage for 1% accuracy on the HPT primarily because of the lore that Humans have focused on high accuracy weapons.", "target": 0}
{"idx": 2206, "commit_message": "Merge pull request #2472 from jezdez/vagrant-performance  Improve Vagrant VM performance.", "target": 1}
{"idx": 2438, "commit_message": "rewrite code of on_response_writable to be simpler/more efficient", "target": 1}
{"idx": 2012, "commit_message": "Various changes to extend and improve activities in marble-touch.  Simplify ActivityModel and addActivity(), settings are adjusted in the respective activity .qml files now. Use one common MarbleWidget instance instead of one in each activity, huge performance benefit. Also fixes crashes and settings corruptions. The current parent change needed to accomplish that doesn't look perfect in the code yet, but seems to work well in practice. Disable dummy activities for now. Extend five activities to behave more sane, still more things needed to make them work like planned.", "target": 1}
{"idx": 2328, "commit_message": "Merge pull request #162 from trivago/fix/performance  Performance improvements", "target": 1}
{"idx": 760, "commit_message": "perf: reduce repainting in animations  By profiling qTox using perf I discovered, that NotificationIcon::updateGradient takes significant amount of CPU time even though qTox is idle and no one is typing.  This commit fixes:  1) correctly determine visibility of NotificationIcon 2) only invalidate boundingRect in fixed intervals 3) apply the same fixes to Spinner since it has the same problem", "target": 1}
{"idx": 3718, "commit_message": "Enhanced & Modified cpu_consolidation testcase: We can pass additional argument performance to use the same testcase for Performance test. Fixed issues in cpu consolidation test.", "target": 0}
{"idx": 1712, "commit_message": "test(transition): Improve tests on promise resolution & Add some doc comments", "target": 0}
{"idx": 3746, "commit_message": "Fixed jpg bug when attempting to reformat images and reorganised the type generation code so it is much more efficient. It no longer loops through all of the extensions and now intellegiently figures out which extension to use based of the URL", "target": 1}
{"idx": 4043, "commit_message": "[PATCH] Enforce memory alignment to improve performance of vector\n operations.  Also fixed bugs in an earlier optimization.", "target": 1}
{"idx": 1958, "commit_message": "rcu: Avoid counter wrap in synchronize_sched_expedited()  There is a counter scheme similar to ticket locking that synchronize_sched_expedited() uses to service multiple concurrent callers with the same expedited grace period.  Upon entry, a sync_sched_expedited_started variable is atomically incremented, and upon completion of a expedited grace period a separate sync_sched_expedited_done variable is atomically incremented.  However, if a synchronize_sched_expedited() is delayed while in try_stop_cpus(), concurrent invocations will increment the sync_sched_expedited_started counter, which will eventually overflow. If the original synchronize_sched_expedited() resumes execution just as the counter overflows, a concurrent invocation could incorrectly conclude that an expedited grace period elapsed in zero time, which would be bad.  One could rely on counter size to prevent this from happening in practice, but the goal is to formally validate this code, so it needs to be fixed anyway.  This commit therefore checks the gap between the two counters before incrementing sync_sched_expedited_started, and if the gap is too large, does a normal grace period instead.  Overflow is thus only possible if there are more than about 3.5 billion threads on 32-bit systems, which can be excluded until such time as task_struct fits into a single byte and 4G/4G patches are accepted into mainline. It is also easy to encode this limitation into mechanical theorem provers.", "target": 0}
{"idx": 2658, "commit_message": "Merge pull request #939 from andrey-helldar/patch-2018-11-10  Visual improvements todo list", "target": 0}
{"idx": 2967, "commit_message": "Merge pull request #264 from SkyeYoung/patch-1  Improved Chinese translation", "target": 0}
{"idx": 826, "commit_message": "Merge tag 'mac80211-for-davem-2019-10-08' of [URL]/pub/scm/linux/kernel/git/jberg/mac80211  Johannes Berg says:  ==================== A number of fixes:  * allow scanning when operating on radar channels in    ETSI regdomains  * accept deauth frames in IBSS - we have code to parse    and handle them, but were dropping them early  * fix an allocation failure path in hwsim  * fix a failure path memory leak in nl80211 FTM code  * fix RCU handling & locking in multi-BSSID parsing  * reject malformed SSID in mac80211 (this shouldn't    really be able to happen, but defense in depth)  * avoid userspace buffer overrun in ancient wext code    if SSID was too long ====================", "target": 0}
{"idx": 1467, "commit_message": "binfmt_elf.c: use get_random_int() to fix entropy depleting  Changes: -------- v4->v3: - s/random_stack_user()/get_atrandom_bytes()/ - Move this function to ahead of its use to avoid the predeclaration.  v3->v2: - Tweak code comments of random_stack_user(). - Remove redundant bits mask and shift upon the random variable.  v2->v1: - Fix random copy to check up buffer length that are not 4-byte multiples.  v3 can be found at: [URL]/lists/linux-fsdevel/msg59597.html v2 can be found at: [URL]/lists/linux-fsdevel/msg59418.html v1 can be found at: [URL]/lists/linux-fsdevel/msg59128.html  Thanks, -Jeff  Entropy is quickly depleted under normal operations like ls(1), cat(1), etc...  between 2.6.30 to current mainline, for instance:  $ cat /proc/sys/kernel/random/entropy_avail 3428 $ cat /proc/sys/kernel/random/entropy_avail 2911 $cat /proc/sys/kernel/random/entropy_avail 2620  We observed this problem has been occurring since 2.6.30 with fs/binfmt_elf.c: create_elf_tables()->get_random_bytes(), introduced by f06295b44c296c8f (\"ELF: implement AT_RANDOM for glibc PRNG seeding\").  /*  * Generate 16 random bytes for userspace PRNG seeding.  */ get_random_bytes(k_rand_bytes, sizeof(k_rand_bytes));  The patch introduces a wrapper around get_random_int() which has lower overhead than calling get_random_bytes() directly.  With this patch applied: $ cat /proc/sys/kernel/random/entropy_avail 2731 $ cat /proc/sys/kernel/random/entropy_avail 2802 $ cat /proc/sys/kernel/random/entropy_avail 2878  Analyzed by John Sobecki.", "target": 1}
{"idx": 2561, "commit_message": "Add ConnectionsMax function that limits connections per pid.  The goal is to improve performance of connection fetching connections across all processes when some processes can have several hundred or thousands of file descriptors. Right now when you have many thousands of fds the process spends lots of time inside the syscalls from Readdir and Readlink.  The public API works as before with two new functions:  - `ConnectionsMax` - `ConnectionsPidMax`  Each function takes an additional int argument that sets the max number of fds read per process.", "target": 1}
{"idx": 4018, "commit_message": "[PATCH] Introduce self-pairs search in nbsearch\n\nMake it possible to search for all pairs within a single set of\npositions using AnalysisNeighborhood.  This effectively excludes half of\nthe pairs from the search, speeding things up.\n\nNot used yet anywhere, but this makes the code a better reference for\nperformance comparisons, and for places where this is applicable it has\npotential for speeding things up quite a bit.\n\nChange-Id: Ib0e6f36460b8dbda97704447222c864c149d8e56", "target": 1}
{"idx": 3723, "commit_message": "Semaphore: Avoid bugs in POSIX semaphores; use futexes directly. Addresses #18.  Glibc's implementation of POSIX semaphores had a race until very recently. See: [URL]/bugzilla/show_bug.cgi?id=12674.  It meant that when performing sem_wait() followed by sem_destroy(), the corresponding sem_post() could spuriously return EINVAL (best case) or read from unmapped memory and crash (if you're really unlucky).  Glibc was fixed only recently, so many users of libdispatch won't be using it, so I've written a wrapper around futexes to use instead of POSIX sempahores, heavily inspired by the Musl and Glibc implementations.  Further reading: - Glibc's fix on Jan 21 2015: [URL]/git/gitweb.cgi?p=glibc.git;h=042e1521c794a945edc43b5bfa7e69ad70420524 - Musl libc's fix on August 2 2011: [URL]/cgit/musl/commit/?id=88c4e720317845a8e01aee03f142ba82674cd23d - Discussion on Musl's proposed fix on Stack Overflow: [URL]/q/6907339/192102  Also: - Refactored the wait_slow() functions to minimise code duplication and   mirror the changes in upstream libdispatch from OS X 10.9. - Improved error checking: we no longer blindly loop around a   sem_wait/dispatch_futex_wait waiting a 0 return code.  Only -1 and   EINTR or ETIMEDOUT should be expected -- anything else should trigger   a crash.", "target": 0}
{"idx": 3488, "commit_message": "more efficient implementation of toList, toOptList and flatten", "target": 1}
{"idx": 2266, "commit_message": "Add diamond truncation method for multi-tone HB  The diamond truncation method is a standard frequency selection technique for multi-tone HB and it is avaiable in most RF simulation tools. This commit adds this diamond truncation method in Xyce and it now works with APFT based multi-tone HB methods. It can be enabled by using option selectharms. This new feature is testd in multiple ways and is verified to work as expected. The intmodmax is required for diamond truncation method. The method can be more efficient in some circuits than box truncation method for multi-tone HB.  Xyce/code/uur-proprietary/Xyce#352", "target": 1}
{"idx": 2388, "commit_message": "Merge branch 'rc/diff-cleanup-records'  * rc/diff-cleanup-records:   xdiff/xprepare: improve O(n*m) performance in xdl_cleanup_records()", "target": 1}
{"idx": 3978, "commit_message": "Servlet version 1.14b1 - better performance with thumbnails (really, this time :-) - new DocuInfo class - new Directory class - DocuFile uses String and Directory as data members - parameter rearrangements", "target": 1}
{"idx": 1498, "commit_message": "Merge pull request #996 from harishkashyap/fix-memory-issues  Adds option to decompress images and select prefetcher Queue", "target": 0}
{"idx": 3793, "commit_message": "Improve vector API  Improve vector functions. Fix vector_grow bug when size is 0.", "target": 0}
{"idx": 3939, "commit_message": "[performance optimization] By registry option idea.concurrent.scanning.files.to.index use fork joint pool concurrent processing for pusher properties update / files to index calculation. Different threads process different module or root. Major speed up happens upon initial vfs initialization: we build vfs with many random reads and (when project is opened first time) detect text file type by reading (many) files with unmapped extension in the project.  A part of the change is also time logging for pushed properties update", "target": 1}
{"idx": 620, "commit_message": "Improved the Plugin engine  * Added the basis for new plugin engine. * Fields are generated dinamically, so making new plugins are more easy since now * Added FreePaymentBundle and PaypalWebCheckoutBundle as plugins * Added the basis for new payment engine", "target": 0}
{"idx": 2569, "commit_message": "Refactorizations in CheckBufferOverrun: - Improved performance of CheckBufferOverrun::checkScope() - Made some patterns less restrictive", "target": 1}
{"idx": 1589, "commit_message": "Improve C compiler detection - use ExtUtils::CBuilder if available.", "target": 0}
{"idx": 3289, "commit_message": "Refactor the __checkClass() and must_be_a_Dir() methods into a more general and more efficient must_be_same() method.", "target": 1}
{"idx": 2296, "commit_message": "[nls] NlsMessages: cache formats to improve performance  GitOrigin-RevId: baad77fec8e7e9ce27d4d023e5a4a15c4e407eae", "target": 1}
{"idx": 2687, "commit_message": "powerpc/vdso: Avoid link stack corruption in __get_datapage()  powerpc has a link register (lr) used for calling functions. We \"bl <func>\" to call a function, and \"blr\" to return back to the call site.  The lr is only a single register, so if we call another function from inside this function (ie. nested calls), software must save away the lr on the software stack before calling the new function. Before returning (ie. before the \"blr\"), the lr is restored by software from the software stack.  This makes branch prediction quite difficult for the processor as it will only know the branch target just before the \"blr\".  To help with this, modern powerpc processors keep a (non-architected) hardware stack of lr called a \"link stack\". When a \"bl <func>\" is run, the lr is pushed onto this stack. When a \"blr\" is called, the branch predictor pops the lr value from the top of the link stack, and uses it to predict the branch target. Hence the processor pipeline knows a lot earlier the branch target.  This works great but there are some cases where you call \"bl\" but without a matching \"blr\". Once such case is when trying to determine the program counter (which can't be read directly). Here you \"bl+4; mflr\" to get the program counter. If you do this, the link stack will get out of sync with reality, causing the branch predictor to mis-predict subsequent function returns.  To avoid this, modern micro-architectures have a special case of bl. Using the form \"bcl 20,31,+4\", ensures the processor doesn't push to the link stack.  The 32 and 64 bit variants of __get_datapage() use a \"bl; mflr\" to determine the loaded address of the VDSO. The current versions of these attempt to use this special bl variant.  Unfortunately they use +8 rather than the required +4. Hence the current code results in the link stack getting out of sync with reality and hence the resulting performance degradation.  This patch moves it to bcl+4 by moving __kernel_datapage_offset out of __get_datapage().  With this patch, running a gettimeofday() (which uses __get_datapage()) microbenchmark we get a decent bump in performance on POWER7/8.  For the benchmark in tools/testing/selftests/powerpc/benchmarks/gettimeofday.c   POWER8:     64bit gets ~4% improvement     32bit gets ~9% improvement   POWER7:     64bit gets ~7% improvement", "target": 1}
{"idx": 346, "commit_message": "fixed BFM GPU test compile-time error on ubuntu x64 in debug mode", "target": 0}
{"idx": 1627, "commit_message": "Portlet AnnotationMethodHandlerAdapter resolves PortletPreferences, PortletMode, WindowState, PortalContext arguments; improved exception messages", "target": 0}
{"idx": 2756, "commit_message": "Start version 1.2 Add iterator options on find* commands (To improve memory) Add readOnly options on find* commands (To make no cache on object that do not need updates, improve memory performance)", "target": 1}
{"idx": 732, "commit_message": "remove unsunsed delegate methods, improve error handling (#743)", "target": 1}
{"idx": 1678, "commit_message": "sched: Optimize the select_best_cpu() \"for\" loop  select_best_cpu() is agnostic of the hardware topology. This means that certain functions such as task_will_fit() and skip_cpu() are run unnecessarily for every CPU in a cluster whereas they need to run only once per cluster. Reduce the execution time of select_best_cpu() by ensuring these functions run only once per cluster. The frequency domain mask is used to identify CPUs that fall in the same cluster.  CRs-fixed: 849655", "target": 1}
{"idx": 3265, "commit_message": "msm_fb: Set RR sched policy for Glupdator thread  Set Round Robin Scheduling policy for GLUpdator thread to improve performance.", "target": 1}
{"idx": 2968, "commit_message": "Add applyTransientDateFilter option to the map layer configs  If this settings is false (the default), then the map will not respond to the date-selected events that the timeline and line chart send out when the user mouses over dates. When it is true, the corresponding layer will only show data from the moused-over date. This can be useful, but it can also have a large performance hit.", "target": 1}
{"idx": 3134, "commit_message": "Optimized and commented the GGen_Data_2D::Noise function (profiler suggests 30-40% performance increase)", "target": 1}
{"idx": 3069, "commit_message": "sched: reinitialize rq->next_balance when a CPU is hot-added  Reinitialize rq->next_balance when a CPU is hot-added.  Otherwise, scheduler domain rebalancing may be skipped if rq->next_balance was set to a future time when the CPU was last active, and the newly-re-added CPU is in idle_balance().  As a result, the newly-re-added CPU will remain idle with no tasks scheduled until the softlockup watchdog runs - potentially 4 seconds later.  This can waste energy and reduce performance.  This behavior can be observed in some SoC kernels, which use CPU hotplug to dynamically remove and add CPUs in response to load.  In one case that triggered this behavior,  0. the system started with all cores enabled, running multi-threaded    CPU-bound code;  1. the system entered some single-threaded code;  2. a CPU went idle and was hot-removed;  3. the system started executing a multi-threaded CPU-bound task;  4. the CPU from event 2 was re-added, to respond to the load.  The time interval between events 2 and 4 was approximately 300 milliseconds.  Of course, ideally CPU hotplug would not be used in this manner, but this patch does appear to fix a real bug.  Nvidia folks: this patch is submitted as at least a partial fix for bug 1243368 (\"[sched] Load-balancing not happening correctly after cores brought online\")", "target": 1}
{"idx": 671, "commit_message": "Basic 5th order implementation - only partly optimized - very slow", "target": 1}
{"idx": 3901, "commit_message": "Move API redirect for jobsearch to the routes file  Doing the redirect further up will be more efficient and simplifies the RootController#jobsearch method", "target": 1}
{"idx": 661, "commit_message": "drm/nouveau/therm: namespace + nvidia gpu names (no binary change)  The namespace of NVKM is being changed to nvkm_ instead of nouveau_, which will be used for the DRM part of the driver.  This is being done in order to make it very clear as to what part of the driver a given symbol belongs to, and as a minor step towards splitting the DRM driver out to be able to stand on its own (for virt).  Because there's already a large amount of churn here anyway, this is as good a time as any to also switch to NVIDIA's device and chipset naming to ease collaboration with them.  A comparison of objdump disassemblies proves no code changes.", "target": 0}
{"idx": 1506, "commit_message": "Writing Pcapng files no longer holds a copy in memory also added access to flush for pcapng writing", "target": 0}
{"idx": 3124, "commit_message": "lib/sha1: use the git implementation of SHA-1  For ChromiumOS, we use SHA-1 to verify the integrity of the root filesystem.  The speed of the kernel sha-1 implementation has a major impact on our boot performance.  To improve boot performance, we investigated using the heavily optimized sha-1 implementation used in git.  With the git sha-1 implementation, we see a 11.7% improvement in boot time.  10 reboots, remove slowest/fastest.  Before:    Mean: 6.58 seconds Stdev: 0.14  After (with git sha-1, this patch):    Mean: 5.89 seconds Stdev: 0.07  The other cool thing about the git SHA-1 implementation is that it only needs 64 bytes of stack for the workspace while the original kernel implementation needed 320 bytes.", "target": 1}
{"idx": 3712, "commit_message": "Optimizing ForInObjectEnumerator overhead  The overhead for ForInObjectEnumerator can become significant if we enumerate a lot of object with small number of properties.  This change improves Sunspider by about 3.5ms (or 1.6%) and Speedometer by about 60ms (or 0.6%) on my machine. No change on Octane or Kraken.  1.  Allocate ForInObjectEnumerator on the stack instead of dynamically - Keep track of the maximum for..in loop depth at byte code generation. - Change the for..in byte code to InitForInEnumerator and BrOnEmpty to refer to the for..in loop depth - Allocate stack space for the ForInObjectEnumerator for interpreter and JIT'ed code. - When bailing out of JIT'ed code, the bailout interpreter frame will not allocate new stack space for the ForInObjectEnumerator, but instead reuse the space allocated on the JIT'ed frame. - When we are in JIT loop body, it also won't allocate new ForInObjectEnumerator. the loop body code will instead refer to the ForInObjectEnumerator allocated in the interpreter frame. - In JIT inlining, we need to keep track of inlinee for..in loop depth as well to allocate enough space for all of them.  2. Reduce the size of ForInObjectEnumerator - Remove scriptContext and flags fields in ForInObjectEnumerator by reusing the same fields in DynamicObjectPropertyEnumerator and always initializing those. - Move all the fields needed to keep track of properties shadowing in prototypes into a dynamically allocated structure.  We already needed to allocate the sparse bit vector before already, so this is not a new allocation, but it will minimize stack usage for cases that doesn't have enumerable properties on the prototype.  3. Add inline cache that maps the object type to DynamicObjectPropertyEnumerator::CacheData on InitForInEnumerator - The cache is pass to all GetEnumerator API to be given to DynamicObjectPropertyEnumerator to avoid the dictionary look up - Since we clear the type to cache data map on every GC, we also clear the inline cache on every GC as well.  4. Implemented JIT fast path for OP_InitForInEnumerator and improved JIT fast path for BrOnEmpty - Implemented the OP_InitForInEnumerator when we have an inline cache match, with a plain dynamic object, doesn't have enumerable property on the prototype and doesn't index properties (object array) - Instead of checking multiple conditions, initialize a single bool on ForInObjectEnumerator canUseJITFastPath to indicate whether we can use the fast path, that combines the check for no prefix/array enumerator, no enumerable property on the prototype and have cache data - Avoid going to the helper before we exit the loop by adding a loop exit check for whether the cache is complete at the end of the enumeration - If prototype doesn't have any enumerable property, we don't have to keep track of shadowing.  So just ask the object enumerator to return enumerable property only, so that the for in object enumerator and the jit fast path doesn't have to check whether the property is enumerable or not.  5. Minor cleanup - Delete JavascriptEnumeratorIterator, which is no longer used. - Refactor code in the backend to add loop in lower", "target": 1}
{"idx": 1496, "commit_message": "speedup merging of histograms with same axis limits", "target": 1}
{"idx": 3594, "commit_message": "improve performance of get project api", "target": 1}
{"idx": 1510, "commit_message": "removed random, except to use it once at initialization. Performance enhanced to 123,350 char/s!", "target": 1}
{"idx": 3430, "commit_message": "category path introduced + performance improvements", "target": 1}
{"idx": 1535, "commit_message": "cpuidle: Use wake_up_all_idle_cpus() to wake up all idle cpus  Currently kick_all_cpus_sync() or smp_call_function() can not break the polling idle cpu immediately.  Instead using wake_up_all_idle_cpus() which can wake up the polling idle cpu quickly is much more helpful for power.", "target": 1}
{"idx": 1151, "commit_message": "ipc ns: fix memory leak (idr)  We have apparently had a memory leak since 7ca7e564e049d8b350ec9d958ff25eaa24226352 \"ipc: store ipcs into IDRs\" in 2007.  The idr of which 3 exist for each ipc namespace is never freed.  This patch simply frees them when the ipcns is freed.  I don't believe any idr_remove() are done from rcu (and could therefore be delayed until after this idr_destroy()), so the patch should be safe.  Some quick testing showed no harm, and the memory leak fixed.  Caught by kmemleak.", "target": 0}
{"idx": 1636, "commit_message": "[CPUFREQ] Print out CPU name in debug info. Add template for Nehemiah.", "target": 0}
{"idx": 832, "commit_message": "Merge pull request #420 from jgranley/optimizer_clone  [ENH] Remove estimator cloning during PSO optimization", "target": 0}
{"idx": 2532, "commit_message": "Eliminated the grid-metric dimension memory macros.    Eliminated the macros that enabled the grid metrics to effectively be 1-D or scalars in some cases.  While this made the model more efficient in idealized configurations, it added greater complexity and was of no value in the more realistic configurations.  The files MOM_grid_macros.h and HOM_hor_visc.h were eliminated entirely, as they are no longer needed.  Answers are bitwise identical in all cases.", "target": 1}
{"idx": 3703, "commit_message": "Improved linphone_friend_list_parse_multipart_related_body performances by preventing parsing multiple times a multipart body", "target": 1}
{"idx": 1194, "commit_message": "add answers management, improve questions management", "target": 0}
{"idx": 3811, "commit_message": "ANIM performance improvements and a crash fix", "target": 1}
{"idx": 2916, "commit_message": "[APROF-52] Core: improve performance of tracked methods", "target": 1}
{"idx": 2744, "commit_message": "Importer mapping - v1 (#3677)  * Move importer to an inline-template, allows for translations and easier passing of data from laravel to vue.    * Pull the modal out into a dedicated partial, move importer to views/importer.    * Add document of CSV->importer mappings.  Reorganize some code.    Progress.    * Add header_row and first_row to imports table, and process upon uploading a file    * Use an expandable table row instead of a modal for import processing.  This should allow for field mapping interaction easier.    * Fix import processing after moving method.    * Frontend importer mapping improvements.    Invert display so we show found columns and allow users to select an  importer field to map to.  Also implement sample data based on first row  of csv.    * Update select2.  Maintain selected items properly.    * Backend support for importing.  Only works on the web importer currently.  Definitely needs testing and polish.    * We no longer use vue-modal plugin.    * Add a column to track field mappings to the imports table.    * Cleanup/rename methods+refactor    * Save field mappings and import type when attempting an import, and repopulate these values when returning to the page.    * Update debugbar to fix a bug in the debugbar code.    * Fix asset tag detection.    Also rename findMatch to be a bit clearer as to what it does.    Remove logging to file of imports for http imports because  it eats an incredible amouint of memory.    This commit also moves imports out of the hardware namespace and into  their own webcontroller and route prefix, remove dead code from  AssetController as a result.    * Dynamically limit options for select2 based on import type selected, and group them by item type.    * Add user importer.    Still need to implement emailing of passwords to new users, and probably  test a bit more.    This also bumps the memory limit for web imports up as well, I need to  profile memory usage here before too long.    * Query the db to find user matches rather than search the array.  Performance is much much better.    * Speed/memory improvements in importers.    Move to querying the db rather than maintaining an array for all  importers.  Also only store the id of items when we import, rather than  the full model.  It saves a decent amount of memory.    * Remove grouping of items in select2    With the values being set dynamically, the grouping is redundant.  It  also caused a regression with automatically guessing/matching field  names.  This is starting to get close.    * Remove debug line on every create.    * Switch migration to be text field instead of json field for compatibility with older mysql/mariadb    * Fix asset import regression matching email address.    * Rearrange travis order in attempt to fix null settings.    * Use auth::id instead of fetching it off the user.  Fixes a null object reference during seeding.", "target": 1}
{"idx": 3494, "commit_message": "block: Reserve only one queue tag for sync IO if only 3 tags are available  In case a device has three tags available we still reserve two of them for sync IO. That leaves only a single tag for async IO such as writeback from flusher thread which results in poor performance.  Allow async IO to consume two tags in case queue has three tag availabe to get a decent async write performance.  This patch improves streaming write performance on a machine with such disk from ~21 MB/s to ~52 MB/s. Also postmark throughput in presence of streaming writer improves from 8 to 12 transactions per second so sync IO doesn't seem to be harmed in presence of heavy async writer.", "target": 1}
{"idx": 2476, "commit_message": "Use zuul-cloner instead of git clone  Use zuul-cloner for more efficient cloning because it can take advantage of the local git cache on disk", "target": 1}
{"idx": 2293, "commit_message": "Roll DevTools Frontend from 2df80116cfa5 to 1d8133f7289f (4 revisions)  [URL]/devtools/devtools-frontend.git/+log/2df80116cfa5..1d8133f7289f  2021-08-04 [URL] [l10n] Add remaining locales 2021-08-04 [URL] [l10n] Enable localized DevTools experiment by default 2021-08-04 [URL] [DevTools Element Panel] Move 'cut' and 'paste' out of \"copy menu\" 2021-08-04 [URL] [CSS] panels/mobile_throttling, panels/performance_monitor,  If this roll has caused a breakage, revert this CL and stop the roller using the controls here: [URL]/r/devtools-frontend-chromium Please CC [URL] on the revert to ensure that a human is aware of the problem.  To report a problem with the AutoRoller itself, please file a bug: [URL]/p/skia/issues/entry?template=Autoroller+Bug  Documentation for the AutoRoller is here: [URL]/buildbot/+doc/main/autoroll/README.md  Bug: chromium:1106746,chromium:1163928 Tbr: [URL]", "target": 0}
{"idx": 3695, "commit_message": "Remove the SVG paint culling optimization  This patch removes the paint culling optimization added in [1] which is not as useful as it once was. We now use Skia which culls internally and the overhead of checking for culling in SVG makes this optimization a small loss in terms of performance on our microbenchmarks [2].  The primary change in this patch is to remove the updating and checking of PaintInfo.rect within the SVG painting code. For ForeignObject and Text, an adjustment of the PaintInfo rect is required to avoid clipping in the text painting code. This adjustment is implemented by caching the paint invalidation transform. For filters in SVG, this patch replaces the PaintInfo rect adjustment with an infinite rect.  [1] [URL]/changeset/52900 [2] http://pr.gg/svgperfresults.png  BUG=442008  Review URL: [URL]/802833003", "target": 0}
{"idx": 236, "commit_message": "chore: Rakefile improvements  - run init task before all other tasks - ensure a Logs/ directory exists in init and output all build logs there - redirect STDERR to STDOUT for all xcodebuild invocations, and fail the Rakefile task if the build fails - skip existing ruby installs with rbenv", "target": 0}
{"idx": 921, "commit_message": "client: Use g_malloc0 in get_filter_strs  Use g_malloc0 instead of g_try_malloc0 to allocate list. All users expects to get valid pointer from it anyway. Also size of allocated memory is small.", "target": 0}
{"idx": 141, "commit_message": "Merge branch 'for-linus' of [URL]/pub/scm/linux/kernel/git/roland/infiniband  * 'for-linus' of [URL]/pub/scm/linux/kernel/git/roland/infiniband: (46 commits)   IB/uverbs: Don't serialize with ib_uverbs_idr_mutex   IB/mthca: Make all device methods truly reentrant   IB/mthca: Fix memory leak on modify_qp error paths   IB/uverbs: Factor out common idr code   IB/uverbs: Don't decrement usecnt on error paths   IB/uverbs: Release lock on error path   IB/cm: Use address handle helpers   IB/sa: Add ib_init_ah_from_path()   IB: Add ib_init_ah_from_wc()   IB/ucm: Get rid of duplicate P_Key parameter   IB/srp: Factor out common request reset code   IB/srp: Support SRP rev. 10 targets   [SCSI] srp.h: Add I/O Class values   IB/fmr: Use device's max_map_map_per_fmr attribute in FMR pool.   IB/mthca: Fill in max_map_per_fmr device attribute   IB/ipath: Add client reregister event generation   IB/mthca: Add client reregister event generation   IB: Move struct port_info from ipath to <rdma/ib_smi.h>   IPoIB: Handle client reregister events   IB: Add client reregister event type   ...", "target": 0}
{"idx": 309, "commit_message": "platform/netlink: merge branch 'th/netlink' (#67)  [URL]/NetworkManager/NetworkManager/pull/67", "target": 0}
{"idx": 2574, "commit_message": "mm: compaction: detect when scanners meet in isolate_freepages  Compaction of a zone is finished when the migrate scanner (which begins at the zone's lowest pfn) meets the free page scanner (which begins at the zone's highest pfn).  This is detected in compact_zone() and in the case of direct compaction, the compact_blockskip_flush flag is set so that kswapd later resets the cached scanner pfn's, and a new compaction may again start at the zone's borders.  The meeting of the scanners can happen during either scanner's activity. However, it may currently fail to be detected when it occurs in the free page scanner, due to two problems.  First, isolate_freepages() keeps free_pfn at the highest block where it isolated pages from, for the purposes of not missing the pages that are returned back to allocator when migration fails.  Second, failing to isolate enough free pages due to scanners meeting results in -ENOMEM being returned by migrate_pages(), which makes compact_zone() bail out immediately without calling compact_finished() that would detect scanners meeting.  This failure to detect scanners meeting might result in repeated attempts at compaction of a zone that keep starting from the cached pfn's close to the meeting point, and quickly failing through the -ENOMEM path, without the cached pfns being reset, over and over.  This has been observed (through additional tracepoints) in the third phase of the mmtests stress-highalloc benchmark, where the allocator runs on an otherwise idle system.  The problem was observed in the DMA32 zone, which was used as a fallback to the preferred Normal zone, but on the 4GB system it was actually the largest zone.  The problem is even amplified for such fallback zone - the deferred compaction logic, which could (after being fixed by a previous patch) reset the cached scanner pfn's, is only applied to the preferred zone and not for the fallbacks.  The problem in the third phase of the benchmark was further amplified by commit 81c0a2bb515f (\"mm: page_alloc: fair zone allocator policy\") which resulted in a non-deterministic regression of the allocation success rate from ~85% to ~65%.  This occurs in about half of benchmark runs, making bisection problematic.  It is unlikely that the commit itself is buggy, but it should put more pressure on the DMA32 zone during phases 1 and 2, which may leave it more fragmented in phase 3 and expose the bugs that this patch fixes.  The fix is to make scanners meeting in isolate_freepage() stay that way, and to check in compact_zone() for scanners meeting when migrate_pages() returns -ENOMEM.  The result is that compact_finished() also detects scanners meeting and sets the compact_blockskip_flush flag to make kswapd reset the scanner pfn's.  The results in stress-highalloc benchmark show that the \"regression\" by commit 81c0a2bb515f in phase 3 no longer occurs, and phase 1 and 2 allocation success rates are also significantly improved.", "target": 0}
{"idx": 3403, "commit_message": "Allow use of raw images denoted by .raw extension  Allow downburst to use raw disk images instead of our normal compressed qcow2 images (for better performance).  The raw images are detected/set by their file-extension which is .raw instead of .img.", "target": 1}
{"idx": 3039, "commit_message": "Merge pull request #436 from skeeet/master  Another iOS-specific TyphoonClassFromString performance optimization", "target": 1}
{"idx": 3376, "commit_message": "fix 315545 (find_TTEntry_from_hcode): Assertion '(UChar*)sec->tt[tteNo].tcptr <= (UChar*)hcode' failed  Assertion    valgrind: m_transtab.c:674 (find_TTEntry_from_hcode):   Assertion '(UChar*)sec->tt[tteNo].tcptr <= (UChar*)hcode' failed. failure (encountered on some platforms while running gdbsrv tests).  The problem is related to invalidated entries and the host_extents mapping between hostcode and the translation table entry.  The problem: when an entry is invalidated, the translation table entry is changed to status Deleted. However, the host extent array element is not cleaned up. If a search for a host code address (find_TTEntry_from_hcode) finds this entry, the translation table entry in Deleted status is considered as a 'not found', which ensures that the invalidated entry is not used (e.g. for chaining). This is all ok.  However, it might be that this Deleted entry is re-used (see function VG_(add_to_transtab), searching for a Empty or Deleted entry. If the Deleted entry is re-used, then a search for the dead host code can give a result pointing to the re-used entry. That is clearly wrong. Note that it is unclear if this bug can only be triggered while using gdbsrv or if this bug can be triggered with just the \"normal\" invalidation logic of translation. gdbsrv being a heavy \"user\" of invalidation, it might be it helps to trigger the code. Alternatively, as gdbsrv invalidation is special (e.g. invalidation of some entries is done during translation of other entries), it might be the bug is specific to gdbsrv.  In any case, to avoid the bug: searching for an host code address must not only ignore Deleted entries, but must also ignore an entry found via a host_extent element which is for a Deleted entry that was re-used afterwards (pointed to by a newer host_extent element).   Multiple solutions are possible for fixing the bug: Sol1: cleanup the host_extents array when an entry is deleted.   The cleanup is however deemed costly:   Each invalidate operation must do a search in the host_extents.   The host_extents array must then be \"compacted\" to remove   the \"dead\" host extent element from the array.   The compact operation can be avoided if instead of removing   the element, one marks instead the element as \"dead\"   e.g. by using one bit of UInt len for that:      UInt len : 31;      Bool dead : 1;   This avoids the compact, but still incurrs the cost of   search and modify the host_extent for each entry invalidated.   Invalidating entries seems to be a critical operation   (e.g. specific ECLASS related  data structures have been    done to allow fast deletion).   => it is deemed that a solution not incurring cost during   invaliation is preferrable.  * Sol 2: detect in find_TTEntry_from_hcode   that the host_extent element is re-used, and handle it similarly   to an host_extents which points at a Deleted entry.   This detection is possible as if an entry is re-used after   having been deleted, this implies that its host code will be   after the end of the host code of the deleted entry   (as host code of a sector is not re-used).   The attached patch implements this solution.  * Sol 3: avoid re-using an entry : the entry would then stay   in Deleted state. This is deemed not ok as it would   imply that invalidation of entries will cause a sector to   become full faster.  The patch: * adds a new function   Bool HostExtent__is_dead (const HostExtent* hx, const Sector* sec)   telling if the host extent hx from sector sec is a dead entry. * this function is used in find_TTEntry_from_hcode so that   dead host extents are not resulting in host code to be found. * adds a regression test which caused the assert failure before   (bug was found/reported/isolated in a small test case by Dejan Jevtic). * To check the logic of HostExtent__is_dead, m_transtab.c sanity check is   completed to verify that the nr of entries in use in a sector is equal   to the nr of non dead entries in the host extent array. * adds/improves traces in m_transtab.c (enabled at compile   time using #define DEBUG_TRANSTAB).   Some already existing 'if (0)' conditions are replaced   by if (DEBUG_TRANSTAB)  Regression tested on     f12/x86    debian6/amd64 (also with export EXTRA_REGTEST_OPTS=--sanity-level=4)", "target": 0}
{"idx": 2229, "commit_message": "Allow to build P4 tools without debug flags to improve BMv2 performance  If the env variable DEBUG_FLAGS is set to false, build tools without debug features to improve throughput of BMv2 and reduce CPU/memory footprint.  Debug features include BMv2 logging, debugger, nanomsg, etc.  With DEBUG_FLAGS=true, when running 20 BMv2 instances, it requires 4 CPU cores 100%. With DEBUG_FLAGS=false, when running 50 BMv2 instances, overall CPU usage is only 1%.", "target": 1}
{"idx": 1350, "commit_message": "ipv6: call udp_push_pending_frames when uncorking a socket with AF_INET pending data  [ Upstream commit 8822b64a0fa64a5dd1dfcf837c5b0be83f8c05d1 ]  We accidentally call down to ip6_push_pending_frames when uncorking pending AF_INET data on a ipv6 socket. This results in the following splat (from Dave Jones):  skbuff: skb_under_panic: text:ffffffff816765f6 len:48 put:40 head:ffff88013deb6df0 data:ffff88013deb6dec tail:0x2c end:0xc0 dev:<NULL> ------------[ cut here ]------------ kernel BUG at net/core/skbuff.c:126! invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC Modules linked in: dccp_ipv4 dccp 8021q garp bridge stp dlci mpoa snd_seq_dummy sctp fuse hidp tun bnep nfnetlink scsi_transport_iscsi rfcomm can_raw can_bcm af_802154 appletalk caif_socket can caif ipt_ULOG x25 rose af_key pppoe pppox ipx phonet irda llc2 ppp_generic slhc p8023 psnap p8022 llc crc_ccitt atm bluetooth +netrom ax25 nfc rfkill rds af_rxrpc coretemp hwmon kvm_intel kvm crc32c_intel snd_hda_codec_realtek ghash_clmulni_intel microcode pcspkr snd_hda_codec_hdmi snd_hda_intel snd_hda_codec snd_hwdep usb_debug snd_seq snd_seq_device snd_pcm e1000e snd_page_alloc snd_timer ptp snd pps_core soundcore xfs libcrc32c CPU: 2 PID: 8095 Comm: trinity-child2 Not tainted 3.10.0-rc7+ #37 task: ffff8801f52c2520 ti: ffff8801e6430000 task.ti: ffff8801e6430000 RIP: 0010:[<ffffffff816e759c>]  [<ffffffff816e759c>] skb_panic+0x63/0x65 RSP: 0018:ffff8801e6431de8  EFLAGS: 00010282 RAX: 0000000000000086 RBX: ffff8802353d3cc0 RCX: 0000000000000006 RDX: 0000000000003b90 RSI: ffff8801f52c2ca0 RDI: ffff8801f52c2520 RBP: ffff8801e6431e08 R08: 0000000000000000 R09: 0000000000000000 R10: 0000000000000001 R11: 0000000000000001 R12: ffff88022ea0c800 R13: ffff88022ea0cdf8 R14: ffff8802353ecb40 R15: ffffffff81cc7800 FS:  00007f5720a10740(0000) GS:ffff880244c00000(0000) knlGS:0000000000000000 CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033 CR2: 0000000005862000 CR3: 000000022843c000 CR4: 00000000001407e0 DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000 DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000600 Stack:  ffff88013deb6dec 000000000000002c 00000000000000c0 ffffffff81a3f6e4  ffff8801e6431e18 ffffffff8159a9aa ffff8801e6431e90 ffffffff816765f6  ffffffff810b756b 0000000700000002 ffff8801e6431e40 0000fea9292aa8c0 Call Trace:  [<ffffffff8159a9aa>] skb_push+0x3a/0x40  [<ffffffff816765f6>] ip6_push_pending_frames+0x1f6/0x4d0  [<ffffffff810b756b>] ? mark_held_locks+0xbb/0x140  [<ffffffff81694919>] udp_v6_push_pending_frames+0x2b9/0x3d0  [<ffffffff81694660>] ? udplite_getfrag+0x20/0x20  [<ffffffff8162092a>] udp_lib_setsockopt+0x1aa/0x1f0  [<ffffffff811cc5e7>] ? fget_light+0x387/0x4f0  [<ffffffff816958a4>] udpv6_setsockopt+0x34/0x40  [<ffffffff815949f4>] sock_common_setsockopt+0x14/0x20  [<ffffffff81593c31>] SyS_setsockopt+0x71/0xd0  [<ffffffff816f5d54>] tracesys+0xdd/0xe2 Code: 00 00 48 89 44 24 10 8b 87 d8 00 00 00 48 89 44 24 08 48 8b 87 e8 00 00 00 48 c7 c7 c0 04 aa 81 48 89 04 24 31 c0 e8 e1 7e ff ff <0f> 0b 55 48 89 e5 0f 0b 55 48 89 e5 0f 0b 55 48 89 e5 0f 0b 55 RIP  [<ffffffff816e759c>] skb_panic+0x63/0x65  RSP <ffff8801e6431de8>  This patch adds a check if the pending data is of address family AF_INET and directly calls udp_push_ending_frames from udp_v6_push_pending_frames if that is the case.  This bug was found by Dave Jones with trinity.  (Also move the initialization of fl6 below the AF_INET check, even if not strictly necessary.)", "target": 0}
{"idx": 635, "commit_message": "Merge Bug#47991 fix from mysql-5.1-innodb    ------------------------------------------------------------   revno: 3517   revision-id: [URL]-20100622163043-dc0lxy0byg74viet   parent: [URL]-20100621095148-8g73k8k68dpj080u   committer: Vasil Dimov [URL]>   branch nick: mysql-5.1-innodb   timestamp: Tue 2010-06-22 19:30:43 +0300   message:     Fix Bug#47991 InnoDB Dictionary Cache memory usage increases indefinitely     when renaming tables          Allocate the table name using ut_malloc() instead of table->heap because     the latter cannot be freed.          Adjust dict_sys->size calculations all over the code.          Change dict_table_t::name from const char* to char* because we need to     ut_malloc()/ut_free() it.          Reviewed by:\tInaam, Marko, Heikki (rb://384)     Approved by:\tHeikki (rb://384)   ------------------------------------------------------------", "target": 0}
{"idx": 3255, "commit_message": "dpdk-cryptodev: scalable session count  Originally cryptodev allocates mempools for seesion and session private data during its initialization. Moreover the size of these mempools are fixed resulting in limited session count (up to value specified in CRYPTODEV_NB_SESSION macro).  This patch allows for session count to scale up by allocating new mempools as they are needed during session creation.  Type: improvement", "target": 1}
{"idx": 486, "commit_message": "Zooming / Panning enhancements, Simulation reheating and boundary removal, and dynamic Filter menu  - New Feature: Removed boundaries from Force Simulation (controlled via const isContrained). Nodes now may drift out of the view boundaries during the Force Simulation, even with the default zoom level. However, you can pan and/or zoom out, to get access to any Nodes that have drifted out of view. - New Feature: Added an extra level of zoom out from the default level. In other words, from the default zoom level, you can zoom out one further step (or zoom in the same as before). - New Feature: Restart no longer resets zooming to default level. So now if you zoom in or out, then Restart, the Force Simulation will replay at your current zoom level. - New Feature: If you click on Play, without first clicking on Pause, additional \"heat\" will be added to the Force Simulation. - New Feature: Right-click 'Recenter Panning' and 'Pan (Node) to center' commands. The latter menu option appears when you right-click on a Node, else you get the former menu option if you right-click anywhere else. - New Feature: Enabled zooming by mouse wheel. This type of zooming is relative to the position of your mouse cursor. Can also double-click in client area to zoom in. - New Feature: Filter types in the 'Filter On Selection' dropdown menu are now generated dynamically by parsing them from the data. These were previously hard- coded and therefore did not match the actual Nodes and Links in the AtomSpace data.", "target": 0}
{"idx": 2666, "commit_message": "6611830: UUID thread-safety and performance improvements", "target": 1}
{"idx": 3898, "commit_message": "Merge pull request #371 from svaarala/perf-rework-debugger-skip-interrupt  Fix debugger \"lockout\" in interrupt handling for better performance", "target": 1}
{"idx": 2090, "commit_message": "DFG should handle polymorphic array modes by eagerly transforming arrays into the most general applicable form [URL]/show_bug.cgi?id=99269  Reviewed by Geoffrey Garen.  This kills off a bunch of code for \"polymorphic\" array modes in the DFG. It should also be a performance win for code that uses a lot of array storage arrays.  * dfg/DFGAbstractState.cpp: (JSC::DFG::AbstractState::execute): * dfg/DFGArrayMode.cpp: (JSC::DFG::fromObserved): (JSC::DFG::modeAlreadyChecked): (JSC::DFG::modeToString): * dfg/DFGArrayMode.h: (DFG): (JSC::DFG::modeUsesButterfly): (JSC::DFG::modeIsJSArray): (JSC::DFG::mayStoreToTail): (JSC::DFG::mayStoreToHole): (JSC::DFG::canCSEStorage): (JSC::DFG::modeSupportsLength): (JSC::DFG::benefitsFromStructureCheck): * dfg/DFGFixupPhase.cpp: (JSC::DFG::FixupPhase::checkArray): (JSC::DFG::FixupPhase::blessArrayOperation): * dfg/DFGGraph.h: (JSC::DFG::Graph::byValIsPure): * dfg/DFGSpeculativeJIT.cpp: (JSC::DFG::SpeculativeJIT::jumpSlowForUnwantedArrayMode): (JSC::DFG::SpeculativeJIT::checkArray): (JSC::DFG::SpeculativeJIT::arrayify): (DFG): (JSC::DFG::SpeculativeJIT::compileGetArrayLength): * dfg/DFGSpeculativeJIT.h: (JSC::DFG::SpeculativeJIT::putByValWillNeedExtraRegister): (SpeculativeJIT): * dfg/DFGSpeculativeJIT32_64.cpp: (JSC::DFG::SpeculativeJIT::compile): * dfg/DFGSpeculativeJIT64.cpp: (JSC::DFG::SpeculativeJIT::compile):", "target": 1}
{"idx": 3315, "commit_message": "lib: introduce some memory copy macros and functions  the kernel's memcpy and memmove is very inefficient. But the glibc version is quite fast, in some cases it is 10 times faster than the kernel version. So I introduce some memory copy macros and functions of the glibc to improve the kernel version's performance.  The strategy of the memory functions is: 1. Copy bytes until the destination pointer is aligned. 2. Copy words in unrolled loops.  If the source and destination are not aligned    in the same way, use word memory operations, but shift and merge two read    words before writing. 3. Copy the few remaining bytes.", "target": 1}
{"idx": 3607, "commit_message": "Removed the keydispatcher.  I'm now sending almost all key events to the top widget itself (except the button). The button needs to be improved, so it's easier to distinguis if it's clicked what to do. I tried a signal connect, but can't stop the event loop in the view. That somehow needs a better solution.", "target": 0}
{"idx": 2332, "commit_message": "remove global find refs and renaming  Summary: global find refs (`textDocument/references` and `flow find-refs --global`) has been in \"beta\" for years. sometimes it works, sometimes it takes a super long time, sometimes it crashes the server (e.g. using the workers when the workers are already busy). similar for `textDocument/rename`, which is powered by the same code.  we don't have the bandwidth to improve this -- or even maintain it, really -- so we're removing it for the time being. we do recognize that this is an important feature, and will bring it back as soon as we can.  since we're no longer advertising the `referencesProvider` or `renameProvider` LSP capabilities, this shouldn't be a \"breaking\" change, per se, when using the LSP. `flow find-refs --global` is now an error.  Changelog: [feat?] Support for finding references and renaming has been removed. While these features often worked well, they also caused extremely bad performance and crashes. We hope to reimplement these features as soon as we can.  Reviewed By: vrama628  Differential Revision: D31829851  fbshipit-source-id: ce5e8bd2289b9f735a9d206d9cfac189bd4a07d7", "target": 0}
{"idx": 4122, "commit_message": "[PATCH] Use more efficient iterators in MeshCommunication", "target": 1}
{"idx": 2162, "commit_message": "include rb-fsevent in gemfile  if I don't have gem 'rb-fsevent', '~> 0.9' in my gemfile I get this warning:    Listen warning]:    Missing dependency 'rb-fsevent' (version '~> 0.9')!    Please add the following to your Gemfile to satisfy the dependency:      gem 'rb-fsevent', '~> 0.9'      For a better performance, it's recommended that you satisfy the missing dependency.    Listen will be polling changes. Learn more at [URL]/guard/listen#polling-fallback.      not sure why so I suggest it gets added in or at least documented", "target": 1}
{"idx": 1570, "commit_message": "Trove create with --backup fails for postgresql  Here are the steps to reproduce: 1. Create a postgresql instance:  trove create postgresql_instance 100 --datastore postgresql --datastore_version 9.3 --size 1 --databases db1 --users user1:password1  2. Verify it is ACTIVE:  trove list  3. Create a backup of this new instance:  trove backup-create <id> postgresql_instance-backup --description postgresql_instance-description  4. Verify backup is complete:  trove backup-list  5. Create a new instance, using this backup instance:  trove create postgresql_instance-restored 100 --datastore postgresql --datastore_version 9.3 --size 1 --backup <backup_id>  Here are the problems: 1. postgresql doesn't migrate the data, when backup_info is passed in. 2. postgresql outputs few benign messages into the stderr stream during a normal restore procedure.  Here is the solution: 1. make sure that the postgresql manager always migrates the data by not skipping the that step when recreating an instance from backup in 'guestagent/datastore/postgresql/manager.py'. 2. watch for the expected error messages in the stderr stream and avoid raising an exception in response. Message 'ERROR:  role \"postgres\" already exists' is expected and does not pose any problems to the restore operation. We override the default error handling behavior in 'guestagent/strategies/restore/postgresql_impl.py'.  UPDATES: - Applied suggested style improvements. - Use message whitelist rather than sequence. - Match messages by regex.", "target": 0}
{"idx": 2314, "commit_message": "Add getLengthSq()  Which can be used in some cases for better performance because we don't need to calculate the square root.", "target": 1}
{"idx": 3012, "commit_message": "Switch index requests to updates with docAsUpsert  Switch all index statements to updates with docAsUpsert to make sure we don't throw out any fields maintained outside the normal index mechanism like local_sites_with_dupe.  This should be safe because the merging mechanism that docAsUpsert uses sits well with us because it won't try to merge lists.  Wonderful!  This does cost some performance on the Elasticsearch side but we're not really hurting there.  Bug: 58508", "target": 0}
{"idx": 2212, "commit_message": "workqueue: Replace pool->attach_mutex with global wq_pool_attach_mutex  To improve workqueue visibility, we want to be able to access workqueue information from worker tasks.  The per-pool attach mutex makes that difficult because there's no way of stabilizing task -> worker pool association without knowing the pool first.  Worker attach/detach is a slow path and there's no need for different pools to be able to perform them concurrently.  This patch replaces the per-pool attach_mutex with global wq_pool_attach_mutex to prepare for visibility improvement changes.", "target": 1}
{"idx": 3160, "commit_message": "Add comment referencing Chrome performance bug for Array.splice.", "target": 0}
{"idx": 1085, "commit_message": "Merge pull request #62 from pilch-cit/minor_fixes  Minor fixes and additions for storages and cpu", "target": 0}
{"idx": 1043, "commit_message": "Update README.md with   Ran a Grammarly scan to check for spelling & grammar to improve readability.  Added Chessable to list of sites who are using this awesome library.", "target": 0}
{"idx": 1452, "commit_message": "rot0x1a-common: Added extra byte for null terminator in loadHexStringToMemory and result of xorDataBlocks. xorDataBlocks no longer loops twice as long as intended.", "target": 0}
{"idx": 2136, "commit_message": "perf script: Enable printing of branch stack  This patch improves perf script by enabling printing of the branch stack via the 'brstack' and 'brstacksym' arguments to the field selection option -F. The option is off by default and operates only if the perf.data file has branch stack content.  The branches are printed in to/from pairs. The most recent branch is printed first. The number of branch entries vary based on the underlying hardware and filtering used.  The brstack prints FROM/TO addresses in raw hexadecimal format. The brstacksym prints FROM/TO addresses in symbolic form wherever possible.   $ perf script -F ip,brstack   5d3000 0x401aa0/0x5d2000/M/-/-/-/0 ...   $ perf script -F ip,brstacksym   4011e0 noploop+0x0/noploop+0x0/P/-/-/0  The notation F/T/M/X/A/C describes the attributes of the branch. F=from, T=to, M/P=misprediction/prediction, X=TSX, A=TSX abort, C=cycles (SKL)", "target": 0}
{"idx": 3400, "commit_message": "Optimization (performance regression fix): Use bigger buffer for server reads.  Change the server read buffer limits to 16KB minimum and 256KB maximum. Used to be: 2KB and 2GB. And before r9766: 4KB and SQUID_TCP_SO_RCVBUF.  Trunk r9766 (Remove limit on HTTP headers read) made the default HTTP server read buffer size 2KB instead of 4KB, visibly slowing down Squid when kernel network buffers are full and can sustain larger Squid reads. Doing up to twice as many network reads is expensive (and probably not just because of the extra system call overheads).  We never grow that buffer size if the _parser_ does not need a bigger buffer:  Even if the HTTP client is slower than the server, the buffer stays small because it gives all the data to Store and Store eventually just stalls reading via delayAwareRead() and read_ahead_gap. The situation may be different with RESPMOD, but if the adaptation service is fast, the buffer would still not grow.  This change does not reset the minimum buffer size to the old 4KB default because memory is much cheaper compared to the days where that default was set. 8KB may have worked too, but with 12KB median typical response size a larger buffer may be a good idea for a busy Squid. More performance work is needed to find the optimal value (which could depend on the environment).  This change does not set the maximum buffer size to the current 2GB limit because we have not tested how header and chunking parsers would cope with malicious messages trying to run Squid out of RAM; and also because no good parser should need that much lookahead space. Is 256KB enough for all legitimate real-world response headers? We do not know.  It is tempting to use Config.tcpRcvBufsz or SQUID_TCP_SO_RCVBUF to find the right minimum or maximum buffer size, but those parameters deal with low-level TCP buffering aspects while this buffer deals with HTTP parsing.", "target": 1}
{"idx": 2035, "commit_message": "Fix a potential performance problem in placing ARM constant pools. In the case where there are no good places to put constants and we fall back upon inserting unconditional branches to make new blocks, allow all constant pool references in range of those blocks to put constants there, even if that means resetting the \"high water marks\" for those references.  This will still terminate because you can't keep splitting blocks forever, and in the bad cases where we have to split blocks, it is important to avoid splitting more than necessary.", "target": 1}
{"idx": 3085, "commit_message": "* src/SDCCast.c (decorateType): fix promotion of unary minus * src/SDCCsymt.c (computeType): beautified * src/SDCCval.c (cheapestVal): beautified, old non-Ansi version removed, (valUnaryPM, valComplement, valNot): fix sign and promotion * support/regression/tests/uminus.c: speedup by removing superflous test case 'int' * support/regression/tests/onebyte.c: added promotion and signedness tests for unary minus * support/regressions/tests/bug-477927.c: disable warning about uninitialized variables", "target": 0}
{"idx": 2254, "commit_message": "[FW][MERGE] portal, *: portal performance improvements  * portal, `*`: Avoid the `search_count`'s of the portal homepage in other portal pages (/my/*) Main performance gain, gains up to 50% of a portal page queries (depending on the modules installed, and the given page). * portal: Improved template to reduce queries   * multiple queries avoided for the `can_edit_vat` check (on `/my/account` page, if `sale`/`account` installed). * *: do not compute archive_groups if not shown to the user (1 read_group call gained by concerned portal subpage)  closes odoo/odoo#55228  Forward-port-of: odoo/odoo#55199 Forward-port-of: odoo/odoo#52983 Related: odoo/enterprise#12126", "target": 1}
{"idx": 2831, "commit_message": "Some performance improvements to getting values from properties (I don't know why I ever though DynamicInvoke was a good idea)", "target": 1}
{"idx": 151, "commit_message": "Merge pull request #8 from brianloveswords/error-handling  Improve error handling.", "target": 0}
{"idx": 163, "commit_message": "Header Elevation (#2876)  * Added Elevation    * added test    * improved    * Improved    * Docs    * Update Header.tsx    * Update Header.tsx", "target": 0}
{"idx": 2949, "commit_message": "Multisite: Improve performance by caching not found lookups for sites and networks.  With this change, the result of a site or network lookup by ID will be cached even if the ID does not exist. When a new site or network is created, the cache for the respective new ID is cleared.  Props mnelson4, nielsdeblaauw. Fixes #42251.  Built from [URL]/", "target": 1}
{"idx": 3458, "commit_message": "Case 8332: Improved TsfGetForeignPaths to provide paramaterized paths for _id and _entity_id based queries with low cost estimates, resulting it planner often choosing Nested Loop based joins, generally improving join query performance.  - Optimized paramaterized _id by not resetting iterator when param changes by re-evaluating new param in TsfReScanForeignScan", "target": 1}
{"idx": 3847, "commit_message": "Change 20090326-bargull-IHD by   on 2009-03-26 11:52:18     in /home/Admin/src/svn/openlaszlo/trunk     for [URL]/openlaszlo/trunk  Summary: remove constructWithArgs()  New Features:  Bugs Fixed: LPP-7905 (Noticable performance differences between OL 4.0.x and 4.2.x) (partial)  Technical Reviewer: ptw QA Reviewer: max Doc Reviewer: (pending)  Documentation:  Release Notes:  Details: This removes another (most times) unnecessary function-call. constructWithArgs() was only used in LzReplicationManager and LaszloLayout as a callback after __LZapplyArgs() has been called, so after the arguments were installed.         Tests:", "target": 1}
{"idx": 2122, "commit_message": "sh: maple: Support block reads and writes.  This patch updates the maple bus to support asynchronous block reads and writes as well as generally improving the quality of the code and supporting concurrency (all needed to support the Dreamcast visual memory unit - a driver will also be posted for that).  Changes in the bus driver necessitate some changes in the two maple bus input drivers that are currently in mainline.  As well as supporting block reads and writes this code clean up removes some poor handling of locks, uses an atomic status variable to serialise access to devices and more robusly handles the general performance problems of the bus.", "target": 1}
{"idx": 4036, "commit_message": "[PATCH] Improve performance of GEMM for small matrices when SMP is\n defined.\n\nAlways checking num_cpu_avail() regardless of whether threading will actually\nbe used adds noticeable overhead for small matrices.  Most other uses of\nnum_cpu_avail() do so only if threading will be used, so do the same here.", "target": 1}
{"idx": 2779, "commit_message": "*REQUIRES SOLR schema.xml update based on solr-31_schema.xml* - Added sek_lookup_function search key values to solr so they don't have to be looked up after a page load to improve performance (still to be disabled after this) - Added sherpa/romeo data, admin internal notes to solr - Changed the cleaning of pdf content to happen during cache time, rather than reading from cache - requires a single sql UPDATE clean once off of existing data though - to be added to an SQL upgrade.. - reformatted class.fulltext_index_solr_csv.php indentation via phpstorm autoformat *still to do: add ERA 2010/2012 matched journal and conference lookups* - relates to story [URL]/story/show/49725977 #bing dog look up", "target": 1}
{"idx": 3967, "commit_message": "Merge \"Improve the performance of TimeZone.getTimeZone.\" into dalvik-dev", "target": 1}
{"idx": 2596, "commit_message": "Change in_tag_browser generation to not build the list of books if the tag browser categories haven't been restricted by 'find'. As the comment in the code says, this will improve performance while making in_tag_browser:true fail in extremely rare cases.", "target": 1}
{"idx": 3519, "commit_message": "On Fri, 07 Sep 2001 01:34:46 -0400, Tom Lane wrote: >there is still an unpatched reference to pg_description in >getColumns(), in both jdbc1 and jdbc2.  This was introduced by Jeroen's patch (see [URL]/db/mw/msg.html?mid=1032468). Attached is a patch that returns getColumns() to using \"select obj_description()\" instead of direct access to pg_description, as per the request by Tom.  I've incorporated Jeroen's fix to left outer join with pg_attrdef instead of inner join, so getColumns() also returns columns without a default value.  I have, however, not included Jeroen's attempt to combine multiple queries into one huge multi-join query for better performance, because: 1) I don't know how to do that using obj_description() instead of direct access to pg_description 2) I don't think a performance improvement (if any) in this method is very important  Because of the outer join, getColumns() will only work with a backend >= 7.1. Since the conditional coding for 7.1/7.2 and jdbc1/jdbc2 is already giving me headaches I didn't pursue a pre-7.1 solution.  Regards, Ren? Pijlman < >", "target": 0}
{"idx": 3033, "commit_message": "[Analysis] add isSplatValue() for vectors in IR  We have the related getSplatValue() already in IR (see code just above the proposed addition). But sometimes we only need to know that the value is a splat rather than capture the splatted scalar value. Also, we have an isSplatValue() function already in SDAG.  Motivation - recent bugs that would potentially benefit from improved splat analysis in IR: [URL]/show_bug.cgi?id=37428 [URL]/show_bug.cgi?id=42174  Differential Revision: [URL]/D63138", "target": 0}
{"idx": 1650, "commit_message": "Workaround some bugs that cause assertion failures  Estimated hours taken: 0 Branches: main  browser/Mercury.options: \tWorkaround some bugs that cause assertion failures \tin the browser directory when compiling with -O5 \t--intermodule-optimization --opt-space.", "target": 0}
{"idx": 2581, "commit_message": "ASRC-260: lazy-init procedure select table  This improves performance slightly on modern browsers but drastically on IE8.", "target": 1}
{"idx": 503, "commit_message": "Improve math/linalg to support both f32 and f64 basic procedures for the specific*.odin files", "target": 0}
{"idx": 4028, "commit_message": "[PATCH] LJ combination rule kernels for OpenCL\n\nThe current implementation enables combination rules for both AMD and\nNVIDIA OpenCL (also ports the changes to the \"nowarp\" test/CPU kernel).\n\nLike in the CUDA implementation, all kernels support it, but only for\nplain cut-off are combination rules used.\n\nNotes:\n- On AMD tested on Hawaii, Fiji, Spectre and Oland devices;\n  combination rules in all cases improve performance, although combined\n  with the i-prefetching, the improvement is typically only ~10%.\n- On NVIDIA tested on Kepler and Maxwell; in most cases the combination\n  rule kernels are fastest.\n  However, with certain inputs these kernels are 25% slower on Maxwell\n  (e.g. pure water box, cut-off LJ, pot shift), but not on Kepler.\n  This is likely a compiler mis-optimization, so we'll just leave the\n  defaults the same as AMD.\n\nChange-Id: I05396e000cdf93c1d872729e6b477192af152495", "target": 1}
{"idx": 2284, "commit_message": "Added performance guidelines  Fixes gitlab-org/gitlab-ce#15254 gitlab-org/gitlab-ce#14277  [ci skip]", "target": 0}
{"idx": 2297, "commit_message": "Merge pull request #174 from nlharris/patch-12  improved app name & description", "target": 0}
{"idx": 1531, "commit_message": "updated code for getting interacting molecular pairs and their weights", "target": 0}
{"idx": 2897, "commit_message": "Improve pyghmi performance  The session.py uses lists and struct liberally.  We can be clearer and more efficient by just working with bytearrays instead, which are better fit for this purpose.", "target": 1}
{"idx": 2335, "commit_message": "Use wgxpath instead of jQuery XPath for smaller file size and better performance", "target": 1}
{"idx": 3807, "commit_message": "mutation_reader_merger: drop unneded readers in small batches  It was observed that destroying readers as soon as they are not needed negatively affects performance of relatively small reads. We don't want to keep them alive for too long either, since they may own a lot of memory, but deferring the destruction slightly and removing them in batches of 4 seems to solve the problem for the small reads.", "target": 1}
{"idx": 1363, "commit_message": "improve the inferencer's startup, and add a progress indicator.", "target": 0}
{"idx": 1933, "commit_message": "(tck) optimizing the idea of a batch of tickets, when there is only one ticket, a simple ticket is printed out refs #1868", "target": 1}
{"idx": 99, "commit_message": "Merge pull request #234 from OCSInventory-NG/updateipdiscover  Add TAG to link ipdiscover networks", "target": 0}
{"idx": 1846, "commit_message": "[Druid] Minor Feral APL (incarnation improvement) and regenerate profiles.", "target": 0}
{"idx": 3059, "commit_message": "Merged changes in jab branch: * Started porting TVB implementation for CUDA (currently disabled) * Updated csdecode:   - Renamed single-block flag as known-ends   - Added frame count parameter   - Modified stream receiver to pad short frames where possible * Changed mechanism for simulating stream systems:   - Instead of keeping prev, this, and next frames, keep indefinite stream   - Removes the possibility of program failure in cases of global desync * Added creation of stream sims with reset * Added support for non-binary IDS codes (on CPU version only):   - Added q-ary IDS channel   - Added TVB codes as a generalization of dminner2; highlights:     + Separate from dminner, re-implementing any necessary methods     + Templatized with respect to channel symbol type     + Has its own receiver, also templatized wrt channel symbol type     + Uses arrays of channel symbol type instead of bitfields     + Depends on qids channel rather than bsid     + Supports random codebooks (only restriction is unique codewords)     + Supports random sequencing of codebooks and marker vectors     + Sparse codebook generation not supported on non-binary types     + Internally, encoding uses a per-frame encoding table     + File format is not backward-compatible with dminner2;       old 'user' codebook is obtainable through 'tvb',       old 'alt-symbol' marker is obtainable through 'mod-vec',       nomenclature has changed   - Templatized fba2 wrt receiver object type     (allows use with different encodings and channels)   - Added implementations of above for all defined field sizes   - Created intermediate base for stream-oriented channels; methods that     assumed bsid now use this intermediate base * Changed type of return value in dminner2 receiver definition;   conersion now done internally * Changed gf stream input to stop after the fixed number of characters   (allows reading multiple consecutive elements without whitespace) * Added template method to allow setting indirect vectors with specific value * Fixes to logrealfast:   - Bailout on invalid values (negative and NaN)   - Changed handling of debug output for extreme range (0 and +Inf)   - Changed handling of log-domain infinity   - Added check for internal infinity in stream output   - Changed handling of 0 and +Inf values   - Fixed loading from stream * Fixes to make build:   - Added setting to delete targets on error and disable default suffix rules   - Added unrolling for libs target   - Added validation of release value   - Joined targets for all   - Added clean-dep target * Changes to facilitate debugging   - Changed masterslave::enable(), to return when slave dies gracefully   - Destroying heap objects at program end (facilitates checks for leaks)   - Added copy assignment for random to keep track of assignment   - Added tracking for copy construction for random (depend on DEBUG level) * Bug fixes:   - Fixed regression causing incorrect creation of sparse tables   - Fixed list runaway problem with timers that were never collected   - Fixes to allow compilation on VS 2008 and gcc 4.1 * Updates to CUDA-specific build:   - Using CUDA assert on supported devices   - Changed handling of warning-disable due to change in CUDA 4.1 * Other minor refactorings and documentation updates", "target": 0}
{"idx": 1421, "commit_message": "Make the content of the drawer dynamic as per the nav and logo components", "target": 0}
{"idx": 2491, "commit_message": "Merge tag 'ext4_for_linus' of [URL]/pub/scm/linux/kernel/git/tytso/ext4  Pull ext4 updates from Ted Ts'o:  \"Improvements to ext4's block allocator performance for very large file   systems, especially when the file system or files which are highly   fragmented. There is a new mount option, prefetch_block_bitmaps which   will pull in the block bitmaps and set up the in-memory buddy bitmaps   when the file system is initially mounted.    Beyond that, a lot of bug fixes and cleanups. In particular, a number   of changes to make ext4 more robust in the face of write errors or   file system corruptions\"  * tag 'ext4_for_linus' of [URL]/pub/scm/linux/kernel/git/tytso/ext4: (46 commits)   ext4: limit the length of per-inode prealloc list   ext4: reorganize if statement of ext4_mb_release_context()   ext4: add mb_debug logging when there are lost chunks   ext4: Fix comment typo \"the the\".   jbd2: clean up checksum verification in do_one_pass()   ext4: change to use fallthrough macro   ext4: remove unused parameter of ext4_generic_delete_entry function   mballoc: replace seq_printf with seq_puts   ext4: optimize the implementation of ext4_mb_good_group()   ext4: delete invalid comments near ext4_mb_check_limits()   ext4: fix typos in ext4_mb_regular_allocator() comment   ext4: fix checking of directory entry validity for inline directories   fs: prevent BUG_ON in submit_bh_wbc()   ext4: correctly restore system zone info when remount fails   ext4: handle add_system_zone() failure in ext4_setup_system_zone()   ext4: fold ext4_data_block_valid_rcu() into the caller   ext4: check journal inode extents more carefully   ext4: don't allow overlapping system zones   ext4: handle error of ext4_setup_system_zone() on remount   ext4: delete the invalid BUGON in ext4_mb_load_buddy_gfp()   ...", "target": 1}
{"idx": 1042, "commit_message": "x11: use KlausT optimisation (+20 KHs)  But use a define in AES to use or not device initial memcpy  I already tried to use everywhere direct device constants and its not faster for big arrays (difference is small)  also change launch bounds to reduce spills (72 regs)  to check on windows too, could improve the perf... or not", "target": 1}
{"idx": 2626, "commit_message": "Merge branch 'dev/gui-enhancements' into dev/gui-enhancements-update  * dev/gui-enhancements: (41 commits)   Update GUI user manual   Add image options   Add projected-to-ground image in world view   Remove default translucency of trails   Update user manual   Add method to get camera projection matrix   Move image loading to MainWindow   Fix performance updating tracks   Fix landmark initial visibility   Use simple get object method in place of vtkGetObjectMacro   Don't leak \"internal\" objects   Add option to toggle perspective   Add more view rotation presets   Make links in about dialog clickable   Fix rich text generation in about dialog   Add basic description text to about dialog   Fix minor error in README   Implement simple markdown parsing for About dialog   Disable lighting of ground plane grid   Add option for historic-only trails   ...  Conflicts:         gui/CameraView.cxx", "target": 0}
{"idx": 2265, "commit_message": "Replace content of branch 'master' with 'lifetimes'.  'lifetimes' is where the development's been happening for some time, and not that close to the original idea that yielded the name 'lifetimes'.  Thus we really need to just call it 'master' and use a 'master-old' branch to point to where master used to be.  * lifetimes:   Targets will need to init themselves; that means no statics.   cargo update   Better abstract parent scopes.  Enable target as a root scope.   More work to abstract scope parentage.  Not done yet.   impl Lookup for Target   Reparent mod context to aex.  Add an idea of its contents.   Cleanup   Ideas for functions on trait Target.   Move dispatch code to its own submodule.   Cosmetic   An idea for later.   Values for test target.   Test target   Require access to target via its trait object.   Ability to get the target for a given value.   Simplify visibility of target module items.   Use CfValue in Value   Constness info for Value; remove Const trait.   Cosmetic   Minor cleanup   Brackets, parens, braces.   Re-enable keyword test.   Refactor   Cosmetic   Support for escapes in character and string literals.   String and character literals (no escapes yet).   More error actions.   Re-enable tests that depended on number literals: space and EOS.   Number literals.   Add some error actions.   Identifier support.   Banish warnings.   Second test passing (though partial due to missing int literals).   Get first test passing.   Constructor for temporary Compiler stub.   Enable construction of File with just name and data strings.   WIP: Get Lexer to work with TokenBuilder.   Calculate token length.   Uncomment some Token variants.   Reimplement constructor. Factor keyword mapping to a function.   Add macro to simulate HashMap literals.   Extract Token and lexer context (now TokenBuilder) into their own module.   Use Source and friends from their new module.   Cosmetic; remove old commented-out code.   WIP: new ideas for representing operators.   Comment out enough lexer until it builds again.   Cosmetic   Update dependencies   Factor out common subexpressions from tests.   AsRef for Source to access file text.   Tests.  Improve Source/File/Pos debug output.   Add Pos tests from pos module.   Integrate File with Pos/Source   Add a File type to represent an input file.   WIP get lexer working again with rest of the code.   Format operator precedence chart and add descriptions.   cargo update   Current ideas for operators and their precedence   Implement labels and uninitialized data declarations.   TypeInfo::size_bytes   Allow unsized parameters.  Formatting.   Cosmetic   Expand AST using the newer pattern.   Create Generator type with some stubbed fns.   Blocks have subscopes   Implement cg_block   Make macros in util visible to rest of project.   Add macro to make Results from bools.   Clean up CG stub.   Cleanup cruft in output, asm, message modules.   Re-enable modules: asm, message, output, cg (was codegen).  Stub CG.   Resolve struct, union, and func.   On second thought, target shouldn't verify types during resolution.   Re-enable module target.  Add target validation of pointer types.   Type resolution, type definition pass.   WIP: Restructure AST; type resolution.   Capture notes on type check pass.   More stubbing. Improve lifetimes for compiler phases.   Do a top-down stubbing of Compiler to discover lifetime problems needing solved.   Re-enable scope and symbol.   Simplify lifetimes   Re-enable types   Ren-enable pos   Re-enable util with improved tests.   Re-enable interner tests.  Polish.   Stub out an idea for Value to simplify Operator.   Enable module mem   Add Ptr.  Remove lifetime param from Interner.  Need to convert tests.   Yet another \"disable everything and try another design\" event.", "target": 0}
{"idx": 1031, "commit_message": "* dcache.c (dcache_write_line): Fix typo.  * memattr.c (delete_mem_region): Replace free() with xfree(). (mem_number): Add explicit type.  * sol-thread.c (sol_thread_xfer_memory): Add attrib argument. (rw_common): Likewise.", "target": 0}
{"idx": 1328, "commit_message": "binder: return errors from buffer copy functions  The buffer copy functions assumed the caller would ensure correct alignment and that the memory to be copied was completely within the binder buffer. There have been a few cases discovered by syzkallar where a malformed transaction created by a user could violated the assumptions and resulted in a BUG_ON.  The fix is to remove the BUG_ON and always return the error to be handled appropriately by the caller.  Acked-by: Martijn Coenen [URL]> Reported-by: [URL] Fixes: bde4a19fc04f (\"binder: use userspace pointer as base of buffer space\") Suggested-by: Dan Carpenter [URL]>", "target": 0}
{"idx": 3418, "commit_message": "fixed invalid label ids for conditions  Label ids are expected to be strictly ordered (for performance reasons when executing the program - this limitation should be removed when the IR code for programs will bne revamped). As a consequence, the lvid for the label must be created when generating the new label, even if used by the previous opcodes.  Fixes #31", "target": 1}
{"idx": 2327, "commit_message": "Procedural Terrain (#408)  0.60.50:  - Added procedural terrain generator (for now this is Editor only preview version)  - Added LOD (Level Of Detail) support  - Added LOD Generator to Editor (Mesh Window -> LOD Gen), uses the meshoptimizer library  - Editor can merge multiple objects now into one mesh (Mesh window -> Merge Selected)  - Ocean: added occlusion culling support to detect when ocean is occluded          - can skip planar reflection render for ocean          - can skip ocean simulation          - can skip ocean rendering  - CPU ray tracing optimization: TMin and TMax parameter          - can improve Ray-AABB and Ray-Triangle tests          - improves performance of third person character controller script  - other fixes", "target": 1}
{"idx": 3643, "commit_message": "Some platforms (notably, the BSDs) have a more efficient implementation called closefrom(3).", "target": 1}
{"idx": 1948, "commit_message": "aoe: do not call bdi_init after blk_alloc_queue  BugLink: [URL]/bugs/1100376  commit 0a41409c518083133e79015092585d68915865be upstream.  blk_alloc_queue has already done a bdi_init, so do not bdi_init again in aoeblk_gdalloc.  The extra call causes list corruption in the per-CPU backing dev info stats lists.  Affected users see console WARNINGs about list_del corruption on percpu_counter_destroy when doing \"rmmod aoe\" or \"aoeflush -a\" when AoE targets have been detected and initialized by the system.  The patch below applies to v3.6.11, with its v47 aoe driver.  It is expected to apply to all currently maintained stable kernels except 3.7.y.  A related but different fix has been posted for 3.7.y.  References:    RedHat bugzilla ticket with original report   [URL]/show_bug.cgi?id=853064    LKML discussion of bug and fix   [URL]/gmane.linux.kernel/1416336/focus=1416497  Reported-by: Josh Boyer [URL]>", "target": 0}
{"idx": 3627, "commit_message": "don't send performance warnings for rate limits unless it's enabled. stats logging improvements", "target": 0}
{"idx": 3421, "commit_message": "Fix calculations for frame and tile threads with dav1d.  21699e36971304727ce89601ff9b669e57e63ecb incorrectly stated that when configuring tilethreads=t and framethreads=f that the total number of threads would be (t - 1)  + (f - 1), the actual total is t * f.  To avoid overpopulating thread counts for lower end systems, correct this mistake when asking for the system limits to be applied to the total.  If a system has the cores for it, we'll now use the following: <300p: 2 tile threads, 2 frame threads = 4 total threads. <700p: 3 tile threads, 2 frame threads = 6 total threads.  For higher resolutions we hit limit::kMaxVideoThreads (16): <1000p: 5 tile threads, 3 frame thread = 15 total threads. >1000p: 8 tile threads, 2 frame threads = 16 total threads.  Due to the (surprising) performance issues which occurred when setting framethreads=1 [URL]/957511) the minimum number of threads is 4 (two tile and two frame) regardless of core count. The maximum is 2 * core_count (up to limits::kMaxVideoThreads).  BUG=954659,957511 TEST=manual inspection of pthread_create() calls. R=chcunningham", "target": 0}
{"idx": 1342, "commit_message": "Merge remote-tracking branch 'origin/devel' into talbpaul/improved-warning-summary", "target": 0}
{"idx": 2334, "commit_message": "Merge pull request #11313 from CyrusNajmabadi/findRefsOneProject  Find dependent types more efficiently by storing inheritance info directly in our indices.    Fixes #11255", "target": 1}
{"idx": 2531, "commit_message": "[PATCH] manifest.readflags performance buglet  -----BEGIN PGP SIGNED MESSAGE----- Hash: SHA1  [PATCH] manifest.readflags performance buglet  From: Chris Mason [URL]>  Performance buglet in manifest.readflags: only re-read the manifest when the mapcache is not present or does not correspond to this node  manifest hash: 188ad778308a2e5c885d452d7b7e61c082e8ceb2 -----BEGIN PGP SIGNATURE----- Version: GnuPG v1.4.0 (GNU/Linux)  iD8DBQFCsG4wywK+sNU5EO8RAv+IAJ9sU87MythE/HYf3wH/V7ctzNdR1gCfclr9 ydsk6wtk/n6uKb4U7BvGvLM= =5cOx -----END PGP SIGNATURE-----", "target": 0}
{"idx": 1558, "commit_message": "* put new arrows (green, blinking, better design, working on light and dark backgrounds) in /extra/images/arrows * improved some mini gfx * edited level misc/misc_078", "target": 0}
{"idx": 1488, "commit_message": "improved docs and validation for Dupes::bounds", "target": 0}
{"idx": 2426, "commit_message": "Bulk commit :(  - Clear auto-targets that move too far from reticle - Adjust reticle defaults - Add unit whitelist for explorer swinging challenge - Pause targeting momentarily on Esc - Suspend \"Invalid\" targets instead of completely ignoring them  - Rewrite scheduler to work off VarChange_FrameCount, which runs every four frames (Do slow actions every 4 calls - every 16 frames). This should lighten the load and scale it against client performance. - Automatically buffer units while player is invalid - Handle init and player-invalid-unit-buffer processing in scheduler - Cut down on premature optimization - Extract routines into separate functions: -  DestroyMarker(uid) -  IsDesiredUnit(unit) -  UnitInReticle(unit) - Remove or disable currently unused stuff", "target": 1}
{"idx": 567, "commit_message": "improved benchmarks, added color to console", "target": 0}
{"idx": 2013, "commit_message": "usbnet: do not pretend to support SG/TSO  [ Upstream commit 20f0170377264e8449b6987041f0bcc4d746d3ed ]  usbnet doesn't support yet SG, so drivers should not advertise SG or TSO capabilities, as they allow TCP stack to build large TSO packets that need to be linearized and might use order-5 pages.  This adds an extra copy overhead and possible allocation failures.  Current code ignore skb_linearize() return code so crashes are even possible.  Best is to not pretend SG/TSO is supported, and add this again when/if usbnet really supports SG for devices who could get a performance gain.  Based on a prior patch from Freddy Xin [URL].tw>", "target": 0}
{"idx": 3517, "commit_message": "PG-1248: Completed logic to downgrade a Quotation by the original speaker to an Alternate if it defaults to narrator and it accompanied by a Quotation entry for the narrator  Related to this, I also tweaked the ICharacterDeliveryInfo interface and the underlying implementation in a way that should make the quote system guesser slightly more efficient.", "target": 1}
{"idx": 1729, "commit_message": "Ev2 shims: Ensure directories really are marked as such.  Greg rightly points out that this is something of a hack, and this whole recursive operation code could probably be improved upon.  I agree.  Current number of Ev2 test failures: 23  * subversion/libsvn_delta/compat.c   (get_operation): If the parent has children, it must be a directory.", "target": 0}
{"idx": 2971, "commit_message": "Refactoring.  - Add an accept button to AboutDialog, and fix its size. - Move some code from EditableMask to ImageStack to hide its image vector. - Improve the Histrogram unit tests.", "target": 0}
{"idx": 2401, "commit_message": "Added options for Camera Icon  Now, clicking on the Camera Icon will bring up 4 options: * Take picture * Take video * Choose picture * Choose video  Stored in array ^  Also added a listener so that when one of these items are tapped on, the dialog will be dismissed. No further action from this as of yet.  Also moved if statements to a switch for better performance.", "target": 1}
{"idx": 322, "commit_message": "Merge pull request #33 from ianfab/master  Racing Kings evaluation and search improvements", "target": 0}
{"idx": 2450, "commit_message": "[wpe] revert to optimize for performance", "target": 1}
{"idx": 3982, "commit_message": "cpufreq: governor: Be friendly towards latency-sensitive bursty workloads  Cpufreq governors like the ondemand governor calculate the load on the CPU periodically by employing deferrable timers. A deferrable timer won't fire if the CPU is completely idle (and there are no other timers to be run), in order to avoid unnecessary wakeups and thus save CPU power.  However, the load calculation logic is agnostic to all this, and this can lead to the problem described below.  Time (ms)               CPU 1  100                Task-A running  110                Governor's timer fires, finds load as 100% in the last                    10ms interval and increases the CPU frequency.  110.5              Task-A running  120\t\t   Governor's timer fires, finds load as 100% in the last \t\t   10ms interval and increases the CPU frequency.  125\t\t   Task-A went to sleep. With nothing else to do, CPU 1 \t\t   went completely idle.  200\t\t   Task-A woke up and started running again.  200.5\t\t   Governor's deferred timer (which was originally programmed \t\t   to fire at time 130) fires now. It calculates load for the \t\t   time period 120 to 200.5, and finds the load is almost zero. \t\t   Hence it decreases the CPU frequency to the minimum.  210\t\t   Governor's timer fires, finds load as 100% in the last \t\t   10ms interval and increases the CPU frequency.  So, after the workload woke up and started running, the frequency was suddenly dropped to absolute minimum, and after that, there was an unnecessary delay of 10ms (sampling period) to increase the CPU frequency back to a reasonable value. And this pattern repeats for every wake-up-from-cpu-idle for that workload. This can be quite undesirable for latency- or response-time sensitive bursty workloads. So we need to fix the governor's logic to detect such wake-up-from- cpu-idle scenarios and start the workload at a reasonably high CPU frequency.  One extreme solution would be to fake a load of 100% in such scenarios. But that might lead to undesirable side-effects such as frequency spikes (which might also need voltage changes) especially if the previous frequency happened to be very low.  We just want to avoid the stupidity of dropping down the frequency to a minimum and then enduring a needless (and long) delay before ramping it up back again. So, let us simply carry forward the previous load - that is, let us just pretend that the 'load' for the current time-window is the same as the load for the previous window. That way, the frequency and voltage will continue to be set to whatever values they were set at previously. This means that bursty workloads will get a chance to influence the CPU frequency at which they wake up from cpu-idle, based on their past execution history. Thus, they might be able to avoid suffering from slow wakeups and long response-times.  However, we should take care not to over-do this. For example, such a \"copy previous load\" logic will benefit cases like this: (where # represents busy and . represents idle)  ##########.........#########.........###########...........##########........  but it will be detrimental in cases like the one shown below, because it will retain the high frequency (copied from the previous interval) even in a mostly idle system:  ##########.........#.................#.....................#...............  (i.e., the workload finished and the remaining tasks are such that their busy periods are smaller than the sampling interval, which causes the timer to always get deferred. So, this will make the copy-previous-load logic copy the initial high load to subsequent idle periods over and over again, thus keeping the frequency high unnecessarily).  So, we modify this copy-previous-load logic such that it is used only once upon every wakeup-from-idle. Thus if we have 2 consecutive idle periods, the previous load won't get blindly copied over; cpufreq will freshly evaluate the load in the second idle interval, thus ensuring that the system comes back to its normal state.  [ The right way to solve this whole problem is to teach the CPU frequency governors to also track load on a per-task basis, not just a per-CPU basis, and then use both the data sources intelligently to set the appropriate frequency on the CPUs. But that involves redesigning the cpufreq subsystem, so this patch should make the situation bearable until then. ]  Experimental results: +-------------------+  I ran a modified version of ebizzy (called 'sleeping-ebizzy') that sleeps in between its execution such that its total utilization can be a user-defined value, say 10% or 20% (higher the utilization specified, lesser the amount of sleeps injected). This ebizzy was run with a single-thread, tied to CPU 8.  Behavior observed with tracing (sample taken from 40% utilization runs): ------------------------------------------------------------------------  Without patch: ~~~~~~~~~~~~~~ kworker/8:2-12137  416.335742: cpu_frequency: state=2061000 cpu_id=8 kworker/8:2-12137  416.335744: sched_switch: prev_comm=kworker/8:2 ==> next_comm=ebizzy       <...>-40753  416.345741: sched_switch: prev_comm=ebizzy ==> next_comm=kworker/8:2 kworker/8:2-12137  416.345744: cpu_frequency: state=4123000 cpu_id=8 kworker/8:2-12137  416.345746: sched_switch: prev_comm=kworker/8:2 ==> next_comm=ebizzy       <...>-40753  416.355738: sched_switch: prev_comm=ebizzy ==> next_comm=kworker/8:2 <snip>  ---------------------------------------------------------------------  <snip>       <...>-40753  416.402202: sched_switch: prev_comm=ebizzy ==> next_comm=swapper/8      <idle>-0      416.502130: sched_switch: prev_comm=swapper/8 ==> next_comm=ebizzy       <...>-40753  416.505738: sched_switch: prev_comm=ebizzy ==> next_comm=kworker/8:2 kworker/8:2-12137  416.505739: cpu_frequency: state=2061000 cpu_id=8 kworker/8:2-12137  416.505741: sched_switch: prev_comm=kworker/8:2 ==> next_comm=ebizzy       <...>-40753  416.515739: sched_switch: prev_comm=ebizzy ==> next_comm=kworker/8:2 kworker/8:2-12137  416.515742: cpu_frequency: state=4123000 cpu_id=8 kworker/8:2-12137  416.515744: sched_switch: prev_comm=kworker/8:2 ==> next_comm=ebizzy  Observation: Ebizzy went idle at 416.402202, and started running again at 416.502130. But cpufreq noticed the long idle period, and dropped the frequency at 416.505739, only to increase it back again at 416.515742, realizing that the workload is in-fact CPU bound. Thus ebizzy needlessly ran at the lowest frequency for almost 13 milliseconds (almost 1 full sample period), and this pattern repeats on every sleep-wakeup. This could hurt latency-sensitive workloads quite a lot.  With patch: ~~~~~~~~~~~  kworker/8:2-29802  464.832535: cpu_frequency: state=2061000 cpu_id=8 <snip>  ---------------------------------------------------------------------  <snip> kworker/8:2-29802  464.962538: sched_switch: prev_comm=kworker/8:2 ==> next_comm=ebizzy       <...>-40738  464.972533: sched_switch: prev_comm=ebizzy ==> next_comm=kworker/8:2 kworker/8:2-29802  464.972536: cpu_frequency: state=4123000 cpu_id=8 kworker/8:2-29802  464.972538: sched_switch: prev_comm=kworker/8:2 ==> next_comm=ebizzy       <...>-40738  464.982531: sched_switch: prev_comm=ebizzy ==> next_comm=kworker/8:2 <snip>  ---------------------------------------------------------------------  <snip> kworker/8:2-29802  465.022533: sched_switch: prev_comm=kworker/8:2 ==> next_comm=ebizzy       <...>-40738  465.032531: sched_switch: prev_comm=ebizzy ==> next_comm=kworker/8:2 kworker/8:2-29802  465.032532: sched_switch: prev_comm=kworker/8:2 ==> next_comm=ebizzy       <...>-40738  465.035797: sched_switch: prev_comm=ebizzy ==> next_comm=swapper/8      <idle>-0      465.240178: sched_switch: prev_comm=swapper/8 ==> next_comm=ebizzy       <...>-40738  465.242533: sched_switch: prev_comm=ebizzy ==> next_comm=kworker/8:2 kworker/8:2-29802  465.242535: sched_switch: prev_comm=kworker/8:2 ==> next_comm=ebizzy       <...>-40738  465.252531: sched_switch: prev_comm=ebizzy ==> next_comm=kworker/8:2  Observation: Ebizzy went idle at 465.035797, and started running again at 465.240178. Since ebizzy was the only real workload running on this CPU, cpufreq retained the frequency at 4.1Ghz throughout the run of ebizzy, no matter how many times ebizzy slept and woke-up in-between. Thus, ebizzy got the 10ms worth of 4.1 Ghz benefit during every sleep-wakeup (as compared to the run without the patch) and this boost gave a modest improvement in total throughput, as shown below.  Sleeping-ebizzy records-per-second: -----------------------------------  Utilization  Without patch  With patch  Difference (Absolute and % values)     10%         274767        277046        +  2279 (+0.829%)     20%         543429        553484        + 10055 (+1.850%)     40%        1090744       1107959        + 17215 (+1.578%)     60%        1634908       1662018        + 27110 (+1.658%)  A rudimentary and somewhat approximately latency-sensitive workload such as sleeping-ebizzy itself showed a consistent, noticeable performance improvement with this patch. Hence, workloads that are truly latency-sensitive will benefit quite a bit from this change. Moreover, this is an overall win-win since this patch does not hurt power-savings at all (because, this patch does not reduce the idle time or idle residency; and the high frequency of the CPU when it goes to cpu-idle does not affect/hurt the power-savings of deep idle states).", "target": 1}
{"idx": 2046, "commit_message": "Conpherence - change \"A, B, C...\" subtitle to \"A: what most recent person said\" when we can  Summary: For the price of loading transactions more consistently, we get a better subtitle. We do this in all cases EXCEPT for when we're grabbing handles, because that makes the handles pretty heavy weight and I could even feel the perf hit on my development machine and we don't use subtitle there anyway. We may want to cache the latest message on the conpherence thread object to improve performance here as well as consider falling back to \"A, B, C...\" more often. Code is written such that no transactions means an automagical fallback.  Fixes T7795. (Technically, there's still a note about handle code conversion work on T7795 but we'll get that generally later.)  Test Plan: played around with conpherence in both views and things seemed to work nicely. made sure to try the original repro in T7795 and couldn't get that to go either posted a long comment and verified that the CSS / string truncation both make it display nicely. Note that without the CSS the chosen glyph value can be too high to fit nicely at times.  Reviewers: chad, epriestley  Reviewed By: epriestley  Subscribers: Korvin, epriestley  Maniphest Tasks: T7795  Differential Revision: [URL]/D12347", "target": 0}
{"idx": 3952, "commit_message": "Merge #7430  7430: Improve `release:prepare_patch` task r=hsbt a=deivid-rodriguez  ### What was the end-user problem that led to this PR?    The problem was some more little issues with the `bin/rake release:prepare_patch` task.    ### What is your fix for the problem, implemented in this PR?    My fix is to improve the task with better fallbacks and better informational and error messages.", "target": 0}
{"idx": 212, "commit_message": "ARM: Exynos: switch to using generic cpufreq driver for Exynos5250  The new CPU clock type allows the use of generic CPUfreq driver. Switch Exynos5250 to using generic cpufreq driver.  Changes by Bartlomiej: - split Exynos5250 support from the original patch  Cc: Tomasz Figa [URL]> Cc: Kukjin Kim [URL]> Cc: Javier Martinez Canillas < > Cc: Chander Kashyap [URL]>", "target": 0}
{"idx": 1075, "commit_message": "* build tweak  [config/ChangeLog] 2001-02-05  Frank Ch. Eigler  [URL]>          * ltmain.sh (link/dlpreload): Apply export-symbols-regexp to         preloaded libtool archives too.  [main/dynamic/ChangeLog] 2001-02-05  Frank Ch. Eigler  [URL]>          * Makefile.am (sid_LDFLAGS): Add export-symbols-regex parameter to         shrink the list of static symbols in the dlpreload case.         * Makefile.in: Regenerated.", "target": 0}
{"idx": 2143, "commit_message": "Proportional Rate Reduction for TCP.  This patch implements Proportional Rate Reduction (PRR) for TCP. PRR is an algorithm that determines TCP's sending rate in fast recovery. PRR avoids excessive window reductions and aims for the actual congestion window size at the end of recovery to be as close as possible to the window determined by the congestion control algorithm. PRR also improves accuracy of the amount of data sent during loss recovery.  The patch implements the recommended flavor of PRR called PRR-SSRB (Proportional rate reduction with slow start reduction bound) and replaces the existing rate halving algorithm. PRR improves upon the existing Linux fast recovery under a number of conditions including:   1) burst losses where the losses implicitly reduce the amount of outstanding data (pipe) below the ssthresh value selected by the congestion control algorithm and,   2) losses near the end of short flows where application runs out of data to send.  As an example, with the existing rate halving implementation a single loss event can cause a connection carrying short Web transactions to go into the slow start mode after the recovery. This is because during recovery Linux pulls the congestion window down to packets_in_flight+1 on every ACK. A short Web response often runs out of new data to send and its pipe reduces to zero by the end of recovery when all its packets are drained from the network. Subsequent HTTP responses using the same connection will have to slow start to raise cwnd to ssthresh. PRR on the other hand aims for the cwnd to be as close as possible to ssthresh by the end of recovery.  A description of PRR and a discussion of its performance can be found at the following links: - IETF Draft:     [URL]/html/draft-mathis-tcpm-proportional-rate-reduction-01 - IETF Slides:     [URL]/proceedings/80/slides/tcpm-6.pdf     [URL]/agenda/81/slides/tcpm-2.pdf - Paper to appear in Internet Measurements Conference (IMC) 2011:     Improving TCP Loss Recovery     Nandita Dukkipati, Matt Mathis, Yuchung Cheng", "target": 1}
{"idx": 351, "commit_message": "[MERGE] cherry picking of revision 4422-4423 of lp:~openerp-dev/openobject-addons/trunk-dev2-hr-improvements  bzr revid: [URL]-20110314104327-3n3xfjibl4x0yy2y", "target": 0}
{"idx": 2272, "commit_message": "[SYSTEMML-1836] Reduced GC overhead codegen rowwise ops (static buffer)   Scripts like Kmeans and Mlogreg showed unnecessarily large GC overhead when ran with codegen enabled. These scripts heavily rely on rowwise fused operators, which already used a thread-local buffer for row intermediates (where the size of this buffer is derived from the cplan, usually <10). However, this ring buffer used a poor implementation based on linked lists, which created new objects per vector allocation (i.e., per row intermediate).   This patch changes this implementation to a static array ring buffer, which significantly improved end-to-end performance. For example, here are the results for Kmeans and Mlogreg on a 10Mx10 scenario:  Baselines w/o codegen: Kmeans 1,399s, Mlogreg 507s. Kmeans w/ codegen: 466s (102s GC) -> 326s (13s GC) Mlogreg w/ codegen: 196s (37s GC) -> 134s (6s GC)  Furthermore, this patch also cleans up the statistics collection (collect all outside loop and only for top-level problems), statistics output formatting (mis-aligned outputs), and introduces a new util function for integer power 2^x in order to increase readability while leveraging the performance benefits of simply shifts.", "target": 1}
{"idx": 3645, "commit_message": "Merge branch 'asnyc-when-necessary' to master  This adds synchronous diffing, until an asynchronous `expect.it` is encountered, when it breaks out to asynchronous diffing. This should improve performance for the majority of cases (where synchronous is all that is needed), and reduce performance for the odd case where async is required.", "target": 1}
{"idx": 1805, "commit_message": "Merge \"Update permissions assets for Quantum Theme\" into lmp-preview-dev", "target": 0}
{"idx": 3001, "commit_message": "libcontent: rename functions  Problem: libcontent internal functions are named inappropriately given RFC 10 protocol changes in the pipeline.  We will still want functions that operate on blobrefs for convenience, but also more efficient ones that match the protocol.  In anticipation of this, rename:   content_load()      -> content_load_byblobref()   content_store_get() -> content_store_get_blobref()  Update users.", "target": 0}
{"idx": 688, "commit_message": "Add Redis version and memory usage to info handler responses.", "target": 0}
{"idx": 3413, "commit_message": "Implmented a new system to manage to DMA and presenting of frames when using the bluefish hadrware. This system uses FIFO mode on the hadware which allows for some degree of buffering on the card.  Frames are copied from caspar to a internal Q, a seperate thread then extracts frames from the Q, and does the DMA and present calls. This system removes our DMA from the core loop of Caspar, and allows up to a full frames time to be used for the DMA. - Important when using multiple channels.  Moved the Wait for Sync caLl to happen after the Memcopy, this should create a more stable sync time.  No longer need to set the executor thread to high priority, but setting the std::thread that i am using for the DMA to highest priority.  This change results in much better performance when doing multiple streams.  This change required some additional functions to be added to the blue_velvet.h/cpp files too, to properly support the FIFO playback mode.  Also minor change to tell the Keyer that data is pre-multiplied when we receive it.", "target": 1}
{"idx": 1249, "commit_message": "qt5webkit: increase performance on gstreamer player", "target": 1}
{"idx": 4118, "commit_message": "[PATCH] EA:increased MAXMEM size to 512 since it gives large\n performance improvement on big matrix multiplies", "target": 1}
{"idx": 3166, "commit_message": "sin_cos.c, tsin_cos.c: ported patch and tests from the trunk. More precisely:   * tsin_cos.c: more testing, in particular in the underflow case.   * sin_cos.c: in case of tiny inputs, keep the flags. In practice,     this fixes the following bug in mpfr_sin_cos (shown by the improved     tsin_cos.c): if emin is the minimum exponent (MPFR_EMIN_MIN), the     absolute value of the input is the minimum positive number and the     rounding mode is toward 0 (or equivalent), then the underflow flag     is dropped. The other exception cases (e.g., in case of reduced     exponent range) are handled by mpfr_check_range().", "target": 0}
{"idx": 2118, "commit_message": "- Patch #724788 by boombatower: improved code style of some tests in user.test.", "target": 0}
{"idx": 779, "commit_message": "Many tweaks, but most notably, vast improvements to ~sna1", "target": 1}
{"idx": 3086, "commit_message": "Merge pull request #23 from stackmob/faster_caching  Attempt to make the InMemoryResponseCacher more performant", "target": 1}
{"idx": 3309, "commit_message": "cmake: set CCACHE_BASEDIR & CCACHE_NOHASHDIR when using ccache  Dramatically improves build performance when building multiple projects in different directories.", "target": 1}
{"idx": 3036, "commit_message": "WL#5259 PERFORMANCE_SCHEMA HOST_CACHE  Fixed FreeBSD build break", "target": 0}
{"idx": 1672, "commit_message": "Adding in-memory mock service for Keychain.", "target": 0}
{"idx": 611, "commit_message": "Minor improvement to show clip in project bin", "target": 0}
{"idx": 2449, "commit_message": "Performance tests for loading into AO/CO tables  Removing old defunct performance directory and replace with a simple way to test AO/CO table loading. This will help measure performance changes when we start generating XLOGs for AO/CO tables and implement WAL replication between primaries and mirrors. This current performance implementation is a bit hacky currently but it gets the job done and does not rely on TPC (which we can't have in our source unfortunately).  Current implementation: 1. Create csv data file (specified by NUM_COPIES Makefile variable) 2. Host the csv data file in an external table to load data into a    base table faster (and to work around a known memory leak bug when    doing many inserts in a LOOP) 3. Create the AO and AOCO tables and start testing loading times    sequentially and concurrently 4. Parse the output into a csv to allow separate comparison analysis", "target": 1}
{"idx": 2568, "commit_message": "[Traffic Annotations] Implement Auditor in auditor.py  This includes all the glue code to make auditor.py a feature-complete, drop-in replacement for the C++ auditor (except with fewer supported command-line arguments, and probably more bugs).  Notable new features:   - Save the new annotations.xml file (without --test-only)   - Report required annotations.xml changes (with --test-only)   - Ignore files/annotations based on safe_list.txt   - Combine partial/completing annotations together before running     checks   - Export to TSV file   - Path filters now work the same as the C++ auditor.   - Validate grouping.xml contents   - Logging at each step (with timestamps), so we can measure     performance.  Also fix many small bugs in previously-untested code. Many such cases were revealed while writing the glue code.  Also update 2 invalid annotations in annotations.xml (hash_code doesn't match the unique_id) and clean up deprecated annotations in grouping.xml.  Bug: 1119417", "target": 0}
{"idx": 3230, "commit_message": "Register overutilization for arbitrary sequence sizes rework -This update brings generalization of register overutilization technique for arbitrary sequences. With it enabled, bigger sequences can be done in one upload to the chip, effectively bringing shared memory size to 128KB or even 256KB. It trades occupancy for lower number of memory transfers and can be useful for high-end GPUs with high CU count. Works both for non-strided and strided axes. Tested for C2C and single upload mode, no convolutions (will be improved in the future). Enabled for power of 2 sequences by default (works for non-power of 2 sequences as well, but performance gains are not yet tested). -Switched FFT exponent sign to be conformant with FFTW. Added an option to disable normalization in inverse FFT (enabled by default).", "target": 0}
{"idx": 1187, "commit_message": "drivers/char/applicom.c: fix information leak to userland  Structure st_loc is copied to userland with some fields unitialized.  It leads to leaking of stack memory.", "target": 0}
{"idx": 110, "commit_message": "Merge branch 'master' of [URL]:globaleaks/GLClient  * 'master' of [URL]:globaleaks/GLClient:   Add notes on submission interface on which file to modify   Modify the submission Step 3 text from lorem ipsum   updated view in admin mail, along with docs   Receiver and Context need to be configured both   Specify that one is hostname and the other is url   Fix name in content settings   improved tip list view", "target": 0}
{"idx": 3619, "commit_message": "Pass Strings by const reference  Still immutable, and more efficient than making a temporary copy", "target": 1}
{"idx": 2610, "commit_message": "Merge pull request #40630 from liggitt/apply-null  Automatic merge from submit-queue (batch tested with PRs 40529, 40630)  propagate explicit nulls in apply  Rebase of [URL]/kubernetes/kubernetes/pull/35496 on top of [URL]/kubernetes/kubernetes/pull/40260    The client-side propagation of the raw value is no longer needed, since the client is preserving the original object in unstructured form (explicit nulls are preserved).    Kept tests and CreateThreeWayMergePatch changes from [URL]/kubernetes/kubernetes/pull/35496    ```release-note  kubectl apply now supports explicitly clearing values not present in the config by setting them to null  ```    - [x] Clean up orphaned objects in test-cmd to preserve pre- and post- conditions  - [x] improve CreateThreeWayMergePatch test to not filter based on string comparison to test name", "target": 0}
{"idx": 2377, "commit_message": "msm_rmnet: support IPV6, QoS, and raw IP framing  The RmNET network driver is updated to support additional functionality. To improve performance, the Modem offers use of raw IP framing over RmNET channel.  The userspace application can select to use either Ethernet (default) or raw IP framing via IOCTL command.  This change requires minor updates to kernel network code to support raw IP mode in IPV6 address configuration.  Additionally, the Rx packet protocol (IP version) must be assigned before sending packet to data stack by examining the IP header field.  To support end-to-end quality of service (QoS) packet handling, the Modem requires tx frames to have a QoS header pre-pended.  The header contains the Modem QoS flow handle, which is specified in the skb \"mark\" field provided by data stack.  This value is zero by default, indicating Modem primary flow.  When required, the mark value will be assigned by IP table mangle rule configured by userspace application. The userspace application can enable driver QoS support via IOCTL command.", "target": 1}
{"idx": 3481, "commit_message": "Merge pull request #6 from lob/performance  feat(performance): Performance improvements", "target": 1}
{"idx": 2812, "commit_message": "Merge pull request #329 from zhmcclient/andy/improve-objectid-filter  Fixes #261: Improved performance of lookup by object-id", "target": 1}
{"idx": 3669, "commit_message": "More efficient GraphBuilder - probably should be in another branch...", "target": 1}
{"idx": 2655, "commit_message": "treemanifest: optimize treemanifest._walk() to skip directories  This makes treemanifest.walk() not visit submanifests that are known not to have any matching files. It does this by calling match.visitdir() on submanifests as it walks.  This change also updates largefiles to be able to work with this new behavior in treemanifests. It overrides match.visitdir(), the function that dictates how walk() and matches() skip over directories.  The greatest speed improvements are seen with narrower scopes. For example, this commit speeds up the following command on the Mozilla repo from 1.14s to 1.02s:   hg files -r . dom/apps/  Whereas with a wider scope, dom/, the speed only improves from 1.21s to 1.13s.  As with similar a similar optimization to treemanifest.matches(), this change will bring out even bigger performance improvements once treemanifests are loaded lazily. Once that happens, we won't just skip over looking at submanifests, but we'll skip even loading them.", "target": 1}
{"idx": 3985, "commit_message": "drm/amd/display: 3.2.152  * Correct degamma coefficients * Optimize bandwidth on following fast update * Fix multiple memory leaks reported by coverity * Get backlight from PWM if DMCU is not initialized  Acked-by: Mikita Lipski [URL]>", "target": 1}
{"idx": 3180, "commit_message": "[ResourceTiming] Interrogate more attributes in Resource Timing WPT  The Resource Timing spec enumerates the attributes for PerformanceResourceTiming values as well as rules for what each attribute must contain.  This changes adds tests to validate the computed attributes match expectations from the spec.  Bug: 1171767", "target": 0}
{"idx": 366, "commit_message": "lib bpf: Add support for BPF_PROG_ATTACH and BPF_PROG_DETACH", "target": 0}
{"idx": 3874, "commit_message": "2006-11-25  Roman Kennke  [URL]>  \t* javax/swing/text/GapContent.java \t(getPositionsInRange): Rewritten to use the more efficient \tbinary search searchFirst() and avoid an NPE that was caused \tby GC'ed positions.", "target": 1}
{"idx": 2262, "commit_message": "Allocate trx_t's in (mostly) contiguous memory to improve performance  Summary: Previously, trx_t's were allocated at random heap locations. This causes performance issues when iterating over all open transactions (such as when creating a new transaction's list of visible transactions).  This change allocates larger blocks of trx_t's and tracks the next usable trx_t with a singly linked list.  As blocks are filled, new blocks are allocated.  This results in a 50% improvement in performance in the 2000 transaction test case.  Test Plan: mtr, performance testing  Reviewed By: mcallaghan Reviewers: mcallaghan", "target": 1}
{"idx": 3714, "commit_message": "exp/norm: Added Iter type for iterating on segment boundaries.  This type is mainly to be used by other low-level libraries, like collate.  Extra care has been given to optimize the performance of normalizing to NFD, as this is what will be used by the collator.  The overhead of checking whether a string is normalized vs simply decomposing a string is neglible.  Assuming that most strings are in the FCD form, this iterator can be used to decompose strings and normalize with minimal overhead.  R=r CC=golang-dev [URL]/5676057", "target": 1}
{"idx": 2646, "commit_message": "rcu: Provide OOM handler to motivate lazy RCU callbacks In kernels built with CONFIG_RCU_FAST_NO_HZ=y, CPUs can accumulate a large number of lazy callbacks, which as the name implies will be slow to be invoked.  This can be a problem on small-memory systems, where the default 6-second sleep for CPUs having only lazy RCU callbacks could well be fatal.  This commit therefore installs an OOM hander that ensures that every CPU with lazy callbacks has at least one non-lazy callback, in turn ensuring timely advancement for these callbacks.  Updated to fix bug that disabled OOM killing, noted by Lai Jiangshan.  Updated to push the for_each_rcu_flavor() loop into rcu_oom_notify_cpu(), thus reducing the number of IPIs, as suggested by Steven Rostedt.  Also to make the for_each_online_cpu() loop be preemptible.  (Later, it might be good to use smp_call_function(), as suggested by Peter Zijlstra.)", "target": 1}
{"idx": 3636, "commit_message": "performance is much faster now, even with dozens of drones onscreen at the same time. collision still has bugs", "target": 1}
{"idx": 1991, "commit_message": "- fixes retry on plus PUSH - workaround for the famous Windows 10 Update 2004 issue that also breaks optimal smoothing - update numpy on Windows with updated OpenBLAS that might fix some of the Windows 10 Update 2004 issues - resets PID RS actions on PID ON - removes check for CPU state in S7 port", "target": 0}
{"idx": 762, "commit_message": "OMAPDSS: DISPC: set irq_safe for runtime PM  We have a bug with omapdrm, where omapdrm calls dispc's pm_runtime function in atomic context, and dispc's pm_runtime is not marked as irq_safe:  BUG: sleeping function called from invalid context at drivers/base/power/runtime.c:952  Dispc's runtime PM callbacks are irq safe, so we can just set the irq_safe flag to fix the issue.  However, in the long term, I'd rather have omapdrm manage the runtime PM calls in a better way. Calling get/put for every small operation that touches the dispc registers is very inefficient. It'd be better and cleaner to have clear \"in-use\" and \"not-in-use\" states for dispc, so that we don't need to do register context restore for small operations, only to turn dispc off right afterwards.", "target": 0}
{"idx": 1866, "commit_message": "Use \"ports\" or \"from\" as identifying key for \"ingress\" (#175)  * Use \"ports\" or \"from\" as identifying key for \"ingress\"    * add TestNetworkPoliciesFix for fix-167", "target": 0}
{"idx": 4016, "commit_message": "[PATCH] performance improvement for DD assignment of settles with\n cg's", "target": 1}
{"idx": 2713, "commit_message": "= Source =  * Really minor performance improvement on skill_check_condition_castbegin vs a player mounted on a wug, so that it doesn't unnecessarily allocate skill_get_requirement stuff when you won't be able to use the skill at all due to wug riding restrictions.", "target": 1}
{"idx": 2485, "commit_message": "set the nebulae image paths relative to the json file  This makes StelSkyImageTile more efficient at loading the json file, because by default the images are expected to be relative to the parent json file.  It seems to improve the fluidity the first time we zoom in.", "target": 1}
{"idx": 167, "commit_message": "zsmalloc: factor page chain functionality out  For page migration, we need to create page chain of zspage dynamically so this patch factors it out from alloc_zspage.  Link: [URL]", "target": 0}
{"idx": 3863, "commit_message": "feat: news filtering by minister and department  * add department and minister filter to news    * fix helper method to use instance var instead    * update tests to include filter testing    * update changelog    * remove old code    * remove redundant section set and use helper instead    * implement changes from pr #491    * update to reflect performance improvements    * ensure articles are filtered when present    * fix: remove redundant line of code    * ref: improve means of loading section ids for better performance    * shift includes into preload helper    * fix: improve tests to be kinder with article fabricators and distributions    * fix: include legend in markup for accessibility", "target": 1}
{"idx": 3511, "commit_message": "Create property attributes on demand.  This reduces the memory footprint of large projects. Unfortunately, I haven't seen much of a performance difference.", "target": 0}
{"idx": 3005, "commit_message": "AUS-1753:Improve layer download performance:Change response to stream and returned in a POJO.", "target": 1}
{"idx": 3393, "commit_message": "2010-02-24  Oliver Hunt  [URL]>          Reviewed by Gavin Barraclough.          Speed up getter performance in the jit         [URL]/show_bug.cgi?id=35332          Implement getter lookup caching in the interpreter.         The getter stubs are generated through basically the         same code paths as the normal get_by_id caching.         Instead of simply loading a property and returning,         we load the getter slot, and pass the getter, base value         and return address to a shared stub used for getter         dispatch.          * jit/JIT.h:         (JSC::JIT::compileGetByIdProto):         (JSC::JIT::compileGetByIdSelfList):         (JSC::JIT::compileGetByIdProtoList):         (JSC::JIT::compileGetByIdChainList):         (JSC::JIT::compileGetByIdChain):         * jit/JITPropertyAccess.cpp:         (JSC::JIT::privateCompileGetByIdProto):         (JSC::JIT::privateCompileGetByIdSelfList):         (JSC::JIT::privateCompileGetByIdProtoList):         (JSC::JIT::privateCompileGetByIdChainList):         (JSC::JIT::privateCompileGetByIdChain):         * jit/JITPropertyAccess32_64.cpp:         (JSC::JIT::privateCompileGetByIdProto):         (JSC::JIT::privateCompileGetByIdSelfList):         (JSC::JIT::privateCompileGetByIdProtoList):         (JSC::JIT::privateCompileGetByIdChainList):         (JSC::JIT::privateCompileGetByIdChain):         * jit/JITStubs.cpp:         (JSC::JITThunks::tryCacheGetByID):         (JSC::DEFINE_STUB_FUNCTION):         * jit/JITStubs.h:         (JSC::):         * runtime/GetterSetter.h:", "target": 1}
{"idx": 2067, "commit_message": "Make run_diff_index() use unpack_trees(), not read_tree()  A plain \"git commit\" would still run lstat() a lot more than necessary, because wt_status_print() would cause the index to be repeatedly flushed and re-read by wt_read_cache(), and that would cause the CE_UPTODATE bit to be lost, resulting in the files in the index being lstat'ed three times each.  The reason why wt-status.c ended up invalidating and re-reading the cache multiple times was that it uses \"run_diff_index()\", which in turn uses \"read_tree()\" to populate the index with *both* the old index and the tree we want to compare against.  So this patch re-writes run_diff_index() to not use read_tree(), but instead use \"unpack_trees()\" to diff the index to a tree.  That, in turn, means that we don't need to modify the index itself, which then means that we don't need to invalidate it and re-read it!  This, together with the lstat() optimizations, means that \"git commit\" on the kernel tree really only needs to lstat() the index entries once. That noticeably cuts down on the cached timings.  Best time before:          [  linux]$ time git commit > /dev/null         real    0m0.399s         user    0m0.232s         sys     0m0.164s  Best time after:          [  linux]$ time git commit > /dev/null         real    0m0.254s         user    0m0.140s         sys     0m0.112s  so it's a noticeable improvement in addition to being a nice conceptual cleanup (it's really not that pretty that \"run_diff_index()\" dirties the index!)  Doing an \"strace -c\" on it also shows that as it cuts the number of lstat() calls by two thirds, it goes from being lstat()-limited to being limited by getdents() (which is the readdir system call):  Before:         % time     seconds  usecs/call     calls    errors syscall         ------ ----------- ----------- --------- --------- ----------------          60.69    0.000704           0     69230        31 lstat          23.62    0.000274           0      5522           getdents           8.36    0.000097           0      5508      2638 open           2.59    0.000030           0      2869           close           2.50    0.000029           0       274           write           1.47    0.000017           0      2844           fstat  After:         % time     seconds  usecs/call     calls    errors syscall         ------ ----------- ----------- --------- --------- ----------------          45.17    0.000276           0      5522           getdents          26.51    0.000162           0     23112        31 lstat          19.80    0.000121           0      5503      2638 open           4.91    0.000030           0      2864           close           1.48    0.000020           0       274           write           1.34    0.000018           0      2844           fstat         ...  It passes the test-suite for me, but this is another of one of those really core functions, and certainly pretty subtle, so..  NOTE! The Linux lstat() system call is really quite cheap when everything is cached, so the fact that this is quite noticeable on Linux is likely to mean that it is *much* more noticeable on other operating systems. I bet you'll see a much bigger performance improvement from this on Windows in particular.", "target": 1}
{"idx": 4008, "commit_message": "[PATCH] Performance improvements to kd_tree_test, added peer bounds\n checking.", "target": 1}
{"idx": 649, "commit_message": "Don't reference the enclosing type instance when it's not used (memory optimisation)", "target": 1}
{"idx": 3774, "commit_message": "Fix dreaded seal collector (#271)  * Now handles crafted seals, works at max realm rank    More valuable seals created via crafting are given their proper values rather than all seals being treated equally and giving somebody turning in an effulgent dreaded seal 1/250th of it's value.    The collector now takes seals and grants BPs when the player is at max realm rank rather than refusing to take the seal entirely.    There was a fair bit of clean up as well.  The script this was based on had several people fiddle with it before it got to me, and there was a lot of room for improvement.  It's possible I'm better at this than I was three years ago.    * Added dreaded seal value properties    BPs/RPs given is the level multiplier * BP/RP value * seal count.  Item bonuses and bp_rate/rp_rate server properties are applied to the result.    Default values are based on 1.125 patch notes.    * Server property based BP/RP rewards    Now uses server properties to determine BP/RP rewards, and the code is a lot cleaner.    * Removed unused ParseValues() argument    * Trimmed leading zero multiplier    * Various improvements    Removed reeding a superfluous leading zero level multiplier.    Made function and variable names more descriptive.    Made collectors communicate more accurate and useful information to players, standardized their responses to use the chat rather than system window.    Added error log message and made collector responses more informative to help admins track down server property issues.    Collectors can now give out just BPs or just RPs, rather that failing to award anything if only BP or RP rewards are defined.  This allows for things like glowing seals only giving BP rewards so you have to kill keep lords to get seals which grant RPs.", "target": 0}
{"idx": 647, "commit_message": "lib/lzo: huge LZO decompression speedup on ARM by using unaligned access", "target": 1}
{"idx": 3509, "commit_message": "proc: much faster /proc/vmstat  Every current KDE system has process named ksysguardd polling files below once in several seconds:  \t$ strace -e trace=open -p $(pidof ksysguardd) \tProcess 1812 attached \topen(\"/etc/mtab\", O_RDONLY|O_CLOEXEC)   = 8 \topen(\"/etc/mtab\", O_RDONLY|O_CLOEXEC)   = 8 \topen(\"/proc/net/dev\", O_RDONLY)         = 8 \topen(\"/proc/net/wireless\", O_RDONLY)    = -1 ENOENT (No such file or directory) \topen(\"/proc/stat\", O_RDONLY)            = 8 \topen(\"/proc/vmstat\", O_RDONLY)          = 8  Hell knows what it is doing but speed up reading /proc/vmstat by 33%!  Benchmark is open+read+close 1.000.000 times.  \t\t\tBEFORE $ perf stat -r 10 taskset -c 3 ./proc-vmstat   Performance counter stats for 'taskset -c 3 ./proc-vmstat' (10 runs):        13146.768464      task-clock (msec)         #    0.960 CPUs utilized            ( +-  0.60% )                 15      context-switches          #    0.001 K/sec                    ( +-  1.41% )                  1      cpu-migrations            #    0.000 K/sec                    ( +- 11.11% )                104      page-faults               #    0.008 K/sec                    ( +-  0.57% )     45,489,799,349      cycles                    #    3.460 GHz                      ( +-  0.03% )      9,970,175,743      stalled-cycles-frontend   #   21.92% frontend cycles idle     ( +-  0.10% )      2,800,298,015      stalled-cycles-backend    #   6.16% backend cycles idle       ( +-  0.32% )     79,241,190,850      instructions              #    1.74  insn per cycle                                                   #    0.13  stalled cycles per insn  ( +-  0.00% )     17,616,096,146      branches                  # 1339.956 M/sec                    ( +-  0.00% )        176,106,232      branch-misses             #    1.00% of all branches          ( +-  0.18% )        13.691078109 seconds time elapsed                                          ( +-  0.03% )       ^^^^^^^^^^^^  \t\t\tAFTER $ perf stat -r 10 taskset -c 3 ./proc-vmstat   Performance counter stats for 'taskset -c 3 ./proc-vmstat' (10 runs):         8688.353749      task-clock (msec)         #    0.950 CPUs utilized            ( +-  1.25% )                 10      context-switches          #    0.001 K/sec                    ( +-  2.13% )                  1      cpu-migrations            #    0.000 K/sec                104      page-faults               #    0.012 K/sec                    ( +-  0.56% )     30,384,010,730      cycles                    #    3.497 GHz                      ( +-  0.07% )     12,296,259,407      stalled-cycles-frontend   #   40.47% frontend cycles idle     ( +-  0.13% )      3,370,668,651      stalled-cycles-backend    #  11.09% backend cycles idle       ( +-  0.69% )     28,969,052,879      instructions              #    0.95  insn per cycle                                                   #    0.42  stalled cycles per insn  ( +-  0.01% )      6,308,245,891      branches                  #  726.058 M/sec                    ( +-  0.00% )        214,685,502      branch-misses             #    3.40% of all branches          ( +-  0.26% )         9.146081052 seconds time elapsed                                          ( +-  0.07% )        ^^^^^^^^^^^  vsnprintf() is slow because:  1. format_decode() is busy looking for format specifier: 2 branches    per character (not in this case, but in others)  2. approximately million branches while parsing format mini language    and everywhere  3.  just look at what string() does /proc/vmstat is good case because    most of its content are strings  Link:", "target": 1}
{"idx": 3334, "commit_message": "f2fs: avoid wait if IO end up when do_checkpoint for better performance  Previously, do_checkpoint() will call congestion_wait() for waiting the pages (previous submitted node/meta/data pages) to be written back. Because congestion_wait() will set a regular period (e.g. HZ / 50 ) for waiting, and no additional wake up mechanism was introduced if IO ends up before regular period costed. Yuan Zhong found there is a situation that after the pages have been written back, but the checkpoint thread still wait for congestion_wait to exit.  So here we store checkpoint task into f2fs_sb when doing checkpoint, it'll wait for IO completes if there's IO going on, and in the end IO path, wake up checkpoint task when IO ends up.  Thanks to Yuan Zhong's pre work about this problem.  Reported-by: Yuan Zhong [URL]>", "target": 1}
{"idx": 2920, "commit_message": "tracing: Fix potential out-of-bounds in trace_get_user()  commit 057db8488b53d5e4faa0cedb2f39d4ae75dfbdbb upstream.  Andrey reported the following report:  ERROR: AddressSanitizer: heap-buffer-overflow on address ffff8800359c99f3 ffff8800359c99f3 is located 0 bytes to the right of 243-byte region [ffff8800359c9900, ffff8800359c99f3) Accessed by thread T13003:   #0 ffffffff810dd2da (asan_report_error+0x32a/0x440)   #1 ffffffff810dc6b0 (asan_check_region+0x30/0x40)   #2 ffffffff810dd4d3 (__tsan_write1+0x13/0x20)   #3 ffffffff811cd19e (ftrace_regex_release+0x1be/0x260)   #4 ffffffff812a1065 (__fput+0x155/0x360)   #5 ffffffff812a12de (____fput+0x1e/0x30)   #6 ffffffff8111708d (task_work_run+0x10d/0x140)   #7 ffffffff810ea043 (do_exit+0x433/0x11f0)   #8 ffffffff810eaee4 (do_group_exit+0x84/0x130)   #9 ffffffff810eafb1 (SyS_exit_group+0x21/0x30)   #10 ffffffff81928782 (system_call_fastpath+0x16/0x1b)  Allocated by thread T5167:   #0 ffffffff810dc778 (asan_slab_alloc+0x48/0xc0)   #1 ffffffff8128337c (__kmalloc+0xbc/0x500)   #2 ffffffff811d9d54 (trace_parser_get_init+0x34/0x90)   #3 ffffffff811cd7b3 (ftrace_regex_open+0x83/0x2e0)   #4 ffffffff811cda7d (ftrace_filter_open+0x2d/0x40)   #5 ffffffff8129b4ff (do_dentry_open+0x32f/0x430)   #6 ffffffff8129b668 (finish_open+0x68/0xa0)   #7 ffffffff812b66ac (do_last+0xb8c/0x1710)   #8 ffffffff812b7350 (path_openat+0x120/0xb50)   #9 ffffffff812b8884 (do_filp_open+0x54/0xb0)   #10 ffffffff8129d36c (do_sys_open+0x1ac/0x2c0)   #11 ffffffff8129d4b7 (SyS_open+0x37/0x50)   #12 ffffffff81928782 (system_call_fastpath+0x16/0x1b)  Shadow bytes around the buggy address:   ffff8800359c9700: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd   ffff8800359c9780: fd fd fd fd fd fd fd fd fa fa fa fa fa fa fa fa   ffff8800359c9800: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa   ffff8800359c9880: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa   ffff8800359c9900: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 =>ffff8800359c9980: 00 00 00 00 00 00 00 00 00 00 00 00 00 00[03]fb   ffff8800359c9a00: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa   ffff8800359c9a80: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa   ffff8800359c9b00: fa fa fa fa fa fa fa fa 00 00 00 00 00 00 00 00   ffff8800359c9b80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00   ffff8800359c9c00: 00 00 00 00 00 00 00 00 fa fa fa fa fa fa fa fa Shadow byte legend (one shadow byte represents 8 application bytes):   Addressable:           00   Partially addressable: 01 02 03 04 05 06 07   Heap redzone:          fa   Heap kmalloc redzone:  fb   Freed heap region:     fd   Shadow gap:            fe  The out-of-bounds access happens on 'parser->buffer[parser->idx] = 0;'  Although the crash happened in ftrace_regex_open() the real bug occurred in trace_get_user() where there's an incrementation to parser->idx without a check against the size. The way it is triggered is if userspace sends in 128 characters (EVENT_BUF_SIZE + 1), the loop that reads the last character stores it and then breaks out because there is no more characters. Then the last character is read to determine what to do next, and the index is incremented without checking size.  Then the caller of trace_get_user() usually nulls out the last character with a zero, but since the index is equal to the size, it writes a nul character after the allocated space, which can corrupt memory.  Luckily, only root user has write access to this file.  Link: [URL]/r/   Reported-by: Andrey Konovalov [URL]>", "target": 0}
{"idx": 3075, "commit_message": "I think I've made it more efficient.", "target": 1}
{"idx": 3386, "commit_message": "Minor performance improvement on script function is_function -- replaced strdb_get with strdb_exists since we don't use the data at all. Modified get_revision to return the revision number rather than it's string, when revision is not known by the server it now returns -1.", "target": 1}
{"idx": 3876, "commit_message": "Introduce ClrArray and API for reading multiple values from arrays (#482)  * Add GetArrayElementsValues API for getting multiple values from array in  one call.    Measurements shows performance of new API is ~4-5 times faster than  calling getting the elements one by one.    * Fix bug return early reading multiple array values    * Introduce new ClrArray type for methods pertaining to array operations.    * Fix nullability and early return    * Update some XML documentation    * Update XML doc    * ReadArray writes into given T[]    * Conform to style convention of rep    * Update Equals(Object?) to support ClrObject and ulong    * Use underlying Read instead of introducing new ReadArray    * Add early exit on GetValuesFromAddress    * Compare to buffer.length not values.length    * Add early out to Equals(object)", "target": 1}
{"idx": 2838, "commit_message": "slight performance fix in disk elevator algorithm", "target": 1}
{"idx": 2267, "commit_message": "Roll Catapult from 70bf08ecdba1 to 644d96b1c3e2 (2 revisions)  [URL]/catapult.git/+log/70bf08ecdba1..644d96b1c3e2  2021-06-16 [URL] [NetLogViewer] Improve search filter performance 2021-06-16 [URL] Minor Python 3 fix  If this roll has caused a breakage, revert this CL and stop the roller using the controls here: [URL]/r/catapult-autoroll Please CC [URL] on the revert to ensure that a human is aware of the problem.  To report a problem with the AutoRoller itself, please file a bug: [URL]/p/skia/issues/entry?template=Autoroller+Bug  Documentation for the AutoRoller is here: [URL]/buildbot/+doc/master/autoroll/README.md  Cq-Include-Trybots: luci.chromium.try:android_optional_gpu_tests_rel;luci.chromium.try:chromeos-kevin-rel;luci.chromium.try:linux_optional_gpu_tests_rel;luci.chromium.try:mac_optional_gpu_tests_rel;luci.chromium.try:win_optional_gpu_tests_rel Bug: chromium:1092952,chromium:1198237 Tbr: [URL]", "target": 1}
{"idx": 731, "commit_message": "ACPICA: ACPICA: Fix for _INI regression  This change fixes a problem introduced by recent commit c34c82b (ACPICA: Predefine names: Add allowed argument types to master info table) in 20130328 where _INI methods are no longer executed properly because of a memory block that is not initialized properly.  ACPICA BZ1016. Tomasz Nowicki [URL]>  References: [URL]/show_bug.cgi?id=1016", "target": 0}
{"idx": 289, "commit_message": "Improve testing infrastructure  Goals: * Be able to run tests from the command line or from the browser using code compiled the same way (as much as possible given browser vs node differences) * Have an `npm run test:watch` that doesn't thrash the CPU * Avoid having to work around the absence of webpack loader issues when running Mocha.  This solution does the following: * Use the new mocha-webpack package for command-line test running (and watching).  In my limited testing this seems to solve the mocha --watch issues with CPU load * Can run a second webpack-dev-server on 8081 that runs the tests in the browser with hot reloading.  The hot reloading makes it so that only tests that were affected by a code change are run.  Webpack's very nature makes it possible to precisely identify which tests need to be re-run, resulting in a pretty sweet workflow * Eliminates the cssModules and shimImageLoader work-arounds * Eliminates Karma * Makes some configuration changes to work around various browser testing issues", "target": 0}
{"idx": 3993, "commit_message": "[PATCH] Wrote the compute_children_node_keys() function in elem.h\n which allows one to generate appropriate node keys while reading in a mesh\n with multiple refinement levels. This allows us to avoid a linear search in\n the MeshRefinement::add_point routine since all the nodes can now be found in\n the nodes hash table.  The resulting performance improvement was significant.", "target": 1}
{"idx": 1969, "commit_message": "Improve `dataclass` handling in `unpack_collections` (#9345)  * Try to detect a custom __init__    * Mutate dataclass instances instead of creating new ones    * Immutable approach to dataclass unpacking    * Code review comments    * Minor", "target": 0}
{"idx": 1774, "commit_message": "Merge pull request #720 from Microsoft-CISL/weimer_size_to_memory  Replace size with explicit memory in examples and tests", "target": 0}
{"idx": 2076, "commit_message": "ENH: Added more efficient versions of GetAdjacentVertices, GetInVertices, GetOutVertices in vtkTree.", "target": 1}
{"idx": 399, "commit_message": "Meta server: keep up to 8K of the most recently received from synchronous replication channel(s) \"future\" log blocks while inactive node is in the process of actively fetching / syncing log and retry merging these log blocks if / when log fetch \"catches up\" to the received log blocks sequence numbers. This mechanism is intended to handle the case when log sync finishes / exits prior to reaching the most recently received log block due to high RPC rate and / or network / IO latency. Implement debug instrumentation to test this logic by allowing to configure log fetch / sync to optionally discard received log data.", "target": 0}
{"idx": 2170, "commit_message": "added more efficient Java 8 code, just incase we switch one day", "target": 1}
{"idx": 3606, "commit_message": "rbtree: reference Documentation/rbtree.txt for usage instructions  I recently started looking at the rbtree code (with an eye towards improving the augmented rbtree support, but I haven't gotten there yet). I noticed a lot of possible speed improvements, which I am now proposing in this patch set.  Patches 1-4 are preparatory: remove internal functions from rbtree.h so that users won't be tempted to use them instead of the documented APIs, clean up some incorrect usages I've noticed (in particular, with the recently added fs/proc/proc_sysctl.c rbtree usage), reference the documentation so that people have one less excuse to miss it, etc.  Patch 5 is a small module I wrote to check the rbtree performance.  It creates 100 nodes with random keys and repeatedly inserts and erases them from an rbtree.  Additionally, it has code to check for rbtree invariants after each insert or erase operation.  Patches 6-12 is where the rbtree optimizations are done, and they touch only that one file, lib/rbtree.c .  I am getting good results out of these - in my small benchmark doing rbtree insertion (including search) and erase, I'm seeing a 30% runtime reduction on Sandybridge E5, which is more than I initially thought would be possible.  (the results aren't as impressive on my two other test hosts though, AMD barcelona and Intel Westmere, where I am seeing 14% runtime reduction only).  The code size - both source (ommiting comments) and compiled - is also shorter after these changes.  However, I do admit that the updated code is more arduous to read - one big reason for that is the removal of the tree rotation helpers, which added some overhead but also made it easier to reason about things locally.  Overall, I believe this is an acceptable compromise, given that this code doesn't get modified very often, and that I have good tests for it.  Upon Peter's suggestion, I added comments showing the rtree configuration before every rotation.  I think they help; however it's still best to have a copy of the cormen/leiserson/rivest book when digging into this code.  This patch: reference Documentation/rbtree.txt for usage instructions  include/linux/rbtree.h included some basic usage instructions, while Documentation/rbtree.txt had some more complete and easier to follow instructions.  Replacing the former with a reference to the latter.", "target": 1}
{"idx": 1996, "commit_message": "change agora.js so it uses path relative to directory of file, fix memory leak from eventlisteners, defer next process request to next tick, add a quit function", "target": 0}
{"idx": 3123, "commit_message": "- Modifed patch by ccourtne: made the tracker module take advantage of the node_comment_statistics table.  Improves performance of the tracker page by facter 10 because it eliminates up to 20 SQL queries.", "target": 1}
{"idx": 1918, "commit_message": "VM: Simplify dispatcher code for closure calls.  The getter call to \".call\" can be avoided for Function objects, since it just returns the receiver there.  This makes the unoptimized code smaller. Optimized code will only be affected if the getter call was not inlined before.  [URL]  Review URL: [URL]//890573002", "target": 0}
{"idx": 3103, "commit_message": "Much more efficient to use a border on the photoset blocks rather than trying to dynamically calculate the widths all the time!", "target": 1}
{"idx": 3246, "commit_message": "finishing up some of the performance testing.  Found a bug in one of the edge files.", "target": 0}
{"idx": 1057, "commit_message": "ccutil/ambigs: Optimize tesseract::UnicharIdArrayUtils::compare  The compare method is called very often, so even small improvements are important.  The new code avoids one comparison in each loop iteration. This results in smaller code (60 bytes for x86_64, gcc).", "target": 1}
{"idx": 1940, "commit_message": "Memory Tracking/Cleanup (#105)  * Add general structure definitions    * Add tests, style, and buf fixes    * Rename block to page    * Address feedback    * Style    * Add dealloc callback    * Add API status codes, refactor error handling    * Remove dealloc return and style fixes    * style fix    * Linker errors    * remove dealloc return    * Add fields for tracking and clearing memory    * Add cleanup to complete    * Style fixes    * Style fixes    * Add constructor and null pointers after clear    * Refactor constructor    * Use empty    * Refactor public interface into seperate header    * Zero initialize    * Document command ratio    * Refactor switch return structure    * Address comments    * Use uint64_t, style    * Include blocks    * Final cleanup    * Add newline to test/translator/BUILD    * Update comment", "target": 0}
{"idx": 3819, "commit_message": "Merge pull request #5 from LucaColonnello/development  perf(reducer): Improve reducer performance and helpful indicators", "target": 1}
{"idx": 2292, "commit_message": "BOY: rewrite labelFigure for performance optimization and rename LabelFigure to TextFigure.", "target": 1}
{"idx": 3851, "commit_message": "Received a patch from Jonathan Hudson [URL]> to implement quick visibility testing for particle systems (i.e. the DrawTest() method). This means that putting a lot of particle systems in a sector will now be more efficient as only the ones that need to be drawn will be considered for drawing.", "target": 1}
{"idx": 2999, "commit_message": "Portlet support: serve resources via portlet for improved performance.", "target": 1}
{"idx": 2340, "commit_message": "New version of COMPONENT_REPS_TRANS  The new method is a bit faster and uses less memory.", "target": 1}
{"idx": 1170, "commit_message": "Throttle DOM timers on hidden pages. [URL]/show_bug.cgi?id=98474  Patch by Kiran Muppala [URL]> on 2012-10-08 Reviewed by Maciej Stachowiak.  Source/JavaScriptCore:  Add HIDDEN_PAGE_DOM_TIMER_THROTTLING feature define.  * Configurations/FeatureDefines.xcconfig:  Source/WebCore:  When the visibility of a page changes to \"hidden\", all it's DOM timers are updated to align their fire times on one second intervals.  This limits the number of CPU wakes due to a hidden pages to one per second.  Test: fast/dom/timer-throttling-hidden-page.html  * Configurations/FeatureDefines.xcconfig: * WebCore.exp.in: * dom/Document.cpp: (WebCore): (WebCore::Document::timerAlignmentInterval): Read Page::timerAlignmentInterval and pass it along to DOMTimer.  * dom/Document.h: (Document): * dom/ScriptExecutionContext.cpp: (WebCore): (WebCore::ScriptExecutionContext::didChangeTimerAlignmentInterval): Scan through self DOM Timers and tell them to recompute their fire time based on the updated alignment interval. (WebCore::ScriptExecutionContext::timerAlignmentInterval):  * dom/ScriptExecutionContext.h: (ScriptExecutionContext): * page/DOMTimer.cpp: (WebCore): (WebCore::DOMTimer::alignedFireTime): If the document's alignment interval is non zero, round up the fire time to the next multiple of alignment interval.  * page/DOMTimer.h: (DOMTimer): (WebCore::DOMTimer::defaultTimerAlignmentInterval): (WebCore::DOMTimer::setDefaultTimerAlignmentInterval): * page/Page.cpp: (WebCore::Page::Page): (WebCore): (WebCore::Page::setTimerAlignmentInterval): (WebCore::Page::timerAlignmentInterval): (WebCore::Page::setVisibilityState): Getter and Setter for alignment interval.  Expose setVisibilityState if either PAGE_VISIBILITY_API is enabled or if HIDDEN_PAGE_DOM_TIMER_REDUCTION is enabled.  * page/Page.h: (Page): * page/Settings.cpp: (WebCore): (WebCore::Settings::setDefaultDOMTimerAlignmentInterval): (WebCore::Settings::defaultDOMTimerAlignmentInterval): (WebCore::Settings::setDOMTimerAlignmentInterval): (WebCore::Settings::domTimerAlignmentInterval): * page/Settings.h: (Settings): * page/SuspendableTimer.cpp: (WebCore::SuspendableTimer::suspend): Save the time remaining to the original unaligned fire time, so that on resuming, the fire time will be correctly aligned using the latest alignment interval.  * platform/ThreadTimers.cpp: (WebCore::ThreadTimers::sharedTimerFiredInternal): Clear m_unalignedNextFireTime along with m_nextFireTime to keep them always in sync.  * platform/Timer.cpp: (WebCore::TimerBase::TimerBase): (WebCore::TimerBase::setNextFireTime): Save the requested fire time in m_unalignedNextFireTime and set m_nextFireTime to the aligned value.  The unalinged value is used to recompute fire time if alignment interval changes. (WebCore): (WebCore::TimerBase::didChangeAlignmentInterval): Recompute next fire time from m_unalignedNextFireTime. (WebCore::TimerBase::nextUnalignedFireInterval): Interval from current time to the original unaligned fire time.  * platform/Timer.h: (TimerBase): (WebCore::TimerBase::alignedFireTime):  Source/WebKit/mac:  Add HIDDEN_PAGE_DOM_TIMER_THROTTLING feature define and provide a SPI for DumpRenderTree to modify the visibility state of a page.  The latter is needed to test throttling of timers on hidden pages through DumpRenderTree.  * Configurations/FeatureDefines.xcconfig: * WebView/WebView.mm: (-[WebView _setVisibilityState:isInitialState:]): * WebView/WebViewPrivate.h:  Source/WebKit2:  Add HIDDEN_PAGE_DOM_TIMER_THROTTLING feature define.  Use existing code of PAGE_VISIBILITY_API to detect changes to page visibility state.  * Configurations/FeatureDefines.xcconfig: * UIProcess/WebPageProxy.cpp: (WebKit::WebPageProxy::WebPageProxy): Check visibility state on construction. (WebKit::WebPageProxy::initializeWebPage): Send initial visibility state message if HIDDEN_PAGE_DOM_TIMER_THROTTLING is enabled or if PAGE_VISIBILITY_API is enabled. (WebKit::WebPageProxy::viewStateDidChange): When PAGE_VISIBILITY_API is not enabled, compare new visibility against WebPageProxy::m_isVisible, to minimize number of messages sent. Remove unnecessary second call to PageClient::isViewVisible for updating visibility state.  * WebProcess/InjectedBundle/InjectedBundle.cpp: (WebKit::InjectedBundle::setPageVisibilityState): WebKitTestRunner uses this method to implement testRunner.setPageVisibility(), hence enable it for testing hidden page timer throttling as well.  * WebProcess/WebPage/WebPage.cpp: (WebKit): (WebKit::WebPage::setVisibilityState): Ensure Page::setVisibilityState is called either if PAGE_VISIBILITY_API is enabled or if HIDDEN_PAGE_DOM_TIMER_THROTTLING is enabled.  * WebProcess/WebPage/WebPage.h: (WebPage): * WebProcess/WebPage/WebPage.messages.in:  Tools:  Implement testRunner.setPageVisibility on mac for testing throttling of timers on hidden pages using DumpRenderTree.  * DumpRenderTree/mac/Configurations/Base.xcconfig: Fix build error on mac-ews bot.  Add JSC copy of ICU headers to search path.  * DumpRenderTree/mac/TestRunnerMac.mm: (TestRunner::resetPageVisibility): (TestRunner::setPageVisibility):  WebKitLibraries:  Add HIDDEN_PAGE_DOM_TIMER_THROTTLING feature define.  * win/tools/vsprops/FeatureDefines.vsprops: * win/tools/vsprops/FeatureDefinesCairo.vsprops:  LayoutTests:  Add a test for DOM timer throttling on hidden pages.  * fast/dom/timer-throttling-hidden-page-expected.txt: Added. * fast/dom/timer-throttling-hidden-page.html: Added. * platform/chromium/TestExpectations: * platform/efl/TestExpectations: * platform/gtk/TestExpectations: * platform/qt/TestExpectations: * platform/win/TestExpectations: Skip the test since HIDDEN_PAGE_DOM_TIMER_THROTTLING is not enabled by default.", "target": 0}
{"idx": 555, "commit_message": "[#228] Fix performance issues with Multi-File QuickOutline View  Add timer inside the filter's modify listener so that refresh only happens after a certain amount of time (500ms), avoiding refresh at each text input.", "target": 1}
{"idx": 2455, "commit_message": "improved looks of performance data screen", "target": 0}
{"idx": 1205, "commit_message": "working version of the Gauss-Seidel Preconditioner We need to optimize (like crazy) the preconditioner", "target": 0}
{"idx": 3436, "commit_message": "Echo notification oo-ui-popupWidget-anchor should point to icon  In Vector, these rules result in the anchor pointing to the wrong place. They seem to be improve things in Minerva, so these are restricted to that skin.  Bug: T276566", "target": 0}
{"idx": 1878, "commit_message": "improve verifier error about unterminated block to include function name, patch by Yuri", "target": 0}
{"idx": 2249, "commit_message": "Update RelativeDateFormat.java (#4111)  simplify logic and improve performance", "target": 1}
{"idx": 2618, "commit_message": "sched: Implement smarter wake-affine logic  The wake-affine scheduler feature is currently always trying to pull the wakee close to the waker. In theory this should be beneficial if the waker's CPU caches hot data for the wakee, and it's also beneficial in the extreme ping-pong high context switch rate case.  Testing shows it can benefit hackbench up to 15%.  However, the feature is somewhat blind, from which some workloads such as pgbench suffer. It's also time-consuming algorithmically.  Testing shows it can damage pgbench up to 50% - far more than the benefit it brings in the best case.  So wake-affine should be smarter and it should realize when to stop its thankless effort at trying to find a suitable CPU to wake on.  This patch introduces 'wakee_flips', which will be increased each time the task flips (switches) its wakee target.  So a high 'wakee_flips' value means the task has more than one wakee, and the bigger the number, the higher the wakeup frequency.  Now when making the decision on whether to pull or not, pay attention to the wakee with a high 'wakee_flips', pulling such a task may benefit the wakee. Also imply that the waker will face cruel competition later, it could be very cruel or very fast depends on the story behind 'wakee_flips', waker therefore suffers.  Furthermore, if waker also has a high 'wakee_flips', that implies that multiple tasks rely on it, then waker's higher latency will damage all of them, so pulling wakee seems to be a bad deal.  Thus, when 'waker->wakee_flips / wakee->wakee_flips' becomes higher and higher, the cost of pulling seems to be worse and worse.  The patch therefore helps the wake-affine feature to stop its pulling work when:          wakee->wakee_flips > factor &&         waker->wakee_flips > (factor * wakee->wakee_flips)  The 'factor' here is the number of CPUs in the current CPU's NUMA node, so a bigger node will lead to more pulling since the trial becomes more severe.  After applying the patch, pgbench shows up to 40% improvements and no regressions.  Tested with 12 cpu x86 server and tip 3.10.0-rc7.  The percentages in the final column highlight the areas with the biggest wins, all other areas improved as well:          pgbench                    base        smart          | db_size | clients |  tps  |        |  tps  |         +---------+---------+-------+   +-------+         | 22 MB   |       1 | 10598 |   | 10796 |         | 22 MB   |       2 | 21257 |   | 21336 |         | 22 MB   |       4 | 41386 |   | 41622 |         | 22 MB   |       8 | 51253 |   | 57932 |         | 22 MB   |      12 | 48570 |   | 54000 |         | 22 MB   |      16 | 46748 |   | 55982 | +19.75%         | 22 MB   |      24 | 44346 |   | 55847 | +25.93%         | 22 MB   |      32 | 43460 |   | 54614 | +25.66%         | 7484 MB |       1 |  8951 |   |  9193 |         | 7484 MB |       2 | 19233 |   | 19240 |         | 7484 MB |       4 | 37239 |   | 37302 |         | 7484 MB |       8 | 46087 |   | 50018 |         | 7484 MB |      12 | 42054 |   | 48763 |         | 7484 MB |      16 | 40765 |   | 51633 | +26.66%         | 7484 MB |      24 | 37651 |   | 52377 | +39.11%         | 7484 MB |      32 | 37056 |   | 51108 | +37.92%         | 15 GB   |       1 |  8845 |   |  9104 |         | 15 GB   |       2 | 19094 |   | 19162 |         | 15 GB   |       4 | 36979 |   | 36983 |         | 15 GB   |       8 | 46087 |   | 49977 |         | 15 GB   |      12 | 41901 |   | 48591 |         | 15 GB   |      16 | 40147 |   | 50651 | +26.16%         | 15 GB   |      24 | 37250 |   | 52365 | +40.58%         | 15 GB   |      32 | 36470 |   | 50015 | +37.14%", "target": 1}
{"idx": 3787, "commit_message": "[FIX] website: refactore parallax snippet (perf / browser compatibility)  * Do not read multiple DOM data on each scroll. Simply read this when necessary (edition / initialization). * Throttle scroll event and debounce resize events (-> performance in edition and navigation improved). * Do not save useless data in the DOM. * Have the parallax state consistent if the page undergo other changes * Simplify DOM structure and LESS     - Allow to better see how to place snippets inside the area     - Before this commit, default parallax had different height on     chrome and firefox", "target": 1}
{"idx": 3748, "commit_message": "Auto merge of #44978 - jamesmunns:armv5te-os-atomics, r=alexcrichton  Allow atomic operations up to 32 bits  The ARMv5te platform does not have instruction-level support for atomics, however the kernel provides [user space helpers] which can be used to perform atomic operations. When linked with `libgcc`, the atomic symbols needed by Rust will be provided, rather than CPU level intrinsics.  [user space helpers]: [URL]/doc/Documentation/arm/kernel_user_helpers.txt  32-bit versions of these kernel level helpers were introduced in Linux Kernel 2.6.12, and 64-bit version of these kernel level helpers were introduced in Linux Kernel 3.1. I have selected 32 bit versions as std currently only requires Linux version 2.6.18 and above as far as I am aware.  As this target is specifically linux and gnueabi, it is reasonable to assume the Linux Kernel and libc will be available for the target. There is a large performance penalty, as we are not using CPU level intrinsics, however this penalty is likely preferable to not having the target at all.  I have used this change in a custom target (along with xargo) to build std, as well as a number of higher level crates.  ## Additional information  For reference, here is what a a code snippet decompiles to:  ```rust use std::sync::atomic::{AtomicIsize, Ordering};  #[no_mangle] pub extern fn foo(a: &AtomicIsize) -> isize {      a.fetch_add(1, Ordering::SeqCst) } ```  ``` Disassembly of section .text.foo:  00000000 <foo>:    0:\te92d4800 \tpush\t{fp, lr}    4:\te3a01001 \tmov\tr1, #1    8:\tebfffffe \tbl\t0 <__sync_fetch_and_add_4>    c:\te8bd8800 \tpop\t{fp, pc} ```  Which in turn is provided by `libgcc.a`, which has code which looks like this:  ``` Disassembly of section .text:  00000000 <__sync_fetch_and_add_4>:        0:\te92d40f8 \tpush\t{r3, r4, r5, r6, r7, lr}        4:\te1a05000 \tmov\tr5, r0        8:\te1a07001 \tmov\tr7, r1        c:\te59f6028 \tldr\tr6, [pc, #40]\t; 3c <__sync_fetch_and_add_4+0x3c>       10:\te5954000 \tldr\tr4, [r5]       14:\te1a02005 \tmov\tr2, r5       18:\te1a00004 \tmov\tr0, r4       1c:\te0841007 \tadd\tr1, r4, r7       20:\te1a0e00f \tmov\tlr, pc       24:\te12fff16 \tbx\tr6       28:\te3500000 \tcmp\tr0, #0       2c:\t1afffff7 \tbne\t10 <__sync_fetch_and_add_4+0x10>       30:\te1a00004 \tmov\tr0, r4       34:\te8bd40f8 \tpop\t{r3, r4, r5, r6, r7, lr}       38:\te12fff1e \tbx\tlr       3c:\tffff0fc0 \t.word\t0xffff0fc0 ```  Where you can see the reference to `0xffff0fc0`, which is provided by the [user space helpers].", "target": 0}
{"idx": 3879, "commit_message": "Admin: improve picotable filters choice defaults  Choice default as false was causing unexpected behavior. Also when the data is empty the default values was not applied at all.  While at it make both groups and shops lists values list to improve performance on situation when there is a lot of groups or shops.", "target": 1}
{"idx": 3380, "commit_message": "fix: improve performance of permissions filter queries", "target": 1}
{"idx": 117, "commit_message": "start on adding the own langues, this version create a memory leak if u try run this tool in translate mode. but not in  disambler mode. (only true for ppc brain about memory leak)", "target": 0}
{"idx": 3885, "commit_message": "Refactor path filter  This does not affect functionality, but it unifies the way filters are applies, facilitating more filters.  The change in performance is so small it may not be noticeable. When there is no filter, which is common (except maybe with Winapp2.ini) the speed improves by -0.6%, and when there is a regex filter, speed declines by 1%.  R code follows  rate_none_new=c(19667.5321348,19655.5826713,19751.9748071) rate_none_old=c(19497.4911467,19612.8964198,19579.7100191) mean(rate_none_new) mean(rate_none_old) (mean(rate_none_old)-mean(rate_none_new))/mean(rate_none_old)  rate_regex_new=c(18075.920258,18164.2513082,18066.5536692) rate_regex_old=c(18242.9319634,18329.5043295,18334.9785095) mean(rate_regex_new) mean(rate_regex_old) (mean(rate_regex_old)-mean(rate_regex_new))/mean(rate_regex_old)", "target": 0}
{"idx": 368, "commit_message": "Merge a big batch of documentation fixes for escaping, marking URLs, places where verbatim text went off the end of the page on the PDF, and various other improvements (closes issue #10307, IgorG)", "target": 0}
{"idx": 4044, "commit_message": "[PATCH] Removed Reaction-Field-nec\n\nThe RF no exclusion correction option was only introduced for\nbackward compatibility and a performance advantage for systems\nwith only rigid molecules (e.g. water). For all other systems\nthe forces are incorrect. The Verlet scheme did not support this\noption and if it would, it wouldn't even improve performance.\n\nChange-Id: Ic22ccf76d50b5bb7951fcac2293621b5eef285c5", "target": 1}
{"idx": 1750, "commit_message": "Refactored Logic.Prover.Proof_status:   now a Record datatype with only two variants:         (1) Proof_status for goals         (2) Consistency   The status of a goal is now represented by a separate enumerated datatype:     GoalStatus   added field goalIsUsedInProof which should be True if the goal was in the     list of used formulae other changes:   * improved display of proof details in GUI.ProofManagement   * added todo point for Isabelle.IsaProve   * Logic.Logic.Sentences demands Ord instancew for proof_tree now       so it was easier to derive the Ord instance of Proof_status automatically   * SPASS removes now the goal from the list of used axioms and stores the       derived information properly", "target": 0}
{"idx": 2729, "commit_message": "slight performance optimization, bug fix  Fixed a bug where a plot larger than the saved plot would cause the plugin to crash. Smaller plots should just cause only a part of the saved plot to be loaded", "target": 1}
{"idx": 1530, "commit_message": "- Improved node_get() so that it will try to skip one additional query   if possible (ie. to reduce the number of queries).  - Automatically removed tabs and trailing spaces from the poll.module.", "target": 0}
{"idx": 2563, "commit_message": "Merge pull request #426 from PasaLab/Fix-Bug-in-Performance  [TACHYON-148] Fix bug in tachyon.examples.Performance", "target": 0}
{"idx": 4113, "commit_message": "[PATCH] more efficient jacobian of mapping modes", "target": 1}
{"idx": 1855, "commit_message": "several trunc* bugs fixed - to accomplish that, search algorithm was somewhat changed.", "target": 0}
{"idx": 3432, "commit_message": "Performance improvement from ENG-2461: WAN repl slowdown. I identified hashing of results as a non-trivial part of the problem and made that faster. The rest of the problem is probably serialization work. More in the ticket.", "target": 1}
{"idx": 2227, "commit_message": "ring-buffer: Fix first commit on sub-buffer having non-zero delta  commit d651aa1d68a2f0a7ee65697b04c6a92f8c0a12f2 upstream.  Each sub-buffer (buffer page) has a full 64 bit timestamp. The events on that page use a 27 bit delta against that timestamp in order to save on bits written to the ring buffer. If the time between events is larger than what the 27 bits can hold, a \"time extend\" event is added to hold the entire 64 bit timestamp again and the events after that hold a delta from that timestamp.  As a \"time extend\" is always paired with an event, it is logical to just allocate the event with the time extend, to make things a bit more efficient.  Unfortunately, when the pairing code was written, it removed the \"delta = 0\" from the first commit on a page, causing the events on the page to be slightly skewed.  Fixes: 69d1b839f7ee \"ring-buffer: Bind time extend and data events together", "target": 0}
{"idx": 3743, "commit_message": "Improve --help performance for x.py  Since compiling the bootstrap command doesn't require any submodules, we can skip updating submodules when a --help command is passed in. On my machine, this saves 1 minute if the submodules are already downloaded, and 10 minutes if run on a clean repo.  This commit also adds a message before compiling/downloading anything when a --help command is passed in, to tell the user WHY --help takes so long to complete. It also points the user to the bootstrap README.md for faster help.  Finally, this fixes one warning message that still referenced using make instead of x.py, even though x.py is now the standard way of building rust.", "target": 1}
{"idx": 2730, "commit_message": "ARM: mutex: use generic atomic_dec-based implementation for ARMv6+  Commit a76d7bd96d65 (\"ARM: 7467/1: mutex: use generic xchg-based implementation for ARMv6+\") removed the barrier-less, ARM-specific mutex implementation in favour of the generic xchg-based code.  Since then, a bug was uncovered in the xchg code when running on SMP platforms, due to interactions between the locking paths and the MUTEX_SPIN_ON_OWNER code. This was fixed in 0bce9c46bf3b (\"mutex: place lock in contended state after fastpath_lock failure\"), however, the atomic_dec-based mutex algorithm is now marginally more efficient for ARM (~0.5% improvement in hackbench scores on dual A15).  This patch moves ARMv6+ platforms to the atomic_dec-based mutex code.", "target": 1}
{"idx": 3043, "commit_message": "Renamed create_face_neighbors_index() to its_face_edge_ids(). Renamed its_create_neighbors_index() / its_create_neighbors_index_par() to its_face_neighbors() / its_face_neighbors_par(). New variant of its_face_edge_ids() to create edge IDs from face neighbors. Fixed some incorrect use of _NDEBUG, it should be NDEBUG. PrintObject::slice_support_volumes() returns newly Polygons, which are cheaper than ExPolygons. Updated SeamPlacer and SupportMaterial to use regions defined as Polygons, not ExPolygons. TriangleSelector::get_facets_strict() returning a patch with T-joints retriangulated. New slice_mesh_slabs() - slicing projections of a triangle patch into top / bottom layers of slices, for MMU top / bottom segmentation. TriangleMeshSlicer - use 64 mutexes instead of one when scattering sliced triangles into layers. This makes a big difference on modern many core desktop computers. When applying MM segmented regions to input regions, the split regions are now re-merged with 10x higher positive offset epsilon to avoid creating gaps. When testing for existence of paint-on supports or seam, use a more efficient has_facets() test, which does not deserialize into the expensive TriangleSelector tree structure. GLIndexedVertexArray newly uses Eigen::AlignedBox<float, 3> for efficiency instead of our double based BoundingBoxf3. Improved MMU painting refresh speed by optimizing generation of the vertex buffers. Refactored MMU segmentation - projection of painted surfaces from top / bottom. \t1) Parallelized. \t2) Using the new slice_mesh_slabs() instead of projecting one triangle by the other and merging them with Clipper.", "target": 1}
{"idx": 4041, "commit_message": "[PATCH] Beginning to add support for freezing the sparsity pattern of\n graphs and sparse matrices to improve the performance of subsequent updates", "target": 1}
{"idx": 3628, "commit_message": "mutex: Make more scalable by doing less atomic operations  In the __mutex_lock_common() function, an initial entry into the lock slow path will cause two atomic_xchg instructions to be issued. Together with the atomic decrement in the fast path, a total of three atomic read-modify-write instructions will be issued in rapid succession. This can cause a lot of cache bouncing when many tasks are trying to acquire the mutex at the same time.  This patch will reduce the number of atomic_xchg instructions used by checking the counter value first before issuing the instruction. The atomic_read() function is just a simple memory read. The atomic_xchg() function, on the other hand, can be up to 2 order of magnitude or even more in cost when compared with atomic_read(). By using atomic_read() to check the value first before calling atomic_xchg(), we can avoid a lot of unnecessary cache coherency traffic. The only downside with this change is that a task on the slow path will have a tiny bit less chance of getting the mutex when competing with another task in the fast path.  The same is true for the atomic_cmpxchg() function in the mutex-spin-on-owner loop. So an atomic_read() is also performed before calling atomic_cmpxchg().  The mutex locking and unlocking code for the x86 architecture can allow any negative number to be used in the mutex count to indicate that some tasks are waiting for the mutex. I am not so sure if that is the case for the other architectures. So the default is to avoid atomic_xchg() if the count has already been set to -1. For x86, the check is modified to include all negative numbers to cover a larger case.  The following table shows the jobs per minutes (JPM) scalability data on an 8-node 80-core Westmere box with a 3.7.10 kernel. The numactl command is used to restrict the running of the high_systime workloads to 1/2/4/8 nodes with hyperthreading on and off.  +-----------------+-----------+------------+----------+ |  Configuration  | Mean JPM  |  Mean JPM  | % Change | |\t\t  | w/o patch | with patch |\t      | +-----------------+-----------------------------------+ |\t\t  |      User Range 1100 - 2000\t      | +-----------------+-----------------------------------+ | 8 nodes, HT on  |    36980   |   148590  | +301.8%  | | 8 nodes, HT off |    42799   |   145011  | +238.8%  | | 4 nodes, HT on  |    61318   |   118445  |  +51.1%  | | 4 nodes, HT off |   158481   |   158592  |   +0.1%  | | 2 nodes, HT on  |   180602   |   173967  |   -3.7%  | | 2 nodes, HT off |   198409   |   198073  |   -0.2%  | | 1 node , HT on  |   149042   |   147671  |   -0.9%  | | 1 node , HT off |   126036   |   126533  |   +0.4%  | +-----------------+-----------------------------------+ |\t\t  |       User Range 200 - 1000\t      | +-----------------+-----------------------------------+ | 8 nodes, HT on  |   41525    |   122349  | +194.6%  | | 8 nodes, HT off |   49866    |   124032  | +148.7%  | | 4 nodes, HT on  |   66409    |   106984  |  +61.1%  | | 4 nodes, HT off |  119880    |   130508  |   +8.9%  | | 2 nodes, HT on  |  138003    |   133948  |   -2.9%  | | 2 nodes, HT off |  132792    |   131997  |   -0.6%  | | 1 node , HT on  |  116593    |   115859  |   -0.6%  | | 1 node , HT off |  104499    |   104597  |   +0.1%  | +-----------------+------------+-----------+----------+  At low user range 10-100, the JPM differences were within +/-1%. So they are not that interesting.  AIM7 benchmark run has a pretty large run-to-run variance due to random nature of the subtests executed. So a difference of less than +-5% may not be really significant.  This patch improves high_systime workload performance at 4 nodes and up by maintaining transaction rates without significant drop-off at high node count.  The patch has practically no impact on 1 and 2 nodes system.  The table below shows the percentage time (as reported by perf record -a -s -g) spent on the __mutex_lock_slowpath() function by the high_systime workload at 1500 users for 2/4/8-node configurations with hyperthreading off.  +---------------+-----------------+------------------+---------+ | Configuration | %Time w/o patch | %Time with patch | %Change | +---------------+-----------------+------------------+---------+ |    8 nodes    |      65.34%     |      0.69%       |  -99%   | |    4 nodes    |       8.70%\t  |      1.02%\t     |  -88%   | |    2 nodes    |       0.41%     |      0.32%       |  -22%   | +---------------+-----------------+------------------+---------+  It is obvious that the dramatic performance improvement at 8 nodes was due to the drastic cut in the time spent within the __mutex_lock_slowpath() function.  The table below show the improvements in other AIM7 workloads (at 8 nodes, hyperthreading off).  +--------------+---------------+----------------+-----------------+ |   Workload   | mean % change | mean % change  | mean % change   | |              | 10-100 users  | 200-1000 users | 1100-2000 users | +--------------+---------------+----------------+-----------------+ | alltests     |     +0.6%     |   +104.2%      |   +185.9%       | | five_sec     |     +1.9%     |     +0.9%      |     +0.9%       | | fserver      |     +1.4%     |     -7.7%      |     +5.1%       | | new_fserver  |     -0.5%     |     +3.2%      |     +3.1%       | | shared       |    +13.1%     |   +146.1%      |   +181.5%       | | short        |     +7.4%     |     +5.0%      |     +4.2%       | +--------------+---------------+----------------+-----------------+", "target": 1}
{"idx": 159, "commit_message": "Use absolute-url instead of passing baseUrl's around  While at it, some minor fixes and improvements, and make account enrollment emails contain the right url.", "target": 0}
{"idx": 3788, "commit_message": "fixed: #42 Add conversion from ExpressionInfo to Expression fixed: Copyright dates changed: Added note about performance expectations into readme", "target": 0}
{"idx": 2768, "commit_message": "HUE-7198 [editor] Remove unused onBlur code to improve IE 11 debug performance  For some reason the exception handling make the IE 11 dev tools sluggish. The event handler always hits the catch block as there's no global viewModel, the lastWrittenSnippet cache is not used anymore so removing it.", "target": 1}
{"idx": 2962, "commit_message": "some more performance fixes related to deserializing bulk responses, also updated protocolload tests so that it covers more areas of nest", "target": 1}
{"idx": 1062, "commit_message": "Slight improvement to platooning initialisation Stateflow chart  - Vehicles now stabilise at speed, then close the gap before entering   platooning mode - V2V bus updated to include an 'inPlatoon' flag. This enables vehicles to   only begin platooning if their preceding vehicle is already in the   platoon - Generally tidied up systems, particularly lateral platoon control - Changed from understeer gradient approach for steering control to   conventional PI controller regulating curvature. U/S grad was difficult   to estimate from low data rate measurements, lead to oscillitory   behaviour", "target": 0}
{"idx": 3253, "commit_message": "Fix for old versions of PyPy.  Cython + Abstract Base Classes + Old PyPy doesn't work quite right. For example, `isinstance(1, numbers.Integral)` and `isinstance([42], collections.Iterable)` will fail if the code was generated by Cython and run inside an old PyPy versions. To work around this, I replaced the `isinstance(.., some ABC)` checks with appropriate `hasattr` checks.  This also significantly improves the validation performance for collections, etc.", "target": 1}
{"idx": 2157, "commit_message": "Use QString::at(0) instead of left(1), since it's more efficient and doesn't allocate a QString", "target": 1}
{"idx": 3113, "commit_message": "Improve performance for small index and large dict.", "target": 1}
{"idx": 3389, "commit_message": "PR middle-end/85090 \t* config/i386/sse.md (V): Add V64QI and V32HI for TARGET_AVX512F. \t(V_128_256): New mode iterator. \t(*avx512dq_vextract<shuffletype>64x2_1 splitter): New define_split. \t(*avx512f_vextract<shuffletype>32x4_1 splitter): Likewise. \t(xop_pcmov_<mode><avxsizesuffix>): Use V_128_256 mode iterator instead \tof V. \t* config/i386/i386.c (ix86_expand_vector_set): Improve V32HImode and \tV64QImode expansion for !TARGET_AVX512BW && TARGET_AVX512F.  \t* gcc.target/i386/avx512f-pr85090-1.c: New test. \t* gcc.target/i386/avx512f-pr85090-2.c: New test. \t* gcc.target/i386/avx512f-pr85090-3.c: New test. \t* gcc.target/i386/avx512bw-pr85090-2.c: New test. \t* gcc.target/i386/avx512bw-pr85090-3.c: New test.", "target": 0}
{"idx": 670, "commit_message": "ARM: OMAP4: PRM: move omap4xxx_prm_init earlier in init order  OMAP4 has different ordering of PRM and CM init calls in the early init. Re-oder these accordingly for OMAP4 also. This is needed so that we can do some optimizations in the following patches for the PRCM init.", "target": 1}
{"idx": 2024, "commit_message": "Merge pull request #26 from tanoabeleyra/patch  Improve docs", "target": 0}
{"idx": 9, "commit_message": "Merge pull request #7 from zalando/improve_readme  merging as discussed with @LauriZalando", "target": 0}
{"idx": 2309, "commit_message": "vfs: fix bad hashing of dentries  commit 99d263d4c5b2f541dfacb5391e22e8c91ea982a6 upstream.  Josef Bacik found a performance regression between 3.2 and 3.10 and narrowed it down to commit bfcfaa77bdf0 (\"vfs: use 'unsigned long' accesses for dcache name comparison and hashing\"). He reports:   \"The test case is essentially        for (i = 0; i < 1000000; i++)               mkdir(\"a$i\");    On xfs on a fio card this goes at about 20k dir/sec with 3.2, and 12k   dir/sec with 3.10.  This is because we spend waaaaay more time in   __d_lookup on 3.10 than in 3.2.    The new hashing function for strings is suboptimal for <   sizeof(unsigned long) string names (and hell even > sizeof(unsigned   long) string names that I've tested).  I broke out the old hashing   function and the new one into a userspace helper to get real numbers   and this is what I'm getting:        Old hash table had 1000000 entries, 0 dupes, 0 max dupes       New hash table had 12628 entries, 987372 dupes, 900 max dupes       We had 11400 buckets with a p50 of 30 dupes, p90 of 240 dupes, p99 of 567 dupes for the new hash    My test does the hash, and then does the d_hash into a integer pointer   array the same size as the dentry hash table on my system, and then   just increments the value at the address we got to see how many   entries we overlap with.    As you can see the old hash function ended up with all 1 million   entries in their own bucket, whereas the new one they are only   distributed among ~12.5k buckets, which is why we're using so much   more CPU in __d_lookup\".  The reason for this hash regression is two-fold:   - On 64-bit architectures the down-mixing of the original 64-bit    word-at-a-time hash into the final 32-bit hash value is very    simplistic and suboptimal, and just adds the two 32-bit parts    together.     In particular, because there is no bit shuffling and the mixing    boundary is also a byte boundary, similar character patterns in the    low and high word easily end up just canceling each other out.   - the old byte-at-a-time hash mixed each byte into the final hash as it    hashed the path component name, resulting in the low bits of the hash    generally being a good source of hash data.  That is not true for the    word-at-a-time case, and the hash data is distributed among all the    bits.  The fix is the same in both cases: do a better job of mixing the bits up and using as much of the hash data as possible.  We already have the \"hash_32|64()\" functions to do that.  Reported-by: Josef Bacik [URL]> Cc: Al Viro [URL].uk> Cc: Christoph Hellwig [URL]> Cc: Chris Mason [URL]> Cc: [URL]", "target": 1}
{"idx": 3980, "commit_message": "fix performance problem with tactical overview", "target": 1}
{"idx": 2922, "commit_message": "Non-intrusive but significant performance improvement when Squid is running as a https reverse proxy (ssl enabled peers), allowing Squid to reuse the same SSL session.", "target": 1}
{"idx": 2881, "commit_message": "crypto: msm: Update clock vote for improved performance", "target": 1}
{"idx": 1719, "commit_message": "UI improvements  - Added app logo - Auto login feature - Login and Sign up field validations", "target": 0}
{"idx": 3644, "commit_message": "Update issue #185 Status: Fixed The code to support this was already in place, but did not work because Application.Exit() had been invoked, making all messageboxes return Cancel without showing.  I also improved the logic a bit so a cancel does not invoke the cleanup afterwards, making the exit procedure faster.  I also added checks for the stop command to the code that fetches the signature files, to make the application respond faster to the stop command.", "target": 1}
{"idx": 2589, "commit_message": "usb: ehci: make HC see up-to-date qh/qtd descriptor ASAP  This patch introduces the helper of ehci_sync_mem to flush qtd/qh into memory immediately on some ARM, so that HC can see the up-to-date qtd/qh descriptor asap.  This patch fixs one performance bug on ARM Cortex A9 dual core platform, which has been reported on quite a few ARM machines (OMAP4, Tegra 2, snowball...), see details from link of [URL]/bugs/709245.  The patch has been tested ok on OMAP4 panda A1 board, and the performance of 'dd' over usb mass storage can be increased from 4~5MB/sec to 14~16MB/sec after applying this patch.  Cc: Alan Stern [URL]> Cc: Russell King [URL].uk>", "target": 1}
{"idx": 3979, "commit_message": "Improve associations performance by using symbol callbacks instead of string callbacks. Closes #11108 [adymo]", "target": 1}
{"idx": 1860, "commit_message": "Improved avro parser as replacement for messy avro_to_pyschema", "target": 0}
{"idx": 3269, "commit_message": "pmdabcc: move ext4dist metric under bcc.fs name space  Move ext4 metrics under the bcc.fs performance metrics name space. Print the BPF program to be compiled if debugging enabled. Some completely cosmetic coding style unifications while at it.", "target": 0}
{"idx": 282, "commit_message": "design: define tasks rewards  Design of tasks and rewards programs upon which the network is setup and evaluated.", "target": 0}
{"idx": 3133, "commit_message": "refactor codes to have better performance", "target": 1}
{"idx": 3893, "commit_message": "disabling grayscale filter because of safari performance problem   Former-commit-id: b0ef8fcab4ea8f2fd7e24ef8d8f4ce6615feb7e3 [formerly 10322e9ce962cbe9e28953fef38de6b7d51190f6] [formerly 5c8bc767a470d8eda503c6b23de17ac26212501a [formerly 86e7fcc407da9b6727a94d04248bb0c0123ef9fb]] [formerly 1b60694482c6e9d123e765ba28e24a53afc91b4b [formerly e55d82709faab0d19f9a8ca9e0825fbffc333fdd] [formerly 170a29a3fdea2e3357d592cf253e7a05897c42c2 [formerly 170a29a3fdea2e3357d592cf253e7a05897c42c2 [formerly 1747313655139f9c701ec47176799b908166f92b]]]] Former-commit-id: 3ad28df9cdcbcd551d5317f8cb9da474b12d4fba [formerly 20a6911a8d80246674bcd5490215f9bae254a0e0] [formerly 420a0b17e12fa549d1c24e3bd2e80d41b58358ed [formerly 3ae19dad2185f4ee2774194af4c2789b7c9835f4]] Former-commit-id: ad94fe049aee31d8eff9c62448ea671d9007353b [formerly 66ae27efaf7340f90dd7546e6fb44467dafda53b] Former-commit-id: b7d4314f093672a6bf78a714c35eb236776aea8f Former-commit-id: 35373cb54cad4f5100116c81c695b55df884e0b9", "target": 1}
{"idx": 2477, "commit_message": "core: Remove member init in business entities  Since the upgrade to GWT 2.5.1, we've seen several cases of GWT pruning member initialization.  To prevent these (and future) bugs, this series of patches removes all such initializations from the packages that should be compiled by GWT. These initialization are either moved to the appropriate constructor(s), or removed them completely if they are redundant. Constants with the wrong modifiers are amended to have static final, and are allowed to be initialized directly.  As a side bonus, this patch offers a minor performance improvement, as some of these members are now only initialized once instead of twice (once in the member initialization and then again via a constructor parameter).  This patch takes care of all the project's business entities, as noted in the subject.", "target": 1}
{"idx": 1497, "commit_message": "improve morphological disambiguation of obja in output", "target": 0}
{"idx": 84, "commit_message": "Merge remote-tracking branch 'origin/development' into feature/IFS-3530-better-overheads-guidance-for-internal-users", "target": 0}
{"idx": 1527, "commit_message": "Discrete model, using histograms  Possible improvement: the model-building phase should abort as soon as the number of classes becomes too large", "target": 0}
{"idx": 1261, "commit_message": "Removing libgdx.so, will be linking dynamically", "target": 0}
{"idx": 3391, "commit_message": "Fixed performance issues with decoding values containing encoded-words... it scaled exponentially for long strings", "target": 1}
{"idx": 2482, "commit_message": "Merge pull request #14 from EricArndt/performanceImprovement  Performance improvement", "target": 1}
{"idx": 1569, "commit_message": "ARM: EXYNOS: Modify S5M8767A ramp delay value  To optimize Buck ramp delay value, Modify S5M8767A ramp delay value from 10mV/us to 25mV/us.", "target": 1}
{"idx": 3397, "commit_message": "Refactored Mom's spaghetti  Made it Crockford compliant, fixed a few performance pitfalls and removed useless code.", "target": 1}
{"idx": 1383, "commit_message": "Add warning in docs on performance when using EXSLT regexp functions", "target": 0}
{"idx": 3495, "commit_message": "Draft ui, bug fixes.  Finished draft ui, draft now playable. Fixed a bug with missing cards that caused very slow performance when debuging. Removed weird charecters from some of players names.", "target": 1}
{"idx": 1153, "commit_message": "network: do not configure static configs more than once simultaneously", "target": 0}
{"idx": 3329, "commit_message": "Optimized detail query flow and cleanup (#691)  * Optimizing detail query    * Optimizing detail query flow    * Optimizing detail query flow    * Optimized raw detail query to improve push up performance.    * Fixed bugs    * reverted wrong check in    * Rebased the code    * Removed aggregation from core    * Refactored core package and fixed test cases    * Fixed bugs    * Fixed review comments and deleted aggregate classes after merge from master    * Removed unused code    * Optimized scanner flow    * Optimized scanner flow    * Optimized scanning flow    * Optimized scanner flow    * Refactored code    * Refactored code    * Removed unused code    * Reverted unnecessary comment    * Reverted queryinterface package from core    * Removed queryinterface package from core    * Handled review comments    * Handled review comments    * Added assert", "target": 1}
{"idx": 69, "commit_message": "remove VLA (fix `-Wvla`).  VLA are not supported in C++, that's a C99 feature not a C++ one (and even in C, it becames optional since C11).  Even if they were supported, it's not a good idea to use them (especially with an unbounded size such as `this->n`) this is a recipe for easy stack overflows.  Now, dumbly replacing VLAs by `std::vector` simply won't do (the code becomes 50% slower). But, we can implement a scratch space inside the `gf::NF4` object that can replaces the VLAs and get a nice 10% speedup :)", "target": 1}
{"idx": 3382, "commit_message": "Minor performance improvement with IE<9 detection", "target": 1}
{"idx": 877, "commit_message": "Fixed: Crash during initialization of GraphicEQ/Convolution filters when loading the configuration in multiple threads concurrently. This occurred most often when using GraphicEQ both for playback and capture devices. Improved: Updated FFTW to version 3.3.6-pl2.", "target": 0}
{"idx": 3140, "commit_message": "Add a test to show a problem in switch pattern translation  The performance optimization in #6607 assumed that a translated match would always be a `Match` node itself, but it can also be a `{ synthetic val x1 = ...; x1 match { .. } }` block.", "target": 0}
{"idx": 3152, "commit_message": "- Patch #130366 by webchick and steven: improved signature handling.  Step 1 of 2.", "target": 0}
{"idx": 1207, "commit_message": "[Test] Improve testPauseResume_innerTask & testTry_cancel to reproduce chained-task-pause/resume bug & try() bug.", "target": 0}
{"idx": 3254, "commit_message": "net/mlx5e: RX, Make sure packet header does not cross page boundary  In the non-linear SKB memory scheme of Striding RQ, a packet header could cross page boundary. This requires special care in fast path that costs LoC, additional runtime instructions and branches.  It could happen when the header (up to 256B) does not fit in a single stride. Avoid this by working with a stride size that fits the maximum possible header. Stride is increased form 64B to 256B.  Performance: Tested packet rate for UDP streams, single ring, on ConnectX-5.  Configuration: Set Striding RQ and LRO ON (to enabled the non-linear SKB scheme). GRO OFF, early drop by TC rule.  64B: 4x worse memory utilization, no page-crossers headers - No degradation (5,887,305 pps). - The reduction in memory utilization is compensated by the saving of   branches tests.  192B: 1.33x worse memory utilization, avoid page-crossers headers - Before: 5,727,252. After: 5,777,037. ~1% gain.  256B: Same memory util, no page-crossers - Before: 5,691,885. After: 5,748,007. ~1% gain.", "target": 1}
{"idx": 2318, "commit_message": "usb: cdns3: should not use the same dev_id for shared interrupt handler  Both drd and gadget interrupt handler use the struct cdns3 pointer as dev_id, it causes devm_free_irq at cdns3_gadget_exit doesn't free gadget's interrupt handler, it freed drd's handler. So, when the host interrupt occurs, the gadget's interrupt hanlder is still called, and causes below oops. To fix it, we use gadget's private data priv_dev as interrupt dev_id for gadget.  Unable to handle kernel NULL pointer dereference at virtual address 0000000000000380 Mem abort info:   ESR = 0x96000006   EC = 0x25: DABT (current EL), IL = 32 bits   SET = 0, FnV = 0   EA = 0, S1PTW = 0 Data abort info:   ISV = 0, ISS = 0x00000006   CM = 0, WnR = 0 user pgtable: 4k pages, 48-bit VAs, pgdp=0000000971d79000 [0000000000000380] pgd=0000000971d6f003, pud=0000000971d6e003, pmd=0000000000000000 Internal error: Oops: 96000006 [#1] PREEMPT SMP Modules linked in: mxc_jpeg_encdec crct10dif_ce fsl_imx8_ddr_perf CPU: 0 PID: 0 Comm: swapper/0 Not tainted 5.4.0-03486-g69f4e7d9c54a-dirty #254 Hardware name: Freescale i.MX8QM MEK (DT) pstate: 00000085 (nzcv daIf -PAN -UAO) pc : cdns3_device_irq_handler+0x1c/0xb8 lr : __handle_irq_event_percpu+0x78/0x2c0 sp : ffff800010003e30 x29: ffff800010003e30 x28: ffff8000129bb000 x27: ffff8000126e9000 x26: ffff0008f61b5600 x25: ffff800011fe1018 x24: ffff8000126ea120 x23: ffff800010003f04 x22: 0000000000000000 x21: 0000000000000093 x20: ffff0008f61b5600 x19: ffff0008f5061a80 x18: 0000000000000000 x17: 0000000000000000 x16: 0000000000000000 x15: 0000000000000000 x14: 003d090000000000 x13: 00003d0900000000 x12: 0000000000000000 x11: 00003d0900000000 x10: 0000000000000040 x9 : ffff800012708cb8 x8 : ffff800012708cb0 x7 : ffff0008f7c7a9d0 x6 : 0000000000000000 x5 : ffff0008f7c7a910 x4 : ffff8008ed359000 x3 : ffff800010003f40 x2 : 0000000000000000 x1 : ffff0008f5061a80 x0 : ffff800010161a60 Call trace:  cdns3_device_irq_handler+0x1c/0xb8  __handle_irq_event_percpu+0x78/0x2c0  handle_irq_event_percpu+0x40/0x98  handle_irq_event+0x4c/0xd0  handle_fasteoi_irq+0xbc/0x168  generic_handle_irq+0x34/0x50  __handle_domain_irq+0x6c/0xc0  gic_handle_irq+0xd4/0x174  el1_irq+0xb8/0x180  arch_cpu_idle+0x3c/0x230  default_idle_call+0x38/0x40  do_idle+0x20c/0x298  cpu_startup_entry+0x28/0x48  rest_init+0xdc/0xe8  arch_call_rest_init+0x14/0x1c  start_kernel+0x48c/0x4b8 Code: aa0103f3 aa1e03e0 d503201f f9409662 (f941c040) ---[ end trace 091dcf4dee011b0e ]--- Kernel panic - not syncing: Fatal exception in interrupt SMP: stopping secondary CPUs Kernel Offset: disabled CPU features: 0x0002,2100600c Memory Limit: none ---[ end Kernel panic - not syncing: Fatal exception in interrupt ]---  Fixes: 7733f6c32e36 (\"usb: cdns3: Add Cadence USB3 DRD Driver\") Cc: [URL]> #v5.4", "target": 0}
{"idx": 4051, "commit_message": "[PATCH] Stage bonded kernel atomics through shared memory\n\nFixes performance bug introduced in 01b2f20bd5 by staging energy step\natomics through shared memory rather than have all threads write\natomically directly to global memory.\n\nFixes #3443", "target": 1}
{"idx": 1551, "commit_message": "Change HashMap declaration in ResourceLoadPriorityOptimizer to use UnsignedWithZeroKeyHashTraits.  Key values of 0 aren't allowed in HashMap with default traits, and we'll hit an assert in HashTable since we just use the resource's identifier as key in the table.  BUG=369412  Review URL: [URL]/271323002", "target": 0}
{"idx": 2668, "commit_message": "better culling algorithm works more efficiently when cache size is small  svn path=/src/trunk/; revision=13170", "target": 1}
{"idx": 1879, "commit_message": "Improve syntax to please Rails 6's loader", "target": 0}
{"idx": 3194, "commit_message": "Turns out that BGE_STATFLAG_UPDATED bit in the status block doesn't get properly updated by the newer hardware (seen in the TX completion case). This leads to very poor transmit performance in the beginning of a TCP connection.   Linux and FreeBSD don't rely on BGE_STATFLAG_UPDATED bit since they enable MSI and tagged status for 5717+.  Doing the same does indeed fix an issue.  Change was tested by David Imhoff on 5719, 5720 and 5721/5750, Hrvoje Popovski on 5704 B0, sthen@ on 5723/5784, benno@ on 5704 A3, and me on 5719, 5720 adn 5714/5715.  No objections from kettenis@ and", "target": 0}
{"idx": 3464, "commit_message": "unsort BuildFileManifest.includes  Summary: My attempt to replace `String` with `AbsPath` was reverted because it seemingly caused perf degration: D27219075.  My suspicion is that sorting includes take significant time, and sorting `AbsPath` objects is more expensive than sorting strings.  So unsort includes (we don't really need them sorted), to be able to actually convert them to `AbsPath`.  Note `ImmutableSet` is less memory efficient than `ImmutableSortedSet`, but hopefully this won't be an issue.  Reviewed By: bobyangyf  fbshipit-source-id: 2b5d732b27c819ec036023ab547278efd0665704", "target": 1}
{"idx": 3262, "commit_message": "OSX fixes merged OSX fixes for CPU usage and serial performance fixed other (apparently minor) issue in serialport-unix.cpp", "target": 0}
{"idx": 541, "commit_message": "Drastically reduced CPU usage on iOS in AU thread, mostly be avoiding unnecessary critical sections and increasing sleep values.", "target": 1}
{"idx": 71, "commit_message": "Issue #10115: Improve Serviceability of JaxRsFactoryImplicitBeanCDICustomizer", "target": 0}
{"idx": 353, "commit_message": "Bug 1566545 - Card UI spoc variants (#5216)  * Bug 1566545 - Card UI spoc variants    * Fix tests    * Design review feedback    * optimize svg and tests    * Update tests", "target": 0}
{"idx": 4134, "commit_message": "[PATCH] reworked the project_vector to be more efficient for Lagrange\n elements.  Changed the corresponding calls in reinit().  amr.cc now tests the\n projection stuff.\n\ngit-svn-id: file:///Users/petejw/Documents/libmesh_svn_bak@279 434f946d-2f3d-0410-ba4c-cb9f52fb0dbf", "target": 1}
{"idx": 394, "commit_message": "[IMP] point_of_sale: View Improvements.  bzr revid: [URL]-20100812064021-hn28k1semhrip49x", "target": 0}
{"idx": 2830, "commit_message": "[ResourceTiming] Refactor connection-reuse tests  This CL migrates the connection reuse WPTs to the new style. See wpt/resource-timing/CodingConventions.md for details.  These tests exist to verify that the Resource Timing API yields correct PerformanceResourceTiming values when the underlying TCP connection is reused across multiple subresources.  Bug: 1171767", "target": 0}
{"idx": 3263, "commit_message": "Merged revisions 104593 via svnmerge from  [URL]/svn/asterisk/branches/1.4  ........ r104593 | kpfleming | 2008-02-27 10:53:06 -0600 (Wed, 27 Feb 2008) | 8 lines  fallback to standard English prompts properly when using new prompt directory layout  (closes issue #11831) Reported by: IgorG Patches:       fallbacken.v1.diff uploaded by IgorG (license 20) (modified by me to improve code and conform rest of function to coding guidelines)   ........", "target": 0}
{"idx": 3909, "commit_message": "zram: introduce compressing backend abstraction  ZRAM performs direct LZO compression algorithm calls, making it the one and only option.  While LZO is generally performs well, LZ4 algorithm tends to have a faster decompression (see [URL]/p/lz4/ for full report)  \tName            Ratio  C.speed D.speed \t                        MB/s    MB/s \tLZ4 (r101)      2.084    422    1820 \tLZO 2.06        2.106    414     600  Thus, users who have mostly read (decompress) usage scenarious or mixed workflow (writes with relatively high read ops number) will benefit from using LZ4 compression backend.  Introduce compressing backend abstraction zcomp in order to support multiple compression algorithms with the following set of operations:          .create         .destroy         .compress         .decompress  Schematically zram write() usually contains the following steps: 0) preparation (decompression of partioal IO, etc.) 1) lock buffer_lock mutex (protects meta compress buffers) 2) compress (using meta compress buffers) 3) alloc and map zs_pool object 4) copy compressed data (from meta compress buffers) to object allocated by 3) 5) free previous pool page, assign a new one 6) unlock buffer_lock mutex  As we can see, compressing buffers must remain untouched from 1) to 4), because, otherwise, concurrent write() can overwrite data.  At the same time, zram_meta must be aware of a) specific compression algorithm memory requirements and b) necessary locking to protect compression buffers.  To remove requirement a) new struct zcomp_strm introduced, which contains a compress/decompress `buffer' and compression algorithm `private' part. While struct zcomp implements zcomp_strm stream handling and locking and removes requirement b) from zram meta.  zcomp ->create() and ->destroy(), respectively, allocate and deallocate algorithm specific zcomp_strm `private' part.  Every zcomp has zcomp stream and mutex to protect its compression stream. Stream usage semantics remains the same -- only one write can hold stream lock and use its buffers.  zcomp_strm_find() turns caller into exclusive user of a stream (holding stream mutex until zram release stream), and zcomp_strm_release() makes zcomp stream available (unlock the stream mutex).  Hence no concurrent write (compression) operations possible at the moment.  iozone -t 3 -R -r 16K -s 60M -I +Z         test            base           patched --------------------------------------------------   Initial write      597992.91       591660.58         Rewrite      609674.34       616054.97            Read     2404771.75      2452909.12         Re-read     2459216.81      2470074.44    Reverse Read     1652769.66      1589128.66     Stride read     2202441.81      2202173.31     Random read     2236311.47      2276565.31  Mixed workload     1423760.41      1709760.06    Random write      579584.08       615933.86          Pwrite      597550.02       594933.70           Pread     1703672.53      1718126.72          Fwrite     1330497.06      1461054.00           Fread     3922851.00      3957242.62  Usage examples:  \tcomp = zcomp_create(NAME) /* NAME e.g. \"lzo\" */  which initialises compressing backend if requested algorithm is supported.  Compress: \tzstrm = zcomp_strm_find(comp) \tzcomp_compress(comp, zstrm, src, &dst_len) \t[..] /* copy compressed data */ \tzcomp_strm_release(comp, zstrm)  Decompress: \tzcomp_decompress(comp, src, src_len, dst);  Free compessing backend and its zcomp stream: \tzcomp_destroy(comp)", "target": 1}
{"idx": 564, "commit_message": "[pt] Improved last rule: <token regexp=\"yes\">bom|bons|boas?</token>", "target": 0}
{"idx": 787, "commit_message": "Fixed memory losses. Patch provide by wafro2. Simplify used data structures.", "target": 0}
{"idx": 2149, "commit_message": "Merge #6054  6054: chore(deps): bump chart.js from 3.5.1 to 3.6.0 r=jniles a=dependabot[bot]  Bumps [URL]/chartjs/Chart.js) from 3.5.1 to 3.6.0. <details> <summary>Release notes</summary> <p><em>Sourced from <a [URL]/chartjs/Chart.js/releases\">chart.js's releases</a>.</em></p> <blockquote> <h2>v3.6.0</h2> <h1>Essential Links</h1> <ul> <li><a [URL]/package/chart.js\">npm</a></li> <li><a [URL]/docs/latest/getting-started/v3-migration\">Migration guide</a></li> <li><a [URL]/docs/latest/\">Docs</a></li> <li><a [URL]/docs/latest/api/\">API</a></li> <li><a [URL]/docs/latest/samples/\">Samples</a></li> </ul> <ul> <li><a [URL]/chartjs/Chart.js/issues/9757\">#9757</a> ci(workflow): add cache to workflows using actions/setup-node</li> <li><a [URL]/chartjs/Chart.js/issues/9587\">#9587</a> Ensure that controllers derived from the bar controller work correct in stacked charts</li> </ul> <h2>Enhancements</h2> <ul> <li><a [URL]/chartjs/Chart.js/issues/9761\">#9761</a> Add chart, p0.raw, p1.raw to segment context</li> <li><a [URL]/chartjs/Chart.js/issues/9758\">#9758</a> Support nested scriptable options for datasets</li> <li><a [URL]/chartjs/Chart.js/issues/9751\">#9751</a> Disable animations for BasicPlatform (offcreen)</li> <li><a [URL]/chartjs/Chart.js/issues/9716\">#9716</a> Add layout.autoPadding option</li> <li><a [URL]/chartjs/Chart.js/issues/9679\">#9679</a> Add sanity check for stepSize</li> <li><a [URL]/chartjs/Chart.js/issues/9625\">#9625</a> Configurable tooltip box padding</li> <li><a [URL]/chartjs/Chart.js/issues/9624\">#9624</a> Add sanity checks for scale options</li> <li><a [URL]/chartjs/Chart.js/issues/9622\">#9622</a> Add parsing support to pie/doughnut charts</li> <li><a [URL]/chartjs/Chart.js/issues/9620\">#9620</a> Enable per-corner border radius in tooltip</li> <li><a [URL]/chartjs/Chart.js/issues/9557\">#9557</a> Detect attach/detach from any level</li> </ul> <h2>Performance</h2> <ul> <li><a [URL]/chartjs/Chart.js/issues/9661\">#9661</a> cache also undefined values in option resolver</li> </ul> <h2>Bugs Fixed</h2> <ul> <li><a [URL]/chartjs/Chart.js/issues/9656\">#9656</a> Fix cleaning up metasets</li> <li><a [URL]/chartjs/Chart.js/issues/9767\">#9767</a> Fix stacked fill with lines over multiple scales</li> <li><a [URL]/chartjs/Chart.js/issues/9764\">#9764</a> Bubble: Properly parse radius for non-object data</li> <li><a [URL]/chartjs/Chart.js/issues/9770\">#9770</a> Support nested scriptable defaults for datasets</li> <li><a [URL]/chartjs/Chart.js/issues/9766\">#9766</a> Fix controller.getMinMax for stacked charts</li> <li><a [URL]/chartjs/Chart.js/issues/9729\">#9729</a> Types: Move tooltip methods to model from plugin</li> <li><a [URL]/chartjs/Chart.js/issues/9719\">#9719</a> Linear: determine grace amount from range</li> <li><a [URL]/chartjs/Chart.js/issues/9718\">#9718</a> Fix chart crashing when only min is defined</li> <li><a [URL]/chartjs/Chart.js/issues/9641\">#9641</a> Fix chart crashing when max is defined but ticks are empty</li> <li><a [URL]/chartjs/Chart.js/issues/9678\">#9678</a> Bar: fix too thick borders</li> <li><a [URL]/chartjs/Chart.js/issues/9644\">#9644</a> Fix segment styling with gaps</li> <li><a [URL]/chartjs/Chart.js/issues/9613\">#9613</a> Fix plugin event filtering of renamed events</li> <li><a [URL]/chartjs/Chart.js/issues/9592\">#9592</a> Fix control points on animated line w/o border</li> </ul> <h2>Types</h2> <ul> <li><a [URL]/chartjs/Chart.js/issues/9729\">#9729</a> Types: Move tooltip methods to model from plugin</li> <li><a [URL]/chartjs/Chart.js/issues/9699\">#9699</a> Support false for doughnut and polar area chart animation options</li> <li><a [URL]/chartjs/Chart.js/issues/9680\">#9680</a> Fix some typings issues</li> </ul> <!-- raw HTML omitted --> </blockquote> <p>... (truncated)</p>", "target": 0}
{"idx": 914, "commit_message": "PR tree-optimization/71631         * tree-ssa-reassoc.c (reassociate_bb): Pass true as last argument         to rewrite_expr_tree even if negate_result, move new_lhs var         declaration and initialization earlier, for powi_result set afterwards         new_lhs to lhs.  For negate_result, use new_lhs instead of tmp         if new_lhs != lhs, and don't shadow gsi var.          * gcc.c-torture/execute/pr71631.c: New test.", "target": 0}
{"idx": 2709, "commit_message": "Merge pull request #2063 from mohammadamer/patch-1  Improve year view and highlight today style - hacktoberfeast", "target": 0}
{"idx": 3911, "commit_message": "Performance, Comments  * Improved performance by limiting the number of requests to the DB * Comments widget has configurable option to only input name and e-mail (skipping website) * CSV widget; uses   is content contains  , or r else as line seperator", "target": 1}
{"idx": 3061, "commit_message": "Improve analysis to dramatically improve future-force-elim.  This also improves the performance of analysis slightly.", "target": 1}
{"idx": 3171, "commit_message": "A.......S. [ZBX-8473] improved performance of deleting triggers by API and server - events will be deleted only by the housekeeper", "target": 1}
{"idx": 4073, "commit_message": "[PATCH] new implemenation using boost CSR graph, it can be 1.5x\n faster from prev implementation but there is a performance problem that I\n couldn't solve using public functionality of graph (however there might be a\n solution) will look it back.", "target": 1}
{"idx": 2757, "commit_message": "crypto: user - lock crypto_alg_list on alg dump  commit 63e41ebc6630f39422d87f8a4bade1e793f37a01 upstream.  We miss to take the crypto_alg_sem semaphore when traversing the crypto_alg_list for CRYPTO_MSG_GETALG dumps. This allows a race with crypto_unregister_alg() removing algorithms from the list while we're still traversing it, thereby leading to a use-after-free as show below:  [ 3482.071639] general protection fault: 0000 [#1] SMP [ 3482.075639] Modules linked in: aes_x86_64 glue_helper lrw ablk_helper cryptd gf128mul ipv6 pcspkr serio_raw virtio_net microcode virtio_pci virtio_ring virtio sr_mod cdrom [last unloaded: aesni_intel] [ 3482.075639] CPU: 1 PID: 11065 Comm: crconf Not tainted 4.3.4-grsec+ #126 [ 3482.075639] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014 [ 3482.075639] task: ffff88001cd41a40 ti: ffff88001cd422c8 task.ti: ffff88001cd422c8 [ 3482.075639] RIP: 0010:[<ffffffff93722bd3>]  [<ffffffff93722bd3>] strncpy+0x13/0x30 [ 3482.075639] RSP: 0018:ffff88001f713b60  EFLAGS: 00010202 [ 3482.075639] RAX: ffff88001f6c4430 RBX: ffff88001f6c43a0 RCX: ffff88001f6c4430 [ 3482.075639] RDX: 0000000000000040 RSI: fefefefefefeff16 RDI: ffff88001f6c4430 [ 3482.075639] RBP: ffff88001f713b60 R08: ffff88001f6c4470 R09: ffff88001f6c4480 [ 3482.075639] R10: 0000000000000002 R11: 0000000000000246 R12: ffff88001ce2aa28 [ 3482.075639] R13: ffff880000093700 R14: ffff88001f5e4bf8 R15: 0000000000003b20 [ 3482.075639] FS:  0000033826fa2700(0000) GS:ffff88001e900000(0000) knlGS:0000000000000000 [ 3482.075639] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [ 3482.075639] CR2: ffffffffff600400 CR3: 00000000139ec000 CR4: 00000000001606f0 [ 3482.075639] Stack: [ 3482.075639]  ffff88001f713bd8 ffffffff936ccd00 ffff88001e5c4200 ffff880000093700 [ 3482.075639]  ffff88001f713bd0 ffffffff938ef4bf 0000000000000000 0000000000003b20 [ 3482.075639]  ffff88001f5e4bf8 ffff88001f5e4848 0000000000000000 0000000000003b20 [ 3482.075639] Call Trace: [ 3482.075639]  [<ffffffff936ccd00>] crypto_report_alg+0xc0/0x3e0 [ 3482.075639]  [<ffffffff938ef4bf>] ? __alloc_skb+0x16f/0x300 [ 3482.075639]  [<ffffffff936cd08a>] crypto_dump_report+0x6a/0x90 [ 3482.075639]  [<ffffffff93935707>] netlink_dump+0x147/0x2e0 [ 3482.075639]  [<ffffffff93935f99>] __netlink_dump_start+0x159/0x190 [ 3482.075639]  [<ffffffff936ccb13>] crypto_user_rcv_msg+0xc3/0x130 [ 3482.075639]  [<ffffffff936cd020>] ? crypto_report_alg+0x3e0/0x3e0 [ 3482.075639]  [<ffffffff936cc4b0>] ? alg_test_crc32c+0x120/0x120 [ 3482.075639]  [<ffffffff93933145>] ? __netlink_lookup+0xd5/0x120 [ 3482.075639]  [<ffffffff936cca50>] ? crypto_add_alg+0x1d0/0x1d0 [ 3482.075639]  [<ffffffff93938141>] netlink_rcv_skb+0xe1/0x130 [ 3482.075639]  [<ffffffff936cc4f8>] crypto_netlink_rcv+0x28/0x40 [ 3482.075639]  [<ffffffff939375a8>] netlink_unicast+0x108/0x180 [ 3482.075639]  [<ffffffff93937c21>] netlink_sendmsg+0x541/0x770 [ 3482.075639]  [<ffffffff938e31e1>] sock_sendmsg+0x21/0x40 [ 3482.075639]  [<ffffffff938e4763>] SyS_sendto+0xf3/0x130 [ 3482.075639]  [<ffffffff93444203>] ? bad_area_nosemaphore+0x13/0x20 [ 3482.075639]  [<ffffffff93444470>] ? __do_page_fault+0x80/0x3a0 [ 3482.075639]  [<ffffffff939d80cb>] entry_SYSCALL_64_fastpath+0x12/0x6e [ 3482.075639] Code: 88 4a ff 75 ed 5d 48 0f ba 2c 24 3f c3 66 66 2e 0f 1f 84 00 00 00 00 00 55 48 85 d2 48 89 f8 48 89 f9 4c 8d 04 17 48 89 e5 74 15 <0f> b6 16 80 fa 01 88 11 48 83 de ff 48 83 c1 01 4c 39 c1 75 eb [ 3482.075639] RIP  [<ffffffff93722bd3>] strncpy+0x13/0x30  To trigger the race run the following loops simultaneously for a while:   $ while : ; do modprobe aesni-intel; rmmod aesni-intel; done   $ while : ; do crconf show all > /dev/null; done  Fix the race by taking the crypto_alg_sem read lock, thereby preventing crypto_unregister_alg() from modifying the algorithm list during the dump.  This bug has been detected by the PaX memory sanitize feature.", "target": 0}
{"idx": 539, "commit_message": "Normalized enum naming and added ConvertToString functions to improve logging", "target": 1}
{"idx": 706, "commit_message": "[PATCH] Allow smarter node creation based on visibility during createtree As I've brought up on the mailing list thread \"High latency caused by full tree creation\", there is a large amount of delay per LuCI request which is spent building the node tree in createtree(). Most nodes created aren't  needed for the view presented to the user and only serve to consume memory and CPU time during a page load.  My idea is to provide an easy mechanism for index()ers to determine which needs to be created and what isn't. Due to the constraints of the standard LuCI web interface, this optimization needs to establish a few rules:   * The page requested must have its node created  * All parents of the page being requested must be created, so the children inherit the track  * All the top-level nodes \"Status\", \"System\", \"Services\", \"Network\" (and others added by extensions) must be created in order to have their top-level tabs in the UI  * All peers of second-level nodes need to be created as well for the same reason, to display their links on the subindexes                   To make this easy to implement in each controller, the attached patch adds an \"inreq\" field to each created node to indicate if it lies on the request path. To satisfy the \"top level node\" requirement, we always  add the top level node, then check its inreq property if the top-level node is not \"in request\", then the controller can exit index() early.", "target": 1}
{"idx": 3181, "commit_message": "Improve performance of symbolic integral computation", "target": 1}
{"idx": 3842, "commit_message": "Removes untyped App.get() method to avoid performance problems in large databases due to unsupported relationship indexing in Neo4j.", "target": 1}
{"idx": 382, "commit_message": "* Improved AIL_positionshoot.  * Now will check that it's actually *possible* to shoot from there...", "target": 0}
{"idx": 112, "commit_message": "Clean up complex field hierarchy to improve readability", "target": 0}
{"idx": 795, "commit_message": "* [New sql update: 4584_character_inventory.sql] Optimized access to `character_inventory` for some queries. Patch provided by Alex/AT. * Add to makefile.am and set eol-style for some sql updates.", "target": 1}
{"idx": 22, "commit_message": "[es] improve and enable rules singular/plural", "target": 0}
{"idx": 1555, "commit_message": "CirrusCI: reconfiguring to fit better with new CPU allocation rules", "target": 0}
{"idx": 325, "commit_message": "gpu: ion: Only map as much of the vma as the user requested", "target": 0}
{"idx": 1268, "commit_message": "BugID: 992  Improved makeSubset(). It now only scans the part of the parameter set where keys starting with baseKey might be present.", "target": 0}
{"idx": 1781, "commit_message": "V4L/DVB: ir-core: Add support for RC map code register  Instead of having all RC tables hardcoded on one file with all tables there, add infrastructure for registering and dynamically load the table(s) when needed.", "target": 0}
{"idx": 2839, "commit_message": "Partially rewrite JsonApiHydrator to improve performance", "target": 1}
{"idx": 4106, "commit_message": "[PATCH] Simplifying ARMv8 build parameters\n\nARMv8 builds were a bit mixed up, with ThunderX2 code in ARMv8 mode\n(which is not right because TX2 is ARMv8.1) as well as requiring a few\nredundancies in the defines, making it harder to maintain and understand\nwhat core has what. A few other minor issues were also fixed.\n\nTests were made on the following cores: A53, A57, A72, Falkor, ThunderX,\nThunderX2, and XGene.\n\nTests were: OpenBLAS/test, OpenBLAS/benchmark, BLAS-Tester.\n\nA summary:\n * Removed TX2 code from ARMv8 build, to make sure it is compatible with\n   all ARMv8 cores, not just v8.1. Also, the TX2 code has actually\n   harmed performance on big cores.\n * Commoned up ARMv8 architectures' defines in params.h, to make sure\n   that all will benefit from ARMv8 settings, in addition to their own.\n * Adding a few more cores, using ARMv8's include strategy, to benefit\n   from compiler optimisations using mtune. Also updated cache\n   information from the manuals, making sure we set good conservative\n   values by default. Removed Vulcan, as it's an alias to TX2.\n * Auto-detecting most of those cores, but also updating the forced\n   compilation in getarch.c, to make sure the parameters are the same\n   whether compiled natively or forced arch.\n\nBenefits:\n * ARMv8 build is now guaranteed to work on all ARMv8 cores\n * Improved performance for ARMv8 builds on some cores (A72, Falkor,\n   ThunderX1 and 2: up to 11%) over current develop\n * Improved performance for *all* cores comparing to develop branch\n   before TX2's patch (9% ~ 36%)\n * ThunderX1 builds are 14% faster than ARMv8 on TX1, 9% faster than\n   current develop's branch and 8% faster than deveop before tx2 patches\n\nIssues:\n * Regression from current develop branch for A53 (-12%) and A57 (-3%)\n   with ARMv8 builds, but still faster than before TX2's commit (+15%\n   and +24% respectively). This can be improved with a simplification of\n   TX2's code, to be done in future patches. At least the code is\n   guaranteed to be ARMv8.0 now.\n\nComments:\n * CortexA57 builds are unchanged on A57 hardware from develop's branch,\n   which makes sense, as it's untouched.\n * CortexA72 builds improve over A57 on A72 hardware, even if they're\n   using the same includes due to new compiler tunning in the makefile.", "target": 1}
{"idx": 4055, "commit_message": "[PATCH] Restructured nonbonded calculation to allow more efficient\n vectorization", "target": 1}
{"idx": 3347, "commit_message": "Clingcon: fixed back according to enumeration and btLevel, should be more efficient", "target": 1}
{"idx": 818, "commit_message": "improvements to rand_mps  much quicker, defaults to non-cyclic", "target": 1}
{"idx": 4010, "commit_message": "[PATCH] #1295 Refactored Matrix::setSub(IMatrix,IMatrix) The new\n implementation should be much more efficient and handle non-monotone indices\n correctly", "target": 1}
{"idx": 2680, "commit_message": "Adds a new animation and deletes some testing files  Adds MoveAnimation Removes the web page and algorithm used for testing Adds a SortedList utility Change Animations so that it uses the SortedList to improve performance", "target": 1}
{"idx": 2004, "commit_message": "Merge branch 'master' into feature/172-datalistview  * master:   bumped version number to 0.9.5   Small bug fix   Build assets   Feature/login next check (#140)   Removed css to fieldset tag, and added class to old fieldset tags   Build assets   Added fieldset to all forms to meke it easiear disabled them when needed   Considerate improved performance; no query per has_permission call #182 (#183)   Submenu icons display option was added. (#185)   Changed labels for checkboxes in horizontal forms   Devided big form field html in smaller chunks   Build assets   Added block ofr inline field forms   Removed style horizontal from create update because horizontal is not the default (the style was being ignored before)   removed empty lines   Added option to change the size of the collums for horizontal forms (default is 2 for label and 10 for form field)   second draft   Added first draff of horiontal suport for the forms   Added fieldset to forms  # Conflicts: #        CHANGELOG.md", "target": 1}
{"idx": 1480, "commit_message": ": * Don't double sync on initial load * Don't always sync on app startup -    - if have client changes - sync    - else let WS channel take care of getting server changes * Always sync after login * Optimization: If a \"pull\" sync is requested while a \"push\" sync is ongoing, but the \"push\" sync resulted in a sync request (including an actual pull), then don't double sync.", "target": 1}
{"idx": 1630, "commit_message": "new optimized code for site details", "target": 1}
{"idx": 3475, "commit_message": "Merge #798: [Net] Improve addrman Select() performance when buckets are nearly empty  7dfa9b2 Improve addrman Select() performance when buckets are nearly empty (Pieter Wuille)  Tree-SHA512: 64a16dd027174a45931e73c82e04629738b4caca8500d8cb04a1739d5f5529726d3ff27357f0bdf881fc4ccf278a7a6ac2b904e3a7822af32d8dce096ef16dce", "target": 1}
{"idx": 1666, "commit_message": "Document the -n option and fix manpage Fl usage.  Obtained from:\tTrustedBSD Project Sponsored by:\tDARPA, Network Associates Laboratories", "target": 0}
{"idx": 2822, "commit_message": "ENH:Faster, less memory intensive triangle filter", "target": 1}
{"idx": 2867, "commit_message": "Safari: block programmatic image requests, more thorough XHR  Currently, this is done the same way we block XMLHttpRequests: mess with the constructor. This was done in the most efficient way I could think of (overhead is relatively minimal). This also injects uBlock's blocking interceptor earlier, thusly covering more requests that may have slipped through before.", "target": 1}
{"idx": 970, "commit_message": "KVM: x86: Add support for AMD Core Perf Extension in guest  Add support for AMD Core Performance counters in the guest. The base event select and counter MSRs are changed. In addition, with the core extension, there are 2 extra counters available for performance measurements for a total of 6.  With the new MSRs, the logic to map them to the gp_counters[] is changed. New functions are added to check the validity of the get/set MSRs.  If the guest has the X86_FEATURE_PERFCTR_CORE cpuid flag set, the number of counters available to the vcpu is set to 6. It the flag is not set then it is 4.", "target": 0}
{"idx": 2038, "commit_message": "crypto: arc4 - improve performance by adding ecb(arc4)  Currently arc4.c provides simple one-byte blocksize cipher which is wrapped by ecb() module, giving function call overhead on every encrypted byte. This patch adds ecb(arc4) directly into arc4.c for higher performance.  tcrypt results (speed ratios: new/old):  AMD Phenom II, x86-64 : x2.7 Intel Core 2, x86-64  : x1.9 Intel Atom N260, i386 : x1.4  Cc: Jon Oberheide [URL]>", "target": 1}
{"idx": 307, "commit_message": "Remove debug.ce.mpsafenet: we no longer support running the network stack with conditional Giant acquisition, and IFF_NEEDSGIANT will be removed in the near future.", "target": 0}
{"idx": 67, "commit_message": "[CRT] Hopefully fix build, by specifying minimum MSC versions for some intrinsics", "target": 0}
{"idx": 3745, "commit_message": "Improve WiFi performance by 20X  Polling for the async response was ruinning WiFi and UDP performance. This fix removes that polling while not breaking anything. It has been stress tested while streaming over an hour of wifi video data using the new RPC scripts.", "target": 1}
{"idx": 1505, "commit_message": "Improved systemtap.printf/sharedbuf.exp testcase. * testsuite/systemtap.printf/sharedbuf.exp: Handles failure better and   possible modpost warnings.", "target": 0}
{"idx": 4063, "commit_message": "[PATCH] Attempt to work-around old gcc bugs in a more efficient\n fashion that does not lose performance on newer gcc's. [empty commit message]", "target": 1}
{"idx": 3022, "commit_message": "Now scripts only compile once when level is loading or test play is starting, improves performance. Now in edit mode scripts only run when test play started. Fixed a crash in level editor when exiting test play with R key pressed. Some other minor fixes about ScriptUserData.", "target": 1}
{"idx": 118, "commit_message": "Merge branch 'conversation-network' of [URL]:drewww/unhangout into conversation-network  Conflicts: \tlib/unhangout-sockets.js", "target": 0}
{"idx": 12, "commit_message": "Revamp syscall definitions to use shared folder, dynamically generate includes, etc.", "target": 0}
{"idx": 2021, "commit_message": "blockchain: Refactor to use new chain view.  - Remove inMainChain from block nodes since that can now be efficiently   determined by using the chain view - Track the best chain via a chain view instead of a single block node   - Use the tip of the best chain view everywhere bestNode was used   - Update chain view tip instead of updating best node - Change reorg logic to use more efficient chain view fork finding logic - Change block locator code over to use more efficient chain view logic   - Remove now unused block-index-based block locator code   - Move BlockLocator definition to chain.go   - Move BlockLocatorFromHash and LatestBlockLocator to chain.go     - Update both to use more efficient chain view logic - Rework IsCheckpointCandidate to use block index and chain view - Optimize MainChainHasBlock to use chain view instead of hitting db   - Move to chain.go since it no longer involves database I/O   - Removed error return since it can no longer fail - Optimize BlockHeightByHash to use chain view instead of hitting db   - Move to chain.go since it no longer involves database I/O   - Removed error return since it can no longer fail - Optimize BlockHashByHeight to use chain view instead of hitting db   - Move to chain.go since it no longer involves database I/O   - Removed error return since it can no longer fail - Optimize HeightRange to use chain view instead of hitting db   - Move to chain.go since it no longer involves database I/O - Optimize BlockByHeight to use chain view for main chain check - Optimize BlockByHash to use chain view for main chain check", "target": 1}
{"idx": 2760, "commit_message": "added compress function after download fixed some logic with the left_files & performance issues", "target": 1}
{"idx": 459, "commit_message": "Remove Proxy Config preferences from incognito whitelist.  Preferences related to proxy config are removed from the persistent storage list for incognito mode. After this CL, if these preferences are changed from incognito mode, they are only stored in memory and won't affect user profile.  Bug: 861722", "target": 0}
{"idx": 2084, "commit_message": "Revert \"r225811 - Revert \"r225808 - [PowerPC] Add StackMap/PatchPoint support\"\"  This re-applies r225808, fixed to avoid problems with SDAG dependencies along with the preceding fix to ScheduleDAGSDNodes::RegDefIter::InitNodeNumDefs. These problems caused the original regression tests to assert/segfault on many (but not all) systems.  Original commit message:  This commit does two things:   1. Refactors PPCFastISel to use more of the common infrastructure for call     lowering (this lets us take advantage of this common code for lowering some     common intrinsics, stackmap/patchpoint among them).   2. Adds support for stackmap/patchpoint lowering. For the most part, this is     very similar to the support in the AArch64 target, with the obvious differences     (different registers, NOP instructions, etc.). The test cases are adapted     from the AArch64 test cases.  One difference of note is that the patchpoint call sequence takes 24 bytes, so you can't use less than that (on AArch64 you can go down to 16). Also, as noted in the docs, we take the patchpoint address to be the actual code address (assuming the call is local in the TOC-sharing sense), which should yield higher performance than generating the full cross-DSO indirect-call sequence and is likely just as useful for JITed code (if not, we'll change it).  StackMaps and Patchpoints are still marked as experimental, and so this support is doubly experimental. So go ahead and experiment!", "target": 0}
{"idx": 2884, "commit_message": "mm/filemap/c: break generic_file_buffered_read up into multiple functions  Patch series \"generic_file_buffered_read() improvements\", v2.  generic_file_buffered_read() has turned into a real monstrosity to work with.  And it's a major performance improvement, for both small random and large sequential reads.  On my test box, 4k buffered random reads go from ~150k to ~250k iops, and the improvements to big sequential reads are even bigger.  This incorporates the fix for IOCB_WAITQ handling that Jens just posted as well, also factors out lock_page_for_iocb() to improve handling of the various iocb flags.  This patch (of 2):  This is prep work for changing generic_file_buffered_read() to use find_get_pages_contig() to batch up all the pagecache lookups.  This patch should be functionally identical to the existing code and changes as little as of the flow control as possible.  More refactoring could be done, this patch is intended to be relatively minimal.  Link: [URL] Link: [URL]", "target": 1}
{"idx": 3091, "commit_message": "fix(library/unifier): in the context_check, we should not consider local constants that occur in the type of other constants  This was a performance bug. We were missing higher-order pattern constraints due to this bug.", "target": 1}
{"idx": 3468, "commit_message": "Added properties and labels to the link and link shape classes. The current implementation has performance issues and problems with duplicated text on moving the links around.  Conflicts: \tapp/models/link.coffee \tapp/models/link_shape.coffee \tapp/models/node.coffee \tapp/models/node_shape.coffee", "target": 0}
{"idx": 220, "commit_message": "+review CR-150 ENG-2388  changes based on review # Please enter the commit message for your changes. Lines starting # with '#' will be ignored, and an empty message aborts the commit. # On branch feature/pocperfbench # Changes to be committed: # (use \"git reset HEAD <file>...\" to unstage) # # renamed: src/main/java/com/continuuity/cperf/runner/Renn.java -> src/main/java/com/continuuity/cperf/runner/PerformanceTestRunner.java # renamed: src/main/java/com/continuuity/cperf/runner/SimpleRennen.java -> src/main/java/com/continuuity/cperf/runner/SimplePerformanceTest.java # modified: src/main/java/com/continuuity/cperf/runner/package-info.java # modified: src/main/java/com/continuuity/performance/application/DefaultBenchmarkManager.java # modified: src/main/java/com/continuuity/performance/application/RuntimeMetricsCollector.java", "target": 0}
{"idx": 2127, "commit_message": "Merge pull request #403 from brendanzab/improve-ci-performance  Improve ci build parallelization", "target": 1}
{"idx": 2544, "commit_message": "mtd: omap2: fix omap_nand_remove segfault  commit 7d9b110269253b1d5858cfa57d68dfc7bf50dd77 upstream.  Do not kfree() the mtd_info; it is handled in the mtd subsystem and already freed by nand_release(). Instead kfree() the struct omap_nand_info allocated in omap_nand_probe which was not freed before.  This patch fixes following error when unloading the omap2 module:  ---8<--- ~ $ rmmod omap2 ------------[ cut here ]------------ kernel BUG at mm/slab.c:3126! Internal error: Oops - BUG: 0 [#1] PREEMPT ARM Modules linked in: omap2(-) CPU: 0    Not tainted  (3.6.0-rc3-00230-g155e36d-dirty #3) PC is at cache_free_debugcheck+0x2d4/0x36c LR is at kfree+0xc8/0x2ac pc : [<c01125a0>]    lr : [<c0112efc>]    psr: 200d0193 sp : c521fe08  ip : c0e8ef90  fp : c521fe5c r10: bf0001fc  r9 : c521e000  r8 : c0d99c8c r7 : c661ebc0  r6 : c065d5a4  r5 : c65c4060  r4 : c78005c0 r3 : 00000000  r2 : 00001000  r1 : c65c4000  r0 : 00000001 Flags: nzCv  IRQs off  FIQs on  Mode SVC_32  ISA ARM  Segment user Control: 10c5387d  Table: 86694019  DAC: 00000015 Process rmmod (pid: 549, stack limit = 0xc521e2f0) Stack: (0xc521fe08 to 0xc5220000) fe00:                   c008a874 c00bf44c c515c6d0 200d0193 c65c4860 c515c240 fe20: c521fe3c c521fe30 c008a9c0 c008a854 c521fe5c c65c4860 c78005c0 bf0001fc fe40: c780ff40 a00d0113 c521e000 00000000 c521fe84 c521fe60 c0112efc c01122d8 fe60: c65c4860 c0673778 c06737ac 00000000 00070013 00000000 c521fe9c c521fe88 fe80: bf0001fc c0112e40 c0673778 bf001ca8 c521feac c521fea0 c02ca11c bf0001ac fea0: c521fec4 c521feb0 c02c82c4 c02ca100 c0673778 bf001ca8 c521fee4 c521fec8 fec0: c02c8dd8 c02c8250 00000000 bf001ca8 bf001ca8 c0804ee0 c521ff04 c521fee8 fee0: c02c804c c02c8d20 bf001924 00000000 bf001ca8 c521e000 c521ff1c c521ff08 ff00: c02c950c c02c7fbc bf001d48 00000000 c521ff2c c521ff20 c02ca3a4 c02c94b8 ff20: c521ff3c c521ff30 bf001938 c02ca394 c521ffa4 c521ff40 c009beb4 bf001930 ff40: c521ff6c 70616d6f b6fe0032 c0014f84 70616d6f b6fe0032 00000081 60070010 ff60: c521ff84 c521ff70 c008e1f4 c00bf328 0001a004 70616d6f c521ff94 0021ff88 ff80: c008e368 0001a004 70616d6f b6fe0032 00000081 c0015028 00000000 c521ffa8 ffa0: c0014dc0 c009bcd0 0001a004 70616d6f bec2ab38 00000880 bec2ab38 00000880 ffc0: 0001a004 70616d6f b6fe0032 00000081 00000319 00000000 b6fe1000 00000000 ffe0: bec2ab30 bec2ab20 00019f00 b6f539c0 60070010 bec2ab38 aaaaaaaa aaaaaaaa Backtrace: [<c01122cc>] (cache_free_debugcheck+0x0/0x36c) from [<c0112efc>] (kfree+0xc8/0x2ac) [<c0112e34>] (kfree+0x0/0x2ac) from [<bf0001fc>] (omap_nand_remove+0x5c/0x64 [omap2]) [<bf0001a0>] (omap_nand_remove+0x0/0x64 [omap2]) from [<c02ca11c>] (platform_drv_remove+0x28/0x2c)  r5:bf001ca8 r4:c0673778 [<c02ca0f4>] (platform_drv_remove+0x0/0x2c) from [<c02c82c4>] (__device_release_driver+0x80/0xdc) [<c02c8244>] (__device_release_driver+0x0/0xdc) from [<c02c8dd8>] (driver_detach+0xc4/0xc8)  r5:bf001ca8 r4:c0673778 [<c02c8d14>] (driver_detach+0x0/0xc8) from [<c02c804c>] (bus_remove_driver+0x9c/0x104)  r6:c0804ee0 r5:bf001ca8 r4:bf001ca8 r3:00000000 [<c02c7fb0>] (bus_remove_driver+0x0/0x104) from [<c02c950c>] (driver_unregister+0x60/0x80)  r6:c521e000 r5:bf001ca8 r4:00000000 r3:bf001924 [<c02c94ac>] (driver_unregister+0x0/0x80) from [<c02ca3a4>] (platform_driver_unregister+0x1c/0x20)  r5:00000000 r4:bf001d48 [<c02ca388>] (platform_driver_unregister+0x0/0x20) from [<bf001938>] (omap_nand_driver_exit+0x14/0x1c [omap2]) [<bf001924>] (omap_nand_driver_exit+0x0/0x1c [omap2]) from [<c009beb4>] (sys_delete_module+0x1f0/0x2ec) [<c009bcc4>] (sys_delete_module+0x0/0x2ec) from [<c0014dc0>] (ret_fast_syscall+0x0/0x48)  r8:c0015028 r7:00000081 r6:b6fe0032 r5:70616d6f r4:0001a004 Code: e1a00005 eb0d9172 e7f001f2 e7f001f2 (e7f001f2) ---[ end trace 6a30b24d8c0cc2ee ]--- Segmentation fault --->8---  This error was introduced in 67ce04bf2746f8a1f8c2a104b313d20c63f68378 which was the first commit of this driver.", "target": 0}
{"idx": 1904, "commit_message": "Update funkwhale connector  Add support for new UI. Add improvements for old UI.  Closes #2241.", "target": 0}
{"idx": 576, "commit_message": "Merge pull request #89 from j-h-a/improve-error-checking  Add a type-mismatch error to give more detail when the JSON is invalid because of the wrong type.", "target": 0}
{"idx": 2695, "commit_message": "alloc_percpu() fails to allocate percpu data  upstream commit: be852795e1c8d3829ddf3cb1ce806113611fa555  Some oprofile results obtained while using tbench on a 2x2 cpu machine were very surprising.  For example, loopback_xmit() function was using high number of cpu cycles to perform the statistic updates, supposed to be real cheap since they use percpu data          pcpu_lstats = netdev_priv(dev);         lb_stats = per_cpu_ptr(pcpu_lstats, smp_processor_id());         lb_stats->packets++;  /* HERE : serious contention */         lb_stats->bytes += skb->len;  struct pcpu_lstats is a small structure containing two longs.  It appears that on my 32bits platform, alloc_percpu(8) allocates a single cache line, instead of giving to each cpu a separate cache line.  Using the following patch gave me impressive boost in various benchmarks ( 6 % in tbench) (all percpu_counters hit this bug too)  Long term fix (ie >= 2.6.26) would be to let each CPU allocate their own block of memory, so that we dont need to roudup sizes to L1_CACHE_BYTES, or merging the SGI stuff of course...  Note : SLUB vs SLAB is important here to *show* the improvement, since they dont have the same minimum allocation sizes (8 bytes vs 32 bytes).  This could very well explain regressions some guys reported when they switched to SLUB.", "target": 1}
{"idx": 2817, "commit_message": "Added multiple tree mesh LODs to improve performance", "target": 1}
{"idx": 2706, "commit_message": "Improves shadowed table view performance using image views.", "target": 1}
{"idx": 3291, "commit_message": "MAGETWO-43212: Build performance test environment for cart rules   -- changed cart rule fixtures for performance", "target": 1}
{"idx": 3390, "commit_message": "WebVR: Fire display rAF synchronously with window rAF for magic window  We were posting display rAF for magic window when there was no reason to, which was making comparing window rAF and display rAF performance difficult. This CL fixes that, and adds a test to make sure display rAF is equivalent to window rAF in terms of scheduling.  This exposes the same race in getFrameData_oneframeupdate.html that was found in WebVrTabTest#testPoseDataUnfocusedTab, namely that the pose can start off being null, racily. The previous behavior of posting the vrDisplay rAF was hiding this.  Bug: 734747, 734208, 787196", "target": 0}
{"idx": 3930, "commit_message": "Proportional Rate Reduction for TCP.  This patch implements Proportional Rate Reduction (PRR) for TCP. PRR is an algorithm that determines TCP's sending rate in fast recovery. PRR avoids excessive window reductions and aims for the actual congestion window size at the end of recovery to be as close as possible to the window determined by the congestion control algorithm. PRR also improves accuracy of the amount of data sent during loss recovery.  The patch implements the recommended flavor of PRR called PRR-SSRB (Proportional rate reduction with slow start reduction bound) and replaces the existing rate halving algorithm. PRR improves upon the existing Linux fast recovery under a number of conditions including:   1) burst losses where the losses implicitly reduce the amount of outstanding data (pipe) below the ssthresh value selected by the congestion control algorithm and,   2) losses near the end of short flows where application runs out of data to send.  As an example, with the existing rate halving implementation a single loss event can cause a connection carrying short Web transactions to go into the slow start mode after the recovery. This is because during recovery Linux pulls the congestion window down to packets_in_flight+1 on every ACK. A short Web response often runs out of new data to send and its pipe reduces to zero by the end of recovery when all its packets are drained from the network. Subsequent HTTP responses using the same connection will have to slow start to raise cwnd to ssthresh. PRR on the other hand aims for the cwnd to be as close as possible to ssthresh by the end of recovery.  A description of PRR and a discussion of its performance can be found at the following links: - IETF Draft:     [URL]/html/draft-mathis-tcpm-proportional-rate-reduction-01 - IETF Slides:     [URL]/proceedings/80/slides/tcpm-6.pdf     [URL]/agenda/81/slides/tcpm-2.pdf - Paper to appear in Internet Measurements Conference (IMC) 2011:     Improving TCP Loss Recovery     Nandita Dukkipati, Matt Mathis, Yuchung Cheng", "target": 1}
{"idx": 2840, "commit_message": "more efficient, dynamic algorithm to check winner", "target": 1}
{"idx": 3710, "commit_message": "Re-work annotation -- less wonky, more efficient", "target": 1}
{"idx": 2409, "commit_message": "Reorder the conneg offers to put XML-based formats after Turtle (RDF) and JSON (Resultsets) which are more efficient.", "target": 1}
{"idx": 3804, "commit_message": "Syncing PlayPage to latest reducers. Removing multiple redux actions to generateKua to improve performance", "target": 1}
{"idx": 3284, "commit_message": "wip: intelli_plug: change logic for better benchmark performance", "target": 1}
{"idx": 3697, "commit_message": "alpha: cleanup in bitops.h  Remove 2 functions private to the alpha implemetation, in favor of similar functions in <linux/log2.h>.  Provide a more efficient version of the fls64 function for pre-ev67 alphas.", "target": 1}
{"idx": 269, "commit_message": "Add migration support from agent to NSX dhcp/metadata services  This is feature patch (3 of 3) that introduces support for transitioning existing NSX-based deployments from the agent based model of providing dhcp and metadata proxy services to the new agentless based mode. In 'combined' mode, existing networks will still be served by the existing infrastructure, whereas new networks will be served by the new infrastructure.  Networks may be migrated to the model using a new CLI tool provided, called 'neutron-nsx-manage'. Currently the tool provides two admin-only commands:    neutron-nsx-manage net-report <net-id-or-name>  This will check that the network can be migrated and returns the resources currently in use. And:    neutron-nsx-manage net-migrate <net-id-or-name>  This will move the network over the new model and deallocate resources from the agent. Once a network has been migrated there is no turning back.  Completes-blueprint nsx-integrated-services", "target": 0}
{"idx": 638, "commit_message": "Let's use sync facilities instead of routines. It does not make much sence to sequence reads, so RLock is enough. Also there's no performance benefit of using routines instead of Locks.", "target": 0}
{"idx": 543, "commit_message": "openmoko-panel-memory: shows an out-of-memory warning in the OpenMoko panel * add entry in moko-autorev.inc * add entry in sane-srcrevs.inc", "target": 0}
{"idx": 3118, "commit_message": "[MINOR][SYSTEMML-1741] Improved graph traversal on codegen plan costing   This patch makes a minor improvement of the codegen graph traversal for plan costing by stopping at partition boundaries instead of traversing to the leafs without taking the costs into account. On lenet this led to a minor but consistent improvement of codegen compilation overheads from 14.4s to 13.1s (for enumerating 474,840 plans).", "target": 1}
{"idx": 3195, "commit_message": "Performance improvements (from 11 to 6 seconds loading a library with 95 \"vaccination\" books)", "target": 1}
{"idx": 311, "commit_message": "Provide improved mechanism to add GATK jars into bcbio-nextgen. Handles updating version information in manifest and supports academic and commerical downloads. Fixes #332", "target": 0}
{"idx": 1947, "commit_message": "Mac: improve hover/clicked state appearance of bookmark bar buttons.  I more or less implemented things as per discussion with Cole and Glen. (This does not re-create the appearance on Win Chrome, which is not exactly right either.)  BUG=28477 TEST=Load various themes (in particular, \"Karim Rashid\") and make sure bookmark bar buttons look good and legible in hover and pressed states.  Review URL: [URL]/440001", "target": 0}
{"idx": 1736, "commit_message": "New version: RecurrenceAnalysis v1.5.0 (#27763)  UUID: 639c3291-70d9-5ea2-8c5b-839eba1ee399 Repo: [URL]/JuliaDynamics/RecurrenceAnalysis.jl.git Tree: 7e3ba9dbb628119c8f8333516dd6f128b29c4a70  Registrator tree SHA: 7c16227cd1dc9bae38e25d6dc6f9c020f8ebca46", "target": 0}
{"idx": 2060, "commit_message": "powerpc/fsl: Distribute interrupts on all CPUs by default  At least for crypto/IPSec, doing so provides users with a better performance experience out of the box.", "target": 1}
{"idx": 3990, "commit_message": "asset video: performance optimizations (cache duration)", "target": 1}
{"idx": 1189, "commit_message": "realtime graph for recurrent neural network done !", "target": 0}
{"idx": 2374, "commit_message": "comment about potential improvements before I forget.  this however is not the focus of the migration, let's get things working again before worrying about performance.", "target": 0}
{"idx": 2848, "commit_message": "touch/mouse events are both handled simultaneously, module rewritten for better performances (see issue #18)", "target": 1}
{"idx": 2072, "commit_message": "Introduce additional experimental performance optimization. refs #1232  * Add `RKMappingOperatationDelegate` method to enable the data source to instruct the operation to skip performing value comparisons when assigning properties * Add `RKMappingOperatationDelegate` method to enable the data source to instruct the operation to skip property mapping all together * Add `modificationKey` attribute to enable the property assignment to be skipped when mapping entities that have not changed", "target": 1}
{"idx": 608, "commit_message": "fix(meshing): Raise ValueError on lack of arguments on non-fractured grids (#402)  If the FractureNetwork_3d does not contain any fractures, and impose_external_boundary is  called with domain=None, the method will fail with a cryptic error message unrelated to the  real issue.  Instead, throw an error before anything bad happens", "target": 0}
{"idx": 3095, "commit_message": "mutex: Make more scalable by doing less atomic operations  Date\tMon, 15 Apr 2013 10:37:57 -0400  In the __mutex_lock_common() function, an initial entry into the lock slow path will cause two atomic_xchg instructions to be issued. Together with the atomic decrement in the fast path, a total of three atomic read-modify-write instructions will be issued in rapid succession. This can cause a lot of cache bouncing when many tasks are trying to acquire the mutex at the same time.  This patch will reduce the number of atomic_xchg instructions used by checking the counter value first before issuing the instruction. The atomic_read() function is just a simple memory read. The atomic_xchg() function, on the other hand, can be up to 2 order of magnitude or even more in cost when compared with atomic_read(). By using atomic_read() to check the value first before calling atomic_xchg(), we can avoid a lot of unnecessary cache coherency traffic. The only downside with this change is that a task on the slow path will have a tiny bit less chance of getting the mutex when competing with another task in the fast path.  The same is true for the atomic_cmpxchg() function in the mutex-spin-on-owner loop. So an atomic_read() is also performed before calling atomic_cmpxchg().  The mutex locking and unlocking code for the x86 architecture can allow any negative number to be used in the mutex count to indicate that some tasks are waiting for the mutex. I am not so sure if that is the case for the other architectures. So the default is to avoid atomic_xchg() if the count has already been set to -1. For x86, the check is modified to include all negative numbers to cover a larger case.  The following table shows the jobs per minutes (JPM) scalability data on an 8-node 80-core Westmere box with a 3.7.10 kernel. The numactl command is used to restrict the running of the high_systime workloads to 1/2/4/8 nodes with hyperthreading on and off.  +-----------------+-----------+------------+----------+ |  Configuration  | Mean JPM  |  Mean JPM  | % Change | |\t\t  | w/o patch | with patch |\t      | +-----------------+-----------------------------------+ |\t\t  |      User Range 1100 - 2000\t      | +-----------------+-----------------------------------+ | 8 nodes, HT on  |    36980   |   148590  | +301.8%  | | 8 nodes, HT off |    42799   |   145011  | +238.8%  | | 4 nodes, HT on  |    61318   |   118445  |  +51.1%  | | 4 nodes, HT off |   158481   |   158592  |   +0.1%  | | 2 nodes, HT on  |   180602   |   173967  |   -3.7%  | | 2 nodes, HT off |   198409   |   198073  |   -0.2%  | | 1 node , HT on  |   149042   |   147671  |   -0.9%  | | 1 node , HT off |   126036   |   126533  |   +0.4%  | +-----------------+-----------------------------------+ |\t\t  |       User Range 200 - 1000\t      | +-----------------+-----------------------------------+ | 8 nodes, HT on  |   41525    |   122349  | +194.6%  | | 8 nodes, HT off |   49866    |   124032  | +148.7%  | | 4 nodes, HT on  |   66409    |   106984  |  +61.1%  | | 4 nodes, HT off |  119880    |   130508  |   +8.9%  | | 2 nodes, HT on  |  138003    |   133948  |   -2.9%  | | 2 nodes, HT off |  132792    |   131997  |   -0.6%  | | 1 node , HT on  |  116593    |   115859  |   -0.6%  | | 1 node , HT off |  104499    |   104597  |   +0.1%  | +-----------------+------------+-----------+----------+ At low user range 10-100, the JPM differences were within +/-1%. So they are not that interesting.  AIM7 benchmark run has a pretty large run-to-run variance due to random nature of the subtests executed. So a difference of less than +-5% may not be really significant.  This patch improves high_systime workload performance at 4 nodes and up by maintaining transaction rates without significant drop-off at high node count.  The patch has practically no impact on 1 and 2 nodes system.  The table below shows the percentage time (as reported by perf record -a -s -g) spent on the __mutex_lock_slowpath() function by the high_systime workload at 1500 users for 2/4/8-node configurations with hyperthreading off.  +---------------+-----------------+------------------+---------+ | Configuration | %Time w/o patch | %Time with patch | %Change | +---------------+-----------------+------------------+---------+ |    8 nodes    |      65.34%     |      0.69%       |  -99%   | |    4 nodes    |       8.70%\t  |      1.02%\t     |  -88%   | |    2 nodes    |       0.41%     |      0.32%       |  -22%   | +---------------+-----------------+------------------+---------+ It is obvious that the dramatic performance improvement at 8 nodes was due to the drastic cut in the time spent within the __mutex_lock_slowpath() function.  The table below show the improvements in other AIM7 workloads (at 8 nodes, hyperthreading off).  +--------------+---------------+----------------+-----------------+ |   Workload   | mean % change | mean % change  | mean % change   | |              | 10-100 users  | 200-1000 users | 1100-2000 users | +--------------+---------------+----------------+-----------------+ | alltests     |     +0.6%     |   +104.2%      |   +185.9%       | | five_sec     |     +1.9%     |     +0.9%      |     +0.9%       | | fserver      |     +1.4%     |     -7.7%      |     +5.1%       | | new_fserver  |     -0.5%     |     +3.2%      |     +3.1%       | | shared       |    +13.1%     |   +146.1%      |   +181.5%       | | short        |     +7.4%     |     +5.0%      |     +4.2%       | +--------------+---------------+----------------+-----------------+", "target": 1}
{"idx": 420, "commit_message": "Improve html for article Improve admin panel title Add title in frontend", "target": 0}
{"idx": 155, "commit_message": "godoc: peephole optimization for generated HTML  When searching for regular expressions such as \".\", there are many consecutive matches. In the generated HTML, combine them instead of generating a new <span> for each adjacent text segment highlighting a match.  Massively reduces the size of the generated HTML in those cases.  R=r, rsc CC=golang-dev [URL]/3971041  Committer: Robert Griesemer [URL]>", "target": 1}
{"idx": 3196, "commit_message": "ENH: hugely improve performance of to_datetime on ISO8601 data #1571", "target": 1}
{"idx": 3904, "commit_message": "assoc_array: don't call compare_object() on a node  [ Upstream commit 8d4a2ec1e0b41b0cf9a0c5cd4511da7f8e4f3de2 ]  Changes since V1: fixed the description and added KASan warning.  In assoc_array_insert_into_terminal_node(), we call the compare_object() method on all non-empty slots, even when they're not leaves, passing a pointer to an unexpected structure to compare_object(). Currently it causes an out-of-bound read access in keyring_compare_object detected by KASan (see below). The issue is easily reproduced with keyutils testsuite. Only call compare_object() when the slot is a leave.  KASan warning: ================================================================== BUG: KASAN: slab-out-of-bounds in keyring_compare_object+0x213/0x240 at addr ffff880060a6f838 Read of size 8 by task keyctl/1655 ============================================================================= BUG kmalloc-192 (Not tainted): kasan: bad access detected -----------------------------------------------------------------------------  Disabling lock debugging due to kernel taint INFO: Allocated in assoc_array_insert+0xfd0/0x3a60 age=69 cpu=1 pid=1647 \t___slab_alloc+0x563/0x5c0 \t__slab_alloc+0x51/0x90 \tkmem_cache_alloc_trace+0x263/0x300 \tassoc_array_insert+0xfd0/0x3a60 \t__key_link_begin+0xfc/0x270 \tkey_create_or_update+0x459/0xaf0 \tSyS_add_key+0x1ba/0x350 \tentry_SYSCALL_64_fastpath+0x12/0x76 INFO: Slab 0xffffea0001829b80 objects=16 used=8 fp=0xffff880060a6f550 flags=0x3fff8000004080 INFO: Object 0xffff880060a6f740 @offset=5952 fp=0xffff880060a6e5d1  Bytes b4 ffff880060a6f730: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................ Object ffff880060a6f740: d1 e5 a6 60 00 88 ff ff 0e 00 00 00 00 00 00 00  ...`............ Object ffff880060a6f750: 02 cf 8e 60 00 88 ff ff 02 c0 8e 60 00 88 ff ff  ...`.......`.... Object ffff880060a6f760: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................ Object ffff880060a6f770: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................ Object ffff880060a6f780: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................ Object ffff880060a6f790: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................ Object ffff880060a6f7a0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................ Object ffff880060a6f7b0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................ Object ffff880060a6f7c0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................ Object ffff880060a6f7d0: 02 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................ Object ffff880060a6f7e0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................ Object ffff880060a6f7f0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................ CPU: 0 PID: 1655 Comm: keyctl Tainted: G    B           4.5.0-rc4-kasan+ #291 Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011  0000000000000000 000000001b2800b4 ffff880060a179e0 ffffffff81b60491  ffff88006c802900 ffff880060a6f740 ffff880060a17a10 ffffffff815e2969  ffff88006c802900 ffffea0001829b80 ffff880060a6f740 ffff880060a6e650 Call Trace:  [<ffffffff81b60491>] dump_stack+0x85/0xc4  [<ffffffff815e2969>] print_trailer+0xf9/0x150  [<ffffffff815e9454>] object_err+0x34/0x40  [<ffffffff815ebe50>] kasan_report_error+0x230/0x550  [<ffffffff819949be>] ? keyring_get_key_chunk+0x13e/0x210  [<ffffffff815ec62d>] __asan_report_load_n_noabort+0x5d/0x70  [<ffffffff81994cc3>] ? keyring_compare_object+0x213/0x240  [<ffffffff81994cc3>] keyring_compare_object+0x213/0x240  [<ffffffff81bc238c>] assoc_array_insert+0x86c/0x3a60  [<ffffffff81bc1b20>] ? assoc_array_cancel_edit+0x70/0x70  [<ffffffff8199797d>] ? __key_link_begin+0x20d/0x270  [<ffffffff8199786c>] __key_link_begin+0xfc/0x270  [<ffffffff81993389>] key_create_or_update+0x459/0xaf0  [<ffffffff8128ce0d>] ? trace_hardirqs_on+0xd/0x10  [<ffffffff81992f30>] ? key_type_lookup+0xc0/0xc0  [<ffffffff8199e19d>] ? lookup_user_key+0x13d/0xcd0  [<ffffffff81534763>] ? memdup_user+0x53/0x80  [<ffffffff819983ea>] SyS_add_key+0x1ba/0x350  [<ffffffff81998230>] ? key_get_type_from_user.constprop.6+0xa0/0xa0  [<ffffffff828bcf4e>] ? retint_user+0x18/0x23  [<ffffffff8128cc7e>] ? trace_hardirqs_on_caller+0x3fe/0x580  [<ffffffff81004017>] ? trace_hardirqs_on_thunk+0x17/0x19  [<ffffffff828bc432>] entry_SYSCALL_64_fastpath+0x12/0x76 Memory state around the buggy address:  ffff880060a6f700: fc fc fc fc fc fc fc fc 00 00 00 00 00 00 00 00  ffff880060a6f780: 00 00 00 00 00 00 00 00 00 00 00 fc fc fc fc fc >ffff880060a6f800: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc                                         ^  ffff880060a6f880: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc  ffff880060a6f900: fc fc fc fc fc fc 00 00 00 00 00 00 00 00 00 00 ==================================================================", "target": 0}
{"idx": 1041, "commit_message": "runtime cpu detection for the idct", "target": 0}
{"idx": 8, "commit_message": "* README improved with other modules section.", "target": 0}
{"idx": 1404, "commit_message": "Improvements to helper class for cases where index or path not required", "target": 0}
{"idx": 2852, "commit_message": "CCured: changed the qualifier hashtable to an array in the hopes of improving performance.  My hopes were quickly dashed, but the change probably doesn't hurt.  Added Util.deepCopyGrowArray", "target": 1}
{"idx": 2466, "commit_message": "Bug#51741 Unit test pfs-t failing in mysql-next-mr-bugfixing  The root cause of the failure is that when Bug#51447 performance schema evil twin files was fixed, instrumented file names got normalized.  The pfs-t unit test depends on this file normalization, but it was not updated.  This fix aligns pfs-t.cc lookup_file_by_name() with the logic in pfs_instr.cc find_or_create_file().", "target": 0}
{"idx": 2142, "commit_message": "undid some of the mailbox changes, modified message handlers to take a string-based stream rather than a generic stream, which allows for some more efficient usage", "target": 1}
{"idx": 2570, "commit_message": "at76c50x-usb: use ether_addr_equal_64bits  Ether_addr_equal_64bits is more efficient than ether_addr_equal, and can be used when each argument is an array within a structure that contains at least two bytes of data beyond the array.  The structures involved are: at76_priv defined in drivers/net/wireless/at76c50x-usb.h and ieee80211_mgmt defined in include/linux/ieee80211.h  This was done using Coccinelle (http://coccinelle.lip6.fr/).", "target": 1}
{"idx": 3317, "commit_message": "Merge pull request #1305 from oakdays/patch-1  Small improvements to the documentation", "target": 0}
{"idx": 2974, "commit_message": "defconfig: msm8916: Enable BALANCE_ANON_FILE_RECLAIM  BALANCE_ANON_FILE_RECLAIM helps in improving headroom by swapping anon memory earlier. This helps saving more memory and helps overall system performance when ZRAM is enabled. Enable this config for performance reasons.", "target": 1}
{"idx": 3790, "commit_message": "Merge remote-tracking branch 'refs/remotes/origin/feature' into feature  add feature suggested in issue #7, improve performance of annotation view.", "target": 1}
{"idx": 4013, "commit_message": "[PATCH] reverted commit 76d5bddd5c3dfdef76beaab8222231624eb75e89.\n Split ga_acc in moints2x_trf2K in smaller ga_acc on MPI-PR since gives large\n performance improvement on NERSC Cori", "target": 1}
{"idx": 1522, "commit_message": "fs/dcache.c: add cond_resched() to shrink_dcache_parent()  commit 421348f1ca0bf17769dee0aed4d991845ae0536d upstream.  Call cond_resched() in shrink_dcache_parent() to maintain interactivity.  Before this patch:  \tvoid shrink_dcache_parent(struct dentry * parent) \t{ \t\twhile ((found = select_parent(parent, &dispose)) != 0) \t\t\tshrink_dentry_list(&dispose); \t}  select_parent() populates the dispose list with dentries which shrink_dentry_list() then deletes.  select_parent() carefully uses need_resched() to avoid doing too much work at once.  But neither shrink_dcache_parent() nor its called functions call cond_resched().  So once need_resched() is set select_parent() will return single dentry dispose list which is then deleted by shrink_dentry_list().  This is inefficient when there are a lot of dentry to process.  This can cause softlockup and hurts interactivity on non preemptable kernels.  This change adds cond_resched() in shrink_dcache_parent().  The benefit of this is that need_resched() is quickly cleared so that future calls to select_parent() are able to efficiently return a big batch of dentry.  These additional cond_resched() do not seem to impact performance, at least for the workload below.  Here is a program which can cause soft lockup if other system activity sets need_resched().  \tint main() \t{ \t        struct rlimit rlim; \t        int i; \t        int f[100000]; \t        char buf[20]; \t        struct timeval t1, t2; \t        double diff;  \t        /* cleanup past run */ \t        system(\"rm -rf x\");  \t        /* boost nfile rlimit */ \t        rlim.rlim_cur = 200000; \t        rlim.rlim_max = 200000; \t        if (setrlimit(RLIMIT_NOFILE, &rlim)) \t                err(1, \"setrlimit\");  \t        /* make directory for files */ \t        if (mkdir(\"x\", 0700)) \t                err(1, \"mkdir\");  \t        if (gettimeofday(&t1, NULL)) \t                err(1, \"gettimeofday\");  \t        /* populate directory with open files */ \t        for (i = 0; i < 100000; i++) { \t                snprintf(buf, sizeof(buf), \"x/%d\", i); \t                f[i] = open(buf, O_CREAT); \t                if (f[i] == -1) \t                        err(1, \"open\"); \t        }  \t        /* close some of the files */ \t        for (i = 0; i < 85000; i++) \t                close(f[i]);  \t        /* unlink all files, even open ones */ \t        system(\"rm -rf x\");  \t        if (gettimeofday(&t2, NULL)) \t                err(1, \"gettimeofday\");  \t        diff = (((double)t2.tv_sec * 1000000 + t2.tv_usec) - \t                ((double)t1.tv_sec * 1000000 + t1.tv_usec));  \t        printf(\"done: %g elapsed \", diff/1e6); \t        return 0; \t}", "target": 1}
{"idx": 2088, "commit_message": "Patch by P. Pelissier to improve accuracy of x86/amd64 timings", "target": 0}
{"idx": 4091, "commit_message": "[PATCH] Increase memory allocation for NPT simulation in Ewald.cpp.\n Assign linear molecule with 3 and more atoms to DCGraph at higher level to\n improve code performance", "target": 1}
{"idx": 384, "commit_message": "Fix small memory leak and refactor libpythonWorkaround", "target": 0}
{"idx": 2312, "commit_message": "Merged revisions 4369-4576 via svnmerge from  [URL]/svn/scons/trunk  ........   r4375 | stevenknight | 2009-09-19 18:10:42 -0700 (Sat, 19 Sep 2009) | 3 lines      Update project pages for tigris ........   r4376 | gregnoel | 2009-09-23 14:13:24 -0700 (Wed, 23 Sep 2009) | 1 line      Use Glob() instead of glob.glob() ........   r4377 | cournape | 2009-09-26 05:00:20 -0700 (Sat, 26 Sep 2009) | 1 line      Update CHANGES.txt for the small bug fixes I commited recently. ........   r4378 | garyo | 2009-10-14 14:06:24 -0700 (Wed, 14 Oct 2009) | 1 line      MSVC: Add correct x86_64/x66_64 msvc bat file location for VC 9.0 (2008). ........   r4379 | cournape | 2009-10-31 00:20:44 -0700 (Sat, 31 Oct 2009) | 1 line      BUG: fix bootstrap on windows 64. ........   r4380 | bdbaddog | 2009-11-09 22:49:02 -0800 (Mon, 09 Nov 2009) | 4 lines      Add check for python 3.0.0 or higher and exit with message.   Resolve bug 2445 ........   r4381 | gregnoel | 2009-11-10 18:06:25 -0800 (Tue, 10 Nov 2009) | 1 line      Remove old news items. ........   r4384 | bdbaddog | 2009-11-11 23:32:38 -0800 (Wed, 11 Nov 2009) | 3 lines      Fix bug 2465 - bootstrap.py should now use the python it was invoked with instead of finding the same named executable via the PATH ........   r4388 | bdbaddog | 2009-11-13 16:47:32 -0800 (Fri, 13 Nov 2009) | 3 lines      Fix bug 1944 - handle non-existant .i files when swig emitter is called. Make an educated guess on the generated module name based on the .i file name. ........   r4389 | bdbaddog | 2009-11-13 21:56:42 -0800 (Fri, 13 Nov 2009) | 3 lines      Fix issue 2519 - add textfile to list of builders ........   r4392 | garyo | 2009-11-15 06:32:02 -0800 (Sun, 15 Nov 2009) | 3 lines      Apply patch submitted in issue #947 to fix race condition in   TempFileMunge by using mkstemp instead of mktemp.  Includes   pre-Python-2.3 compat version of mkstemp.  Thanks to Jim Randall. ........   r4393 | stevenknight | 2009-11-15 08:18:17 -0800 (Sun, 15 Nov 2009) | 2 lines      1.5.2 fix in compat/__init__.py:  \"flags |= ...\" => \"flags = flags | ...\" ........   r4396 | stevenknight | 2009-11-15 10:03:52 -0800 (Sun, 15 Nov 2009) | 2 lines      1.5 fix:  use apply() instead of (*args, **kw). ........   r4397 | stevenknight | 2009-11-15 11:32:06 -0800 (Sun, 15 Nov 2009) | 2 lines      Python 1.5 fix:  \"mname += ...\" => \"mname = mname + ...\" ........   r4401 | stevenknight | 2009-11-17 18:00:43 -0800 (Tue, 17 Nov 2009) | 2 lines      Issue 2481:  Fix the msvc_exists() call in Tool/msvc.py. ........   r4402 | stevenknight | 2009-11-17 20:55:03 -0800 (Tue, 17 Nov 2009) | 2 lines      Fix name typo in 1.5.2 patch. ........   r4433 | cournape | 2009-11-18 20:51:43 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: refactor function to get msvc version. ........   r4434 | cournape | 2009-11-18 20:52:17 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: script_env now takes an args argument to forward arguments to the executed script. ........   r4435 | cournape | 2009-11-18 20:52:55 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: bypass complicated VisualC logic, and use the .bat file to get correct arch settings instead. ........   r4436 | cournape | 2009-11-18 20:53:31 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: factor host/target handling in separate function. ........   r4437 | cournape | 2009-11-18 20:54:08 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: move user info gathering at the top of msvc_setup_env. ........   r4438 | cournape | 2009-11-18 20:54:49 -0800 (Wed, 18 Nov 2009) | 1 line      BUG: fix arch argument to pass to batfile. ........   r4439 | cournape | 2009-11-18 20:55:31 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: add a wrapper around msvc_setup_env to guarantee the function is called only once. ........   r4440 | cournape | 2009-11-18 20:56:16 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: use msvc env, not msvs to set up mslib and mslink paths. ........   r4441 | cournape | 2009-11-18 20:56:55 -0800 (Wed, 18 Nov 2009) | 1 line      BUG: do not call msvs bat file in merge_default_version, only set up version. ........   r4442 | cournape | 2009-11-18 20:57:30 -0800 (Wed, 18 Nov 2009) | 1 line      BUG: fix cross-compilation from x86 -> x86_64 for VS 2008. ........   r4443 | cournape | 2009-11-18 20:58:09 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: start a new, simpler and more robust vc module. ........   r4444 | cournape | 2009-11-18 20:58:46 -0800 (Wed, 18 Nov 2009) | 1 line      BUG: do not set up the SDK for now - it messes up cross compilation. ........   r4445 | cournape | 2009-11-18 20:59:23 -0800 (Wed, 18 Nov 2009) | 1 line      BUG: fix get_installed_vcs such as most recent versions are the first ones. ........   r4446 | cournape | 2009-11-18 20:59:58 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: raise an exception when we detect an error while executing the batch file. ........   r4447 | cournape | 2009-11-18 21:00:41 -0800 (Wed, 18 Nov 2009) | 1 line      DOC: add a TODO for updated vc support. ........   r4448 | cournape | 2009-11-18 21:01:22 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: use a pre-sorted list for MSVC versions to check. ........   r4449 | cournape | 2009-11-18 21:02:08 -0800 (Wed, 18 Nov 2009) | 1 line      REF: move vc2 to vc module. ........   r4450 | cournape | 2009-11-18 21:02:55 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: handle MSVS_VERSION additionally to MSVC_VERSION, but raise deprecation warnings if used. ........   r4451 | cournape | 2009-11-18 21:03:36 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: use msvc_exists for all tools in the Visual Studio toolchain. ........   r4452 | cournape | 2009-11-18 21:04:17 -0800 (Wed, 18 Nov 2009) | 1 line      BUG: catch error while canonalizing arch for host/target. ........   r4453 | cournape | 2009-11-18 21:04:55 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: set up MSVS_VERSION and MSVS dict while setting up msvc as well. ........   r4454 | cournape | 2009-11-18 21:05:37 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: use Gary error checking, but using exception instead of returning error message (thanks Gary). ........   r4455 | cournape | 2009-11-18 21:06:20 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: add support for Itanium architecture. ........   r4456 | cournape | 2009-11-18 21:07:01 -0800 (Wed, 18 Nov 2009) | 1 line      BUG: catch any VisualCException when querying available versions through find_vc_pdir. ........   r4457 | cournape | 2009-11-18 21:07:41 -0800 (Wed, 18 Nov 2009) | 1 line      BUG: return early with warning if no version of vc is found. ........   r4458 | cournape | 2009-11-18 21:08:16 -0800 (Wed, 18 Nov 2009) | 1 line      BUG: fix MSVC_USE_SCRIPT=False case. ........   r4459 | cournape | 2009-11-18 21:08:51 -0800 (Wed, 18 Nov 2009) | 1 line      REF: remove duplicated function msvc_setup_env_once. ........   r4460 | cournape | 2009-11-18 21:09:27 -0800 (Wed, 18 Nov 2009) | 1 line      DOC: add doc for TARGET_ARCH/HOST_ARCH + obsolete MSVS_VERSION. ........   r4461 | cournape | 2009-11-18 21:22:18 -0800 (Wed, 18 Nov 2009) | 1 line      BUG: fix caching bug for msvc_setup_once. ........   r4462 | cournape | 2009-11-18 21:38:09 -0800 (Wed, 18 Nov 2009) | 1 line      ENH: add a cache for get_installed_vcs, as it used for every MS tool exists function and is expensive. ........   r4463 | stevenknight | 2009-11-19 00:03:26 -0800 (Thu, 19 Nov 2009) | 2 lines      Capture initial infrastructure for working performance tests. ........   r4464 | gregnoel | 2009-11-19 17:44:49 -0800 (Thu, 19 Nov 2009) | 1 line      Faster backward-compatible code ........   r4465 | stevenknight | 2009-11-22 10:26:25 -0800 (Sun, 22 Nov 2009) | 2 lines      Python 1.5 fixes in the TimeSCons class. ........   r4467 | stevenknight | 2009-11-22 17:59:17 -0800 (Sun, 22 Nov 2009) | 2 lines      Python 1.5 compat:  if 'text' in kw.keys() ........   r4470 | cournape | 2009-11-22 23:43:58 -0800 (Sun, 22 Nov 2009) | 1 line      REF: query host/target arch only when using bat file. ........   r4471 | cournape | 2009-11-22 23:44:43 -0800 (Sun, 22 Nov 2009) | 1 line      ENH: explicit check for supported arch per version when using batch file. ........   r4474 | stevenknight | 2009-11-23 17:58:03 -0800 (Mon, 23 Nov 2009) | 2 lines      Fix incorrectly inverted condition in test for non-TimeSCons entries. ........   r4475 | garyo | 2009-11-23 18:05:34 -0800 (Mon, 23 Nov 2009) | 1 line      Fix check for too-old Visual Studio with non-x86 arch; thanks to Roberto De Vecchi. ........   r4476 | stevenknight | 2009-11-23 18:12:50 -0800 (Mon, 23 Nov 2009) | 6 lines      Rename the TimeSCons.run_build() method to just TimeSCons.run() so   the parent class TestSCons.up_to_date() method will use it to print   the --debug=memory and --debug=times stats during up-to-date runs.   Fix the TestSCons.up_to_date() regular expression so the memory   and timing output won't cause the check to fail. ........   r4477 | garyo | 2009-11-23 19:13:13 -0800 (Mon, 23 Nov 2009) | 1 line      Doc tweaks for MSVC_VERSION and TARGET_ARCH. ........   r4480 | garyo | 2009-11-24 18:17:20 -0800 (Tue, 24 Nov 2009) | 1 line      Fix tests to ignore missing MSVC warnings. ........   r4481 | garyo | 2009-11-24 19:27:20 -0800 (Tue, 24 Nov 2009) | 1 line      A couple more test fixes, to make test/import.py work on Linux. ........   r4482 | garyo | 2009-11-24 19:51:06 -0800 (Tue, 24 Nov 2009) | 1 line      Another test fix for the MSVS tests. ........   r4483 | managan | 2009-11-25 13:47:43 -0800 (Wed, 25 Nov 2009) | 10 lines      Add a test for the case where a latex file uses input{} to include the   file that contains the documentclass command      Add logic to is_LaTeX routine to search through included files until   documentclass is found      Also added comments, converted comments at start of 2 routines into doc   strings.. ........   r4485 | stevenknight | 2009-11-26 11:20:47 -0800 (Thu, 26 Nov 2009) | 2 lines      Python 1.5 fix:  no += ........   r4486 | garyo | 2009-11-26 13:13:37 -0800 (Thu, 26 Nov 2009) | 1 line      Use VisualCMissingWarning instead of making a stack trace for unsupported MSVC version. ........   r4487 | garyo | 2009-11-26 14:09:23 -0800 (Thu, 26 Nov 2009) | 1 line      Fix wrong var name in r4486, thanks Greg! ........   r4488 | stevenknight | 2009-11-27 07:30:53 -0800 (Fri, 27 Nov 2009) | 2 lines      Add __COPYRIGHT__ strings. ........   r4489 | stevenknight | 2009-11-27 08:41:56 -0800 (Fri, 27 Nov 2009) | 5 lines      Add a compat module for the (Python 2.3) platform.py module so that tests   using early Python versions work correctly, and without relying on the   QMTest infrastructure adding the installed Python version's directories   to sys.path. ........   r4490 | stevenknight | 2009-11-27 16:41:26 -0800 (Fri, 27 Nov 2009) | 2 lines      Fix test infrastructure querying for installed Visual Studio versions. ........   r4491 | stevenknight | 2009-11-27 16:41:44 -0800 (Fri, 27 Nov 2009) | 2 lines      Remove the obsolete msvs_exists() unit test. ........   r4492 | stevenknight | 2009-11-27 20:52:19 -0800 (Fri, 27 Nov 2009) | 3 lines      Don't hard-code the swig location in the expected output.   Use test.wrap_stdout() instead of hard-coding the SCons messages. ........   r4493 | stevenknight | 2009-11-27 22:17:41 -0800 (Fri, 27 Nov 2009) | 3 lines      Fix get_host_target()'s use of platform.machine() on Python versions   before 2.6, when it always returns a null string. ........   r4494 | stevenknight | 2009-11-28 20:25:57 -0800 (Sat, 28 Nov 2009) | 2 lines      Add missing \"import string\" to test that uses string.replace(). ........   r4495 | stevenknight | 2009-11-28 21:11:31 -0800 (Sat, 28 Nov 2009) | 3 lines      Fix c++ compiler detection:  correct the order of values returned,   return the dirname of the executables found, not the full path. ........   r4498 | stevenknight | 2009-11-30 05:47:11 -0800 (Mon, 30 Nov 2009) | 4 lines      Explicitly initialize the environment tools=['mssdk', 'msvc', 'mslink']   to get the path to the SDK include directory (so our test program can   #include <windows.h>). ........   r4512 | garyo | 2009-12-04 18:39:27 -0800 (Fri, 04 Dec 2009) | 1 line      Integrate patch from issue #2436: fix regression from r3691 which stopped printing \"Entering Directory\" with -C/-u. ........   r4513 | garyo | 2009-12-06 06:17:33 -0800 (Sun, 06 Dec 2009) | 1 line      Fix typo in man page, per patch in issue #2529. ........   r4534 | stevenknight | 2009-12-08 14:02:30 -0800 (Tue, 08 Dec 2009) | 2 lines      Update the TimeSCons \"elapsed time\" message to match the log processor. ........   r4538 | stevenknight | 2009-12-09 10:23:57 -0800 (Wed, 09 Dec 2009) | 5 lines      Have the TimeSCons class examine the run output for the reported memory   use and timings, and translate these into TRACE: lines with keyword=value   pairs that will be processed by the now more generic buildbot-side log   processor to populate the timings graph data. ........   r4539 | stevenknight | 2009-12-09 11:28:41 -0800 (Wed, 09 Dec 2009) | 4 lines      Update the TimeSCons class for use of the sort= keyword instead of   important=.  Fix an old-version Python problem (use of True in   keyword arg initialization). ........   r4541 | stevenknight | 2009-12-09 19:42:30 -0800 (Wed, 09 Dec 2009) | 4 lines      Infrastructure to support calibration runs of TimeSCons tests, which   only run a full build and report back the values of any variables   affecting the configuration, and the elapsed time of the full build. ........   r4542 | stevenknight | 2009-12-09 22:19:43 -0800 (Wed, 09 Dec 2009) | 4 lines      Add a script for calibrating settings for timing configurations.   Update the timings scripts with calibrated settings that run   a full build between 9.5 and 10.0 seconds on the buildbot slave. ........   r4543 | stevenknight | 2009-12-10 05:36:10 -0800 (Thu, 10 Dec 2009) | 2 lines      Record memory in kbytest, not bytes. ........   r4544 | stevenknight | 2009-12-10 08:00:17 -0800 (Thu, 10 Dec 2009) | 4 lines      Add separate memory graphs for the stats in the full and null runs.   Refactor stats-gathering so we collect them from the output in one step   and can then trace them in multiple different ways. ........   r4545 | stevenknight | 2009-12-10 08:27:03 -0800 (Thu, 10 Dec 2009) | 5 lines      Provide an environment variable that can be used to override   setting --warn=no-visual-c-missing when trying to run the new   timing-script infrastructure against older versions of SCons that   don't have that warning. ........   r4546 | garyo | 2009-12-14 18:43:01 -0800 (Mon, 14 Dec 2009) | 1 line      Integrated patch for bug 2530: SCons should not exit with 0 (success) on unimplemented option error. ........   r4547 | stevenknight | 2009-12-14 22:35:05 -0800 (Mon, 14 Dec 2009) | 3 lines      Add a TestSCons.option_not_yet_implemented() method and use it so   the tests of those options expect an exit status of 1. ........   r4548 | stevenknight | 2009-12-15 13:44:56 -0800 (Tue, 15 Dec 2009) | 7 lines      Add a bin/time-scons.py script to manage invocation of runtest.py to   collect SCons timings.      The script will build SCons and time the pre-compiled *.pyc files,   and also provides options for timing a range of revisions directly   from SVN. ........   r4550 | stevenknight | 2009-12-15 14:40:17 -0800 (Tue, 15 Dec 2009) | 2 lines      Disable QMTest by default, leave it available when --qmtest is used. ........   r4551 | stevenknight | 2009-12-15 15:44:04 -0800 (Tue, 15 Dec 2009) | 2 lines      Typo fix. ........   r4552 | stevenknight | 2009-12-15 15:46:55 -0800 (Tue, 15 Dec 2009) | 2 lines      ...and call the correct method. ........   r4553 | garyo | 2009-12-15 18:29:54 -0800 (Tue, 15 Dec 2009) | 1 line      Better fix for #2530: dont exit at all on unimplemented options, just print a warning and keep going. ........   r4554 | stevenknight | 2009-12-15 23:07:13 -0800 (Tue, 15 Dec 2009) | 6 lines      Fix the tests of runtest.py now that QMTest is no longer being used   by default.  Fix use of subprocess in Python 2.4+ and exit statuses   of popen'ed scripts in earlier versions of Python.  Support the ability   to execute a directory's tests by naming the directory as a command-   line argument. ........   r4555 | stevenknight | 2009-12-16 18:09:50 -0800 (Wed, 16 Dec 2009) | 2 lines      Fix the time-scons.py --logfiles option. ........   r4556 | stevenknight | 2009-12-16 21:51:33 -0800 (Wed, 16 Dec 2009) | 2 lines      Add a separate test of the runtest.py --qmtest option. ........   r4557 | stevenknight | 2009-12-16 23:11:51 -0800 (Wed, 16 Dec 2009) | 4 lines      Ignore the exit status from the --help run on timing builds, since some   early revisions have bugs and we can still go on and get useful stats   from the full and null builds. ........   r4558 | stevenknight | 2009-12-17 07:23:20 -0800 (Thu, 17 Dec 2009) | 10 lines      Avoids bailing on non-zero exit status from commands.  This will lets   us collect as many stats as possible, even when a test for a revision   in the middle of the list fails due to a bug.   Updates the \"baseline\" timing revision (the revision that has   the earliest \"stable\" TimeSCons infrastructure   Removes --noqmtest, since the \"baseline\" revision no longer uses   QMTest by default.   Changes the --logfiles option to a --logsdir option.   Updates the usage message. ........   r4559 | managan | 2009-12-17 13:13:17 -0800 (Thu, 17 Dec 2009) | 4 lines      Add scanning of files included in Latex by means of lstinputlisting{}   Patch from Stefan Hepp. ........   r4560 | managan | 2009-12-17 14:06:41 -0800 (Thu, 17 Dec 2009) | 7 lines      Running PDF() on an .eps file on windows with MikTex 2.7.2767 does not work,    because it does not support '-o <outfile>'. This patch uses --outfile= instead,    since this works both unter linux and windows.      Patch from Stefan Hepp ........   r4561 | stevenknight | 2009-12-17 22:58:37 -0800 (Thu, 17 Dec 2009) | 3 lines      Trace the system load average (Linux-only code) before starting the   help / full / null builds in a timing run. ........   r4562 | stevenknight | 2009-12-18 00:03:50 -0800 (Fri, 18 Dec 2009) | 8 lines      Move the timings-specific pieces of the buildbot infrastructure into   the trunk/timings directory.  We'll map them into the buildbot directory   using svn:externals.  This will let us keep all the pieces of a timing   configuration, including its buildbot pieces, in one place, and will   let us simplify the Master initialization (since it will be able to look   on-disk for the configurations for which it should set up buildbot steps,   instead of querying the SVN server). ........   r4566 | stevenknight | 2009-12-18 01:26:23 -0800 (Fri, 18 Dec 2009) | 4 lines      Add config.js files to the timing configurations, and update graph.html   to use them to display configuration-specific info (right now just   the title) for each graph's page. ........   r4568 | stevenknight | 2009-12-19 08:11:40 -0800 (Sat, 19 Dec 2009) | 12 lines      Speed up the time-scons.py \"build\" of SCons with compiled *.pyc files,   by just invoking setup.py directly instead of packing and unpacking the   distributable .tar.gz file.      Refactor to be able to capture historical statistics (of previous   revisions) by preparing the \"built\" revision once and then running all   of the requested timing scripts, with output going to a separate log   file for each revision + script.      Fix TestSCons.py so that it interprets the scons script name to be tested   relative to the invoking directory, not always relative to src/script. ........   r4569 | stevenknight | 2009-12-19 08:18:25 -0800 (Sat, 19 Dec 2009) | 4 lines      Update the number of the \"base\" revision of bin/time-scons.py to use   for historical statistics.  Close the triple-quote in the doc string   I added right before the last checkin. ........   r4570 | garyo | 2009-12-20 08:04:13 -0800 (Sun, 20 Dec 2009) | 1 line      Add a message to the UserError raised when trying to do a Dir lookup with create=False.  Should not normally happen, but it did to me, and it is better to have some explanatory message when it happens rather than failing silently. ........   r4571 | gregnoel | 2009-12-20 11:14:04 -0800 (Sun, 20 Dec 2009) | 1 line      Issue 2482: Avoid wrapping decider unnecessarily ........   r4572 | stevenknight | 2009-12-21 23:57:36 -0800 (Mon, 21 Dec 2009) | 2 lines      Don't look for copyright strings in buildbot timings files. ........   r4574 | stevenknight | 2009-12-22 06:26:37 -0800 (Tue, 22 Dec 2009) | 2 lines      Fix the view-change detail tab.  Minor wording improvement. ........   r4575 | stevenknight | 2009-12-22 08:43:30 -0800 (Tue, 22 Dec 2009) | 2 lines      Add a -p option to support calibrating against build SCons packages. ........", "target": 0}
{"idx": 3050, "commit_message": "Overhaul some_cipher to make attacks more efficient.", "target": 1}
{"idx": 2653, "commit_message": "Big performance improvements to Enhanced Furnaces when using Paper", "target": 1}
{"idx": 190, "commit_message": "Small improvement of the benchmarks used for timing validation", "target": 0}
{"idx": 4023, "commit_message": "[PATCH] Changed number of nonbonded thread blocks to improve\n performance", "target": 1}
{"idx": 1411, "commit_message": "added initial support for network providers, and various fixes and refactorings", "target": 0}
{"idx": 4075, "commit_message": "[PATCH] 128-bit AVX2 SIMD for AMD Ryzen\n\nWhile Ryzen supports 256-bit AVX2, the internal units are organized\nto execute either a single 256-bit instruction or two 128-bit SIMD\ninstruction per cycle. Since most of our kernels are slightly\nless efficient for wider SIMD, this improves performance by roughly\n10%.\n\nChange-Id: Ie601b1dbe13d70334cdf9284e236ad9132951ec9", "target": 1}
{"idx": 2342, "commit_message": "INTERLOK-3451 exclude SHA1 from LGTM  - Since we use it for equality on a byte-stream that's going to form the keystore. The collision / insecurity implications from SHA-1 are largely minimal. - It does beg the question as to whether we should even be implementation equals() / hashcode() in this object. - Would it be more efficient to use Arrays.equals() on the whole byte-array rather than a time-constant MessageDigest.isEqual() on the hash?", "target": 0}
{"idx": 3897, "commit_message": "ARM: kernel: fix MPIDR cpu_{suspend}/{resume} usage  The current version of cpu_{suspend}/{resume} relies on the 8 LSBs of the MPIDR register to index the context pointer saved and restored on CPU shutdown. This approach breaks as soon as platforms with populated MPIDR affinity levels 1 and 2 are deployed, since the MPIDR cannot be considered a linear index anymore.  There are multiple solutions to this problem, each with pros and cons.  This patch changes cpu_{suspend}/{resume} so that the CPU logical id is used to retrieve an index into the context pointers array.  Performance is impacted on both save and restore paths. On save path the CPU logical id has to be retrieved from thread_info; since caches are on, the performance hit should be neglectable. In the resume code path the MMU is off and so are the caches. The patch adds a trivial for loop that polls the cpu_logical_map array scanning the present MPIDRs and retrieves the actual CPU logical index. Since everything runs out of strongly ordered memory the perfomance hit in the resume code path must be measured and thought over; it worsens as the number of CPUs increases since it is a linear search (but can be improved).  On the up side, the logical index approach is by far the easiest solution in terms of coding and make dynamic changes to the cpu mapping trivial at run-time.  Any change to the cpu_logical_map (ie in-kernel switcher) at run time must be cleaned from the caches since this data has to be retrieved with the MMU off, when caches are not searched.  Tested on TC2 and fast models.", "target": 0}
{"idx": 381, "commit_message": "2021/11/18 Add AirQuality, Historical, and Tropical API (#16802)  * 2021/08/05 Add Tropical api    * 2021/11/18 Add air quality api    * 2021/11/18 Add Historical api    * 2021/11/22 Update enum and add x-ms-client-name    * 2021/11/23 Update examples    * 2021/11/23 Update naming    * 2021/11/23 Create parameter for Position    * 2021/11/23 Update active storm    * 2021/11/30 Change reponse to result    * 2021/11/30 Add x-ms-client-name    * 2021/11/30 Update timestamp, coordinate, and radius naming in SDK    * 2021/11/30 Use WeatherUnit for Concentration    * 2021/11/30 Update Daily Air quality dominantPollutant    * 2021/11/30 Unify response format    * 2021/11/30 Unify CurrentAirQuality and HourlyAirQualityForecast    * 2021/12/01 Update window and weatherValue SDK name    * 2021/12/02 Update coordinate and left, right SDK name    * 2021/12/03 Add SDK name for results    * 2021/12/03 Improve Object name    * 2021/12/03 Update ActiveStorm    * 2021/12/03 Remove needless object and update name    * 2021/12/06 Add weather 2.0 directory    * 2021/12/06 Recover Weather 1.0 Swagger file    * 2021/12/07 Remove v2 from operationId    * 2021/12/08 Update readme.md    * Set default API version as 2.0    * 2022/01/07 Remove default value for api-version    * 2022/01/07 Remove needless custom-words    * 2022/01/11 Update api-version and add nextLink    * 2022/01/11 Update api-version in readme.md", "target": 0}
{"idx": 1633, "commit_message": "memory problem when installing matplotlib in dockerfile solved", "target": 0}
{"idx": 3692, "commit_message": "Patch.  Subtle improvements and corrects some small errors.", "target": 0}
{"idx": 3758, "commit_message": "Prefer AES when hardware acceleration is available  ChaCha20-Poly1305 is more efficient in software, but many modern CPUs have acceleration for AES which makes AES-GCM the more preferable choice in terms of throughput and battery consumption (i.e., less CPU cycles per byte).  Use the CPU features as reported by BoringSSL to determine when to prioritize AES-GCM over ChaCha20-Poly1305. This should be good enough to say when the trade-off should be made.  Bug: 26945889", "target": 1}
{"idx": 676, "commit_message": "Fixes to basic tutorial (#287)  Fix syntax issue in TPU example.    Better emphasize GPU driver installation step.", "target": 0}
{"idx": 2684, "commit_message": "[DASHBOARD] Improbe autoscale, prevent some glitch and improve performances by adding soft_redraw method", "target": 1}
{"idx": 2963, "commit_message": "go/printer: remove gratuitous string/[]byte conversions  Cleanup and slight performance improvement (1.5%).  Before (best of 3 runs): printer.BenchmarkPrint\t      50\t  47377420 ns/op  After (best of 3 runs): printer.BenchmarkPrint\t      50\t  46707180 ns/op  R=rsc CC=golang-dev [URL]/5416049", "target": 1}
{"idx": 3342, "commit_message": "Made the tree loading more efficient. Added paging to the project tree to overcome the speed of the tree and the potential number of tree nodes. Added a mechanism to update the project tree and others when a database update occurs. Added the project tree to the standard diagrams. Added the drag handler to the project tree. Added a query type that returns all entities that do not have a relation type eg ancestor or descendant. This will be used to display a ancestor or descendant tree for the project. Added an end point query which returns all entities that are the farthest ancestor or most recent descendant for use in the project tree. Added a project tree, project panel and project root node. refs #1814 #1825", "target": 1}
{"idx": 1407, "commit_message": "workqueue: skip nr_running sanity check in worker_enter_idle() if trustee is active  worker_enter_idle() has WARN_ON_ONCE() which triggers if nr_running isn't zero when every worker is idle.  This can trigger spuriously while a cpu is going down due to the way trustee sets %WORKER_ROGUE and zaps nr_running.  It first sets %WORKER_ROGUE on all workers without updating nr_running, releases gcwq->lock, schedules, regrabs gcwq->lock and then zaps nr_running.  If the last running worker enters idle inbetween, it would see stale nr_running which hasn't been zapped yet and trigger the WARN_ON_ONCE().  Fix it by performing the sanity check iff the trustee is idle.", "target": 0}
{"idx": 1824, "commit_message": "New using of MVP, creation of helpers. Weakreferences in prensenter for prevent memory leak about context", "target": 0}
{"idx": 467, "commit_message": "Moved two thrust-wrapped reducts out of class-loop  It was noticed that there was a large overhead associated with launching thrust-kernels. In the 3D-case this overhead is negligble compared to the time it takes to run the reductions, however, in the 2D case the problem size is so much reduced that theis is no longer the case. This commit represent edits to the code which benefits the 2D-classification by grouping reductions into a single call over all classes. It will benefit the 3D-classification to the same absolute extent, however that might not even be noticable.  The changes are made to thrust reductions  - min(diff) @ end of diff2coarse  - max_element(weight) @ end of storeWS", "target": 1}
{"idx": 2825, "commit_message": "Track the original assets more efficiently in Phase.  [URL] BUG=  Review URL: [URL]//26598002", "target": 0}
{"idx": 1827, "commit_message": "mm/huge_memory.c: respect FOLL_FORCE/FOLL_COW for thp  commit 8310d48b125d19fcd9521d83b8293e63eb1646aa upstream.  In commit 19be0eaffa3a (\"mm: remove gup_flags FOLL_WRITE games from __get_user_pages()\"), the mm code was changed from unsetting FOLL_WRITE after a COW was resolved to setting the (newly introduced) FOLL_COW instead.  Simultaneously, the check in gup.c was updated to still allow writes with FOLL_FORCE set if FOLL_COW had also been set.  However, a similar check in huge_memory.c was forgotten.  As a result, remote memory writes to ro regions of memory backed by transparent huge pages cause an infinite loop in the kernel (handle_mm_fault sets FOLL_COW and returns 0 causing a retry, but follow_trans_huge_pmd bails out immidiately because `(flags & FOLL_WRITE) && !pmd_write(*pmd)` is true.  While in this state the process is stil SIGKILLable, but little else works (e.g.  no ptrace attach, no other signals).  This is easily reproduced with the following code (assuming thp are set to always):      #include <assert.h>     #include <fcntl.h>     #include <stdint.h>     #include <stdio.h>     #include <string.h>     #include <sys/mman.h>     #include <sys/stat.h>     #include <sys/types.h>     #include <sys/wait.h>     #include <unistd.h>      #define TEST_SIZE 5 * 1024 * 1024      int main(void) {       int status;       pid_t child;       int fd = open(\"/proc/self/mem\", O_RDWR);       void *addr = mmap(NULL, TEST_SIZE, PROT_READ,                         MAP_ANONYMOUS | MAP_PRIVATE, 0, 0);       assert(addr != MAP_FAILED);       pid_t parent_pid = getpid();       if ((child = fork()) == 0) {         void *addr2 = mmap(NULL, TEST_SIZE, PROT_READ | PROT_WRITE,                            MAP_ANONYMOUS | MAP_PRIVATE, 0, 0);         assert(addr2 != MAP_FAILED);         memset(addr2, 'a', TEST_SIZE);         pwrite(fd, addr2, TEST_SIZE, (uintptr_t)addr);         return 0;       }       assert(child == waitpid(child, &status, 0));       assert(WIFEXITED(status) && WEXITSTATUS(status) == 0);       return 0;     }  Fix this by updating follow_trans_huge_pmd in huge_memory.c analogously to the update in gup.c in the original commit.  The same pattern exists in follow_devmap_pmd.  However, we should not be able to reach that check with FOLL_COW set, so add WARN_ONCE to make sure we notice if we ever do.  [URL]: coding-style fixes] Link: [URL]", "target": 0}
{"idx": 442, "commit_message": "Improved auto-completion  Now you can press tab to choose among incomplete commands.", "target": 0}
{"idx": 910, "commit_message": "modules: map the cache files in memory", "target": 0}
{"idx": 1579, "commit_message": "-Fixed build.xml, to be able to run functional test (Vasile : $dist.lib.dir was'nt useless...) -Improved P2PNodeSource, which is twice a RM's NodeSource and a P2P node lookup.", "target": 0}
{"idx": 3073, "commit_message": "HDRenderPipeline: Handle UINT_MAX case of materialFeatures  - This should increase performance for deferred.shader and also allow to debug material feature in the Gbuffer", "target": 1}
{"idx": 3532, "commit_message": "mm: compaction: partially revert capture of suitable high-order page  Eric Wong reported on 3.7 and 3.8-rc2 that ppoll() got stuck when waiting for POLLIN on a local TCP socket.  It was easier to trigger if there was disk IO and dirty pages at the same time and he bisected it to commit 1fb3f8ca0e92 (\"mm: compaction: capture a suitable high-order page immediately when it is made available\").  The intention of that patch was to improve high-order allocations under memory pressure after changes made to reclaim in 3.6 drastically hurt THP allocations but the approach was flawed.  For Eric, the problem was that page->pfmemalloc was not being cleared for captured pages leading to a poor interaction with swap-over-NFS support causing the packets to be dropped.  However, I identified a few more problems with the patch including the fact that it can increase contention on zone->lock in some cases which could result in async direct compaction being aborted early.  In retrospect the capture patch took the wrong approach.  What it should have done is mark the pageblock being migrated as MIGRATE_ISOLATE if it was allocating for THP and avoided races that way.  While the patch was showing to improve allocation success rates at the time, the benefit is marginal given the relative complexity and it should be revisited from scratch in the context of the other reclaim-related changes that have taken place since the patch was first written and tested.  This patch partially reverts commit 1fb3f8ca0e92 (\"mm: compaction: capture a suitable high-order page immediately when it is made available\").", "target": 0}
{"idx": 2716, "commit_message": "Performance improvements (mostly related to startup)", "target": 1}
{"idx": 441, "commit_message": "sync: don't block the flusher thread waiting on IO  When sync does it's WB_SYNC_ALL writeback, it issues data Io and then immediately waits for IO completion. This is done in the context of the flusher thread, and hence completely ties up the flusher thread for the backing device until all the dirty inodes have been synced. On filesystems that are dirtying inodes constantly and quickly, this means the flusher thread can be tied up for minutes per sync call and hence badly affect system level write IO performance as the page cache cannot be cleaned quickly.  We already have a wait loop for IO completion for sync(2), so cut this out of the flusher thread and delegate it to wait_sb_inodes(). Hence we can do rapid IO submission, and then wait for it all to complete.  Effect of sync on fsmark before the patch:  FSUse%        Count         Size    Files/sec     App Overhead .....      0       640000         4096      35154.6          1026984      0       720000         4096      36740.3          1023844      0       800000         4096      36184.6           916599      0       880000         4096       1282.7          1054367      0       960000         4096       3951.3           918773      0      1040000         4096      40646.2           996448      0      1120000         4096      43610.1           895647      0      1200000         4096      40333.1           921048  And a single sync pass took:    real    0m52.407s   user    0m0.000s   sys     0m0.090s  After the patch, there is no impact on fsmark results, and each individual sync(2) operation run concurrently with the same fsmark workload takes roughly 7s:    real    0m6.930s   user    0m0.000s   sys     0m0.039s  IOWs, sync is 7-8x faster on a busy filesystem and does not have an adverse impact on ongoing async data write operations.", "target": 1}
{"idx": 1021, "commit_message": "acpuclock: Set 192mhz min freq, also deactivate some unused Frequencies like in my 4.2.2 Kernel.", "target": 0}
{"idx": 88, "commit_message": "Merge branch 'mapnik-query-improvements' into 259-remove-old-api  Conflicts: \tlib/windshaft/renderers/mapnik/factory.js", "target": 0}
{"idx": 2534, "commit_message": "Fix the value of DDR's latency for Performance improvement", "target": 1}
{"idx": 2696, "commit_message": "ath5k: remove ts_retry from ath5k_tx_status  Reusing the configured retry counts from the skb cb is more efficient than reloading the data from uncached memory. Replace ts_longretry (unused) with ts_final_retry which contains the retry count for the final rate only", "target": 1}
{"idx": 3297, "commit_message": "Add index on trunk_id in the subports model  An index on trunk_id will make queries that return subports from a given trunk_id efficient.  When I first approved the trunk and subports model, I thought that having trunk_id in the primary key would be sufficient. However, thinking about it some more, I realize that isn't the case because trunk_id is listed as the second column in the primary key.  Think about it like searching a string index for something that matches in the last half of a string.  The index doesn't make that efficient. The DB must still search all entries for matches.  It is the same with the index on (port_id, trunk_id) that the primary key provides.  You need to look through every row to find matching trunk_ids.  Hence the addition of an index.", "target": 1}
{"idx": 3740, "commit_message": "locking/rtmutex: Drop usage of __HAVE_ARCH_CMPXCHG  The rtmutex code is the only user of __HAVE_ARCH_CMPXCHG and we have a few other user of cmpxchg() which do not care about __HAVE_ARCH_CMPXCHG. This define was first introduced in 23f78d4a0 (\"[PATCH] pi-futex: rt mutex core\") which is v2.6.18. The generic cmpxchg was introduced later in 068fbad288 (\"Add cmpxchg_local to asm-generic for per cpu atomic operations\") which is v2.6.25. Back then something was required to get rtmutex working with the fast path on architectures without cmpxchg and this seems to be the result.  It popped up recently on rt-users because ARM (v6+) does not define __HAVE_ARCH_CMPXCHG (even that it implements it) which results in slower locking performance in the fast path. To put some numbers on it: preempt -RT, am335x, 10 loops of 100000 invocations of rt_spin_lock() + rt_spin_unlock() (time \"total\" is the average of the 10 loops for the 100000 invocations, \"loop\" is \"total / 100000 * 1000\"):       cmpxchg |    slowpath used  ||    cmpxchg used              |   total   | loop  ||   total    | loop      --------|-----------|-------||------------|-------      ARMv6   | 9129.4 us | 91 ns ||  3311.9 us |  33 ns      generic | 9360.2 us | 94 ns || 10834.6 us | 108 ns      ----------------------------||--------------------  Forcing it to generic cmpxchg() made things worse for the slowpath and even worse in cmpxchg() path. It boils down to 14ns more per lock+unlock in a cache hot loop so it might not be that much in real world. The last test was a substitute for pre ARMv6 machine but then I was able to perform the comparison on imx28 which is ARMv5 and therefore is always is using the generic cmpxchg implementation. And the numbers:                |   total     | loop      -------- |-----------  |--------      slowpath | 263937.2 us | 2639 ns      cmpxchg  |  16934.2 us |  169 ns      --------------------------------  The numbers are larger since the machine is slower in general. However, letting rtmutex use cmpxchg() instead the slowpath seem to improve things.  Since from the ARM (tested on am335x + imx28) point of view always using cmpxchg() in rt_mutex_lock() + rt_mutex_unlock() makes sense I would drop the define.", "target": 0}
{"idx": 2606, "commit_message": "Fixed debug performance labels for new component types (#12609)  * Added new debug performance tests for AsyncMode, StrictMode, forwardRef, and context provider/consumer components.  * Updated performance labels to exclude AsyncMode and StrictMode.  * Added labels for forwardRef (and inner function) that mirror DevTools labels.", "target": 0}
{"idx": 2750, "commit_message": "Merge pull request #150 from Wikia/bugid-33811  Bugid 33811 & 52368 - Achievements performance improvements", "target": 1}
{"idx": 2457, "commit_message": "Performance improvements and fixed preview crash  Preview crash was caused by rendering at the wrong places.", "target": 1}
{"idx": 3816, "commit_message": "regmap: Support register patch sets  Device manufacturers frequently provide register sequences, usually not fully documented, to be run at startup in order to provide better defaults for devices (for example, improving performance in the light of silicon evaluation). Support such updates by allowing drivers to register update sets with the core. These updates will be written to the device immediately and will also be rewritten when the cache is synced.  The assumption is that the reason for resyncing the cache will always be that the device has been powered off. If this turns out to not be the case then a separate operation can be provided.  Currently the implementation only allows a single set of updates to be specified for a device, this could be extended in future.", "target": 0}
{"idx": 3437, "commit_message": "dev: Add onEdit prop to Editor for more efficient updates (#1216)  * dev: Refactored the editor with TypeScript    * add onEdit prop to Editor and deal with downstream effects", "target": 0}
{"idx": 896, "commit_message": "Minor improvements in handling of indirectly present exclusion triggers.", "target": 0}
{"idx": 133, "commit_message": "Packet: Add derived class FunctionalPacket to enable partial functional reads  This adds the derived class FunctionalPacket to fix a long standing deficiency in the Packet class where it was unable to handle finding data to partially satisfy a functional access.  Made this a derived class as functional accesses are used only in certain contexts and to not add any additional overhead to the existing Packet class.", "target": 0}
{"idx": 3830, "commit_message": "Implement ignore lists.  Glob patterns in BitKeeper/etc/ignore are matched against each file basename in sfiles, and if any of them match, the file is skipped.  sfiles -A will bypass the ignore file. Also contains some performance improvements in sfiles itself and in sccs_root.  t.basic \tAdd tests of ignore-list functionality. glob.c  \tBitKeeper file /work/src/bk/dev/src/glob.c takepatch.c\tsccs_root takes one arg.  Remove redundant call to sccs_root. slib.c  \tsccs_root takes one argument only. slib.c  \tname2sccs: if it can't have an s.file name, return null instead slib.c  \tof aborting. sfind.c \tRewrite for ignore list support: sfind.c \t  new option -A means don't use ignore list sfind.c \t  lftw() guts split to lftw_inner() sfind.c \t  read BitKeeper/etc/ignore in lftw() sfind.c \t  check each file against the ignore list in lftw_inner() sfind.c \tGeneral cleanup: sfind.c \t  file() duplicate processing removed sfind.c \t  lftw() uses new algorithm which uses way less stack sfind.c \t  use d_type field if present (no stat ops on BSD, Linux 2.3) sfind.c \t  some functions that always return an ignored zero changed to sfind.c \t  return nothing. sccs.h  \tsccs_root takes one arg now.  Delete extra prototype of sccs.h  \tsccs_root.  Add proto for freeLines.  Add protos for functions sccs.h  \tin glob.c. Makefile\tTake PORTOBJ out of SCCSOBJ.  Rearrange bk.ver rule so it  Makefile\tisn't rebuilt every time you recompile prs.  Add glob.o to Makefile\tSCCSOBJ.  Add deps for glob.o. sccs_root.c\tSquash Windows and Unix versions together.  Check device number sccs_root.c\tof / as well as inode.  Kill second argument.  Use O(n) algorithm.  bk: 37f397aapPpfJ3HinOWO2hjpeDEDoA", "target": 1}
{"idx": 3973, "commit_message": "tty: fix __tty_insert_flip_char regression  commit 8a5a90a2a477b86a3dc2eaa5a706db9bfdd647ca upstream  Sergey noticed a small but fatal mistake in __tty_insert_flip_char, leading to an oops in an interrupt handler when using any serial port.  The problem is that I accidentally took the tty_buffer pointer before calling __tty_buffer_request_room(), which replaces the buffer. This moves the pointer lookup to the right place after allocating the new buffer space.  Fixes: 979990c62848 (\"tty: improve tty_insert_flip_char() fast path\") Reported-by: Sergey Senozhatsky [URL]> Tested-by: Sergey Senozhatsky [URL]>", "target": 0}
{"idx": 2828, "commit_message": "Optimized new CC box performance Fixed: removed duplicate entries when performing code-complete", "target": 1}
{"idx": 4121, "commit_message": "[PATCH] changed DofMap::build_constraint_matrix to be more efficient\n in the (usual) case that the element has no constraints.  Also fixed for the\n case that an element has constraints in terms of its *own* dofs, (not others)\n\ngit-svn-id: file:///Users/petejw/Documents/libmesh_svn_bak@870 434f946d-2f3d-0410-ba4c-cb9f52fb0dbf", "target": 1}
{"idx": 1368, "commit_message": "Roll Skia from 02d77df60e62 to a28795fd64a4 (1 revision)  [URL]/skia.git/+log/02d77df60e62..a28795fd64a4  2021-08-08 [URL] Update SKP version  If this roll has caused a breakage, revert this CL and stop the roller using the controls here: [URL]/r/skia-autoroll Please CC [URL] on the revert to ensure that a human is aware of the problem.  To report a problem with the AutoRoller itself, please file a bug: [URL]/p/skia/issues/entry?template=Autoroller+Bug  Documentation for the AutoRoller is here: [URL]/buildbot/+doc/main/autoroll/README.md  Cq-Include-Trybots: luci.chromium.try:android_optional_gpu_tests_rel;luci.chromium.try:linux-blink-rel;luci.chromium.try:linux-chromeos-compile-dbg;luci.chromium.try:linux_optional_gpu_tests_rel;luci.chromium.try:mac_optional_gpu_tests_rel;luci.chromium.try:win_optional_gpu_tests_rel Cq-Do-Not-Cancel-Tryjobs: true Bug: None Tbr: [URL]", "target": 0}
{"idx": 1429, "commit_message": "Release control of PPMT to GPU interpreter", "target": 0}
{"idx": 2743, "commit_message": "Tweak drawing code - it is now clearer and may well be faster and not gobble memory. It may also crash in some circumstances:). I haven't found anything bad yet.", "target": 0}
{"idx": 1029, "commit_message": "Improved the README drastically. Needs better planning. :poop:", "target": 0}
{"idx": 1140, "commit_message": "windows: multiple improvements and cleanups  The callback mechanism has been made more flexible. Eliminated one round of argument copying in Syscall. Faster Get/SetLastError implemented. Added gettime for gc perf profiling.  R=rsc, brainman, mattn, rog CC=golang-dev [URL]/4058046  Committer: Russ Cox [URL]>", "target": 1}
{"idx": 2306, "commit_message": "Inline allocation of function objects [URL]/show_bug.cgi?id=65779  Reviewed by Gavin Barraclough.  Inline allocation and initilisation of function objects in generated code.  This ended up being a 60-70% improvement in function allocation performance.  This improvement shows up as a ~2% improvement in 32bit sunspider and V8, but is a wash on 64-bit.  We currently don't inline the allocation of named function expressions, as that requires being able to gc allocate a variable object.  * jit/JIT.cpp: (JSC::JIT::privateCompileSlowCases): * jit/JIT.h: (JSC::JIT::emitStoreCell): * jit/JITInlineMethods.h: (JSC::JIT::emitAllocateBasicJSObject): (JSC::JIT::emitAllocateJSFinalObject): (JSC::JIT::emitAllocateJSFunction): * jit/JITOpcodes.cpp: (JSC::JIT::emit_op_new_func): (JSC::JIT::emitSlow_op_new_func): (JSC::JIT::emit_op_new_func_exp): (JSC::JIT::emitSlow_op_new_func_exp): * jit/JITOpcodes32_64.cpp:     Removed duplicate implementation of op_new_func and op_new_func_exp * runtime/JSFunction.h: (JSC::JSFunction::offsetOfScopeChain): (JSC::JSFunction::offsetOfExecutable):", "target": 1}
{"idx": 3716, "commit_message": "Patch from Thierry Volpiatto: xhg-mq.el: improve xhg-qsingle, allow xhg-mq-export-via-mail to send single patches.", "target": 0}
{"idx": 2981, "commit_message": "Rework build/logs rendering using React.js  This should improve performance when rendering long logs. It also adds some structure in place for JS that might come in handy as a pattern later, should we decide to beef up the UI.   - Uses Fluxxor for modeling the \"Flux\" architecture    - LogStore backed by the already existing SSE infrastructure  - JS packages managed with npm `npm install` on the `web/javascript` directory  should install all you need. `packages.json` manages all the  dependencies.  - Uses gulp for js/jsx compilation    - Browserify for `require('...')` goodness    - Few other gulp plugins to make js compilation happen    - On the `web/javascript/` directory:      - `gulp build`: builds assets (development)      - `gulp watch`: builds assets (development), watching for changes      - `NODE_ENV=production gulp build`:        builds assets (production: uglify)", "target": 1}
{"idx": 273, "commit_message": "util.url: copy urllib.unquote() into util to improve startup times  The ui class uses util.hasscheme() in a couple of places, causing hg to import urllib even when it doesn't need to. This copies urllib.unquote() to avoid that import.  perfstartup time before the URL refactoring (8796fb6af67e):  ! wall 0.050692 comb 0.000000 user 0.000000 sys 0.000000 (best of 100)  before this change:  ! wall 0.064742 comb 0.000000 user 0.000000 sys 0.000000 (best of 100)  after this change:  ! wall 0.052126 comb 0.000000 user 0.000000 sys 0.000000 (best of 100", "target": 1}
{"idx": 2069, "commit_message": "jit: Optimize three-way select_val  Optimize the case when a select_val has exactly two choices which branch to the same label or a fail destination and where the values only differ by one bit.  The optimization makes use of the observation that (V == X || V == Y) is equivalent to (V | (X ^ Y)) == (X | Y) when (X ^ Y) has only one bit set, which allows the select_val to be implemented with only one compare. This optimization is unconditionally performed by both GCC and LLVM on x86_64.  When this optimization is implemented in the code generator, the change in performance compared to the unmodified system varies depending on the probability distribution of the value the select_val operates on. For illustration, consider a {select_val, X, Fail, [{1,Dest}, {2, Dest}]}-instruction where the input only consists of ones. In this case a slowdown of 8% is apparent. If the same instruction is fed only twos, the slowdown decreases to around 3%.  If the input is changed to be a 1/3 each of 1, 2, and 3, the performance change depends strongly on how well the branch predictor functions in the unmodified system. If the input is a repeated sequence i.e. (123)+ or 1+2+3+ the slowdown is between 3% and 4%. If the input is completely random, in which case the branch predictor cannot help things, the optimization provides a speedup of ~25%.  For the larger benchmarks in ebench's `small` class, the only statistically significant performance changes are that `decode` is ~4% faster and `fib` is ~2.5% faster.", "target": 1}
{"idx": 319, "commit_message": "Merge branch 'master' of [URL]/eaciit/windapp  * 'master' of [URL]/eaciit/windapp:   add parametter for powercurve scatter to make dynamic field ploted", "target": 0}
{"idx": 1372, "commit_message": "Update license Rule model   * add a \"solid\" attribute to rules that need to be matched as a whole.    rules shorter than 3 tokens are always made solid.   * remove tracking gaps in rules  * improve representation", "target": 0}
{"idx": 3940, "commit_message": "Added more efficient constructor to array-based sets", "target": 1}
{"idx": 2099, "commit_message": "sched: Implement smarter wake-affine logic  The wake-affine scheduler feature is currently always trying to pull the wakee close to the waker. In theory this should be beneficial if the waker's CPU caches hot data for the wakee, and it's also beneficial in the extreme ping-pong high context switch rate case.  Testing shows it can benefit hackbench up to 15%.  However, the feature is somewhat blind, from which some workloads such as pgbench suffer. It's also time-consuming algorithmically.  Testing shows it can damage pgbench up to 50% - far more than the benefit it brings in the best case.  So wake-affine should be smarter and it should realize when to stop its thankless effort at trying to find a suitable CPU to wake on.  This patch introduces 'wakee_flips', which will be increased each time the task flips (switches) its wakee target.  So a high 'wakee_flips' value means the task has more than one wakee, and the bigger the number, the higher the wakeup frequency.  Now when making the decision on whether to pull or not, pay attention to the wakee with a high 'wakee_flips', pulling such a task may benefit the wakee. Also imply that the waker will face cruel competition later, it could be very cruel or very fast depends on the story behind 'wakee_flips', waker therefore suffers.  Furthermore, if waker also has a high 'wakee_flips', that implies that multiple tasks rely on it, then waker's higher latency will damage all of them, so pulling wakee seems to be a bad deal.  Thus, when 'waker->wakee_flips / wakee->wakee_flips' becomes higher and higher, the cost of pulling seems to be worse and worse.  The patch therefore helps the wake-affine feature to stop its pulling work when:          wakee->wakee_flips > factor &&         waker->wakee_flips > (factor * wakee->wakee_flips)  The 'factor' here is the number of CPUs in the current CPU's NUMA node, so a bigger node will lead to more pulling since the trial becomes more severe.  After applying the patch, pgbench shows up to 40% improvements and no regressions.  Tested with 12 cpu x86 server and tip 3.10.0-rc7.  The percentages in the final column highlight the areas with the biggest wins, all other areas improved as well:          pgbench                    base        smart          | db_size | clients |  tps  |        |  tps  |         +---------+---------+-------+   +-------+         | 22 MB   |       1 | 10598 |   | 10796 |         | 22 MB   |       2 | 21257 |   | 21336 |         | 22 MB   |       4 | 41386 |   | 41622 |         | 22 MB   |       8 | 51253 |   | 57932 |         | 22 MB   |      12 | 48570 |   | 54000 |         | 22 MB   |      16 | 46748 |   | 55982 | +19.75%         | 22 MB   |      24 | 44346 |   | 55847 | +25.93%         | 22 MB   |      32 | 43460 |   | 54614 | +25.66%         | 7484 MB |       1 |  8951 |   |  9193 |         | 7484 MB |       2 | 19233 |   | 19240 |         | 7484 MB |       4 | 37239 |   | 37302 |         | 7484 MB |       8 | 46087 |   | 50018 |         | 7484 MB |      12 | 42054 |   | 48763 |         | 7484 MB |      16 | 40765 |   | 51633 | +26.66%         | 7484 MB |      24 | 37651 |   | 52377 | +39.11%         | 7484 MB |      32 | 37056 |   | 51108 | +37.92%         | 15 GB   |       1 |  8845 |   |  9104 |         | 15 GB   |       2 | 19094 |   | 19162 |         | 15 GB   |       4 | 36979 |   | 36983 |         | 15 GB   |       8 | 46087 |   | 49977 |         | 15 GB   |      12 | 41901 |   | 48591 |         | 15 GB   |      16 | 40147 |   | 50651 | +26.16%         | 15 GB   |      24 | 37250 |   | 52365 | +40.58%         | 15 GB   |      32 | 36470 |   | 50015 | +37.14%", "target": 1}
{"idx": 3775, "commit_message": "Improve the performance of TextJsonParser using top-down parsing.", "target": 1}
{"idx": 2720, "commit_message": "Improve performance by recalculating only after attachment", "target": 1}
{"idx": 3454, "commit_message": "Norm's patch to improve selection speed on large projects by reducing the number of unnecessary auto-saves.  Maybe vertical zooming should also not trigger an auto-save?", "target": 1}
{"idx": 4011, "commit_message": "[PATCH] add (T) kernels optimized for OpenMP+SIMD\n\nThese kernels are taken from https://github.com/jeffhammond/nwchem-tce-triples-kernels/,\nwhich were previously part of private development branch of NWChem hosted by Argonne.\nThe code was developed by Jeff Hammond from 2013-2014 with help from Karol Kowalski.\n\nThese kernels have been tested on Intel Xeon, Intel Xeon Phi, IBM Blue Gene/Q,\nIBM POWER7, AMD Bulldozer and ARM32 processors using the Intel, Cray, IBM XL,\nand GCC compilers.  In rare instances, the optimal loop order is different between\nIntel, Cray and IBM compilers.  In such cases, we default to the Intel compiler case\nbecause it is the most commonly used Fortran compiler for NWChem.  In particular,\nNWChem as a whole cannot be compiled with Cray Fortran, so the only context in which\nit would be used for these kernels is if someone did a mixed build.\nThe performance differences with XLF were observed on POWER7, which is a relatively\nrare platform for NWChem.\n\nIn any case, these optimizations are better than the serial version any time OpenMP\nis used.  Detailed performance information for some platforms can be found at\nhttps://github.com/jeffhammond/nwchem-tce-triples-kernels/tree/master/results.\n\nFinally, it should be noted that all of Jeff Hammond's developments for non-Intel\narchitectures were done prior to his employment at Intel, which can be verified\nfrom the Github commit log associated with the aforementioned repo.", "target": 1}
{"idx": 2608, "commit_message": "Merge pull request #402 from input-output-hk/chore/daef-266-improve-webpack-build-performance  Chore/daef 266 improve webpack build performance", "target": 1}
{"idx": 2276, "commit_message": "R600: Export instructions are no longer terminator  This allows MachineInstScheduler to reorder them, and thus make scheduling more efficient.", "target": 1}
{"idx": 2101, "commit_message": "TMAGridView performance fix  Improved animation performance when using TMAGridView.", "target": 1}
{"idx": 2016, "commit_message": "Added specular highlights  Also improved performance when compiled with SIMD support.", "target": 1}
{"idx": 1147, "commit_message": "Re-implement socket configurability  This was dropped in the networking overhaul.", "target": 0}
{"idx": 892, "commit_message": "Fixed error compiling against wxWidgets 2.9.2: wrong usage of wxDECLARE_CLASS instead of wxDECLARE_DYNAMIC_CLASS", "target": 0}
{"idx": 604, "commit_message": "ASoC: MAX9877: add MAX9877 amp driver  The MAX9877 combines a high-efficiency Class D audio power amplifier with a stereo Class AB capacitor-less DirectDrive headphone amplifier.  The max9877_add_controls() is called to register the MAX9877 specific controls on machine specific init() of the machine driver.  The datasheet for the MAX9877 can find at the following url: [URL]/en/ds/MAX9877.pdf  [Slight edit to sort the ALL_CODECS entries -- broonie.]", "target": 0}
{"idx": 3587, "commit_message": "Property change listener efficiency changes  -   Using direct non-enumerable `__` prefixed properties instead of weak     maps for fast access to change listener records and overridden     property descriptors. -   Method names and reusable active dispatch array now kept in book     keeping to avoid recomputation. -   Presumed hot dispatch loop factored into separate method to isolate     from try/catch deoptimization. -   Removed support for uninstalling property change listeners.", "target": 1}
{"idx": 1507, "commit_message": "Made option to create unoptimesed as well as optimised network.", "target": 0}
{"idx": 2448, "commit_message": "8000316: Huge performance bottleneck in com.sun.tools.javac.comp.Check.localClassName Summary: Speed up Check.localClassName by avoiding generating names known to be in use already", "target": 1}
{"idx": 2841, "commit_message": "Merge pull request #57933 from Calinou/fix-sky-update-performance  Fix 3D sky update performance regression", "target": 1}
{"idx": 3689, "commit_message": "SpirvShaderDebugger: Mark II  This is a major reworking of the way the debugger is implemented.  Instead of generating shader code that is continually driving `vk::dbg` state, the debugger now: * Maintains a full shadow copy of all Intermediate values (SSA) * Only calls out to C++ whenever a trap is set * Only constructs and updates the `vk::dbg` state when a trap is hit  The main goal of this reworking is to properly support OpenCL.Debug.100's DebugValue instructions that may use deref expressions (See [URL]/registry/spir-v/specs/unified1/OpenCL.DebugInfo.100.html#_debug_operations_a_id_operation_a) These are remarkably hard to implement without having everything backed with real memory.  The resulting reimplementation is: * Much, much faster (>1000x faster for sample apps I've tried). Only ~2x slower than non-debug enabled SwiftShader now. * Uses much less runtime memory. * Much cleaner, removing a load of template magic for setting variable state that was extremely hard to follow * More thoroughly commented, explaining each component and method.  Bug: b/145351270", "target": 1}
{"idx": 628, "commit_message": "Update Test Password Entry with Validation with verifying match - parameterized fixlet - Universal.bes  optimizing 2nd relevance query. Needs tested.", "target": 0}
{"idx": 3954, "commit_message": "* replacing Str.split by ExtString.String.nsplit for better performance.", "target": 1}
{"idx": 1280, "commit_message": "Optimize dice multiplication  The optimization inspired by [URL]/package/probability-0.2.4/docs/src/Numeric-Probability-Distribution.html", "target": 1}
{"idx": 2907, "commit_message": "Merge branch 'canon-sraw-interpolators-vectorization' into develop  Cr2Decompressor is pretty, uh, specia. The \"tiling\" is weird, and causes to have several coordinate systems, one for the final output, one for the tile being decoded. That is such a mess. Might warrant a refactoring later on.  What's worse is how we output the decoded data for the subsampled cases: instead of laying out it sequentially, i.e. either `[Y1 Y2 Cb Cr][Y1 Y2 Cb Cr]` or `[Y1 Y2 Y3 Y4 Cb Cr][Y1 Y2 Y3 Y4 Cb Cr]`, we \"unpack\" it, i.e. store it as either `[ Y1 Cb  Cr  ] [ Y2 ... ... ] [ Y1 Cb  Cr  ] [ Y2 ... ... ]` or ``` [ Y1 Cb  Cr  ] [ Y2 ... ... ] [ Y1 Cb  Cr  ] [ Y2 ... ... ] ... [ Y3 ... ... ] [ Y4 ... ... ] [ Y3 ... ... ] [ Y4 ... ... ] ... ```  In turn, interpolator has to read such padded input, which seems fine in itself, but is actually a *horrible* design decision.  I've been looking into vectorizing the interpolator, and the main problem was that LLVM was messing up the interpolation loops, with rough idea being: ``` for(...) {   // the main bulk of interpolation   fun0();   fun1(); } // last 2 pixels fun0(); ``` But SimplifyCFG pass was turning that into ```   fun0(); for(...) {   // the main bulk of interpolation   fun1(); } ``` which completely messed up the code, bloated loop header, prevented the loop from being rotated, which in turn effectively disabled all loop transforms, including vectorization.  But i've been able to address that in [URL]/D84108 / [URL]/llvm/llvm-project/commit/1d51dc38d89bd33fb8874e242ab87b265b4dec1c so the vectorizer finally *could* deal with these interpolation loops.  But that was not the end. The vectorization was still unprofitable, because of *huge* loads needed. Because of that padding we've oh so carefully introduced :)  So i've gradually rewrote the Cr2sRawInterpolator to work on non-padded data, and Cr2Decompressor to not introduce such padding. Finally, 422 interpolation loops vectorized!  420 interpolation loops didn't, mainly because LoopVectorizer is rather conservative about the number of runtime checks for vectorization legality it is okay inserting, which is a known issue, and should hopefully be addressed soon-ish by [URL]/D75981, which will also allow GoPro VC5 decompressor loops to vectorize.  The performance results of this refactoring was (not that?) surprising: ``` raw.pixls.us-unique$ /usr/src/googlebenchmark/tools/compare.py -a benchmarks ~/rawspeed/build-{old,new}/src/utilities/rsbench/rsbench --benchmark_counters_tabular=true --benchmark_repetitions=27 -r ./ --benchmark_filter=\"Canon/.*.[cC][rR]2\" RUNNING: /home/lebedevri/rawspeed/build-old/src/utilities/rsbench/rsbench --benchmark_counters_tabular=true --benchmark_repetitions=27 -r ./ --benchmark_filter=Canon/.*.[cC][rR]2 --benchmark_display_aggregates_only=true --benchmark_out=/tmp/tmp5xrqqo9t 2020-08-15 22:48:44 Running /home/lebedevri/rawspeed/build-old/src/utilities/rsbench/rsbench Run on (8 X 4000 MHz CPU s) CPU Caches:   L1 Data 16 KiB (x8)   L1 Instruction 64 KiB (x4)   L2 Unified 2048 KiB (x4)   L3 Unified 8192 KiB (x1) Load Average: 1.58, 5.79, 7.61 -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Benchmark                                                                                Time             CPU   Iterations  CPUTime,s CPUTime/WallTime     Pixels Pixels/CPUTime Pixels/WallTime Raws/CPUTime Raws/WallTime WallTime,s -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Canon/EOS 5D Mark II/09.canon.sraw1.cr2/threads:8/process_time/real_time_mean          211 ms          211 ms           27   0.211361         0.999991   9.96653M       47.1541M        47.1537M      4.73125       4.73121   0.211363 Canon/EOS 5D Mark II/09.canon.sraw1.cr2/threads:8/process_time/real_time_median        211 ms          211 ms           27   0.211368         0.999996   9.96653M       47.1525M        47.1523M      4.73109       4.73107   0.211369 Canon/EOS 5D Mark II/09.canon.sraw1.cr2/threads:8/process_time/real_time_stddev      0.334 ms        0.335 ms           27   334.997u         13.5329u          0       74.7549k        74.4902k     7.50059m      7.47404m   333.825u Canon/EOS 5D Mark II/10.canon.sraw2.cr2/threads:8/process_time/real_time_mean          117 ms          117 ms           27   0.117404                1   5.25658M       44.7735M        44.7735M      8.51762       8.51762   0.117404 Canon/EOS 5D Mark II/10.canon.sraw2.cr2/threads:8/process_time/real_time_median        117 ms          117 ms           27   0.117331         0.999999   5.25658M       44.8014M        44.8013M      8.52293       8.52291   0.117331 Canon/EOS 5D Mark II/10.canon.sraw2.cr2/threads:8/process_time/real_time_stddev      0.250 ms        0.250 ms           27   249.756u         15.9842u          0       94.9077k        94.8953k     0.018055     0.0180527   249.722u Canon/EOS 5DS/2K4A9927.CR2/threads:8/process_time/real_time_mean                       350 ms          350 ms           27   0.349883         0.999993   52.6643M       150.521M        150.519M      2.85811       2.85809   0.349886 Canon/EOS 5DS/2K4A9927.CR2/threads:8/process_time/real_time_median                     350 ms          350 ms           27   0.349823         0.999997   52.6643M       150.546M        150.539M      2.85859       2.85846   0.349838 Canon/EOS 5DS/2K4A9927.CR2/threads:8/process_time/real_time_stddev                   0.800 ms        0.800 ms           27   800.044u         15.4713u          0       344.373k        344.364k     6.53901m      6.53886m   800.023u Canon/EOS 5DS/2K4A9928.CR2/threads:8/process_time/real_time_mean                       546 ms          546 ms           27   0.545866         0.999993   27.9936M       51.2836M        51.2833M      1.83198       1.83196   0.545869 Canon/EOS 5DS/2K4A9928.CR2/threads:8/process_time/real_time_median                     546 ms          546 ms           27   0.545625         0.999995   27.9936M       51.3056M        51.3042M      1.83276       1.83271    0.54564 Canon/EOS 5DS/2K4A9928.CR2/threads:8/process_time/real_time_stddev                    1.99 ms         1.99 ms           27   1.98917m          17.073u          0       184.877k        184.846k     6.60427m      6.60315m   1.98887m Canon/EOS 5DS/2K4A9929.CR2/threads:8/process_time/real_time_mean                       286 ms          286 ms           27   0.285728         0.999988   12.4416M       43.5457M        43.5452M      3.50001       3.49997   0.285732 Canon/EOS 5DS/2K4A9929.CR2/threads:8/process_time/real_time_median                     285 ms          285 ms           27   0.285357         0.999993   12.4416M       43.6002M        43.6008M      3.50439       3.50444   0.285353 Canon/EOS 5DS/2K4A9929.CR2/threads:8/process_time/real_time_stddev                    2.09 ms         2.08 ms           27   2.08453m         20.6896u          0       316.155k        316.266k    0.0254112     0.0254201   2.08534m Canon/EOS 40D/_MG_0154.CR2/threads:8/process_time/real_time_mean                      52.1 ms         52.1 ms           27  0.0521302         0.999999   2.51942M       48.3311M        48.3311M      19.1834       19.1834  0.0521302 Canon/EOS 40D/_MG_0154.CR2/threads:8/process_time/real_time_median                    52.0 ms         52.0 ms           27  0.0519624         0.999999   2.51942M       48.4855M        48.4863M      19.2447        19.245  0.0519616 Canon/EOS 40D/_MG_0154.CR2/threads:8/process_time/real_time_stddev                   0.311 ms        0.311 ms           27   310.917u          17.419u          0       286.266k        286.166k     0.113624      0.113584   310.802u Canon/EOS 77D/IMG_4049.CR2/threads:8/process_time/real_time_mean                       256 ms          256 ms           27   0.256245         0.999993   25.5041M       99.5307M          99.53M      3.90253       3.90251   0.256247 Canon/EOS 77D/IMG_4049.CR2/threads:8/process_time/real_time_median                     256 ms          256 ms           27   0.256325         0.999991   25.5041M       99.4991M        99.4997M      3.90129       3.90132   0.256324 Canon/EOS 77D/IMG_4049.CR2/threads:8/process_time/real_time_stddev                   0.487 ms        0.487 ms           27   487.145u         14.0342u          0       189.124k        188.983k     7.41544m      7.40989m   486.785u RUNNING: /home/lebedevri/rawspeed/build-new/src/utilities/rsbench/rsbench --benchmark_counters_tabular=true --benchmark_repetitions=27 -r ./ --benchmark_filter=Canon/.*.[cC][rR]2 --benchmark_display_aggregates_only=true --benchmark_out=/tmp/tmpjfp95rea 2020-08-15 22:50:51 Running /home/lebedevri/rawspeed/build-new/src/utilities/rsbench/rsbench Run on (8 X 4000 MHz CPU s) CPU Caches:   L1 Data 16 KiB (x8)   L1 Instruction 64 KiB (x4)   L2 Unified 2048 KiB (x4)   L3 Unified 8192 KiB (x1) Load Average: 1.22, 4.23, 6.80 -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Benchmark                                                                                Time             CPU   Iterations  CPUTime,s CPUTime/WallTime     Pixels Pixels/CPUTime Pixels/WallTime Raws/CPUTime Raws/WallTime WallTime,s -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Canon/EOS 5D Mark II/09.canon.sraw1.cr2/threads:8/process_time/real_time_mean          199 ms          199 ms           27   0.198943         0.999989   9.96653M       50.0978M        50.0972M       5.0266       5.02655   0.198945 Canon/EOS 5D Mark II/09.canon.sraw1.cr2/threads:8/process_time/real_time_median        199 ms          199 ms           27   0.198811         0.999996   9.96653M       50.1307M        50.1295M       5.0299       5.02978   0.198816 Canon/EOS 5D Mark II/09.canon.sraw1.cr2/threads:8/process_time/real_time_stddev      0.511 ms        0.512 ms           27   511.921u         19.6017u          0       128.078k         127.73k    0.0128508     0.0128159   510.531u Canon/EOS 5D Mark II/10.canon.sraw2.cr2/threads:8/process_time/real_time_mean         89.1 ms         89.1 ms           27  0.0891243         0.999982   5.25658M       58.9806M        58.9795M      11.2203       11.2201  0.0891259 Canon/EOS 5D Mark II/10.canon.sraw2.cr2/threads:8/process_time/real_time_median       89.1 ms         89.1 ms           27  0.0891066         0.999986   5.25658M        58.992M        58.9905M      11.2225       11.2222  0.0891088 Canon/EOS 5D Mark II/10.canon.sraw2.cr2/threads:8/process_time/real_time_stddev      0.198 ms        0.198 ms           27   198.195u         22.9807u          0        131.79k        131.413k    0.0250714     0.0249997    197.64u Canon/EOS 5DS/2K4A9927.CR2/threads:8/process_time/real_time_mean                       341 ms          341 ms           27   0.340666         0.999985   52.6643M       154.592M         154.59M      2.93543       2.93539   0.340671 Canon/EOS 5DS/2K4A9927.CR2/threads:8/process_time/real_time_median                     341 ms          341 ms           27    0.34068         0.999985   52.6643M       154.586M        154.586M      2.93531       2.93531    0.34068 Canon/EOS 5DS/2K4A9927.CR2/threads:8/process_time/real_time_stddev                   0.431 ms        0.430 ms           27   430.212u         21.3261u          0       195.065k        195.234k     3.70394m      3.70715m   430.591u Canon/EOS 5DS/2K4A9928.CR2/threads:8/process_time/real_time_mean                       521 ms          521 ms           27   0.520511         0.999985   27.9936M       53.7811M        53.7803M      1.92119       1.92116   0.520519 Canon/EOS 5DS/2K4A9928.CR2/threads:8/process_time/real_time_median                     520 ms          520 ms           27   0.520476          0.99999   27.9936M       53.7846M        53.7844M      1.92132       1.92131   0.520478 Canon/EOS 5DS/2K4A9928.CR2/threads:8/process_time/real_time_stddev                   0.691 ms        0.691 ms           27    690.43u         18.9624u          0       71.3647k        71.4201k     2.54932m       2.5513m   690.973u Canon/EOS 5DS/2K4A9929.CR2/threads:8/process_time/real_time_mean                       247 ms          247 ms           27   0.247127         0.999988   12.4416M       50.3449M        50.3443M       4.0465       4.04645    0.24713 Canon/EOS 5DS/2K4A9929.CR2/threads:8/process_time/real_time_median                     247 ms          247 ms           27   0.247106         0.999986   12.4416M       50.3493M        50.3492M      4.04685       4.04684   0.247106 Canon/EOS 5DS/2K4A9929.CR2/threads:8/process_time/real_time_stddev                   0.282 ms        0.282 ms           27   281.841u         14.8275u          0       57.4075k        57.4171k     4.61416m      4.61493m    281.89u Canon/EOS 40D/_MG_0154.CR2/threads:8/process_time/real_time_mean                      42.5 ms         42.5 ms           27  0.0424687         0.999998   2.51942M       59.3245M        59.3243M      23.5468       23.5468  0.0424688 Canon/EOS 40D/_MG_0154.CR2/threads:8/process_time/real_time_median                    42.5 ms         42.5 ms           27  0.0424781         0.999998   2.51942M       59.3112M        59.3106M      23.5416       23.5413  0.0424785 Canon/EOS 40D/_MG_0154.CR2/threads:8/process_time/real_time_stddev                   0.082 ms        0.082 ms           27   81.6545u         15.0055u          0       114.151k        114.406k    0.0453085     0.0454096   81.8361u Canon/EOS 77D/IMG_4049.CR2/threads:8/process_time/real_time_mean                       227 ms          227 ms           27   0.227204         0.999991   25.5041M       112.252M        112.251M      4.40133       4.40129   0.227206 Canon/EOS 77D/IMG_4049.CR2/threads:8/process_time/real_time_median                     227 ms          227 ms           27   0.227234         0.999993   25.5041M       112.237M        112.237M      4.40074       4.40072   0.227235 Canon/EOS 77D/IMG_4049.CR2/threads:8/process_time/real_time_stddev                   0.264 ms        0.263 ms           27   262.671u         12.4013u          0       130.009k        130.478k     5.09757m      5.11596m   263.623u Comparing /home/lebedevri/rawspeed/build-old/src/utilities/rsbench/rsbench to /home/lebedevri/rawspeed/build-new/src/utilities/rsbench/rsbench Benchmark                                                                                         Time             CPU      Time Old      Time New       CPU Old       CPU New ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ Canon/EOS 5D Mark II/09.canon.sraw1.cr2/threads:8/process_time/real_time_pvalue                 0.0000          0.0000      U Test, Repetitions: 27 vs 27 Canon/EOS 5D Mark II/09.canon.sraw1.cr2/threads:8/process_time/real_time_mean                  -0.0588         -0.0588      211.3599      198.9418      211.3590      198.9407 Canon/EOS 5D Mark II/09.canon.sraw1.cr2/threads:8/process_time/real_time_median                -0.0594         -0.0594      211.3654      198.8124      211.3659      198.8089 Canon/EOS 5D Mark II/09.canon.sraw1.cr2/threads:8/process_time/real_time_stddev                +0.5296         +0.5290        0.3338        0.5105        0.3349        0.5120 Canon/EOS 5D Mark II/10.canon.sraw2.cr2/threads:8/process_time/real_time_pvalue                 0.0000          0.0000      U Test, Repetitions: 27 vs 27 Canon/EOS 5D Mark II/10.canon.sraw2.cr2/threads:8/process_time/real_time_mean                  -0.2409         -0.2409      117.4026       89.1243      117.4033       89.1233 Canon/EOS 5D Mark II/10.canon.sraw2.cr2/threads:8/process_time/real_time_median                -0.2405         -0.2406      117.3290       89.1074      117.3296       89.1058 Canon/EOS 5D Mark II/10.canon.sraw2.cr2/threads:8/process_time/real_time_stddev                -0.2086         -0.2063        0.2497        0.1977        0.2498        0.1982 Canon/EOS 5DS/2K4A9927.CR2/threads:8/process_time/real_time_pvalue                              0.0000          0.0000      U Test, Repetitions: 27 vs 27 Canon/EOS 5DS/2K4A9927.CR2/threads:8/process_time/real_time_mean                               -0.0263         -0.0263      349.8809      340.6666      349.8800      340.6634 Canon/EOS 5DS/2K4A9927.CR2/threads:8/process_time/real_time_median                             -0.0262         -0.0261      349.8341      340.6756      349.8199      340.6771 Canon/EOS 5DS/2K4A9927.CR2/threads:8/process_time/real_time_stddev                             -0.4618         -0.4622        0.8000        0.4306        0.7999        0.4302 Canon/EOS 5DS/2K4A9928.CR2/threads:8/process_time/real_time_pvalue                              0.0000          0.0000      U Test, Repetitions: 27 vs 27 Canon/EOS 5DS/2K4A9928.CR2/threads:8/process_time/real_time_mean                               -0.0464         -0.0464      545.8593      520.5091      545.8592      520.5044 Canon/EOS 5DS/2K4A9928.CR2/threads:8/process_time/real_time_median                             -0.0461         -0.0461      545.6296      520.4674      545.6185      520.4691 Canon/EOS 5DS/2K4A9928.CR2/threads:8/process_time/real_time_stddev                             -0.6525         -0.6528        1.9886        0.6911        1.9891        0.6906 Canon/EOS 5DS/2K4A9929.CR2/threads:8/process_time/real_time_pvalue                              0.0000          0.0000      U Test, Repetitions: 27 vs 27 Canon/EOS 5DS/2K4A9929.CR2/threads:8/process_time/real_time_mean                               -0.1351         -0.1351      285.7268      247.1273      285.7251      247.1255 Canon/EOS 5DS/2K4A9929.CR2/threads:8/process_time/real_time_median                             -0.1340         -0.1340      285.3477      247.1035      285.3538      247.1040 Canon/EOS 5DS/2K4A9929.CR2/threads:8/process_time/real_time_stddev                             -0.8649         -0.8648        2.0854        0.2818        2.0846        0.2818 Canon/EOS 40D/_MG_0154.CR2/threads:8/process_time/real_time_pvalue                              0.0000          0.0000      U Test, Repetitions: 27 vs 27 Canon/EOS 40D/_MG_0154.CR2/threads:8/process_time/real_time_mean                               -0.1853         -0.1853       52.1296       42.4682       52.1298       42.4683 Canon/EOS 40D/_MG_0154.CR2/threads:8/process_time/real_time_median                             -0.1825         -0.1825       51.9609       42.4778       51.9620       42.4777 Canon/EOS 40D/_MG_0154.CR2/threads:8/process_time/real_time_stddev                             -0.7368         -0.7374        0.3108        0.0818        0.3109        0.0816 Canon/EOS 77D/IMG_4049.CR2/threads:8/process_time/real_time_pvalue                              0.0000          0.0000      U Test, Repetitions: 27 vs 27 Canon/EOS 77D/IMG_4049.CR2/threads:8/process_time/real_time_mean                               -0.1133         -0.1133      256.2436      227.2030      256.2429      227.2021 Canon/EOS 77D/IMG_4049.CR2/threads:8/process_time/real_time_median                             -0.1135         -0.1135      256.3206      227.2319      256.3233      227.2320 Canon/EOS 77D/IMG_4049.CR2/threads:8/process_time/real_time_stddev                             -0.4584         -0.4607        0.4867        0.2636        0.4871        0.2627 ```  Not only was the decoding speed of subsampled raws was improved by `-10% .. -25%`, the decoding performance for normal raws was improved, too.  So all in all i'm pretty happy with how this turned out :)  * canon-sraw-interpolators-vectorization: (22 commits)   Cr2Decompressor::decodeN_X_Y(): get rid of getDataUncropped() call   Cr2Decoder: provide properly sized buffer for subsampled image decoding   Cr2Decoder: parse CanonSi SRAWQuality entry, to pre-guess subsampling   Cr2Decompressor: pull out 'is subsampled' check into a function   Cr2Decompressor::decodeN_X_Y(): cleanup dead code   Cr2Decompressor::decodeN_X_Y(): 420: store decoded input packed   Cr2Decompressor::decodeN_X_Y(): 422: stop shuffling intermediate data   Cr2Decompressor::decodeN_X_Y(): 422: stop padding decoded data   Cr2sRawInterpolator: drop implict 1-elt offset from LoadCbCr()   Cr2sRawInterpolator::YCbCr: s/interpolate/interpolateCbCr/, it doesn't touch Y   Cr2sRawInterpolator::interpolate_422_row(): don't load Y when we don't need it   Cr2sRawInterpolator::interpolate_420*(): operate on desparsed input   Cr2sRawInterpolator::interpolate_422_row(): operate on desparsed input   Cr2sRawInterpolator: pretend to read input from some other buffer   Cr2sRawInterpolator::interpolate_420_row(): loop over pixel count, not column count   Cr2sRawInterpolator::interpolate_420(): loop over pixel count, not column count   Cr2sRawInterpolator::interpolate_422_row(): loop over pixel count, not column count   Cr2sRawInterpolator::interpolate_420(): s/y/row/, don't take w/h params   Cr2sRawInterpolator::interpolate_420_row(): migrate to Array2DRef<>   Cr2sRawInterpolator::interpolate_420(): migrate to Array2DRef<>   ...", "target": 1}
{"idx": 392, "commit_message": "- Use Grammar class for top level - More performance enhancements", "target": 1}
{"idx": 3030, "commit_message": "SimpleColoredComponent performance optimizations  1. Cache the fact that TextLayout is not necessary as well as the resulting string width (SimpleTextRenderer) 2. doPaintText: do not draw fragments that are completely off-screen Fixes IDEA-202674 IntelliJ froze after trying to open result from find in path dialog Fixes IDEA-214836 IDE freezes in \"Find in path\" while scrolling through found files  GitOrigin-RevId: 65c24272aa7d13b1b92e4dee2e2cab0111aacec8", "target": 1}
{"idx": 3852, "commit_message": "Merge pull request #331 from nicolasmiller/rendering_performance  GUI: patch rendering performance improvements", "target": 1}
{"idx": 2850, "commit_message": "replaced e.g. type: \"text\" with type: types.TEXT - more efficient, particularly when stringifying compiled templates", "target": 1}
{"idx": 3694, "commit_message": "Allow cgame to get/set world and bmodel surface shaders  trace_t now has world draw surface number for getting and setting surface shader. Trace only hits brushes and patches. So VMs currently cannot find surface numbers for inline models, flares, or foliage to set/get shader.  RE_GetShaderFromModel and RE_GetSurfaceShader are based on code from RTCW and ET. Removed manual mip check (would have been in my RE_GetSurfaceShader), lets assume RegisterShaderNoMip won't be used for world or model surfaces.  Used code from NetRadiant's q3map2 to (try to) find brush side draw surface numbers. Not prefect, may try to improve later.", "target": 0}
{"idx": 609, "commit_message": "Improve dir lookup by storing inode generation, and directly using nfs_bus", "target": 1}
{"idx": 2517, "commit_message": "KTOR-4712 Use Netty's alpn check instead of attempting to load jetty-alpn class (#3115)  Prefer SslProvider.OPENSSL over SslProvider.JDK for better performance", "target": 1}
{"idx": 3355, "commit_message": "Cache OCFVs to improve performance searching for duplicates on add  When adding a new value to a custom field, the HasEntry code is used to first determine whether the new value already exists. When inserting a large number of values one after the other (like along list of IPs), the HasEntry code pulled the full list of values from the DB for every check, creating a performance issue. Cache the values to speed up the existing value check.", "target": 1}
{"idx": 3595, "commit_message": "Roll engine to 6f459e2f10ca77a1dceced8cba062f5760a05f8e  flutter/  Revert \"Reapply \"Some cleanups enabled by removing support for Dart 1\" (#6216)\" flutter/  Roll src/third_party/skia 1b5ece0f06f4..e70aed7066c6 (1 commits) flutter/  Roll src/third_party/skia bd6595544171..1b5ece0f06f4 (22 commits) flutter/  Improve performance of performance overlay by caching. flutter/  Remove root_surface_transformation from PaintContext", "target": 1}
{"idx": 2326, "commit_message": "xen/pat: Disable PAT using pat_enabled value.  commit c79c49826270b8b0061b2fca840fc3f013c8a78a upstream.  The git commit 8eaffa67b43e99ae581622c5133e20b0f48bcef1 (xen/pat: Disable PAT support for now) explains in details why we want to disable PAT for right now. However that change was not enough and we should have also disabled the pat_enabled value. Otherwise we end up with:  mmap-example:3481 map pfn expected mapping type write-back for [mem 0x00010000-0x00010fff], got uncached-minus  ------------[ cut here ]------------ WARNING: at /build/buildd/linux-3.8.0/arch/x86/mm/pat.c:774 untrack_pfn+0xb8/0xd0() mem 0x00010000-0x00010fff], got uncached-minus ------------[ cut here ]------------ WARNING: at /build/buildd/linux-3.8.0/arch/x86/mm/pat.c:774 untrack_pfn+0xb8/0xd0() ... Pid: 3481, comm: mmap-example Tainted: GF 3.8.0-6-generic #13-Ubuntu Call Trace:  [<ffffffff8105879f>] warn_slowpath_common+0x7f/0xc0  [<ffffffff810587fa>] warn_slowpath_null+0x1a/0x20  [<ffffffff8104bcc8>] untrack_pfn+0xb8/0xd0  [<ffffffff81156c1c>] unmap_single_vma+0xac/0x100  [<ffffffff81157459>] unmap_vmas+0x49/0x90  [<ffffffff8115f808>] exit_mmap+0x98/0x170  [<ffffffff810559a4>] mmput+0x64/0x100  [<ffffffff810560f5>] dup_mm+0x445/0x660  [<ffffffff81056d9f>] copy_process.part.22+0xa5f/0x1510  [<ffffffff81057931>] do_fork+0x91/0x350  [<ffffffff81057c76>] sys_clone+0x16/0x20  [<ffffffff816ccbf9>] stub_clone+0x69/0x90  [<ffffffff816cc89d>] ? system_call_fastpath+0x1a/0x1f ---[ end trace 4918cdd0a4c9fea4 ]---  (a similar message shows up if you end up launching 'mcelog')  The call chain is (as analyzed by Liu, Jinsong): do_fork   --> copy_process     --> dup_mm       --> dup_mmap                --> copy_page_range           --> track_pfn_copy             --> reserve_pfn_range               --> line 624: flags != want_flags It comes from different memory types of page table (_PAGE_CACHE_WB) and MTRR (_PAGE_CACHE_UC_MINUS).  Stefan Bader dug in this deep and found out that: \"That makes it clearer as this will do  reserve_memtype(...) --> pat_x_mtrr_type   --> mtrr_type_lookup     --> __mtrr_type_lookup  And that can return -1/0xff in case of MTRR not being enabled/initialized. Which is not the case (given there are no messages for it in dmesg). This is not equal to MTRR_TYPE_WRBACK and thus becomes _PAGE_CACHE_UC_MINUS.  It looks like the problem starts early in reserve_memtype:                 if (!pat_enabled) {                 /* This is identical to page table setting without PAT */                 if (new_type) {                         if (req_type == _PAGE_CACHE_WC)                                 *new_type = _PAGE_CACHE_UC_MINUS;                         else                                        *new_type = req_type & _PAGE_CACHE_MASK;                        }                 return 0;         }  This would be what we want, that is clearing the PWT and PCD flags from the supported flags - if pat_enabled is disabled.\"  This patch does that - disabling PAT.  Reported-by: Sander Eikelenboom < > Reported-and-Tested-by: Konrad Rzeszutek Wilk [URL]> Reported-and-Tested-by: Stefan Bader [URL]>", "target": 0}
{"idx": 15, "commit_message": "Fix bug on sending notification on changing total row in matrix dynamic", "target": 0}
{"idx": 805, "commit_message": "AGPUSH-2201 remove support from MPNS and SimplePush", "target": 0}
{"idx": 1415, "commit_message": "Making every query use TableDefinition (pending optimization).", "target": 0}
{"idx": 3451, "commit_message": "Big changes for performance.  mp_digits are now always unsigned ints. mp_words are used only on machines that support long long arithmetic. s_mp_mod_d() was deleted.  It was not being used and was not part of the public API. The code that computes squares in s_mp_sqr was broken out into a separate new function s_mpv_sqr_add_prop(), which is a target for assembly language optimization.  New function s_mpv_div_2dx1d(), also a target for assembly optimization.  These changes made X86 benchmark time go from 22.5 seconds to 8.3 seconds on my reference test system.", "target": 1}
{"idx": 3750, "commit_message": "Disable GENTLTE_FAIR_SLEEPERS for better performance on Android", "target": 1}
{"idx": 4110, "commit_message": "[PATCH] Fix performances of Triangulation_2 with EPEC\n\nThere was a performance degradation between CGAL-3.7 and CGAL-3.8, when\nTriangulation_2 is used with EPEC. This patch fixes the issue. Using a\nfunctor that is specialized for EPEC, in inexact_orientation, to_double is\nnot called on p.x() but on p.approx().x().", "target": 1}
{"idx": 2892, "commit_message": "More efficient bin sampling in cython", "target": 1}
{"idx": 4035, "commit_message": "[PATCH] Use a fixed-length arrays, avoid heap allocation.\n\nAlso reduce the default number of elements so that it runs fast enough in DBG mode.", "target": 1}
{"idx": 1563, "commit_message": "Updating _posts/2018-04-01-delivering-large-api-responses-as-efficiently-as-possible.markdown via Laneworks CMS Publish", "target": 0}
{"idx": 1357, "commit_message": "network: add functions to manage ipv6 nameservers", "target": 0}
{"idx": 1566, "commit_message": "complete rewrite, respects now memory limits", "target": 1}
{"idx": 2132, "commit_message": "Second phase of performance improvement. Pass the propertyList into processNode(..) and addCharacters(..).  PR: 31699", "target": 1}
{"idx": 3912, "commit_message": "Improve import cli performance  1. Set default numThreads to the num cores 2. Don't use more threads than there are files when importing", "target": 1}
{"idx": 3159, "commit_message": "shared.unattended: Use fixed partition for RHEL5/6 guests  Currently we use autopart in all rhel guests, which bring trouble when RHEL5 RHEL6 guests w/ huge(64+G) RAM. The swap partition will be really huge and not enough space for the root partition, thus installation fails. (we met this problem on huge RAM host before).  With this patch, the RHEL5 RHEL6 guest will have only 2 physical partitions(/boot, PV), and the PV contains 2  LVs(/, swap).  |     | /    |swap| |/boot|----LVM----| |     |    PV     | |---------------- | |guest hard drive |  Note: 1) we can use plain partitions here (w/o LVM) to gain the    possible tiny performance improvement, but I prefer to    choose the LVM scheme, a little bit complex partioning    scheme but test more (also testing the lvm layer). 2) RHEL3, RHEL4, RHEL7 kickstart config didn't update here,    because:    The default kernel shipped w/ RHEL3, RHEL4 dont support    such huge RAM, so they will not met this issue.    The anaconda of RHEL7 looks fixed this problem, install    w/ autopart will not create a huge swap partition.", "target": 0}
{"idx": 487, "commit_message": "master - f298de368 test(mdc-menu): add performance tests for mdc-menu (#20494)", "target": 0}
{"idx": 785, "commit_message": "new file:   0-memory-debugging/README.md \tnew file:   0-memory-management/README.md \tdeleted:    README1.md \tdeleted:    README2.md", "target": 0}
{"idx": 2898, "commit_message": "Proposal notification service improvements (mostly performance related).", "target": 1}
{"idx": 125, "commit_message": "Release v0.15  v0.15 =====  - Add HTTP Proxy support (only with glib >= 2.26) - Add \"port\" channel support, to allow arbitrary communication on top   of spice connection - usb-redir: fix migration support - win32: various keyboard & mouse fixes - Add info message when USB dialog is empty - Fix initial black screen on some 16bits guest - Various bug fixes and improvements", "target": 0}
{"idx": 440, "commit_message": "Using original instruction list in GPU-VE", "target": 0}
{"idx": 572, "commit_message": "implement require.resolve algorithm ourselves, so we can pass any base path we want to fix the issue where node_modules are out of reach from where this module is installed", "target": 0}
{"idx": 849, "commit_message": "Merge branch 'develop' of [URL]/Sage-Bionetworks/BridgeIntegrationTests into app-config-files", "target": 0}
{"idx": 1131, "commit_message": "Removed mutable default value in _inference_tip_cache (#1139)  * Removed mutable default value in _inference_tip_cache    The mutable default is problematic when astroid is used as a library,  because it effectively becomes a memory leak, see #792.    This commit moves the cache to the global namespace and adds a public  API entry point to clear it.    * Removed the itertools.tee call from _inference_tip_cached    This commit is not expected to affect the behavior, and if anything, should  improve memory usage, because result is only materilized once (before it was  also stored in-full inside itertools.tee).", "target": 0}
{"idx": 1811, "commit_message": "Roll src/third_party/catapult/ bbcace52b..cd1fd5940 (1 commit)  [URL]/catapult.git/+log/bbcace52b49e..cd1fd5940f68  $ git log bbcace52b..cd1fd5940 --date=short --no-merges --format='%ad %ae %s' 2017-12-21 kbr Restore original timeout in create-and-connect method.  Created with:   roll-dep src/third_party/catapultBUG=796437   The AutoRoll server is located here: [URL]  Documentation for the AutoRoller is here: [URL]/buildbot/+/master/autoroll/README.md  If the roll is causing failures, please contact the current sheriff, who should be CC'd on the roll, and stop the roller if necessary.   CQ_INCLUDE_TRYBOTS=master.tryserver.chromium.android:android_optional_gpu_tests_rel [URL]", "target": 0}
{"idx": 2053, "commit_message": "Reviewed by Mitz.          - [URL]/show_bug.cgi?id=15944           streamline SegmentedString to speed up parsing          I measured a speed-up of the page load test while developing this patch. I don't         have a precise figure, though.          * html/HTMLTokenizer.h: Removed unneeded lineNumberPtr() function. Also renamed         lineno to m_lineNumber.         * html/HTMLTokenizer.cpp:         (WebCore::HTMLTokenizer::processListing): Don't pass 0 to the advance function         since we don't want to update a line number.         (WebCore::HTMLTokenizer::parseSpecial): Ditto.         (WebCore::HTMLTokenizer::parseComment): Pass the line number data member directly         instead of lineNumberPtr() since the advance function now takes a reference.         (WebCore::HTMLTokenizer::parseServer): Ditto.         (WebCore::HTMLTokenizer::parseProcessingInstruction): Ditto.         (WebCore::HTMLTokenizer::parseText): Ditto.         (WebCore::HTMLTokenizer::parseEntity): Ditto.         (WebCore::HTMLTokenizer::parseTag): Ditto.         (WebCore::HTMLTokenizer::write): Ditto.          * loader/FTPDirectoryDocument.cpp: (WebCore::FTPDirectoryTokenizer::write):         * loader/TextDocument.cpp: (WebCore::TextTokenizer::write):         Don't pass 0 to the advance function.          * platform/SegmentedString.h: (WebCore::SegmentedString::advance): Streamlined         the most common case, and pushed less common cases into a separate function         that is not inlined. Also got rid of a branch by separating the case with a         line number from the case without one.          * platform/SegmentedString.cpp: (WebCore::SegmentedString::advanceSlowCase):         Added. The aforementioned less common cases are here.", "target": 1}
{"idx": 36, "commit_message": "qtnfmac: Use struct_size() in kzalloc()  One of the more common cases of allocation size calculations is finding the size of a structure that has a zero-sized array at the end, along with memory for some number of elements for that array. For example:  struct ieee80211_regdomain {         ...         struct ieee80211_reg_rule reg_rules[]; };  instance = kzalloc(sizeof(*mac->rd) +                           sizeof(struct ieee80211_reg_rule) *                           count, GFP_KERNEL);  Instead of leaving these open-coded and prone to type mistakes, we can now use the new struct_size() helper:  instance = kzalloc(struct_size(instance, reg_rules, count), GFP_KERNEL);  This code was detected with the help of Coccinelle.", "target": 0}
{"idx": 2169, "commit_message": "QtWebkit: Set release build by default  Current Qtwebkit configuration is debug build by default. Change it to release build to have better performance.", "target": 1}
{"idx": 4025, "commit_message": "[PATCH] Optimize the script (from 20 minutes to 0.3 seconds!)\n\n- avoid opening and reading the file `processed_test_results` thousands\n  of time: its content is stored once in a hash, for fast lookup,\n\n- do not call `fuser` for files that are already processed", "target": 1}
{"idx": 3602, "commit_message": "ISSUE #583 - performance improvement to issues service for large models", "target": 1}
{"idx": 3762, "commit_message": "Increased iteration performance. Removed iterator bug.", "target": 1}
{"idx": 3092, "commit_message": "Create the translation handles only once, then translate them to improve performance, see #160", "target": 1}
{"idx": 751, "commit_message": "dynamic-threads: remove all pipe communication and start threads only when needed (unstable). only camd3 and newcamd working so far.", "target": 0}
{"idx": 1819, "commit_message": "Improve isZero test, doxygen and start implementing findSmallestRootInRange01", "target": 0}
{"idx": 416, "commit_message": "Make Graphite Optimizations a config option to easily enable/disable it", "target": 0}
{"idx": 1071, "commit_message": "improve security doc, fix headless link", "target": 0}
{"idx": 1688, "commit_message": "Iterator over sequence range  Use new sequence range iterator to implement Sequence::string() and TwoBit::base_frequencies(). This resulted in a 4 to 5x improvement on TwoBit::base_frequencies(). This is now about 2x slower than C which is not bad given Rust may not be as optimized as it can be.", "target": 1}
{"idx": 3858, "commit_message": "- Patch #13224 by Richard Archer and Gerhard: improved gzip caching.", "target": 1}
{"idx": 473, "commit_message": "MFC: Handle CPUs with APIC IDs higher than 32.", "target": 0}
{"idx": 149, "commit_message": "finished main algorithm, added forward probability", "target": 0}
{"idx": 895, "commit_message": "[PULL_REQUEST_TEMPLATE.md] Add checkable Improvement options PR's purpose", "target": 0}
{"idx": 1612, "commit_message": "Rollback PR #46410 due to performance regression  PiperOrigin-RevId: 353270835", "target": 1}
{"idx": 625, "commit_message": "Update locked frozendict version to 2.3.3 (#13352)  frozendict 2.3.3 includes fixes for memory leaks that get triggered during `/sync`.", "target": 0}
{"idx": 2945, "commit_message": "create TileGeoreferencing once to improve performance", "target": 1}
{"idx": 3474, "commit_message": "Performance improvement  Simplifies the QR code and improves performance Adds a new --dump option to output binary to stdout With thanks to Ismael Luceno", "target": 1}
{"idx": 510, "commit_message": "Improved JavaScriptSerializer.ConvertToType Nullable handling. Fixes #19287. ConvertToType was returning null even when the object was not a string. When the target type is Nullable, ConvertToType returns null if the object is an empty string, if the object is not a string and the target type is obtainable from a string then the object is converted to a string and the string to the target type.", "target": 0}
{"idx": 583, "commit_message": "GPUMemMan now exposes functions under 'tuvok.gpu'.  Changed1DTrans has been exposed as 'tuvok.gpu.changed1DTrans'.", "target": 0}
{"idx": 1278, "commit_message": "Make testdynamic.py work on windows systems", "target": 0}
{"idx": 3077, "commit_message": "[SPARK-2443][SQL] Fix slow read from partitioned tables  This fix obtains a comparable performance boost as [PR [URL]/apache/spark/pull/1390) by moving an array update and deserializer initialization out of a potentially very long loop. Suggested by yhuai. The below results are updated for this fix.  ## Benchmarks Generated a local text file with 10M rows of simple key-value pairs. The data is loaded as a table through Hive. Results are obtained on my local machine using hive/console.  Without the fix:  Type | Non-partitioned | Partitioned (1 part) ------------ | ------------ | ------------- First run | 9.52s end-to-end (1.64s Spark job) | 36.6s (28.3s) Stablized runs | 1.21s (1.18s) | 27.6s (27.5s)  With this fix:  Type | Non-partitioned | Partitioned (1 part) ------------ | ------------ | ------------- First run | 9.57s (1.46s) | 11.0s (1.69s) Stablized runs | 1.13s (1.10s) | 1.23s (1.19s)  Author: Zongheng Yang [URL]>  Closes #1408 from concretevitamin/slow-read-2 and squashes the following commits:  d86e437 [Zongheng Yang] Move update & initialization out of potentially long loop.", "target": 1}
{"idx": 2794, "commit_message": "x86-32, mm: Rip out x86_32 NUMA remapping code  commit f03574f2d5b2d6229dcdf2d322848065f72953c7 upstream.  This code was an optimization for 32-bit NUMA systems.  It has probably been the cause of a number of subtle bugs over the years, although the conditions to excite them would have been hard to trigger.  Essentially, we remap part of the kernel linear mapping area, and then sometimes part of that area gets freed back in to the bootmem allocator.  If those pages get used by kernel data structures (say mem_map[] or a dentry), there's no big deal.  But, if anyone ever tried to use the linear mapping for these pages _and_ cared about their physical address, bad things happen.  For instance, say you passed __GFP_ZERO to the page allocator and then happened to get handed one of these pages, it zero the remapped page, but it would make a pte to the _old_ page. There are probably a hundred other ways that it could screw with things.  We don't need to hang on to performance optimizations for these old boxes any more.  All my 32-bit NUMA systems are long dead and buried, and I probably had access to more than most people.  This code is causing real things to break today:          [URL]/lkml/2013/1/9/376  I looked in to actually fixing this, but it requires surgery to way too much brittle code, as well as stuff like per_cpu_ptr_to_phys().  [ hpa: Cc: this for -stable, since it is a memory corruption issue.   However, an alternative is to simply mark NUMA as depends BROKEN   rather than EXPERIMENTAL in the X86_32 subclause... ]  Link: [URL]", "target": 0}
{"idx": 1955, "commit_message": "Improve h2 readability on mobile devices and update bold text style", "target": 0}
{"idx": 4074, "commit_message": "[PATCH] Improve meanshift filter performance on CPU\n\nImproved the meanshift filter performance on the CPU backend by replacing\nvectors with std::arrays and moving them out of the for loops. Also\nreduced a few conversion operations.", "target": 1}
{"idx": 1625, "commit_message": "Changed terminology back to CG from CD  I changed our terminology back from conjugate direction to conjugate gradient.  It's a small change, but it's been irritating for me to remember and type.  Basically, the origin of the name system came in from the inexact composite step SQP algorithm.  There, the preconditioner may change between iterations due to inexactness, so we take truncated-CG and over orthogonalize against all previous directions.  Since we're not just using the last Krylov vector, we can call it conjugate directions.  At the same time, some people view conjugate directions as an algorithm where we already have a bunch of directions computed and make our search direction conjugate to them. Basically, we could technically decouple conjugate direction from a Krylov method and still have a conjugate direction method.  Anyway, that's not what we do at all.  This is a Krylov method that really is CG, but one where we forcefully orthogonalize things due to problems with inexactness and roundoff error.  Even on unconstrained problems, it makes sense to overorthogonalize if we can spare the memory because, frankly, things become unstable pretty quickly.  Anyway, the name change is a convenience to me and hopefully others who kept wondering what CD versus CG meant.", "target": 0}
{"idx": 3711, "commit_message": "Reviewed by Maciej Stachowiak.                  Some Vector optimizations. These are especially important when using         Vector as a stack for implementing recursive algorithms iteratively.                  [ Broken off from [URL]/show_bug.cgi?id=14868 ]          1. Added shrink(), which is a version of resize() that you can call         to save a branch / improve code generation and inlining when you know          that the vector is not getting bigger.                  2. Changed subclassing relationship in VectorBuffer to remove a call to         fastFree() in the destructor for the inlineCapacity != 0 template         specialization. This brings inline Vectors one step closer to true         stack-allocated arrays.                  Also changed abort() to CRASH(), since the latter works better.          * wtf/Vector.h:         (WTF::VectorBufferBase::allocateBuffer):         (WTF::VectorBufferBase::deallocateBuffer):         (WTF::VectorBufferBase::VectorBufferBase):         (WTF::VectorBufferBase::~VectorBufferBase):         (WTF::):         (WTF::VectorBuffer::VectorBuffer):         (WTF::VectorBuffer::~VectorBuffer):         (WTF::VectorBuffer::deallocateBuffer):         (WTF::VectorBuffer::releaseBuffer):         (WTF::Vector::clear):         (WTF::Vector::removeLast):         (WTF::::operator):         (WTF::::fill):         (WTF::::shrink):", "target": 1}
{"idx": 407, "commit_message": "CHROMIUM: s5p-mfc: Extract open/close MFC instance commands.  This is in preparation for a new flow to fix issues with streamon, which should not be allocating buffer memory.", "target": 0}
{"idx": 2656, "commit_message": "Version: 0.151  Performed a LOT of optimizations and improved performance substantially Reduced precision of textures used in fbo's to 16f Improved SSAO performance and several other parts of the pipeline.", "target": 1}
{"idx": 2172, "commit_message": "Merge pull request #1703 from sorokin/alerts  Use torrent_status to be more efficient.", "target": 1}
{"idx": 3665, "commit_message": "ksmbd-tools: remove cache read/trans buffer  No performance gain when cache read/trans buffer is on/off. And Matthew is improving vmalloc allocation performance.", "target": 0}
{"idx": 4102, "commit_message": "[PATCH] lagrangian: Rationalized the handling of multi-component\n liquids and solids Ensures consistency between the mixture thermodynamics and\n composition specifications for the parcels. Simpler more efficient\n implementation. Resolves bug-report\n http://www.openfoam.org/mantisbt/view.php?id=1395 as well as other\n consistency issues not yet reported.", "target": 1}
{"idx": 3873, "commit_message": "B43: Handle DMA RX descriptor underrun  Add handling of rx descriptor underflow. This fixes a fault that could happen on slow machines, where data is received faster than the CPU can handle. In such a case the device will use up all rx descriptors and refuse to send any more data before confirming that it is ok. This patch enables necessary interrupt to discover such a situation and will handle them by dropping everything in the ring buffer.", "target": 1}
{"idx": 1106, "commit_message": "- worked on optimization for gaussian distribution and error function", "target": 1}
{"idx": 2107, "commit_message": "Improve material test performance. 18 to 15.3 seconds.", "target": 1}
{"idx": 1600, "commit_message": "Move README.regexp into Regexp.chpl chpldoc, improve other docstrings", "target": 0}
{"idx": 629, "commit_message": "Memory leak (postgres -> zlib + ssl) has been fixed by apache developers.", "target": 0}
{"idx": 3585, "commit_message": "Deprecate an unsupported setting of auto-alt-ref > 1  multi_arf is not maintained anymore but there are still some logics depending on it. but setting auto-alt-ref=2 will trigger this flag.  This is the current setting used in AWCY. Fixing this causes 0.09% drop in PSNR. The next patch will bring back the logic which improves the performance to recover the loss.", "target": 1}
{"idx": 757, "commit_message": "Refactored 2D shader and lighting system  -Removed normal/specular properties from nodes -Create CanvasTexture, which can contain normal/specular channels -Refactored, optimized and simplified 2D shaders -Use atlas for light textures. -Use a shadow atlas for shadow textures. -Use both items aboves to make light rendering stateless (faster). -Reorganized uniform sets for more efficiency.", "target": 1}
{"idx": 1591, "commit_message": "VS Code change theme, minor improvements", "target": 0}
{"idx": 2451, "commit_message": "Improve performance when parsing big OGG files  by skipping pages in the middle (unless a full parse is forced).  Additionally, the size of the tracks is now determined on container-level which makes handling the skipping easier.", "target": 1}
{"idx": 3462, "commit_message": "improve geoannotator performance and cleanup code", "target": 1}
{"idx": 3360, "commit_message": "SBlbRunBuilder: Copy long runs of hashes more efficiently.", "target": 1}
{"idx": 3719, "commit_message": "Optimized file loading performance, fixed x-axes reset", "target": 1}
{"idx": 1082, "commit_message": "Specs for dynamic token replacement and multiple captures", "target": 0}
{"idx": 286, "commit_message": "Micro-optimize inventory item rendering on search updates", "target": 1}
{"idx": 4111, "commit_message": "[PATCH] USER-DPD: performance optimizations to ssa_update() in\n fix_shardlow Overall improvements range from 2% to 18% on our benchmarks 1)\n Newton has to be turned on for SSA, so remove those conditionals 2) Rework\n the math in ssa_update() to eliminate many ops and temporaries 3) Split\n ssa_update() into two versions, based on DPD vs. DPDE 4) Reorder code in\n ssa_update_*() to reduce register pressure", "target": 1}
{"idx": 872, "commit_message": "Tweaked alignment of text on several slides. Other minor fixes and improvements.", "target": 0}
{"idx": 2631, "commit_message": "created new crop function which is more efficient and also handles manual overrides", "target": 1}
{"idx": 2782, "commit_message": "v3.2.0  * Update support for Laravel Framework v5.2. * Improved performances by reducing call within `IlluminateContainerContainer`. * Remove registering not found exception logger.", "target": 1}
{"idx": 103, "commit_message": "Peak-memory usage for T3064 varies depending on whether .hi file exists on not  Really, the existence or otherwise of the .hi file shouldn't affect validate output, but it seems to.  Maybe 'make clean' doesn't clean enough?  In ay case peak memory usage is a fragile number because it depends on when GC happens.  So I increased the range to 20% for now.", "target": 0}
{"idx": 329, "commit_message": "Enable zero-copy dxgi sharing for vp9 mft. Requires setup reorder.  Per discussions with Microsoft we need to set these bind flags before calling SetInputType/SetOutputType. Doing so fixes the crashes we get with DXGI sharing and the VP9 MFT!  With this 8K60 VP9 playback is now flawless and likely uses much less power since it's zero copy! Tested on GTX 1050Ti.  BUG=728296 TEST=8K60 vp9 playback is smooth.  Cq-Include-Trybots: master.tryserver.chromium.android:android_optional_gpu_tests_rel;master.tryserver.chromium.linux:linux_optional_gpu_tests_rel;master.tryserver.chromium.mac:mac_optional_gpu_tests_rel;master.tryserver.chromium.win:win_optional_gpu_tests_rel", "target": 1}
{"idx": 3466, "commit_message": "ath9k: increase rx buffers for improved performance with 3x3 chipsets", "target": 1}
{"idx": 2627, "commit_message": "mm: hugetlbfs: fix hugetlbfs optimization  commit 27c73ae759774e63313c1fbfeb17ba076cea64c5 upstream.  Commit 7cb2ef56e6a8 (\"mm: fix aio performance regression for database caused by THP\") can cause dereference of a dangling pointer if split_huge_page runs during PageHuge() if there are updates to the tail_page->private field.  Also it is repeating compound_head twice for hugetlbfs and it is running compound_head+compound_trans_head for THP when a single one is needed in both cases.  The new code within the PageSlab() check doesn't need to verify that the THP page size is never bigger than the smallest hugetlbfs page size, to avoid memory corruption.  A longstanding theoretical race condition was found while fixing the above (see the change right after the skip_unlock label, that is relevant for the compound_lock path too).  By re-establishing the _mapcount tail refcounting for all compound pages, this also fixes the below problem:    echo 0 >/sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages    BUG: Bad page state in process bash  pfn:59a01   page:ffffea000139b038 count:0 mapcount:10 mapping:          (null) index:0x0   page flags: 0x1c00000000008000(tail)   Modules linked in:   CPU: 6 PID: 2018 Comm: bash Not tainted 3.12.0+ #25   Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011   Call Trace:     dump_stack+0x55/0x76     bad_page+0xd5/0x130     free_pages_prepare+0x213/0x280     __free_pages+0x36/0x80     update_and_free_page+0xc1/0xd0     free_pool_huge_page+0xc2/0xe0     set_max_huge_pages.part.58+0x14c/0x220     nr_hugepages_store_common.isra.60+0xd0/0xf0     nr_hugepages_store+0x13/0x20     kobj_attr_store+0xf/0x20     sysfs_write_file+0x189/0x1e0     vfs_write+0xc5/0x1f0     SyS_write+0x55/0xb0     system_call_fastpath+0x16/0x1b", "target": 1}
{"idx": 3945, "commit_message": "Avoid string mutations when resolving package dependencies  I found this bit of code a little difficult to read, mostly because the if statement was spanning multiple lines and had nested blocks in it. I decided to simplify this a bit by just using a better matching regex instead of combining a nested loop with string substitution and a matching regex.  Since this adds regex escaping to the ignore_package_prefixes configuration, I believe that this will also prevent some potentially weird bugs from happening if people used regex characters and didn't know that they were active in this way.  Additionally, I would expect this to improve performance a little, since we no longer have a nested loop here with string substitution.", "target": 1}
{"idx": 2406, "commit_message": "- explicitly set the doctrine/cache package to version 1.3.1 as version 1.4.0 is causing serious performance problems (at least with Windows hosts)", "target": 1}
{"idx": 3918, "commit_message": "Improve filter order cycles tag rule specs' performance", "target": 1}
{"idx": 963, "commit_message": "provide skipIf and skipUnless decorators a-la unittest2 to skip tests in a prettier way; also skipped some memory leak tests of certain functionalities on those platforms for which we are not using a C extension.", "target": 0}
{"idx": 2199, "commit_message": "lpf sse2 14 dual performance improvements  dual 14 horizontal fn - 2x performance dual 14 vertical fn - 3x performance 6,8 and 14 minor code quality improvement", "target": 1}
{"idx": 3379, "commit_message": "Merge pull request #1239 from weaveworks/improve-highlight-perf  Improve canvas highlighting performance.", "target": 1}
{"idx": 4123, "commit_message": "[PATCH] Check in changes to improve performance for nb_puts and\n nb_gets on GPU-hosted global arrays.", "target": 1}
{"idx": 2540, "commit_message": "cpufreq: Optimize cpufreq_frequency_table_verify()  cpufreq_frequency_table_verify() is rewritten here to make it more logical and efficient.  - merge multiple lines for variable declarations together.  - quit early if any frequency between min/max is found.  - don't call cpufreq_verify_within_limits() in case any valid freq is    found as it is of no use.  - rename the count variable as found and change its type to boolean.", "target": 1}
{"idx": 514, "commit_message": "- v3.36 - allow oem-reboot to take effect in recovery mode (bnc #487887) - improved the --list-xmlinfo option which now also prints   information about the repositories used for the image   and it will print out the install size in kB by using   the satsolver. Users can so check how much space is   required to build the root tree of the image", "target": 0}
{"idx": 2061, "commit_message": "Refs #2998: Fixed issue with DiffractionFocussing2TestPerformance where the constructor was called for every single run.", "target": 0}
{"idx": 2445, "commit_message": "Remove the TUI execution info window  The TUI execution info window is unusual in that it is always linked to a source or disassembly window.  Even updates of its content are handled by the source window, so it really has no life of its own.  This patch removes this window entirely and puts its functionality directly into the source window.  This simplifies the code somewhat.  This is a user-visible change, because now the box around the source (or disassembly) window encloses the execution info as well.  I consider this an improvement as well, though.  Note that this patch caused ncurses to start emitting the \"CSI Z\" sequence, so I've added this to the test suite terminal implementation.  gdb/ChangeLog 2019-08-16  Tom Tromey  [URL]>          * tui/tui.h (enum tui_win_type) <EXEC_INFO_WIN>: Remove.         * tui/tui-winsource.h (struct tui_exec_info_window): Remove.         (struct tui_source_window_base) <make_visible, refresh_window,         resize>: Remove methods.         <execution_info>: Remove field.         * tui/tui-winsource.c (tui_source_window_base::do_erase_source_content)         (tui_show_source_line, tui_source_window_base)         (~tui_source_window_base): Update.         (tui_source_window_base::resize)         (tui_source_window_base::make_visible)         (tui_source_window_base::refresh_window): Remove.         (tui_source_window_base::update_exec_info): Update.         * tui/tui-source.c (tui_source_window::set_contents): Update.         * tui/tui-disasm.c (tui_disasm_window::set_contents): Update.  gdb/testsuite/ChangeLog 2019-08-16  Tom Tromey  [URL]>          * lib/tuiterm.exp (_csi_Z): New proc.         * gdb.tui/basic.exp: Update window positions.         * gdb.tui/empty.exp: Update window positions.", "target": 0}
{"idx": 2976, "commit_message": "nios2: remove unused statistic counters  Removed some statistic counters to improve the performance of the handler.", "target": 1}
{"idx": 883, "commit_message": "Improved update last info methods, only change DOM when necessary", "target": 0}
{"idx": 3396, "commit_message": "x86/ldt: Make modify_ldt synchronous  commit 37868fe113ff2ba814b3b4eb12df214df555f8dc upstream.  modify_ldt() has questionable locking and does not synchronize threads.  Improve it: redesign the locking and synchronize all threads' LDTs using an IPI on all modifications.  This will dramatically slow down modify_ldt in multithreaded programs, but there shouldn't be any multithreaded programs that care about modify_ldt's performance in the first place.  This fixes some fallout from the CVE-2015-5157 fixes.", "target": 0}
{"idx": 2688, "commit_message": "Added several performance improvements, most of them still experimental, plus started to prepare for a release.", "target": 1}
{"idx": 3070, "commit_message": "sched: Implement smarter wake-affine logic  The wake-affine scheduler feature is currently always trying to pull the wakee close to the waker. In theory this should be beneficial if the waker's CPU caches hot data for the wakee, and it's also beneficial in the extreme ping-pong high context switch rate case.  Testing shows it can benefit hackbench up to 15%.  However, the feature is somewhat blind, from which some workloads such as pgbench suffer. It's also time-consuming algorithmically.  Testing shows it can damage pgbench up to 50% - far more than the benefit it brings in the best case.  So wake-affine should be smarter and it should realize when to stop its thankless effort at trying to find a suitable CPU to wake on.  This patch introduces 'wakee_flips', which will be increased each time the task flips (switches) its wakee target.  So a high 'wakee_flips' value means the task has more than one wakee, and the bigger the number, the higher the wakeup frequency.  Now when making the decision on whether to pull or not, pay attention to the wakee with a high 'wakee_flips', pulling such a task may benefit the wakee. Also imply that the waker will face cruel competition later, it could be very cruel or very fast depends on the story behind 'wakee_flips', waker therefore suffers.  Furthermore, if waker also has a high 'wakee_flips', that implies that multiple tasks rely on it, then waker's higher latency will damage all of them, so pulling wakee seems to be a bad deal.  Thus, when 'waker->wakee_flips / wakee->wakee_flips' becomes higher and higher, the cost of pulling seems to be worse and worse.  The patch therefore helps the wake-affine feature to stop its pulling work when:  \twakee->wakee_flips > factor && \twaker->wakee_flips > (factor * wakee->wakee_flips) The 'factor' here is the number of CPUs in the current CPU's NUMA node, so a bigger node will lead to more pulling since the trial becomes more severe.  After applying the patch, pgbench shows up to 40% improvements and no regressions.  Tested with 12 cpu x86 server and tip 3.10.0-rc7.  The percentages in the final column highlight the areas with the biggest wins, all other areas improved as well:  \tpgbench\t\t    base\tsmart  \t| db_size | clients |  tps  |\t|  tps  | \t+---------+---------+-------+   +-------+ \t| 22 MB   |       1 | 10598 |   | 10796 | \t| 22 MB   |       2 | 21257 |   | 21336 | \t| 22 MB   |       4 | 41386 |   | 41622 | \t| 22 MB   |       8 | 51253 |   | 57932 | \t| 22 MB   |      12 | 48570 |   | 54000 | \t| 22 MB   |      16 | 46748 |   | 55982 | +19.75% \t| 22 MB   |      24 | 44346 |   | 55847 | +25.93% \t| 22 MB   |      32 | 43460 |   | 54614 | +25.66% \t| 7484 MB |       1 |  8951 |   |  9193 | \t| 7484 MB |       2 | 19233 |   | 19240 | \t| 7484 MB |       4 | 37239 |   | 37302 | \t| 7484 MB |       8 | 46087 |   | 50018 | \t| 7484 MB |      12 | 42054 |   | 48763 | \t| 7484 MB |      16 | 40765 |   | 51633 | +26.66% \t| 7484 MB |      24 | 37651 |   | 52377 | +39.11% \t| 7484 MB |      32 | 37056 |   | 51108 | +37.92% \t| 15 GB   |       1 |  8845 |   |  9104 | \t| 15 GB   |       2 | 19094 |   | 19162 | \t| 15 GB   |       4 | 36979 |   | 36983 | \t| 15 GB   |       8 | 46087 |   | 49977 | \t| 15 GB   |      12 | 41901 |   | 48591 | \t| 15 GB   |      16 | 40147 |   | 50651 | +26.16% \t| 15 GB   |      24 | 37250 |   | 52365 | +40.58% \t| 15 GB   |      32 | 36470 |   | 50015 | +37.14%", "target": 1}
{"idx": 2923, "commit_message": "update README and:  * 'rrails server' changed to 'rrails' * rrails shellrc * performance improvement (ondemand = true) * can run without in Gemfile * Client.run does not call 'exit' * smaller server sleep interval", "target": 1}
{"idx": 1804, "commit_message": "Improve validation of 'name' and 'code' parameters for lint messages  Summary: Ref T9145. Fixes T9316. We now require \"name\" and \"code\" has a maximum length (currently, this is 32, but the next diff will raise it to 128).  Test Plan:   - Installed PHPCS.   - Hit both the \"name\" and \"code\" issues.   - Applied this patch.   - Got better errors sooner.  Reviewers: chad  Reviewed By: chad  Subscribers: aik099  Maniphest Tasks: T9145, T9316  Differential Revision: [URL]/D14165", "target": 0}
{"idx": 2324, "commit_message": "Improving performance of ConversionResult usages of orThrow with String.format", "target": 1}
{"idx": 652, "commit_message": "Fix next.js-specific things  The next.js babel preset can't be used because it messes up dynamic imports. So, instead we use the same preset with some next-specific plugins.", "target": 0}
{"idx": 2994, "commit_message": "Better performance with everything in a single function.", "target": 1}
{"idx": 1654, "commit_message": "Merge pull request #1615 from amtriathlon/VDOT  Added Equivalent Performance for Target Race to VDOT Calculator", "target": 0}
{"idx": 4059, "commit_message": "[PATCH] Made some performance improvements and fixed a bug when\n running on a single processor but compiled with mpi.", "target": 1}
{"idx": 2719, "commit_message": "optimize renders to get reasonable mobile performance", "target": 1}
{"idx": 1236, "commit_message": "Improve the error message for noIdentity", "target": 0}
{"idx": 2381, "commit_message": "Make THaVarList a THashList instead of a TList for better performance.  (Almost) everything just happens automagically as we inherit from THashList instead of TList. THaVarList::Find(const char* name) automatically makes hash table lookups, vastly improving the search speed if a large number of global variables is defined.  Also, make THaVarList the owner of its objects, so as the list is deleted, so are all of its elements. This was already the previous behavior; this just eliminates duplicate code.  Closes #27.", "target": 1}
{"idx": 3899, "commit_message": "Misc changes to phonon postprocessing tools: i) calculation of rigid-ion term made simpler and faster if many atoms are present. It should make any difference in final results, but on a 40-atom cell q2r.x now yields correct results, while the previous version didn't. ii) Large automatic arrays in ASR routine replace by allocatable so that for many atoms the routine doesn't instantly crash any longer. The fancy ASR badly need some serious work to reduce the amount of cpu time and memory they use, or else they are unusable on large and not-so-large systems.", "target": 1}
{"idx": 3796, "commit_message": "Merge pull request #1472 from dotnet-campus/t/lindexi1/inprove_tiny_perform  Improve tiny performance", "target": 1}
{"idx": 2, "commit_message": "[app] improve treeview  * open/close on double-click * expose open status to label comp", "target": 0}
{"idx": 733, "commit_message": "new file:   clean_extra_files.sh \tmodified:   compile_modules_extra.sh \tmodified:   doc/install.txt \tnew file:   ircd.log \tmodified:   settings/network/sslcerts.conf \tmodified:   settings/vhost/vhost.conf", "target": 0}
{"idx": 3405, "commit_message": "PM-610: batch scp transfers for more efficient transfers", "target": 1}
{"idx": 2633, "commit_message": "[MERGE] mail, various: improve post and notification API and performances  Purpose of this merge is to clean and improve performances of post and notification mechanism contained in mail application.  In this merge we provide  * centralization of notification code inside mail.thread instead of being dispatched in mail.thread, mail.message and res.partner; * simplification of call chain, removal of unnecessary methods; * better propagation of messages value through the various calls in order to use given value and avoid browse and cache miss adding queries; * optimization of attachments management in post; * cleaning of message_post now limited to records and simplified in its management of parameter; * cleaning and simplification of recipients grouping for email notification; * cleaning of message_notify; * various code cleaning and tweaking in order to reduce query count;  Performance tests indicate number of queries did fall, especially in use cases involving management of followers and attachments. See sub commits for more details. This merge is linked to task ID 1943901.  closes odoo/odoo#32404", "target": 1}
{"idx": 3151, "commit_message": "fixes issue 973  + Correctness fix: look at symcache for whether have symbols instead of   checking for pdb when symcache may contain negative entries  + Ensure symbols are used: if symbols available but weren't when cached,   don't use symcache and replace it  + Ensure symcache is created: write out the symcache post-module-load in   case we crash or sthg  + Performance: use new drsym_module_has_symbols() which is faster than   drsym_get_module_debug_kind()", "target": 1}
{"idx": 3996, "commit_message": "[PATCH] Fix performance for range copy", "target": 1}
{"idx": 3131, "commit_message": "Prepare for next patches (Improving BKDG implementation of P-states, CPU and northbridge frequency and voltage handling for Fam 10 in SVI mode).  No change of behaviour intended.  Refactor FAM10 fidvid . Factor out the decision whether to update northbridge frequency and voltage because there was the same code in 3 places and so we can later modify it in one place.", "target": 0}
{"idx": 2938, "commit_message": "update performance sections in comparison.md, fixes #1291", "target": 0}
{"idx": 1857, "commit_message": "Alex Romosan:  * Use \"const string&\" rather than \"string\" in function calls when appropriate. * Use \"const Point3D&\" instead of \"Pint3D\" in function calls when appropriate. * Improved course calculation in calc_gc_course_dist() * Safer thread handling code.  Vassilii Khachaturov:  Dont use \"const Point3D&\" for return types unless you're absolutely sure.  Erik Hofman:  * Use SGD_(2)PI(_[24]) as defined in simgear/constants.h rather than   calculating it by hand every time.", "target": 0}
{"idx": 3479, "commit_message": "Reprioritize tests for tail duplication to be aggressive about indirect branches even when optimizing for code size.  Unless we find evidence to the contrary in the future, the special treatment for indirect branches does not have a significant effect on code size, and performance still matters with -Os.", "target": 0}
{"idx": 3259, "commit_message": "apply patch #68986 from Parthasarathy Gopavarapu + few improvement of code about gui layout and coding style. wiki url history is saved/restored between sessions. All points listed by Guillaume Paumier from comment #11 of bug #206842 are implemented. CCBUGS: 206842", "target": 0}
{"idx": 1609, "commit_message": "automaticMemoryManagement tests check for actual connection closing", "target": 0}
{"idx": 933, "commit_message": "Roll src/third_party/catapult/ aa736cc76..ba9bf6aa3 (1 commit)  [URL]/catapult-project/catapult.git/+log/aa736cc76ee5..ba9bf6aa3e74  $ git log aa736cc76..ba9bf6aa3 --date=short --no-merges --format='%ad %ae %s' 2017-09-22 dtu [pinpoint] Increase gitiles request timeout.  Created with:   roll-dep src/third_party/catapult   Documentation for the AutoRoller is here: [URL]/buildbot/+/master/autoroll/README.md  If the roll is causing failures, see: [URL]/developers/tree-sheriffs/sheriff-details-chromium#TOC-Failures-due-to-DEPS-rolls   CQ_INCLUDE_TRYBOTS=master.tryserver.chromium.android:android_optional_gpu_tests_rel [URL]", "target": 0}
{"idx": 4006, "commit_message": "[PATCH] Added preconditions and made it more efficient", "target": 1}
{"idx": 3040, "commit_message": "Improve player comparison performance.  This method is called millions of times and so is one of the bottlenecks.  Tests are now 25% faster.", "target": 1}
{"idx": 1059, "commit_message": "Improved the list of used functions which is save in the COPASI file. Functions used in model quantities of type ASSIGNMENT or ODE were missed.", "target": 0}
{"idx": 3510, "commit_message": "kmemleak: use rbtree instead of prio tree  kmemleak uses a tree where each node represents an allocated memory object in order to quickly find out what object a given address is part of. However, the objects don't overlap, so rbtrees are a better choice than prio tree for this use.  They are both faster and have lower memory overhead.  Tested by booting a kernel with kmemleak enabled, loading the kmemleak_test module, and looking for the expected messages.", "target": 1}
{"idx": 2788, "commit_message": "Bug 730877: Improve _get_string_from_file() performances by caching loaded files r=glob a=LpSolit", "target": 1}
{"idx": 859, "commit_message": "Improve package  - bug fix Formatter - update league uri component dependency - add Basename and Dirname modifiers", "target": 0}
{"idx": 3640, "commit_message": "Revert of [DevTools] Always report encodedDataLength in Network.ResponseReceived. (patchset #1 id:1 of [URL]/2101073002/ )  Reason for revert: Decided to try another approach, see discussion in issue 622018  Original issue's description: > [DevTools] Always report encodedDataLength in Network.ResponseReceived. > > Currently, we only send encodedDataLength for redirects. However, we already know how much we read when sending ResponseReceived. This will improve reporting for failed requests, as they don't get loadingFinished with full encodedDataLength. > > BUG=622018 > > Committed: [URL]/00f8f6c17d27799700974e599d6003b7f376071c >", "target": 0}
{"idx": 2578, "commit_message": "XCF-859 improve performance of importing lardge sets of data by properly delaying replication LazyDaemon now support quiet period - it'll only kick off replication if new replication request was NOT made during last sleepInterval (7s by default)", "target": 1}
{"idx": 1751, "commit_message": "jenkins performance build jenkins-jitsi-performance-statistics-288 Version 179_739_261_1014", "target": 0}
{"idx": 1160, "commit_message": "* Optimize by speed map grids update.", "target": 1}
{"idx": 1981, "commit_message": "rcu: Use smp_hotplug_thread facility for RCUs per-CPU kthread  Bring RCU into the new-age CPU-hotplug fold by modifying RCU's per-CPU kthread code to use the new smp_hotplug_thread facility.  [ tglx: Adapted it to use callbacks and to the simplified rcu yield ]", "target": 0}
{"idx": 3633, "commit_message": "Fix traceback in quads-post-system-test.py  Fixes: [URL]/redhat-performance/quads/issues/129 Fixes: [URL]/redhat-performance/quads/issues/130", "target": 0}
{"idx": 913, "commit_message": "Merge [URL]/pub/scm/linux/kernel/git/nab/target-pending  Pull SCSI target fixes from Nicholas Bellinger:  \"The executive summary includes:     - Post-merge review comments for tcm_vhost (MST + nab)    - Avoid debugging overhead when not debugging for tcm-fc(FCoE) (MDR)    - Fix NULL pointer dereference bug on alloc_page failulre (Yi Zou)    - Fix REPORT_LUNs regression bug with pSCSI export (AlexE + nab)    - Fix regression bug with handling of zero-length data CDBs (nab)    - Fix vhost_scsi_target structure alignment (MST)    Thanks again to everyone who contributed a bugfix patch, gave review   feedback on tcm_vhost code, and/or reported a bug during their own   testing over the last weeks.    There is one other outstanding bug reported by Roland recently related   to SCSI transfer length overflow handling, for which the current   proposed bugfix has been left in queue pending further testing with   other non iscsi-target based fabric drivers.    As the patch is verified with loopback (local SGL memory from SCSI   LLD) + tcm_qla2xxx (TCM allocated SGL memory mapped to PCI HW) fabric   ports, it will be included into the next 3.6-rc-fixes PULL request.\"  * [URL]/pub/scm/linux/kernel/git/nab/target-pending:   target: Remove unused se_cmd.cmd_spdtl   tcm_fc: rcu_deref outside rcu lock/unlock section   tcm_vhost: Fix vhost_scsi_target structure alignment   target: Fix regression bug with handling of zero-length data CDBs   target/pscsi: Fix bug with REPORT_LUNs handling for SCSI passthrough   tcm_vhost: Change vhost_scsi_target->vhost_wwpn to char *   target: fix NULL pointer dereference bug alloc_page() fails to get memory   tcm_fc: Avoid debug overhead when not debugging   tcm_vhost: Post-merge review changes requested by MST   tcm_vhost: Fix incorrect IS_ERR() usage in vhost_scsi_map_iov_to_sgl", "target": 0}
{"idx": 3328, "commit_message": "INTEGRATION - Integration of 8833,8835,8842,8850,8851,8852,8859,8864,8899,8913,8931,8939,8940,8948,8965,9005,9007,9008,9020,9036,9048,9051,9052,9053,9057,9063,9076 from child to parent (branch spec: lcs).       ==> 8833, Date:  2007/03/06 14:58:25           User:    zfong           Description:            LCS/FARRAGO/FENNEL - Enable use of new SnapshotRandomAllocationSegment.                   Fixed various bugs encountered while testing.        ==> 8835, Date:  2007/03/07 09:28:46           User:    zfong           Description:            LCS/FENNEL - Added documentation for VersionedRandomAllocationSegment and                   SnapshotRandomAllocationSegment.  Also fixed a doxygen warning.        ==> 8842, Date:  2007/03/07 17:22:56           User:    rchen           Description:            /lu/dev_lcs(farrago): improve index access costing for single table filters and semi join filters.        ==> 8850, Date:  2007/03/08 16:00:56           User:    zfong           Description:            LCS/FARRAGO/FENNEL/LUCIDDB - Relaxed locking requirements in LucidDb to                   allow concurrent DML, now that snapshots are being used.  Also fixed a                   problem that was incorrectly resulting in snapshot pages being logged.        ==> 8851, Date:  2007/03/09 10:13:54           User:    zfong           Description:            LCS/FARRAGO/FENNEL - Made UML model changes to support new ALTER SYSTEM                   DEALLOCATE statement        ==> 8852, Date:  2007/03/09 15:04:41           User:    zfong           Description:            LCS/LUCIDDB - Modified testcase so each thread writes different data        ==> 8859, Date:  2007/03/12 14:12:46           User:    zfong           Description:            LCS/FENNEL - Fixed a typo        ==> 8864, Date:  2007/03/13 13:08:11           User:    rchen           Description:            /lu/dev_lcs(farrago, luciddb) Adjust index access costing formula. Residual filters are costed along side with indexes.        ==> 8899, Date:  2007/03/20 12:35:14           User:    zfong           Description:            LCS/FARRAGO/FENNEL/LUCIDDB - Implemented the new ALTER SYSTEM DEALLOCATE OLD                   statement.  Also modified drops in LucidDb so they only mark pages                   as needing to be deallocated.  The actual deallocation is done by a                   subsequent ALTER SYSTEM DEALLOCATE OLD.        ==> 8913, Date:  2007/03/21 09:25:44           User:    rchen           Description:            /lu/dev_lcs(farrago, fennel): fix problem in residual column filters when the column store clusters contain multiple columns.        ==> 8931, Date:  2007/03/22 12:58:51           User:    zfong           Description:            LCS/FENNEL - Removed some unneeded code as a result of deferred                   deallocation, and reworked concurrency in                   VersionedRandomAllocationSegment by separating the existing mutex into                   two separate mutexes.        ==> 8939, Date:  2007/03/23 15:02:38           User:    zfong           Description:            LCS/FENNEL - Changed the representation of deallocation-deferred                   pageOwnerIds so we can free these pages only when they're no longer                   being referenced.  Also removed unnecessary writes of anchor pages, and                   fixed a bug in how the next, newest old pageId is determined.        ==> 8940, Date:  2007/03/23 19:13:12           User:    zfong           Description:            LCS/FARRAGO/FENNEL - UML model changes required to support versioning for                   ALTER TABLE REBUILD and TRUNCATE        ==> 8948, Date:  2007/03/26 14:52:49           User:    zfong           Description:            LCS/FARRAGO/FENNEL - Modified model changes in 8940 so the command operates                   on only a single index (to be consistent with other index commands)        ==> 8965, Date:  2007/03/27 15:43:04           User:    zfong           Description:            LCS/FARRAGO/FENNEL/LUCIDDB - Versioned ALTER TABLE REBUILD and TRUNCATE        ==> 9005, Date:  2007/03/30 07:25:14           User:    zfong           Description:               LCS/INTEGRATION: Integration of 8827,8830,8834,8844,8847,8848,8849,8854,8855,8856,8857,8858,8860,8861,8862,8866,8867,8868,8869,8873,8874,8875,8876,8877,8883,8887,8890,8903,8905,8910,8914,8917,8921,8924,8927,8933,8934,8937,8950,8959,8963,8964,8968,8970,8971,8972,8974,8987,8994 from parent to child (branch spec: lcs).                  ==> 8827, Date:  2007/03/06 01:08:36                      User:    elin                      Description:                       LUCIDDB/QA: remove dependency on raksha for checkin tests                   ==> 8830, Date:  2007/03/06 10:51:28                      User:    elin                      Description:                       QA/BUILD: add directories to clean target                   ==> 8834, Date:  2007/03/06 17:19:13                      User:    jvs                      Description:                       FARRAGO:  add dataflow/dependency metadata visualization                       infrastructure and examples                   ==> 8844, Date:  2007/03/08 02:22:48                      User:    jvs                      Description:                       FARRAGO:  processing overview diagram for DMV                   ==> 8847, Date:  2007/03/08 12:35:17                      User:    ogothberg                      Description:                       FARRAGO: added option to have prettyprinter split where clauses on multiple rows FRG-234                   ==> 8848, Date:  2007/03/08 13:37:22                      User:    ogothberg                      Description:                       FARRAGO/BF: missed to include a file.                   ==> 8849, Date:  2007/03/08 14:14:22                      User:    ogothberg                      Description:                       FARRAGO: code cleanup, eclipse settings were off.                   ==> 8854, Date:  2007/03/10 00:45:20                      User:    schoi                      Description:                       FARRAGO: add a method to support converting a relnode to                       another in \"lenient\" mode                    ==> 8855, Date:  2007/03/10 23:29:46                      User:    jvs                      Description:                       FARRAGO:  remove comment which was accidentally duplicated                   ==> 8856, Date:  2007/03/11 11:10:33                      User:    jvs                      Description:                       FARRAGO:  expose warning support from statement validation;                       change SQL/MED mock to test it                   ==> 8857, Date:  2007/03/12 10:31:17                      User:    schoi                      Description:                       FARRAGO: add warnings for SQL/MED source metadata changes;                       bless \"NETSUITE\" wrappers                   ==> 8858, Date:  2007/03/12 11:32:51                      User:    schoi                      Description:                       FARRAGO: fix bug from last checkin                   ==> 8860, Date:  2007/03/12 15:32:27                      User:    jvs                      Description:                       FARRAGO:  fix typo in UDT/UDR doc                   ==> 8861, Date:  2007/03/12 16:09:43                      User:    schoi                      Description:                       FARRAGO: re-align text                   ==> 8862, Date:  2007/03/12 18:38:00                      User:    schoi                      Description:                       FARRAGO: fix more logical errors in toLenientRel                   ==> 8866, Date:  2007/03/14 14:41:15                      User:    schoi                      Description:                       FARRAGO: add USE_SCHEMA_NAME_AS_FOREIGN_QUALIFIER option for                       jdbc foreign servers                   ==> 8867, Date:  2007/03/14 16:13:17                      User:    schoi                      Description:                       BF: switch table_name/object to keep error message happy                   ==> 8868, Date:  2007/03/14 17:53:36                      User:    ogothberg                      Description:                       FARRAGO: FarragoTestCase didn't escape things properly                   ==> 8869, Date:  2007/03/15 09:45:34                      User:    jvs                      Description:                       FARRAGO:  refactor DMV test routine to support other repositories,                       and fix DmvGraphvizRenderer to ignore anonymous objects                   ==> 8873, Date:  2007/03/17 19:37:12                      User:    jvs                      Description:                       FARRAGO:  remove superfluous synchronized blocks from                       FennelTupleAccessor                   ==> 8874, Date:  2007/03/17 19:38:08                      User:    jvs                      Description:                       FARRAGO:  add support for permanently changing RMI listener port                       during tests                   ==> 8875, Date:  2007/03/18 17:44:45                      User:    ogothberg                      Description:                       FARRAGO: first stab at JAAS authentication support for farrago. LER-4046                   ==> 8876, Date:  2007/03/18 17:45:36                      User:    ogothberg                      Description:                       FARRAGO: file had moved LER-4046                   ==> 8877, Date:  2007/03/18 22:45:44                      User:    ogothberg                      Description:                       FARRAGO: small refactoring                   ==> 8883, Date:  2007/03/19 12:32:59                      User:    jvs                      Description:                       FARRAGO:  review comments on FarragoMockLoginModule                   ==> 8887, Date:  2007/03/19 23:52:51                      User:    jvs                      Description:                       FARRAGO:  update reference to macker in CC                   ==> 8890, Date:  2007/03/20 08:04:24                      User:    schoi                      Description:                       FARRAGO: add LENIENT option to JDBC Foreign Server Definition                   ==> 8903, Date:  2007/03/20 19:57:42                      User:    zfong                      Description:                       FARRAGO/LUCIDDB - Refixed LER-4331 by reverting the original changes from                              Eigenchange 8715 and undoing the changes made for LDB-90 in                              RelMdUtil.numDistinctVals                   ==> 8905, Date:  2007/03/20 21:12:17                      User:    jvs                      Description:                       THIRDPARTY/LUCIDDB:  upgrade JGraphT to 0.7.1, fixing                       LDB-125                   ==> 8910, Date:  2007/03/21 06:15:10                      User:    schoi                      Description:                       LU/FARRAGO: remove Disruptive Tech calc code in flatfile reader                   ==> 8914, Date:  2007/03/21 12:36:14                      User:    zfong                      Description:                       FARRAGO - Fixed LER-4650.  An incorrect join order (for an outer join where                              the outer join condition doesn't reference the null generating table)                              was being considered, resulting in a java assert.                   ==> 8917, Date:  2007/03/21 13:54:35                      User:    schoi                      Description:                       FARRAGO: forgot to insert nulls if types are cast-incompatible                   ==> 8921, Date:  2007/03/21 16:10:09                      User:    jvs                      Description:                       FARRAGO/BF:  update ref log for collision of eigenchanges 8903/8905                   ==> 8924, Date:  2007/03/21 23:24:44                      User:    jvs                      Description:                       FARRAGO:  embellish description of JDBC SQL/MED LENIENT parameter                   ==> 8927, Date:  2007/03/22 11:34:17                      User:    jvs                      Description:                       FARRAGO:  expand on the \"after a lot of math\" in RelMdUtil                   ==> 8933, Date:  2007/03/22 14:53:05                      User:    schoi                      Description:                       TEST/LUCIDDB: tests for jdbc wrapper lenient option, using oracle db                   ==> 8934, Date:  2007/03/22 15:37:24                      User:    schoi                      Description:                       FARRAGO: updated doc; table columns are case-sensitive                   ==> 8937, Date:  2007/03/23 08:54:16                      User:    jvs                      Description:                       FARRAGO/FENNEL:  eliminate remaining unused dependencies from                        LucidDB to Disruptive Tech code                   ==> 8950, Date:  2007/03/26 15:03:57                      User:    ogothberg                      Description:                       LUCIDDB: new udx for splitting strings, LER-2248                    ==> 8959, Date:  2007/03/27 12:04:35                      User:    ogothberg                      Description:                       THIRDPARTY: vjdbc upgrade to 1.6.5                   ==> 8963, Date:  2007/03/27 13:36:50                      User:    elin                      Description:                       LUCIDDB/QA: nightly test cleanup                   ==> 8964, Date:  2007/03/27 15:20:37                      User:    fzhang                      Description:                       LUCIDDB: (#8937 continue) eliminate remaining package dependencies from LucidDB to Disruptive                   ==> 8968, Date:  2007/03/28 14:06:12                      User:    elin                      Description:                       LUCIDDB/QA: missed file for nightly test cleanup                   ==> 8970, Date:  2007/03/28 19:07:25                      User:    jvs                      Description:                       FARRAGO:  check in disabled code for supporting                        floating-point division of integers per personality                   ==> 8971, Date:  2007/03/28 19:07:46                      User:    jvs                      Description:                       FARRAGO:  suppress more bogus AWT exceptions                   ==> 8972, Date:  2007/03/28 19:08:20                      User:    jvs                      Description:                       LUCIDDB:  copy FennelResource .properties files over so that                       Fennel messages get localized correctly; update test .refs                       accordingly                   ==> 8974, Date:  2007/03/28 20:18:13                      User:    ogothberg                      Description:                       LUCIDDB: vjdbc upgrade broke sqllineClient                   ==> 8987, Date:  2007/03/29 10:32:34                      User:    ogothberg                      Description:                       FARRAGO/LUCIDDB: adding support for running jdbc over HTTP, LER-4047                   ==> 8994, Date:  2007/03/29 13:32:56                      User:    ogothberg                      Description:                       FARRAGO/BF: passing shell script paths to ant is no good on windows. building directly in the dist directory instead.         ==> 9007, Date:  2007/03/30 16:35:44           User:    zfong           Description:            LCS/LUCIDDB - Updated ref file with correct error message        ==> 9008, Date:  2007/03/30 16:36:22           User:    zfong           Description:            LCS/FARRAGO - Fixes required to make platform build compile and pass tests        ==> 9020, Date:  2007/03/31 22:00:44           User:    jvs           Description:            LCS/FARRAGO/LUCIDDB:  LER-4589, change LucidDB type factory to            use floating point division even when both numerator            and denominator are integers (making this consistent with            division of decimals with scale 0); lots of corresponding            log updates        ==> 9036, Date:  2007/04/03 16:19:54           User:    zfong           Description:            LCS/FENNEL/LUCIDDB - Page successor incorrectly being set when new page                   versions are created.        ==> 9048, Date:  2007/04/04 19:29:26           User:    zfong           Description:            LCS/LUCIDDB - Updated ref file due to changes in Eigenchange 9020        ==> 9051, Date:  2007/04/05 08:22:37           User:    zfong           Description:            LCS/FARRAGO - Fixed table truncation in LucidDb so pages are getting freed.        ==> 9052, Date:  2007/04/05 08:23:12           User:    zfong           Description:            LCS/FENNEL - Performance improvements in snapshot code        ==> 9053, Date:  2007/04/05 12:21:51           User:    zfong           Description:            LCS/FARRAGO/FENNEL - Fixed LucidDb ALTER TABLE REBUILD so the original                   indexes are truncated.        ==> 9057, Date:  2007/04/05 16:42:03           User:    rchen           Description:            /lu/dev_lcs(farrago, luciddb)some optimization for index selection: avoid costing the same index selection multiple times, precalculate some cost measures.         ==> 9063, Date:  2007/04/06 21:33:41           User:    zfong           Description:            LCS/FENNEL - Additional performance changes in the versioning code        ==> 9076, Date:  2007/04/10 09:37:18           User:    zfong           Description:            LCS/INTEGRATION - Integration of 8998,8999,9006,9009,9012,9021,9022,9033,9034,9037,9040,9064 from parent to child (branch spec: lcs).                  ==> 8998, Date:  2007/03/29 22:05:53                      User:    schoi                      Description:                       FARRAGO: change behavior of not-lenient jdbc connectors to                       have more strict checking                   ==> 8999, Date:  2007/03/30 00:13:56                      User:    schoi                      Description:                       FARRAGO: Indentation. No change.                   ==> 9006, Date:  2007/03/30 14:11:57                      User:    fzhang                      Description:                       BUILD: upgrade junit from ver 4.0 to 4.1                   ==> 9009, Date:  2007/03/30 16:42:00                      User:    schoi                      Description:                       BH: properly escape values bh.xml                   ==> 9012, Date:  2007/03/30 17:28:10                      User:    schoi                      Description:                       BH: null integ                   ==> 9021, Date:  2007/04/02 00:08:11                      User:    jvs                      Description:                       FARRAGO:  add support for metamodel version timestamp checking                   ==> 9022, Date:  2007/04/02 00:08:35                      User:    jvs                      Description:                       FARRAGO:  allow resourceDir to be changed from tests which know                       what they are doing                   ==> 9033, Date:  2007/04/03 10:59:16                      User:    ogothberg                      Description:                       FARRAGO: code cleanup                   ==> 9034, Date:  2007/04/03 11:08:39                      User:    jvs                      Description:                       FARRAGO:  fix JmiObjUtil.newClone to deal with null references                   ==> 9037, Date:  2007/04/03 17:49:53                      User:    ogothberg                      Description:                       THIRDPARTY: vjdbc needed a patch, LER-4743                   ==> 9040, Date:  2007/04/04 10:26:54                      User:    elin                      Description:                       APPLIB: Fix and test for LER-4741                   ==> 9064, Date:  2007/04/08 22:23:58                      User:    schoi                      Description:                       LUCIDDB: update boilerplate  [git-p4: depot-paths = \"//open/lu/dev/\": change = 9080]", "target": 0}
{"idx": 2027, "commit_message": "[Files app] Add metrics for ZIP mount time  In the context of making performance tests more precise and reliable, add ZIP mount time UMA metric.  Test: browser_tests --gtest_filter=FileManagerJsTest.FileTasks Bug: 1315091", "target": 0}
{"idx": 2883, "commit_message": "New in-place and or and xor. More efficient standard or and and xor.", "target": 1}
{"idx": 876, "commit_message": "theme: improve the tasklist style  [URL]/show_bug.cgi?id=769012", "target": 0}
{"idx": 2918, "commit_message": "FRESH-658 #370 improve unit test performance  *fix: there was too much tracing involved => big performance penalty * FRESH-658 #370 Material Receipt - Somtimes double click needed for weighing machine", "target": 1}
{"idx": 1715, "commit_message": "Fix deadlock issue in package_built handler  When creating a PackageBuild record, it locks corresponding row of BuildGroup in shared mode. If two transaction creating two PackageBuild records of the same BuildGroup record, they both hold the shared lock. Then when they try to updating BuildGroup record, deadlock occurs.  The solution is moving updating BuildGroup operation in front of inserting PackageBuild. Then the second transaction can't get exclusive lock before the first transaction release(finish).  Also make other improvements as follows:  * save a model only if it's really needed * restart a transaction if deadlock raised  Refs #2192 for more detail of this deadlock issue.  Refs MYSQL docs for constraint check of foreign key. [URL]/doc/refman/5.5/en/innodb-foreign-key-constraints.html", "target": 1}
{"idx": 2431, "commit_message": "Allow the passing of mutants (non-zero alleles) as a dictionary to user-provided function in call-back functions of PySelector, PyQuanTrait, and PyPenetrance. This can be more efficient for large genomes with few mutants.", "target": 1}
{"idx": 143, "commit_message": "Fix layer enable/disable bug introduced in version 1.5.1 with rendering optimizations", "target": 1}
{"idx": 754, "commit_message": "Reinstate ZERO_PAGE optimization in 'get_user_pages()' and fix XIP  KAMEZAWA Hiroyuki and Oleg Nesterov point out that since the commit 557ed1fa2620dc119adb86b34c614e152a629a80 (\"remove ZERO_PAGE\") removed the ZERO_PAGE from the VM mappings, any users of get_user_pages() will generally now populate the VM with real empty pages needlessly.  We used to get the ZERO_PAGE when we did the \"handle_mm_fault()\", but since fault handling no longer uses ZERO_PAGE for new anonymous pages, we now need to handle that special case in follow_page() instead.  In particular, the removal of ZERO_PAGE effectively removed the core file writing optimization where we would skip writing pages that had not been populated at all, and increased memory pressure a lot by allocating all those useless newly zeroed pages.  This reinstates the optimization by making the unmapped PTE case the same as for a non-existent page table, which already did this correctly.  While at it, this also fixes the XIP case for follow_page(), where the caller could not differentiate between the case of a page that simply could not be used (because it had no \"struct page\" associated with it) and a page that just wasn't mapped.  We do that by simply returning an error pointer for pages that could not be turned into a \"struct page *\".  The error is arbitrarily picked to be EFAULT, since that was what get_user_pages() already used for the equivalent IO-mapped page case.  [ Also removed an impossible test for pte_offset_map_lock() failing:   that's not how that function works ]  Acked-by: Oleg Nesterov < > Acked-by: Nick Piggin < > Cc: KAMEZAWA Hiroyuki [URL]> Cc: Hugh Dickins [URL]> Cc: Andrew Morton [URL]> Cc: Ingo Molnar < > Cc: Roland McGrath [URL]>", "target": 1}
{"idx": 3089, "commit_message": "[PATCH] md: improve raid1 \"IO Barrier\" concept  raid1 needs to put up a barrier to new requests while it does resync or other background recovery.  The code for this is currently open-coded, slighty obscure by its use of two waitqueues, and not documented.  This patch gathers all the related code into 4 functions, and includes a comment which (hopefully) explains what is happening.", "target": 0}
{"idx": 135, "commit_message": "Dynamic casts fixed to check for result and throw exception if cast fails. M    csv-handler/CSVRequestHandler.cc", "target": 0}
{"idx": 2321, "commit_message": "Enable fixed-attachment background on Android  We disabled fixed-attachment background on Android when we needed re-rasterization of all such backgrounds on scroll which would degrade scroll performance.  Now we support composited viewport fixed-attachment background (which is the common case), and performance of Android devices has improved. This patch enables fixed-attachment background on Android which removes a platform-specific quirk.  Bug: 521555", "target": 1}
{"idx": 1127, "commit_message": "Insert dummy content script at every location.  This is needed for propagating the extension's permissions to the extension's iframe, in the rare event that the PDF is loaded in a sub frame, and the extension does not have access to the top frame. For instance, when a http:-PDF file is embedded in a local file, while \"Allow access to local URLs\" is disabled.  Note: Propagating permissions by inserting content scripts is an  undocumented feature [URL]/302548).  Whenever it breaks, the issue (cross-domain permissions for XHR) can be solved by using a content script that gets the blob using the XMLHttpRequest API, followed by `postMessage` (via transferables) to efficiently pass the arraybuffer back to the PDF Viewer.", "target": 0}
{"idx": 1849, "commit_message": "Rewrote some things and improved errors", "target": 0}
{"idx": 2397, "commit_message": "Implements more efficient reading of long binary streams (ads7825.py)", "target": 1}
{"idx": 3135, "commit_message": "[mybatis] removed the synchronized block to improve performance see [URL]/p/mybatis/issues/detail?id=461", "target": 1}
{"idx": 2566, "commit_message": "ASoC: cs4234: Add support for Cirrus Logic CS4234 codec  The CS4234 is a highly versatile CODEC that combines 4 channels of high performance analog to digital conversion, 4 channels of high performance digital to analog conversion for audio, and 1 channel of digital to analog conversion to provide a nondelayed audio reference signal to an external Class H tracking power supply.  DAC5 is only supported as a 5th audio channel. Tracking Power Supply mode is not currently supported by the driver.  In DSP_A mode the slots for DAC1-4 and optionally DAC5 can be set. The codec always claims 4 slots for DAC1-4 and these must be in the same nibble of the mask. The codec has a fixed mapping for ADC slots.  In I2S/LJ modes the codec has a fixed mapping for DAC1-4 and ADC1-4. DAC5 is not available in these modes.  The MCLK source must be preset to a valid frequency before probe() because it must be running all the time the codec is out of reset.  The VA_SEL bit will be set automatically to 3.3v or 5v during probe() based on the reported voltage of the regulator supplying VA.", "target": 0}
{"idx": 2972, "commit_message": "Better performance and more stable iteration order  I had to peel open the internals of the annotation and keyword wrappers to expose the ImmutableMap underneath.  Most use cases will never see this method, since IValue is all about interfaces.", "target": 1}
{"idx": 3072, "commit_message": "Merge pull request #73 from kz363/master  Performance improvements", "target": 1}
{"idx": 2591, "commit_message": "Several fixes to cache implementation (bug 22262):  1.  implemented \"null object pattern\" for failed searches so that they don't have to be repeated every time.  those searches are the worst-case scenario for this cache, so it's important that they not be done repeatedly.  In my tests, the previous implementation searched for \"getDeserializer\" methods on java.lang.String, java.lang.Integer, and so forth on *every* WS invocation.  2. replaced the algorithm for matching method signatures -> methods. the earlier one was O(n) [n = number of methods]; the new one is O(1) [replaced linear scan over an arraylist with a hashtable] Note that the hash algorithm is optimized for the common case (distinctly named methods); overloaded methods will collide in the table, so searches for them will be O(m) [m = number of overloaded methods with a given name].  This lets the easy cases be as fast as possible and the less-easy cases be fast enough, without making everything be slow.  3. fixed inconsistency in calls to containsKey/get.  Previously two different objects (of different types) were being used in these calls, causing the cache to be created but *never* used.", "target": 1}
{"idx": 3063, "commit_message": "improved performance for dealing with NaN input data, original fix could not handle 0-d inputs", "target": 1}
{"idx": 2161, "commit_message": "Fix 2 stagnation point bugs  The first bug fixed was in DiagCG as stagnation points have been applied. It was writing values to an array way beyond the allocation.  The send, more subtle, bug fixed was that CGCompFlow was storing a newly introduced state m_stag, which was written to initialize(), after the constructor. This is not allowed, because these equation objects are created very early on and made global adn thus read only. This led to problems in SMP mode only. This was fixed by a slightly more expensive way of testing for stagnation points, based on user config parsed. This, however, does not affect performance in a measurable way, and every loop that calls the new CompFlow::stagPoint() function is still vectorized correctly.  With this all regression tests, except for ALECG/CompFlow, pass again.", "target": 0}
{"idx": 3653, "commit_message": "Transferred from the Adobe Open Source Subversion Repository  Revision: 9948 Author:   [URL] Date:     2009-09-03T02:44:59.359824Z  Log Message:  ----------- Spark Primitive Text Changes.  See [URL]/wiki/display/flexsdk/Spark+Text+Primitives+Decision for the full information and reasoning for the decision.  The main changes are:  * Replace SimpleText with Label, a UIComponent version of the same component * Instead of extending GraphicElement, RichText will extend UIComponent (like Label will) * All of the spark text components will move to spark.components.*, so there will be spark.components.Label, spark.components.RichText, and spark.components.RichEditableText * The base class for SimpleText and RichText, spark.primitives.supportClasses.TextGraphicElement, will now extend UIComponent (instead of GraphicElement) and be moved and renamed to spark.components.supportClasses.TextBase. All of our text skin parts will now be typed as TextBase instead of TextGraphicElement * For now, RichEditableText and RichText will co-exist. Performance numbers showed that it may be possible to collapse them, but we don't have the time right now to do this. We will revisit this later on, time permitting.   QE notes: Jody and Brian have been helping out coordinate this change Doc notes: I updated some ASDoc examples, but more work needs to be done here Bugs: - Reviewer: Gordon Tests run: checkintests, Jody and Brian have been running tests Is noteworthy for integration: Yes  Modified Paths: -------------- <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/wireframe/src/spark/skins/wireframe/ButtonBarFirstButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/DropDownList.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/modules/compiler/src/java/flex2/compiler/fxg/FlexFXG2SWFTranscoder.java</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/Group.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/airframework/src/spark/skins/spark/SparkChromeWindowedApplicationSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/airframework/src/spark/skins/spark/WindowedApplicationSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/DefaultButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/ButtonBarLastButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/wireframe/src/spark/skins/wireframe/DefaultButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/wireframe/src/spark/skins/wireframe/ButtonBarLastButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/development/eclipse/flex/sparkTest/src/SkinTest.mxml</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/RichEditableText.png\" copyfrom-rev=\"9670\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/RichEditableText.png</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/DropDownListSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/HSliderExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/DataGroupVirtualizationExample.mxml</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/RichEditableText.png</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/RichText.png\" copyfrom-rev=\"9670\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/RichText.png</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/styles/examples/PseudoSelectorExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/effects/examples/WipeExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/modules/compiler/src/java/flex2/compiler/mxml/lang/StandardDefs.java</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/ButtonBarExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/tests/basicTests/halo/views/AccordionTests.mxml</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/RichText.png</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/effects/examples/CrossFadeExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/styles/examples/TypeClassSelectorExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/VSliderExample.mxml</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/RichEditableText.as</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/RichText.as\" copyfrom-rev=\"9670\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/RichText.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/ListExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/ButtonBarMiddleButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/ButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/wireframe/src/spark/skins/wireframe/ButtonBarMiddleButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/ToggleButtonSkin.mxml</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/primitives/examples/SimpleTextExample.mxml\" copyfrom-rev=\"9855\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/LabelExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/supportClasses/SkinnableTextBase.as</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/primitives/examples/RichEditableTextExample.mxml\" copyfrom-rev=\"9855\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/RichEditableTextExample.mxml</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/SimpleText.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/airframework/src/spark/skins/spark/windowChrome/TitleBarSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/CheckBoxExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/CheckBoxSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/core/CSSTextLayoutFormat.as</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/primitives/examples/RichTextExample.mxml\" copyfrom-rev=\"9855\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/RichTextExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/styles/examples/IDSelectorExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/RadioButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/wireframe/src/spark/skins/wireframe/RadioButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/PanelExample.mxml</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/supportClasses/RichEditableTextEditManager.as\" copyfrom-rev=\"9670\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/supportClasses/RichEditableTextEditManager.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/mediaClasses/fullScreen/ScrubBarSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/ButtonBarFirstButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/DefaultItemRenderer.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/VSliderSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/ToggleButtonExample.mxml</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/supportClasses/TextGraphicElement.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/tests/basicTests/halo/views/TabNavigatorTests.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/flash-integration/src/mx/flash/UIMovieClip.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/supportClasses/ButtonBase.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/airframework/src/spark/components/windowClasses/TitleBar.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/TextInput.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/DropDownListExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/mediaClasses/normal/ScrubBarSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/framework/src/mx/core/UITextField.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/wireframe/src/spark/skins/wireframe/DropDownListSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/spark-manifest.xml</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/supportClasses/RichEditableTextContainerManager.as\" copyfrom-rev=\"9670\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/supportClasses/RichEditableTextContainerManager.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/TextArea.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/airframework/src/spark/components/WindowedApplication.as</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/SimpleText.as\" copyfrom-rev=\"9670\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/Label.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/airframework/src/spark/components/Window.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/mustella/mustella.swc</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/supportClasses/RichEditableTextContainerManager.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/VideoPlayer.as</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/RichEditableText.as\" copyfrom-rev=\"9670\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/RichEditableText.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/framework/src/mx/core/UIComponent.as</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/SimpleText.png</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/mediaClasses/VolumeBar.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/effects/examples/AnimateTransitionShaderExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/wireframe/src/spark/skins/wireframe/ButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/Panel.as</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/RichText.as</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/SimpleText.png\" copyfrom-rev=\"9670\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/Label.png</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/wireframe/src/spark/skins/wireframe/ToggleButtonSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/effects/examples/AnimateColorEffectExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/VideoPlayerSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/framework/src/mx/styles/StyleProtoChain.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/wireframe/src/spark/skins/wireframe/VideoPlayerSkin.mxml</path> <path kind=\"file\" copyfrom-path=\"/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/supportClasses/TextGraphicElement.as\" copyfrom-rev=\"9670\" action=\"A\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/supportClasses/TextBase.as</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/primitives/examples/RichEditableTextExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/wireframe/src/spark/skins/wireframe/CheckBoxSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/GroupExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/HSliderSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/components/supportClasses/ItemRenderer.as</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/primitives/examples/RichTextExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/skins/spark/PanelSkin.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/modules/compiler/src/java/flex2/compiler/fxg/FXGCompiler.java</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/wireframe/src/spark/skins/wireframe/PanelSkin.mxml</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/primitives/examples/SimpleTextExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/components/examples/NumericStepperExample.mxml</path> <path kind=\"file\" action=\"D\">/flex/sdk/trunk/frameworks/projects/spark/src/spark/primitives/supportClasses/RichEditableTextEditManager.as</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/spark/asdoc/en_US/spark/styles/examples/DescendantSelectorExample.mxml</path> <path kind=\"file\" action=\"M\">/flex/sdk/trunk/frameworks/projects/airframework/src/spark/skins/spark/windowChrome/MacTitleBarSkin.mxml</path>", "target": 0}
{"idx": 3427, "commit_message": "- Added a new plugin called perfstat, and updated walktest so              that it could 'benefit' from its functionality. Perfstat is              basically a nested statistics gatherer which can print out              formatted results to a file. It also prints out system info              as the header. This is meant to be a tool mostly to test the              drivers. The nested bit means it will also gather              seperate statistics for a configurable 'subsection' of the              main section it is gathering statistics for.              Walktest has a max of three nested perfstats with the              recsubperf command (see below).            - Chages to walktest:               - Perfstat now takes care of fps calculations according               to user specifiable resolution. Defaults to 10 frames per               update.             - The demo playing and recording now pauses when you switch               to console             - Suitable commands are now recorded too, like fire missile,               addskel addlight etc. A couple of macros are defined in               walkcmd.cpp as a convenience.             - Modified commands:                loadrec <file> can take an optional name argument to specify a                        <file>.rec to use as its demo file, otherwise it                        defaults to 'record' as before.                 saverec <file> can take an optional name argument to specify                        a <file>.rec to save to.                 play   has optional arguments, otherwise works as before.                 play <file> This outputs summary statistics for the demo                        played to <file>.rps (Recorded Performance Statistics).                 play res, x, <file> The 'res'(olution) option tells perfstat                         to record statistics every 'x' frames and output                         to <file>.rps                 play break, x  The break option when compiled in debug mode                         will trip off a signal trap on the 'x'th frame.                         Useful once you take note of the frame number of                         something interesting in a <file>.rps             - New command:                 recsubperf <name> Once a recording has begun this command                         is used to record the statistics of a subsection                         of the demo and is reported as such in the outputted                         <file>.rps when played back. To finish the subsection                         call the command again without an argument.                         Stands for 'rec(ord)sub(section)perf(ormance)'", "target": 0}
{"idx": 2895, "commit_message": "Only update the language shown in the combo box when it has been changed by the application. This results in significant performance improvements.  svn path=/trunk/KDE/kdelibs/; revision=1010019", "target": 1}
{"idx": 3545, "commit_message": "Add real performance improvements on mobile.  Just puting stuff in a loader doesn't improve much, since the component still gets created. So, also delay component creation, not only item creation.", "target": 1}
{"idx": 3583, "commit_message": "RAT-138 RAT runs very slowly on some input Use String matching rather than building patterns This improves performance somewhat, but is still inefficient", "target": 1}
{"idx": 2456, "commit_message": "Improve GN clean command.  Previously it would detect a case where the build.ninja file was empty and write a default one to replace it. This case is rare and the existing code was broken on Windows because it used printf on a 16-bit file path. It's simpler to just issue an error in this case.  This also adds a small performance improvement by using StringPiece to split the build file (saves allocating ~16K strings).", "target": 1}
{"idx": 2400, "commit_message": "Final Polish on Quick Profiler (#555)  * Toggle for Performance Stats.    * Performance stats window comes & goes as setting is toggled.    * tweaks.    * Stopping point on Performance Stats work: piping to poll and store stats, put up buttons and viewer.    * removing some files    * Got label side of things working.    * More proper includes.  Rendering values.    * respond to review    * responded to review    * reparenting gui to core gui instead of player.    * pause    * pausing    * got parenting right so things lay on top of each other properly, parent is core gui.    * spelling mistakes    * spelling    * graph is working    * whassup    * removed waits on requires.    * responded to review from SolarCrane    * respond to review    * removing files.    * cleaning up stupid Panel3d.lua file.    * Fixmes on number formatting    * respond to review    * nicer formatting on stats    * got average working properly    * more aesthetic tweaks    * respond to review    * pause    * Added targets    * typos    * respond to review    * aesthetic tweaks    * Final polish on quick profiler v1    * untabified    * whitespace cleanup    * removed bad emacs trash file.    * Also move PlayerList so it doesn't overlap Performance Stats    * whitespace    * whitespace    * Reverting.    * changed indentation    * re-indented    * re-indented", "target": 0}
{"idx": 1803, "commit_message": "dcbnl: add appliction tlv handlers  This patch adds application tlv handlers. Networking stacks may use the application priority to set the skb priority of their stack using the negoatiated dcbx priority.  This patch provides the dcb_{get|set}app() routines for the stack to query these parameters. Notice lower layer drivers can use the dcbnl_ops routines if additional handling is needed. Perhaps in the firmware case for example", "target": 0}
{"idx": 3507, "commit_message": "Merge pull request #8873 from andrepereiradasilva/jlanguage-knowlanguages  JLanguage::parseLanguageFiles performance improvements", "target": 1}
{"idx": 1023, "commit_message": "Improved timer module  1. Added the ability to use ints as identifiers for functions, allowing you to stop currently registered functions.  2. Fixed a lot of bugs that I didn't notice. Should have tested better. Mostly related to not getting accurate time. One was a missing volatile adjective. Underflow issue. Race conditions.", "target": 0}
{"idx": 3139, "commit_message": "[hack] Implement the state traversal algorithm and output line-broken statement  Summary: Part two: Take part 1 and do something with it, see details on the algorithm here: [URL]/2015/09/08/the-hardest-program-ive-ever-written/ but the basic flow is, take the initial state generated by the builder with no bound rules, and then add it to the state_queue. While the state_queue is not empty and we haven't found a configuration without overflow, expand_state. Iterates over all unbound rules and all values of those rules and creates a new state for each, they are then added to state_queue ordered by cost. When an appropriate state is found, return it and print it.  There is a ton of performance optimizations that can be done here, and a lot of details (no indention yet) are missing but it's a start.  Differential Revision: D3928144  fbshipit-source-id: f05ead727de66e5ef1499a283623829c3dfce825", "target": 0}
{"idx": 2889, "commit_message": "Merge pull request #224 from INN/perf  Performance improvements to reduce database queries", "target": 1}
{"idx": 2194, "commit_message": "* More efficient handling of system_thread_id feature", "target": 1}
{"idx": 3214, "commit_message": "Change tundra.tn.queue:each to only check the delivery queue and scheduler status once a second to improve performance", "target": 1}
{"idx": 2410, "commit_message": "compile named query: drop of loop over runes 30% performance improvement", "target": 1}
{"idx": 3498, "commit_message": "Merge pull request #8299 from JosJuice/volumeverifier-performance  VolumeVerifier: Performance improvements", "target": 1}
{"idx": 2726, "commit_message": "Merge pull request #17216 from mantidproject/17197_LogManager_PerformanceTest_fix  Fix performance tests for LogManager and Run", "target": 0}
{"idx": 2869, "commit_message": "Fixed bug preventing android from animating.  Has the side effect that performance is slightly better overall.", "target": 1}
{"idx": 98, "commit_message": "Correct unit test for files in memory (see #382)", "target": 0}
{"idx": 1068, "commit_message": "New: support for no close button in MEscapeButtonPanel.  RevBy: Daniel d'Andrada Details: MEscapeButtonPanel can by styled so that it doesn't display the close button at all. Fade animation for back button is then applied when switching modes (instead of standard warp animation between close and back button). MEscapeButtonPanelView exposes hasCloseButton style property by creating dynamic property in MEscapeButtonPanel. It's needed for MSceneManager when calculating home/close button geometries passed to compositor. If this property is not defined, MSceneManager assumes that hasCloseButton == true.  Based on patch by Dominik Kapusta.", "target": 0}
{"idx": 3540, "commit_message": "msm: mdss: debugfs: add support to serialize wait4pingpong  For command mode panels, current code configures the HW to transfer a frame and returns the commit context without waiting for transfer to finish. As an example, after kicking off frame N transfer, commit context doesn't wait for Frame N's transfer to finish. By doing so, it allows SW to configure/queue frame (N+1) and improves the performance. But before frame (N+1) is kicked off, SW needs to make sure that frame N is finished otherwise it may lead to tearing and/or unknown behavior. This is achieved by calling wait4pingpong routine. But this optimization has a side effect when debugging critical issues. If for some reason, frame N had a bad HW configuration and it had HW hang then wait4pingpong during frame (N+1) will timeout. This timeout will lead to HW register dumps but this register dump is related frame (N+1) and not frame N. This gives incorrect debug information. To overcome this side effect, allow wait4pingpong's timing to change using debugfs. Setting this node to true will make the driver to run this processing in a synchronous way, setting it to false will return the driver to normal asynchronous operation: echo 1 > /<debugfs>/mdp/serialize_wait4pp -> sync echo 0 > /<debugfs>/mdp/serialize_wait4pp -> async (default)", "target": 1}
{"idx": 3122, "commit_message": "increase the defaults and warnings for file listing size by 10x, due to performance improvements", "target": 1}
{"idx": 1853, "commit_message": "boot:dtsi: Add the active current values in uA for the cpus in device tree.  Bug: 21498425", "target": 0}
{"idx": 72, "commit_message": "Add support for XFAILing valgrind runs with memory leak checking independently of runs without leak checking.  We add -vg to the triple for non-checked runs, or -vg_leak for checked runs.  Also use this to XFAIL the TableGen tests, since tablegen leaks like a sieve.  This includes some valgrindArgs refactoring.", "target": 0}
{"idx": 2198, "commit_message": "Added return flag to indicate if any dynamics matrices are identical, intended to be used for performance optimizations.", "target": 1}
{"idx": 2686, "commit_message": "r11769: Looking at a performance problem enumerating accounts, wondered if changing to support samr_connect5 might help so quickly coded it up. No it doesn't :-(. Don't merge this for 3.0.21 please. Jeremy. (This used to be commit bff1df678a8948d382f4555e83a1df23146a4b12)", "target": 0}
{"idx": 397, "commit_message": "crypto: cryptd - Add support to access underlaying shash  cryptd_alloc_ahash() will allocate a cryptd-ed ahash for specified algorithm name. The new allocated one is guaranteed to be cryptd-ed ahash, so the shash underlying can be gotten via cryptd_ahash_child().", "target": 0}
{"idx": 2002, "commit_message": "Commit of the NAS Parallel Benchmarks.  These are a set of 5 benchmarks designed by NASA which are representative of common Computational Fluid Dynamics (CFD) computations: CG: is a strong test for small communication (~10,000 messages of few bytes per worker) MG: is a strong test for mid-size communication (~2,500 messages (2KB-512KB) per worker) IS: is a test for data movement (sort of a very large array of integer) EP: is a strong test for floating-point performance (no communication) FT: is a test for both communication speed (few MB messages are sent) and computation performance, thanks to a Fourier Transformation.  All these benchmarks comes with different size of problems : S,W,A,B,C and D S is the easiest while D is the hardest. A reasonable size to use is C.  Example of usage: $ cd ./compile $ ./build compile.benchmarks $ cd ../scripts/unix/benchmarks $ ./nas_benchmarks.sh CG A 4", "target": 0}
{"idx": 3518, "commit_message": "[12629] Don't do periodic heal ticks if the target is already at max health.  If a target is at maximum health already periodic healing spells should not tick.  From the healer's point of view this means far less overhealing, improving their healing performance information.", "target": 0}
{"idx": 2571, "commit_message": "Merge pull request #227 from Outernet-Project/fix/performance-issues  Fix/performance issues", "target": 1}
{"idx": 3433, "commit_message": "Improves performance of UuidUtils#fromString slightly by not using Character#digit method.", "target": 1}
{"idx": 690, "commit_message": "implementing abstract methods to avoid false negatives due to dynamic dispatch issues  Reviewed By: jeremydubreil  Differential Revision: D2680252  fb-gh-sync-id: bc87bb3", "target": 0}
{"idx": 1437, "commit_message": "Improved description for intro problem 1&3", "target": 0}
{"idx": 2077, "commit_message": "Coding style improvements and optimizations  ILOptimizer: - Renamed optimization.cs to Optimization.cs - Renamed optimization class to OptimizationBase - Renamed Execute to Apply (makes more sense) - Added headers to all files - Added XML doc to all files - Updated 'MovZero' optimization for better performance  Also commented stuff for clarity. The functionality didn't change.", "target": 1}
{"idx": 1371, "commit_message": "removed extra memory requirement pragma dynamic 10000", "target": 0}
{"idx": 4022, "commit_message": "[PATCH] Fixed typo in HegstRLVar3/HegstRUVar3 and improved\n performance of Trmm and Symm for relatively small numbers of right-hand\n sides.", "target": 1}
{"idx": 2329, "commit_message": "Merge tag 'kvm-s390-20140130' of [URL]/pub/scm/linux/kernel/git/kvms390/linux into HEAD  Two new features are added by this patch set: - The floating interrupt controller (flic) that allows us to inject,   clear and inspect non-vcpu local interrupts. This also gives us an   opportunity to fix deficiencies in our existing interrupt definitions. - Support for asynchronous page faults via the pfault mechanism. Testing   show significant guest performance improvements under host swap.", "target": 1}
{"idx": 70, "commit_message": "Standardize informal treatment  and some grammar improvements (#32664)  Plus, fix colorblindness translation.", "target": 0}
{"idx": 3997, "commit_message": "[PATCH] Better workaround of g++ 4.1 optimizer bug:\n -fno-strict-aliasing. Performance penalty is 5% vs 24% with -O", "target": 1}
{"idx": 3307, "commit_message": "value operators separated from signal operators  (to improve simulator performance)", "target": 1}
{"idx": 2766, "commit_message": "* Page.cs: fixed RegisterRequiresPostBack, performance improvement  svn path=/branches/mainsoft/gh2.2/mcs/; revision=96081", "target": 1}
{"idx": 1099, "commit_message": "Major rewrite of plugin HTML. More dynamic. Lots of small fixes.", "target": 0}
{"idx": 1479, "commit_message": "Improved detection of cases where the source was not measured (due to not being on the frame) vs having zero flux.  This is mostly for difference imaging but also changes the behaviour for normal list-driven mode.  Now, this condition is detected by looking for quantities written by update, which checks if the entire rcore sized aperture is on the frame.", "target": 0}
{"idx": 1925, "commit_message": "Zul'Drak: Improvements in scripts for quest chain The Amphitheater of Anguish. Now the Korrak movement is done with escortai.  --HG-- branch : trunk", "target": 0}
{"idx": 3308, "commit_message": "Changes history_tree.h to use HistoryString rather than ToString.  Also replaces some uses of the STL with their Abseil counterparts for a drop-in performance boost.  Fixes: #449 PiperOrigin-RevId: 348029069", "target": 1}
{"idx": 969, "commit_message": "Merge pull request #504 in BIOS/core from ~E9926362/core:feature/BIOS-592-rc-script to master  * commit 'c89f241f2f31c399d1224f3bea67317f072e6dfc':   BIOS-592: ci-test-restapi.sh: it is no longer fatal to have the project not-configured   Try to ensure that sysinfo.(e)cpp depends on git_details properly   GitIgnored recently added src/web/src/asset_import.cpp   BIOS-592: ci-test-restapi.sh: ensure that a clean-workspace test is configured if needed, to compile later on   BIOS-592: weblib.sh test_web.sh: differentiate not-yet-tested, not-yet-printed, and have-been-printed results of a test_it()/print_results() test duplet; support existing .res files for renamed (e.g. temporarily disabled) test script filenames; better explain results of the tests without an expected-output file; set up test_it() logging for test scripts that forgot to use one (make an ERROR notice about this condition though)   BIOS-592: returned the empty line to end of metric_computed_average_correct.sh.res because this matces the current server output   JSON.sh: support empty documents (no token in input, empty jpath when we hit EOF) as an empty object   BIOS-592: Makefile.am : try to ensure that changes in generated git_details do cause rebuild of libpriv_git_details_override and then bios_web in this pass of the make, not in the distant future, by requesting sync after generation of these key files   BIOS-592: Makefile and tests with cppcheck improved to use a new target \"all-buildproducts\" to try and compile all binaries and libraries we have, including tests, to cover most possible warnings, etc.   BIOS-592: tests which run tntnet and implement kill_daemon now should report the exit/signal cause of completion to stderr", "target": 0}
{"idx": 1137, "commit_message": "Replace the navigation links with menus  * Create a Navigation component * Render the Navigation component for all pages from PolioScape.js * Create a NavMenu component for opening menus from the navigation bar * Refactor the menu opening / closing code out of the dropdown into   a mixin * Add a new store for managing dynamic links in the navigation * Remove margins from horizontal rules used in menus so they can be used   as separators", "target": 0}
{"idx": 1913, "commit_message": "Lower memory consumption by streaming out request data (#2848)  Prior to this change, the `UrlConnectionHttpClient` implementation of  `SdkHttpClient` would unintentionally cause **the entire `RequestBody`**  to be loaded into memory before being sent, even if the body had been  made using `software.amazon.awssdk.core.sync.RequestBody.fromInputStream()`  and thus was a stream of known content-length. Even worse, as the buffering  `ByteArrayInputStream` received the request, it would have to repeatedly  grow capacity by allocating new arrays and copying the data over, so peak  memory usage would be 1.5x the size of the request data. For instance,  streaming 1 GB of data to S3 with `putObject` would lead to a peak memory  allocation of 1.5 GB. This large allocation of memory can be avoided by  instead *streaming* the request data as it is sent.    [URL].HttpURLConnection` (the core Java class used by  `UrlConnectionHttpClient` to implement `SdkHttpClient`) supports streaming  the request, but will only do it if `setFixedLengthStreamingMode()` or  `setChunkedStreamingMode()` has been called - this is true even if the  `Content-Length` header has already been set. You can see this in the  implementation of [URL].www.protocol.http.HttpURLConnection` where  `streaming()` must be true to avoid **the whole request** being read into  a `PosterOutputStream` (a simple extension of `ByteArrayInputStream`)  before being sent:    [URL]/openjdk/jdk/blob/da75f3c4ad5bdf25167a3ed80e51f567ab3dbd01/src/java.base/share/classes/sun/net/www/protocol/http/HttpURLConnection.java#L1373-L1394    If `Content-Length` is known, we're actually free to call  `setFixedLengthStreamingMode()` on the connection to activate streaming,  the only question is where & when to do it! Unfortunately  `software.amazon.awssdk.http.urlconnection.UrlConnectionFactory`, which  provides a way for end-users of the AWS SDK to customise the creation &  configuration of the `HttpURLConnection`, _doesn't have access to the  request or it's `Content-Length`, so can't call  `setFixedLengthStreamingMode()`. In any case, this behaviour probably  _always_ makes sense, so it doesn't make sense to leave it to users to  customise it. That leaves the best place to do this being the  `createAndConfigureConnection()` method, where the newly created  `HttpURLConnection` is available and the `Content-Length` can be read if  it's present.    Consequently, I've updated `createAndConfigureConnection()` to call  `setFixedLengthStreamingMode` if the `Content-Length` is not null, which  is similar behaviour to the `ApacheHttpClient` SDK client:    [URL]/aws/aws-sdk-java-v2/pull/2848#discussion_r757703947  [URL]/aws/aws-sdk-java-v2/blob/db0b45a0cd29603a1ea95b5e5f3d243755720309/http-clients/apache-client/src/main/java/software/amazon/awssdk/http/apache/internal/impl/ApacheHttpRequestFactory.java#L139-L160    At present, the only way to workaround this issue without a change to the  AWS SDK is to create a custom `SdkHttpClient` that wraps  `UrlConnectionHttpClient` and overrides `prepareRequest()`. As the  `connection` field is not visible in the `ExecutableHttpRequest` object  (it's defined on the private  `software.amazon.awssdk.http.urlconnection.UrlConnectionHttpClient.RequestCallable`  class), it's necessary to use reflection to extract the `connection` field  before operating on it. An example of this in Scala code can be seen here:    [URL]/guardian/ophan-geoip-db-refresher/commit/e2fc370719b020178d30d5266b5363d8c2822311#diff-5780ade773d1bdf8dd5dea40283e6fec88bacdb30c20c5b39955da1faa8e3ade    Running the `ophan-geoip-db-refresher` code locally, the heap required is:    * 560 MB (`-Xmx560m`) - _without_ the workaround, request fully in memory  *  32 MB - with the workaround on, and so streaming enabled", "target": 1}
{"idx": 3862, "commit_message": "ARM: Add optimised swahb32() byteswap helper for v6 and above  ARMv6 and later processors have the REV16 instruction, which swaps the bytes within each halfword of a register value.  This is already used to implement swab16(), but since the native operation performaed by REV16 is actually swahb32(), this patch renames the existing swab16() helper accordingly and defines __arch_swab16() in terms of it.  This allows calls to both swab16() and swahb32() to be optimised.  The compiler's generated code might improve someday, but as of 4.5.2 the code generated for pure C implementing these 16-bit bytesswaps remains pessimal.  swahb32() is useful for converting 32-bit Thumb instructions between integer and memory representation on BE8 platforms (among other uses).", "target": 1}
{"idx": 4138, "commit_message": "[PATCH] issue #2389: re-adding MapSum Function fore efficient\n reduce_in/out", "target": 1}
{"idx": 1576, "commit_message": "x86/speculation/l1tf: Increase 32bit PAE __PHYSICAL_PAGE_SHIFT  L1 Terminal Fault (L1TF) is a speculation related vulnerability. The CPU speculates on PTE entries which do not have the PRESENT bit set, if the content of the resulting physical address is available in the L1D cache.  The OS side mitigation makes sure that a !PRESENT PTE entry points to a physical address outside the actually existing and cachable memory space. This is achieved by inverting the upper bits of the PTE. Due to the address space limitations this only works for 64bit and 32bit PAE kernels, but not for 32bit non PAE.  This mitigation applies to both host and guest kernels, but in case of a 64bit host (hypervisor) and a 32bit PAE guest, inverting the upper bits of the PAE address space (44bit) is not enough if the host has more than 43 bits of populated memory address space, because the speculation treats the PTE content as a physical host address bypassing EPT.  The host (hypervisor) protects itself against the guest by flushing L1D as needed, but pages inside the guest are not protected against attacks from other processes inside the same guest.  For the guest the inverted PTE mask has to match the host to provide the full protection for all pages the host could possibly map into the guest. The hosts populated address space is not known to the guest, so the mask must cover the possible maximal host address space, i.e. 52 bit.  On 32bit PAE the maximum PTE mask is currently set to 44 bit because that is the limit imposed by 32bit unsigned long PFNs in the VMs. This limits the mask to be below what the host could possible use for physical pages.  The L1TF PROT_NONE protection code uses the PTE masks to determine which bits to invert to make sure the higher bits are set for unmapped entries to prevent L1TF speculation attacks against EPT inside guests.  In order to invert all bits that could be used by the host, increase __PHYSICAL_PAGE_SHIFT to 52 to match 64bit.  The real limit for a 32bit PAE kernel is still 44 bits because all Linux PTEs are created from unsigned long PFNs, so they cannot be higher than 44 bits on a 32bit kernel. So these extra PFN bits should be never set. The only users of this macro are using it to look at PTEs, so it's safe.  [ tglx: Massaged changelog ]", "target": 0}
{"idx": 4124, "commit_message": "[PATCH] Fixed race condition in GPU restrictor.  Improved performance\n of both prolongator and restrictor using compile-time evaluated fine-spin ->\n coarse-spin mapper instead of an array.", "target": 1}
{"idx": 1885, "commit_message": "Merge pull request #56 from RemoteMetering/refactor-clientConstructors  [Refactor] improve client constructors", "target": 0}
{"idx": 3770, "commit_message": "cpufreq / powernow-k8: Remove usage of smp_processor_id() in preemptible code  BugLink: [URL]/bugs/1084539  commit e4df1cbcc1f329e53a1fff7450b2229e0addff20 upstream.  Commit 6889125b8b4e09c5e53e6ecab3433bed1ce198c9 (cpufreq/powernow-k8: workqueue user shouldn't migrate the kworker to another CPU) causes powernow-k8 to trigger a preempt warning, e.g.:    BUG: using smp_processor_id() in preemptible [00000000] code: cpufreq/3776   caller is powernowk8_target+0x20/0x49   Pid: 3776, comm: cpufreq Not tainted 3.6.0 #9   Call Trace:    [<ffffffff8125b447>] debug_smp_processor_id+0xc7/0xe0    [<ffffffff814877e7>] powernowk8_target+0x20/0x49    [<ffffffff81482b02>] __cpufreq_driver_target+0x82/0x8a    [<ffffffff81484fc6>] cpufreq_governor_performance+0x4e/0x54    [<ffffffff81482c50>] __cpufreq_governor+0x8c/0xc9    [<ffffffff81482e6f>] __cpufreq_set_policy+0x1a9/0x21e    [<ffffffff814839af>] store_scaling_governor+0x16f/0x19b    [<ffffffff81484f16>] ? cpufreq_update_policy+0x124/0x124    [<ffffffff8162b4a5>] ? _raw_spin_unlock_irqrestore+0x2c/0x49    [<ffffffff81483640>] store+0x60/0x88    [<ffffffff811708c0>] sysfs_write_file+0xf4/0x130    [<ffffffff8111243b>] vfs_write+0xb5/0x151    [<ffffffff811126e0>] sys_write+0x4a/0x71    [<ffffffff816319a9>] system_call_fastpath+0x16/0x1b  Fix this by by always using work_on_cpu().", "target": 0}
{"idx": 569, "commit_message": "evaluate.py: Improve docs and use InpytType.check", "target": 0}
{"idx": 3929, "commit_message": "unpiWithName make lambda check more efficient", "target": 1}
{"idx": 1734, "commit_message": "wl1251: make wl1251_set_partition bus agnostic  The same partition setting code can be used for both SPI and SDIO modes, if we remove the spi-specific commands and use the more generic buffer write routines.  Do that and move it to io.c since it deals with register/memory address offsets.", "target": 0}
{"idx": 3549, "commit_message": "mem: Introduce a variable for the retrying port  This patch introduces a variable to keep track of the retrying port instead of relying on it being the front of the retryList.  Besides the improvement in readability, this patch is a step towards separating out the two cases where a port is waiting for the bus to be free, and where the forwarding did not succeed and the bus is waiting for a retry to pass on to the original initiator of the transaction.  The changes made are currently such that the regressions are not affected. This is ensured by always prioritizing the currently retrying port and putting it back at the front of the retry list.", "target": 0}
{"idx": 3596, "commit_message": "Refactored js script to be more efficient", "target": 1}
{"idx": 1543, "commit_message": "added some diagnostic output to find high cpu load (-d1)", "target": 0}
{"idx": 3805, "commit_message": "Synchronize RCTImageLoader loaders initialization  Summary: The method `imageURLLoaderForURL` can be called from multiple threads. This adds a mutex to make sure that _loaders is initialized with a non-nil value only once.  We'll only lock this mutex at one point in time as long as `_loadersProvider()` gives a value, so the mutex doesn't affect performance.  Changelog: [iOS][Fixed] Synchronize RCTImageLoader loaders initialization  Reviewed By: fkgozali  Differential Revision: D24513083  fbshipit-source-id: b89ef8a82729eda508162b01f7fdaa8a291f40d0", "target": 0}
{"idx": 2937, "commit_message": "obslist: Cache taxonic icons for performance  The old implementation used a large if-else. Java can specifically optimize a large string switch statement, because it uses object.hashcode to make it a hash lookup of time O(log(n)) vs a string lookup of O(n). After I did this, I saw we were still spending time in setImageResource just decoding the bitmaps directly on the UI thread. It's only a minor performance lag to the UI thread, but 1) as we use these icons massively when scrolling this list, 2) they are tiny in total size e.g. 10KB, and 3) every ms counts on the UI thread because we are already dropping frames. All this considered, I decided to trade CPU time for memory. We now lazily load the taxon icon images into memory, and hold them in the static memory. THis somewhat defeats the switch because we only actually run that code ~10 times now (once for each taxon icon), but I had already written it and it's objectively faster so I left it in.  Overall these improvements only give a small performance bump, less than 0.5ms on the UI thread. So nothing to write home about, but I will take it as that's 0.5ms we can spend doing other stuff before dropping a frame (and it might be more than 0.5 on a slower device)", "target": 1}
{"idx": 3803, "commit_message": "[helpers] improve performance of ui color helpers", "target": 1}
{"idx": 2629, "commit_message": "Update perf expectations for improved perf tests.  A number of performance tests which are giving improved results have out of date performance expectations. Update them so that future regressions are detected.  BUG=186843 [URL] NOTRY=True   Review URL: [URL]/12780004", "target": 0}
{"idx": 2144, "commit_message": "Improved performance of love.graphics.present slightly on some platforms", "target": 1}
{"idx": 1103, "commit_message": "NaCl: Update revision in DEPS, r9066 -> r9086  This pulls in the following Native Client changes:  r9067: (eaeltsin) Debug stub: refactor interfaces for testing with GDB r9068: (bradnelson) Revert 9066 - Build gdb on newlib bots. r9069: (kschimpf) Refactor decoder tests to apply test pattern parse preconditions before r9070: (kschimpf) Fix bug where ncval (i.e. detailed reporting) did not correctly report r9071: (dschuff) Prepend gtest to link line in gtest environment r9072: (mcgrathr) Update binutils and newlib in tools/REVISIONS r9073: (mcgrathr) Add test for x86-64 glibc bswap_64 bug r9074: (bradchen) Make ud2 a legal instruction, to be used like HLT. r9075: (mcgrathr) Update glibc revision r9076: (mcgrathr) Remove fixed tests from glibc-tests XFAIL list r9077: (arbenson) Small style changes to handle_r_debug r9078: (eaeltsin) Debug stub: improve GDB tests using parsed GDB/MI output records r9079: (mcgrathr) Don't check alignment of call instructions in x86-32 validator r9080: (mcgrathr) Update x86 toolchain r9082: (mcgrathr) Make syscalls round up misaligned return address to next bundle r9083: (mseaborn) Move Mac OS X outer sandbox initialisation into sel_main.c r9084: (mcgrathr) Use 'naclret' macro in x86 assembly code r9085: (arbenson) Handle at-zero arg in nacl_bootstrap r9086: (bradchen) Fix a few license issues.  BUG=none TEST=nacl_integration   Review URL: [URL]/10700097", "target": 0}
{"idx": 140, "commit_message": "Pass dynamic link in Calendar to a relative one. Closes #36.", "target": 0}
{"idx": 3637, "commit_message": "[Qt][WK2] Add basic support for panning gestures to the QTouchWebView [URL]/show_bug.cgi?id=64105  Patch by Benjamin Poulain [URL]> on 2011-07-08 Reviewed by Kenneth Rohde Christiansen.  This patch adds basic support for the panning gesture on the UI process side.  The events coming back from the WebProcess are processed through the QtPanGestureRecognizer to recognize the pan gesture. When the gesture is recognized, the actions are performed on the view through the TouchViewInterface.  Currently, the viewport just move the page around without limit. This will be improved when a physics engine is integrated.  * UIProcess/API/qt/qtouchwebview.cpp: (QTouchWebViewPrivate::scroll): * UIProcess/API/qt/qtouchwebview.h: * UIProcess/API/qt/qtouchwebview_p.h: * UIProcess/qt/QtPanGestureRecognizer.cpp: Added. (WebKit::QtPanGestureRecognizer::QtPanGestureRecognizer): (WebKit::QtPanGestureRecognizer::recognize): (WebKit::QtPanGestureRecognizer::reset): * UIProcess/qt/QtPanGestureRecognizer.h: Added. * UIProcess/qt/TouchViewInterface.cpp: (WebKit::TouchViewInterface::panGestureStarted): (WebKit::TouchViewInterface::panGestureRequestScroll): (WebKit::TouchViewInterface::panGestureEnded): (WebKit::TouchViewInterface::panGestureCancelled): * UIProcess/qt/TouchViewInterface.h: * UIProcess/qt/qtouchwebpageproxy.cpp: (QTouchWebPageProxy::QTouchWebPageProxy): (QTouchWebPageProxy::processDidCrash): (QTouchWebPageProxy::doneWithTouchEvent): * UIProcess/qt/qtouchwebpageproxy.h: * WebKit2.pro:", "target": 0}
{"idx": 2624, "commit_message": "LANG-877: Performance improvements for StringEscapeUtils. This fixes #49 from github. Thanks to Fabian Lange.", "target": 1}
{"idx": 3872, "commit_message": "Tracking development changes:  - Wrote unit tests for the timestepper and dump file modules in the linear   solver - Changed the complete linear solver to only use ArrayFire. This change   improves performance in addition to resolving conflicts between numpy   and ArrayFire in the segments of code common to both the solvers. - Wrote the solvers which will be used to evolve systems with EM fields. - Made changes to allow for additional terms in A_p as well", "target": 1}
{"idx": 3225, "commit_message": "ALSA: HDA: Lessen CPU usage when waiting for chip to respond  commit 32cf4023e689ad5b3a81a749d8cc99d7f184cb99 upstream.  When an IRQ for some reason gets lost, we wait up to a second using udelay, which is CPU intensive. This patch improves the situation by waiting about 30 ms in the CPU intensive mode, then stepping down to using msleep(2) instead. In essence, we trade some granularity in exchange for less CPU consumption when the waiting time is a bit longer.  As a result, PulseAudio should no longer be killed by the kernel for taking up to much RT-prio CPU time. At least not for *this* reason.", "target": 1}
{"idx": 254, "commit_message": "power: pm8921-bms: Update the FCC learning algorithm  1. Add configurable parameters to \t- enable/disable fcc learning \t- minimum soc to start FCC learning \t- minimum ocv (pc) to start FCC learning \t- minimum cycles to update fcc vs temp. table  2. New FCC is calculated using the cc count- \tFCC_NEW = (cc_end - cc_start) / (soc2 - soc1) \tcc_end = CC count when charing ends \tcc_start = CC count when charging starts \tsoc1, soc2 = starting and ending SOC_rbatt value  3. Add a new sysfs entries to update the learnt fcc values    to userspace. These values are restored back on    reboot.  CRs-Fixed: 417288", "target": 0}
{"idx": 3820, "commit_message": "Optimize loading cache using highest protocol pickle  The current highest protocol 4 results in about ~25% smaller files for large models. Using timeit, the parsing is about ~10% faster, when both pickles are paged into memory. If the pickle is not yet loaded in memory, the reduced filesize will increase the speedup to ~30%.", "target": 1}
{"idx": 3661, "commit_message": "ui: switch UI to use track id instead of ref/ref_type  This CL changes the UI to consistently use track_id instead of ref/ref_type when making queries on the counter tables.  This improves the performance of the worst performing tracks (the cpu frequency track) by 2.5-3x (from 250-300ms to 100-150ms).", "target": 1}
{"idx": 975, "commit_message": "mm, vmscan: prevent kswapd livelock due to pfmemalloc-throttled process being killed  commit 9e5e3661727eaf960d3480213f8e87c8d67b6956 upstream.  Charles Shirron and Paul Cassella from Cray Inc have reported kswapd stuck in a busy loop with nothing left to balance, but kswapd_try_to_sleep() failing to sleep.  Their analysis found the cause to be a combination of several factors:  1. A process is waiting in throttle_direct_reclaim() on pgdat->pfmemalloc_wait  2. The process has been killed (by OOM in this case), but has not yet been    scheduled to remove itself from the waitqueue and die.  3. kswapd checks for throttled processes in prepare_kswapd_sleep():          if (waitqueue_active(&pgdat->pfmemalloc_wait)) {                 wake_up(&pgdat->pfmemalloc_wait); \t\treturn false; // kswapd will not go to sleep \t}     However, for a process that was already killed, wake_up() does not remove    the process from the waitqueue, since try_to_wake_up() checks its state    first and returns false when the process is no longer waiting.  4. kswapd is running on the same CPU as the only CPU that the process is    allowed to run on (through cpus_allowed, or possibly single-cpu system).  5. CONFIG_PREEMPT_NONE=y kernel is used. If there's nothing to balance, kswapd    encounters no voluntary preemption points and repeatedly fails    prepare_kswapd_sleep(), blocking the process from running and removing    itself from the waitqueue, which would let kswapd sleep.  So, the source of the problem is that we prevent kswapd from going to sleep until there are processes waiting on the pfmemalloc_wait queue, and a process waiting on a queue is guaranteed to be removed from the queue only when it gets scheduled.  This was done to make sure that no process is left sleeping on pfmemalloc_wait when kswapd itself goes to sleep.  However, it isn't necessary to postpone kswapd sleep until the pfmemalloc_wait queue actually empties.  To prevent processes from being left sleeping, it's actually enough to guarantee that all processes waiting on pfmemalloc_wait queue have been woken up by the time we put kswapd to sleep.  This patch therefore fixes this issue by substituting 'wake_up' with 'wake_up_all' and removing 'return false' in the code snippet from prepare_kswapd_sleep() above.  Note that if any process puts itself in the queue after this waitqueue_active() check, or after the wake up itself, it means that the process will also wake up kswapd - and since we are under prepare_to_wait(), the wake up won't be missed.  Also we update the comment prepare_kswapd_sleep() to hopefully more clearly describe the races it is preventing.  Fixes: 5515061d22f0 (\"mm: throttle direct reclaimers if PF_MEMALLOC reserves are low and swap is backed by network storage\")", "target": 0}
{"idx": 2059, "commit_message": "Performance improvements by David Bertoni (jira# 1343)", "target": 1}
{"idx": 3728, "commit_message": "lowmemorykiller: adapt to vmpressure  There were issues reported, where page cache thrashing was observed because of LMK not killing tasks when required, resulting in sluggishness and higher app launch latency. LMK does not kill a task for the following reasons. 1. The free and file pages are above the LMK thresholds 2. LMK tries to pick task with an adj level corresponding to current thresholds, but fails to do so because of the absence of tasks in that level. But sometimes it is better to kill a lower adj task, than thrashing. And there are cases where the number of file pages are huge, though we dont thrash, the reclaim process becomes time consuming, since LMK triggers will be delayed because of higher number of file pages. Even in such cases, when reclaim path finds it difficult to reclaim pages, it is better to trigger lmk to free up some memory faster.  The basic idea here is to make LMK more aggressive dynamically when such a thrashing scenario is detected.  To detect thrashing, this patch uses vmpressure events. The values of vmpressure upon which an action has to be taken, was derived empirically.  This patch also adds tracepoints to validate this feature, almk_shrink and almk_vmpressure.  Two knobs are available for the user to tune adaptive lmk behaviour.  /sys/module/lowmemorykiller/parameters/adaptive_lmk - Write 1 to enable the feature, 0 to disable. By default disabled.  /sys/module/lowmemorykiller/parameters/vmpressure_file_min - This parameter controls the behaviour of LMK when vmpressure is in the range of 90-94. Adaptive lmk triggers based on number file pages wrt vmpressure_file_min, when vmpressure is in the range of 90-94. Usually this is a pseudo minfree value, higher than the highest configured value in minfree array.", "target": 1}
{"idx": 2550, "commit_message": "[ARM] msm: kgsl: Disable shadow writes  The use of this freature currently has some known instabilities and does not actually provide a measurable performance improvement.", "target": 0}
{"idx": 2376, "commit_message": "It is redundant to call syncThreads if the number of threads in a block is equal to the size of wavefront. (#1560)  * It is redundant to call syncThreads if the number of threads in a block is equal to the size of wavefront.    * The sync statment is redundant if the number of threads in workgroup is equal to the size of wavefront. However, the performance was poor on MI100. It is caused by the old rocm compiler 4.3. This issue is fixed in a new version like rocm 5.2.    * Replace != sign with > sign as per Koji's suggestion.    * Add comments used in KernelWriteAssembly.py.    * Remove unncessary 'self.indent'.", "target": 0}
{"idx": 2402, "commit_message": "mm: don't use compound_head() in virt_to_head_page()  compound_head() is implemented with assumption that there would be race condition when checking tail flag.  This assumption is only true when we try to access arbitrary positioned struct page.  The situation that virt_to_head_page() is called is different case.  We call virt_to_head_page() only in the range of allocated pages, so there is no race condition on tail flag.  In this case, we don't need to handle race condition and we can reduce overhead slightly.  This patch implements compound_head_fast() which is similar with compound_head() except tail flag race handling.  And then, virt_to_head_page() uses this optimized function to improve performance.  I saw 1.8% win in a fast-path loop over kmem_cache_alloc/free, (14.063 ns -> 13.810 ns) if target object is on tail page.", "target": 1}
{"idx": 3579, "commit_message": "STCOR-520 use == for efficient field-match queries (#1022)  Favor `==` over `=` in queries. This allows field-match queries to   use a more efficient b-tree index than the full-text index used   for `adj` matching when querying with `=`.    Refs STCOR-520", "target": 1}
{"idx": 3878, "commit_message": "examples/ip_pipeline: fix performance with default config  In TM, the read size should be lesser than the write size to improve performance. This enables the TM ports to push maximum packets to the output port.  This fix changes the burst_read value from 64 to 24 in default_tm_params.", "target": 1}
{"idx": 3007, "commit_message": "Release Notes:  Version 2.0 features:  * Newest gradle build system version * Better performance * Disabled horizontal orientation * Improvements and bug fixes", "target": 1}
{"idx": 2386, "commit_message": "performance improvement for the _XMPF_unpack_transpose_vector routine.", "target": 1}
{"idx": 800, "commit_message": "Fix a memory leak in AbstractCompositeByteBufTest", "target": 0}
{"idx": 3276, "commit_message": "Bugfixes  - improved message fetching code - replaced .ToChunks method with simpler and faster code", "target": 1}
{"idx": 3915, "commit_message": "eal/arm64: optimize memcpy  This patch provides an option to do rte_memcpy() using 'restrict' qualifier, which can induce GCC to do optimizations by using more efficient instructions, providing some performance gain over memcpy() on some ARM64 platforms/enviroments.  The memory copy performance differs between different ARM64 platforms. And a more recent glibc (e.g. 2.23 or later) can provide a better memcpy() performance compared to old glibc versions. It's always suggested to use a more recent glibc if possible, from which the entire system can get benefit. If for some reason an old glibc has to be used, this patch is provided for an alternative.  This implementation can improve memory copy on some ARM64 platforms, when an old glibc (e.g. 2.19, 2.17...) is being used. It is disabled by default and needs \"RTE_ARCH_ARM64_MEMCPY\" defined to activate. It's not always proving better performance than memcpy() so users need to run DPDK unit test \"memcpy_perf_autotest\" and customize parameters in \"customization section\" in rte_memcpy_64.h for best performance.  Compiler version will also impact the rte_memcpy() performance. It's observed on some platforms and with the same code, GCC 7.2.0 compiled binary can provide better performance than GCC 4.8.5. It's suggested to use GCC 5.4.0 or later.", "target": 1}
{"idx": 3330, "commit_message": "2014-07-30  Thomas Quinot  [URL]>  \t* sem.ads (Scope_Table_Entry): New component Locked_Shared_Objects. \t* sem_ch8.adb (Push_Scope): Initialize Locked_Shared_Objects. \t* exp_smem.adb (Add_Shared_Var_Lock_Procs): Handle the case where \tthe call returns an unconstrained type: in this case there is \talready a transient scope, and we should not establish a new one. \t* exp_ch7.adb (Insert_Actions_In_Scope_Around): New formal Clean. If \tTrue, also insert cleanup actions in the tree. \t(Wrap_Transient_Declaration): Call Insert_Actions_In_Scope_Around \twith Clean set True.  2014-07-30  Arnaud Charlet  [URL]>  \t* s-taskin.ads (Direct_Index, Direct_Index_Range, \tDirect_Attribute_Element, Direct_Attribute_Array, \tDirect_Index_Vector, Direct_Attributes, Is_Defined, \tIndirect_Attributes): Removed.\t(Atomic_Address, \tAttribute_Array, Attributes): New. \t* s-tasini.ads, s-tasini.adb (Proc_T, Initialize_Attributes, \tFinalize_Attributes_Link, Initialize_Attributes_Link): Removed. \t(Finalize_Attributes): Reimplement. \t* s-tassta.adb (Create_Task): Remove call to \tInitialize_Attributes_Link (Free_Task, Vulnerable_Free_Task): \tReplace Finalize_Attributes_Link by Finalize_Attributes. \t* a-tasatt.ads, a-tasatt.adb, s-tataat.ads, s-tataat.adb: \tReimplement from scratch, using a simpler and more efficient \timplementation. \t* s-tporft.adb (Register_Foreign_Thread): Remove now obsolete comment. \t* s-parame.ads, s-parame-hpux.ads, \t* s-parame-vms-alpha.ads, s-parame-vms-ia64.ads, \t* s-parame-vxworks.ads (Max_Attribute_Count): New, replace \tDefault_Attribute_Count.", "target": 1}
{"idx": 3461, "commit_message": "Merge #13194: Remove template matching and pseudo opcodes  c814e2e7e81fd01fcb07f4a28435741bdc463801 Remove template matching and pseudo opcodes (Pieter Wuille)  Pull request description:    The current code contains a rather complex script template matching engine, which is only used for 3 particular script types (P2PK, P2PKH, multisig). The first two of these are trivial to match for otherwise, and a specialized matcher for multisig is both more compact and more efficient than a generic one.    The goal is being more flexible, so that for example larger standard multisigs inside SegWit outputs are easier to implement.    As a side-effect, it also gets rid of the pseudo opcodes hack.  Tree-SHA512: 643b409c5c36821519f613a43efd399af0ec99b6131f35cd4024decfb2d483d719e0e921cd088bc9832a7ac797cb4a6b1158b8574c82f7fbebb75f1b31b359df", "target": 0}
{"idx": 3054, "commit_message": "TASK2.0: Job scheduling core pipeline fixes  Task Framework 2.0 had stability issues and race conditions that weren't being handled correctly. Also, integration with RuntimeJobDag had some loopholes that needed to be fixed. This diff includes such fixes and improvements that makes it really show performance gains and cuts down on redundant computation. Changelist: 1. Race condition when a job is enqueued, only the new JobConfig is updated and not the DAG     Add a two-way selective update which ensures consistency between JobConfigs and parent DAGs 2. Moved where getNextJob() is called in scheduleJobs() in WorkflowDispatcher     This ensures that once a RuntimeJobDag is rebuilt, update for jobs happens in one pipeline run, which removes any extra delay or slowness 3. Race condition where the job you got from getNextJob is for some reason not schedulable     This is due to deleting and enqueuing a job of the same name     RuntimeJobDag has the old job name, which conflicts with the dependency in the new DAG     This fixes the test: TestTaskRebalancerStopResume so that it does not enqueue a job of the same name 4. JobRebalancer was throwing an NPE when calling processJobStatusUpdateAndAssignment()     This was sometimes making the Controller hang     Added a null check for JobConfig (job could have been deleted/purged) 5. Fix bug with isWorkflowStopped     TargetState comparison was done in the opposite way     This fixes the test: TestRecurringJobQueue's testDeletingRecurrentQueueWithHistory()     Sometimes contexts do not get deleted cleanly but this does not affect correctness 6. Add TestEnqueueJobs 7. Fix unstable TestGetLastScheduledTaskExecInfo 8. Other minor style fixes", "target": 1}
{"idx": 2672, "commit_message": "Btrfs: fix list transaction->pending_ordered corruption  commit d3efe08400317888f559bbedf0e42cd31575d0ef upstream.  When we call btrfs_commit_transaction(), we splice the list \"ordered\" of our transaction handle into the transaction's \"pending_ordered\" list, but we don't re-initialize the \"ordered\" list of our transaction handle, this means it still points to the same elements it used to before the splice. Then we check if the current transaction's state is >= TRANS_STATE_COMMIT_START and if it is we end up calling btrfs_end_transaction() which simply splices again the \"ordered\" list of our handle into the transaction's \"pending_ordered\" list, leaving multiple pointers to the same ordered extents which results in list corruption when we are iterating, removing and freeing ordered extents at btrfs_wait_pending_ordered(), resulting in access to dangling pointers / use-after-free issues. Similarly, btrfs_end_transaction() can end up in some cases calling btrfs_commit_transaction(), and both did a list splice of the transaction handle's \"ordered\" list into the transaction's \"pending_ordered\" without re-initializing the handle's \"ordered\" list, resulting in exactly the same problem.  This produces the following warning on a kernel with linked list debugging enabled:  [109749.265416] ------------[ cut here ]------------ [109749.266410] WARNING: CPU: 7 PID: 324 at lib/list_debug.c:59 __list_del_entry+0x5a/0x98() [109749.267969] list_del corruption. prev->next should be ffff8800ba087e20, but was fffffff8c1f7c35d (...) [109749.287505] Call Trace: [109749.288135]  [<ffffffff8145f077>] dump_stack+0x4f/0x7b [109749.298080]  [<ffffffff81095de5>] ? console_unlock+0x356/0x3a2 [109749.331605]  [<ffffffff8104b3b0>] warn_slowpath_common+0xa1/0xbb [109749.334849]  [<ffffffff81260642>] ? __list_del_entry+0x5a/0x98 [109749.337093]  [<ffffffff8104b410>] warn_slowpath_fmt+0x46/0x48 [109749.337847]  [<ffffffff81260642>] __list_del_entry+0x5a/0x98 [109749.338678]  [<ffffffffa053e8bf>] btrfs_wait_pending_ordered+0x46/0xdb [btrfs] [109749.340145]  [<ffffffffa058a65f>] ? __btrfs_run_delayed_items+0x149/0x163 [btrfs] [109749.348313]  [<ffffffffa054077d>] btrfs_commit_transaction+0x36b/0xa10 [btrfs] [109749.349745]  [<ffffffff81087310>] ? trace_hardirqs_on+0xd/0xf [109749.350819]  [<ffffffffa055370d>] btrfs_sync_file+0x36f/0x3fc [btrfs] [109749.351976]  [<ffffffff8118ec98>] vfs_fsync_range+0x8f/0x9e [109749.360341]  [<ffffffff8118ecc3>] vfs_fsync+0x1c/0x1e [109749.368828]  [<ffffffff8118ee1d>] do_fsync+0x34/0x4e [109749.369790]  [<ffffffff8118f045>] SyS_fsync+0x10/0x14 [109749.370925]  [<ffffffff81465197>] system_call_fastpath+0x12/0x6f [109749.382274] ---[ end trace 48e0d07f7c03d95a ]---  On a non-debug kernel this leads to invalid memory accesses, causing a crash. Fix this by using list_splice_init() instead of list_splice() in btrfs_commit_transaction() and btrfs_end_transaction().  Fixes: 50d9aa99bd35 (\"Btrfs: make sure logged extents complete in the current transaction V3", "target": 0}
{"idx": 558, "commit_message": "Add badges to readme; improve template for generated php migrations", "target": 0}
{"idx": 3013, "commit_message": "#5877: improve performance of repeated open statements on the same module (most useful for local opens).", "target": 1}
{"idx": 1815, "commit_message": "Add support for dynamic attendance.  E.g. 1 class meets 14 weeks. 1 class meets 15.", "target": 0}
{"idx": 2556, "commit_message": "Merge pull request #13 from asiekierka/1.10.x  Optimize doesClassImplement performance by caching", "target": 1}
{"idx": 1624, "commit_message": "s3: Use low level API for saving files      benchmark                        old ns/op       new ns/op       delta     BenchmarkBackendMinio/Save-4     184482294       40663344        -77.96%     BenchmarkBackendS3/Save-4        35030825568     54475455819     +55.51%      benchmark                        old MB/s     new MB/s     speedup     BenchmarkBackendMinio/Save-4     90.95        412.64       4.54x     BenchmarkBackendS3/Save-4        0.48         0.31         0.65x      benchmark                        old allocs     new allocs     delta     BenchmarkBackendMinio/Save-4     631            560            -11.25%     BenchmarkBackendS3/Save-4        646            584            -9.60%      benchmark                        old bytes     new bytes     delta     BenchmarkBackendMinio/Save-4     66818060      50735         -99.92%     BenchmarkBackendS3/Save-4        66834000      73024         -99.89%", "target": 1}
{"idx": 1024, "commit_message": "Added Multiboot video structure, fixed a few codes that could cause issues with CPUID", "target": 0}
{"idx": 985, "commit_message": "fixing spns for non-dynamic ported named instances", "target": 0}
{"idx": 1848, "commit_message": "2012-01-27  Tom de Vries  [URL]>  \tPR tree-optimization/51990 \t* gcc.dg/pr51990.c: New test. \t* gcc.dg/pr51990-2.c: Same.", "target": 0}
{"idx": 3814, "commit_message": "MISC: More performance/structure improvements.  Eliminated vD. And faster too.", "target": 1}
{"idx": 880, "commit_message": "Improvements to delete videos by long press  - LEARNER-1288 - SnackBar's visibility time increased to 5000 milliseconds - Allow whole row long tap if its downloaded i.e. make downloaded state icon non-clickable - Fix crash where SnackBar's dismiss callback gets called twice when it is about to dismiss and the activity finishes", "target": 0}
{"idx": 3078, "commit_message": "Merge #5354  5354: Add opt-in mimalloc feature r=matklad a=ivan  This adds a `mimalloc` feature to use [URL]/microsoft/mimalloc) via [URL]/purpleprotocol/mimalloc_rust), and a corresponding `cargo xtask install --server --mimalloc`.    In my tests on Linux, mimalloc seems to run consistently faster than jemalloc and uses only slightly more memory in `analysis-stats` on chalk. Also, builds with mimalloc produce a binary 3MB smaller than builds with jemalloc.    A summary of `env time -v cargo run --release -p rust-analyzer -- analysis-stats ../chalk/` runs on NixOS master on an Intel 4790K in VMware Workstation:    <table>  <tr>  <td></td><td>self-reported time</td><td>elapsed time</td><td>max RSS</td>  </tr>  <tr><td>glibc 2.30 run 1</td><td>225.1 sec</td><td>3:46.91</td><td>1075208</td></tr>  <tr><td>glibc 2.30 run 2</td><td>228.4 sec</td><td>3:50.13</td><td>1074996</td></tr>  <tr><td>jemalloc run 1</td><td>201.8 sec</td><td>3:23.03</td><td>1055960</td></tr>  <tr><td>jemalloc run 2</td><td>199.2 sec</td><td>3:20.41</td><td>1065040</td></tr>  <tr><td>mimalloc run 1</td><td>188.6 sec</td><td>3:09.77</td><td>1105584</td></tr>  <tr><td>mimalloc run 2</td><td>185.0 sec</td><td>3:06.23</td><td>1108132</td></tr>  <tr><td>mimalloc + lto run 1</td><td>160.7 sec</td><td>2:41.80</td><td>1106076</td></tr>  <tr><td>mimalloc + lto run 2</td><td>162.2 sec</td><td>2:43.31</td><td>1104268</td></tr>  </tr>  </table>    I included an `lto = true; codegen-units = 1` run out of curiosity, this PR doesn't enable it.    <details>  <summary>analysis-stats benchmark runs</summary>    ## default    ```  # env time -v cargo run --release -p rust-analyzer -- analysis-stats ../chalk/      Finished release [optimized] target(s) in 0.10s       Running `target/release/rust-analyzer analysis-stats ../chalk/`  [ERROR ra_project_model] cyclic dependency chalk-integration -> chalk-engine  [ERROR ra_project_model] cyclic dependency chalk-recursive -> chalk-integration  [ERROR ra_project_model] cyclic dependency chalk-solve -> chalk-integration  Database loaded 333.880345ms  Crates in this dir: 11  Total modules found: 159  Total declarations: 2631  Total functions: 1947  Item Collection: 10.176299461s, 0b allocated 0b resident  Total expressions: 57094  Expressions of unknown type: 2938 (5%)  Expressions of partially unknown type: 2427 (4%)  Type mismatches: 232  Inference: 214.968806927s, 0b allocated 0b resident  Total: 225.145114417s, 0b allocated 0b resident          Command being timed: \"cargo run --release -p rust-analyzer -- analysis-stats ../chalk/\"          User time (seconds): 225.34          System time (seconds): 1.49          Percent of CPU this job got: 99%          Elapsed (wall clock) time (h:mm:ss or m:ss): 3:46.91          Average shared text size (kbytes): 0          Average unshared data size (kbytes): 0          Average stack size (kbytes): 0          Average total size (kbytes): 0          Maximum resident set size (kbytes): 1075208          Average resident set size (kbytes): 0          Major (requiring I/O) page faults: 6          Minor (reclaiming a frame) page faults: 294711          Voluntary context switches: 365          Involuntary context switches: 3273          Swaps: 0          File system inputs: 2904          File system outputs: 0          Socket messages sent: 0          Socket messages received: 0          Signals delivered: 0          Page size (bytes): 4096          Exit status: 0  # env time -v cargo run --release -p rust-analyzer -- analysis-stats ../chalk/      Finished release [optimized] target(s) in 0.10s       Running `target/release/rust-analyzer analysis-stats ../chalk/`  [ERROR ra_project_model] cyclic dependency chalk-integration -> chalk-engine  [ERROR ra_project_model] cyclic dependency chalk-recursive -> chalk-integration  [ERROR ra_project_model] cyclic dependency chalk-solve -> chalk-integration  Database loaded 332.711598ms  Crates in this dir: 11  Total modules found: 159  Total declarations: 2631  Total functions: 1947  Item Collection: 9.895020518s, 0b allocated 0b resident  Total expressions: 57094  Expressions of unknown type: 2938 (5%)  Expressions of partially unknown type: 2427 (4%)  Type mismatches: 232  Inference: 218.5001697s, 0b allocated 0b resident  Total: 228.39519833s, 0b allocated 0b resident          Command being timed: \"cargo run --release -p rust-analyzer -- analysis-stats ../chalk/\"          User time (seconds): 228.26          System time (seconds): 1.75          Percent of CPU this job got: 99%          Elapsed (wall clock) time (h:mm:ss or m:ss): 3:50.13          Average shared text size (kbytes): 0          Average unshared data size (kbytes): 0          Average stack size (kbytes): 0          Average total size (kbytes): 0          Maximum resident set size (kbytes): 1074996          Average resident set size (kbytes): 0          Major (requiring I/O) page faults: 9          Minor (reclaiming a frame) page faults: 294748          Voluntary context switches: 330          Involuntary context switches: 1561          Swaps: 0          File system inputs: 12608          File system outputs: 0          Socket messages sent: 0          Socket messages received: 0          Signals delivered: 0          Page size (bytes): 4096          Exit status: 0  ```    ## jemalloc  ```  # env time -v cargo run --release -p rust-analyzer -- analysis-stats ../chalk/      Finished release [optimized] target(s) in 0.11s       Running `target/release/rust-analyzer analysis-stats ../chalk/`  [ERROR ra_project_model] cyclic dependency chalk-integration -> chalk-engine  [ERROR ra_project_model] cyclic dependency chalk-recursive -> chalk-integration  [ERROR ra_project_model] cyclic dependency chalk-solve -> chalk-integration  Database loaded 356.090374ms  Crates in this dir: 11  Total modules found: 159  Total declarations: 2631  Total functions: 1947  Item Collection: 10.176550183s, 439mb allocated 465mb resident  Total expressions: 57094  Expressions of unknown type: 2938 (5%)  Expressions of partially unknown type: 2427 (4%)  Type mismatches: 232  Inference: 191.607201827s, 993mb allocated 1036mb resident  Total: 201.783937913s, 993mb allocated 1036mb resident          Command being timed: \"cargo run --release -p rust-analyzer -- analysis-stats ../chalk/\"          User time (seconds): 201.07          System time (seconds): 1.89          Percent of CPU this job got: 99%          Elapsed (wall clock) time (h:mm:ss or m:ss): 3:23.03          Average shared text size (kbytes): 0          Average unshared data size (kbytes): 0          Average stack size (kbytes): 0          Average total size (kbytes): 0          Maximum resident set size (kbytes): 1055960          Average resident set size (kbytes): 0          Major (requiring I/O) page faults: 0          Minor (reclaiming a frame) page faults: 357755          Voluntary context switches: 240          Involuntary context switches: 1889          Swaps: 0          File system inputs: 256          File system outputs: 0          Socket messages sent: 0          Socket messages received: 0          Signals delivered: 0          Page size (bytes): 4096          Exit status: 0  # env time -v cargo run --release -p rust-analyzer -- analysis-stats ../chalk/      Finished release [optimized] target(s) in 0.10s       Running `target/release/rust-analyzer analysis-stats ../chalk/`  [ERROR ra_project_model] cyclic dependency chalk-integration -> chalk-engine  [ERROR ra_project_model] cyclic dependency chalk-recursive -> chalk-integration  [ERROR ra_project_model] cyclic dependency chalk-solve -> chalk-integration  Database loaded 317.917622ms  Crates in this dir: 11  Total modules found: 159  Total declarations: 2631  Total functions: 1947  Item Collection: 9.902142185s, 439mb allocated 463mb resident  Total expressions: 57094  Expressions of unknown type: 2938 (5%)  Expressions of partially unknown type: 2427 (4%)  Type mismatches: 232  Inference: 189.295317017s, 993mb allocated 1046mb resident  Total: 199.197555943s, 993mb allocated 1046mb resident          Command being timed: \"cargo run --release -p rust-analyzer -- analysis-stats ../chalk/\"          User time (seconds): 198.64          System time (seconds): 1.67          Percent of CPU this job got: 99%          Elapsed (wall clock) time (h:mm:ss or m:ss): 3:20.41          Average shared text size (kbytes): 0          Average unshared data size (kbytes): 0          Average stack size (kbytes): 0          Average total size (kbytes): 0          Maximum resident set size (kbytes): 1065040          Average resident set size (kbytes): 0          Major (requiring I/O) page faults: 0          Minor (reclaiming a frame) page faults: 369013          Voluntary context switches: 243          Involuntary context switches: 2835          Swaps: 0          File system inputs: 0          File system outputs: 0          Socket messages sent: 0          Socket messages received: 0          Signals delivered: 0          Page size (bytes): 4096          Exit status: 0  ```    ## mimalloc  ```  # env time -v cargo run --release -p rust-analyzer -- analysis-stats ../chalk/      Finished release [optimized] target(s) in 0.12s       Running `target/release/rust-analyzer analysis-stats ../chalk/`  [ERROR ra_project_model] cyclic dependency chalk-integration -> chalk-engine  [ERROR ra_project_model] cyclic dependency chalk-recursive -> chalk-integration  [ERROR ra_project_model] cyclic dependency chalk-solve -> chalk-integration  Database loaded 332.116806ms  Crates in this dir: 11  Total modules found: 159  Total declarations: 2631  Total functions: 1947  Item Collection: 9.796643695s, 0b allocated 0b resident  Total expressions: 57094  Expressions of unknown type: 2938 (5%)  Expressions of partially unknown type: 2427 (4%)  Type mismatches: 232  Inference: 178.82132362s, 0b allocated 0b resident  Total: 188.617975605s, 0b allocated 0b resident          Command being timed: \"cargo run --release -p rust-analyzer -- analysis-stats ../chalk/\"          User time (seconds): 187.70          System time (seconds): 1.97          Percent of CPU this job got: 99%          Elapsed (wall clock) time (h:mm:ss or m:ss): 3:09.77          Average shared text size (kbytes): 0          Average unshared data size (kbytes): 0          Average stack size (kbytes): 0          Average total size (kbytes): 0          Maximum resident set size (kbytes): 1105584          Average resident set size (kbytes): 0          Major (requiring I/O) page faults: 0          Minor (reclaiming a frame) page faults: 296481          Voluntary context switches: 222          Involuntary context switches: 1868          Swaps: 0          File system inputs: 256          File system outputs: 0          Socket messages sent: 0          Socket messages received: 0          Signals delivered: 0          Page size (bytes): 4096          Exit status: 0  # env time -v cargo run --release -p rust-analyzer -- analysis-stats ../chalk/      Finished release [optimized] target(s) in 0.13s       Running `target/release/rust-analyzer analysis-stats ../chalk/`  [ERROR ra_project_model] cyclic dependency chalk-integration -> chalk-engine  [ERROR ra_project_model] cyclic dependency chalk-recursive -> chalk-integration  [ERROR ra_project_model] cyclic dependency chalk-solve -> chalk-integration  Database loaded 320.046776ms  Crates in this dir: 11  Total modules found: 159  Total declarations: 2631  Total functions: 1947  Item Collection: 9.287690124s, 0b allocated 0b resident  Total expressions: 57094  Expressions of unknown type: 2938 (5%)  Expressions of partially unknown type: 2427 (4%)  Type mismatches: 232  Inference: 175.710939697s, 0b allocated 0b resident  Total: 184.998640033s, 0b allocated 0b resident          Command being timed: \"cargo run --release -p rust-analyzer -- analysis-stats ../chalk/\"          User time (seconds): 184.38          System time (seconds): 1.81          Percent of CPU this job got: 99%          Elapsed (wall clock) time (h:mm:ss or m:ss): 3:06.23          Average shared text size (kbytes): 0          Average unshared data size (kbytes): 0          Average stack size (kbytes): 0          Average total size (kbytes): 0          Maximum resident set size (kbytes): 1108132          Average resident set size (kbytes): 0          Major (requiring I/O) page faults: 0          Minor (reclaiming a frame) page faults: 297055          Voluntary context switches: 374          Involuntary context switches: 2374          Swaps: 0          File system inputs: 0          File system outputs: 0          Socket messages sent: 0          Socket messages received: 0          Signals delivered: 0          Page size (bytes): 4096          Exit status: 0  ```    ## mimalloc + lto  ```  # env time -v cargo run --release -p rust-analyzer -- analysis-stats ../chalk/      Finished release [optimized] target(s) in 0.11s       Running `target/release/rust-analyzer analysis-stats ../chalk/`  [ERROR ra_project_model] cyclic dependency chalk-integration -> chalk-engine  [ERROR ra_project_model] cyclic dependency chalk-recursive -> chalk-integration  [ERROR ra_project_model] cyclic dependency chalk-solve -> chalk-integration  Database loaded 369.600196ms  Crates in this dir: 11  Total modules found: 159  Total declarations: 2631  Total functions: 1947  Item Collection: 7.572726834s, 0b allocated 0b resident  Total expressions: 57094  Expressions of unknown type: 2938 (5%)  Expressions of partially unknown type: 2427 (4%)  Type mismatches: 232  Inference: 153.090899101s, 0b allocated 0b resident  Total: 160.663635235s, 0b allocated 0b resident          Command being timed: \"cargo run --release -p rust-analyzer -- analysis-stats ../chalk/\"          User time (seconds): 160.01          System time (seconds): 1.70          Percent of CPU this job got: 99%          Elapsed (wall clock) time (h:mm:ss or m:ss): 2:41.80          Average shared text size (kbytes): 0          Average unshared data size (kbytes): 0          Average stack size (kbytes): 0          Average total size (kbytes): 0          Maximum resident set size (kbytes): 1106076          Average resident set size (kbytes): 0          Major (requiring I/O) page faults: 1          Minor (reclaiming a frame) page faults: 296610          Voluntary context switches: 209          Involuntary context switches: 2798          Swaps: 0          File system inputs: 8          File system outputs: 0          Socket messages sent: 0          Socket messages received: 0          Signals delivered: 0          Page size (bytes): 4096          Exit status: 0  # env time -v cargo run --release -p rust-analyzer -- analysis-stats ../chalk/      Finished release [optimized] target(s) in 0.10s       Running `target/release/rust-analyzer analysis-stats ../chalk/`  [ERROR ra_project_model] cyclic dependency chalk-integration -> chalk-engine  [ERROR ra_project_model] cyclic dependency chalk-recursive -> chalk-integration  [ERROR ra_project_model] cyclic dependency chalk-solve -> chalk-integration  Database loaded 334.630658ms  Crates in this dir: 11  Total modules found: 159  Total declarations: 2631  Total functions: 1947  Item Collection: 7.71699197s, 0b allocated 0b resident  Total expressions: 57094  Expressions of unknown type: 2938 (5%)  Expressions of partially unknown type: 2427 (4%)  Type mismatches: 232  Inference: 154.50351318s, 0b allocated 0b resident  Total: 162.220513775s, 0b allocated 0b resident          Command being timed: \"cargo run --release -p rust-analyzer -- analysis-stats ../chalk/\"          User time (seconds): 161.52          System time (seconds): 1.74          Percent of CPU this job got: 99%          Elapsed (wall clock) time (h:mm:ss or m:ss): 2:43.31          Average shared text size (kbytes): 0          Average unshared data size (kbytes): 0          Average stack size (kbytes): 0          Average total size (kbytes): 0          Maximum resident set size (kbytes): 1104268          Average resident set size (kbytes): 0          Major (requiring I/O) page faults: 0          Minor (reclaiming a frame) page faults: 296183          Voluntary context switches: 200          Involuntary context switches: 1666          Swaps: 0          File system inputs: 0          File system outputs: 0          Socket messages sent: 0          Socket messages received: 0          Signals delivered: 0          Page size (bytes): 4096          Exit status: 0  ```  </details>", "target": 1}
{"idx": 3571, "commit_message": "add_editor_style() third pass. better performance and better child theme support. see #11512", "target": 1}
{"idx": 2678, "commit_message": "[TASK] Add AMI getter to target section header  In order to improve MN driver performance the AMI 16 bit getters are added to the local or tightly-coupled memory.", "target": 1}
{"idx": 2253, "commit_message": "VMware: use default values in get_info() when properties are missing  The properties that we retrieve from VirtualMachineConfigSummary are optional ('summary.config.numCpu', 'summary.config.memorySizeMB') and if they are missing we should return default values from get_info()  This patch also improves the unit test for get_info(). It removes the test in test_driver_api.py (test_get_info() and test_spawn() are the same) and adds a new test in test_vmops.py  Closes-Bug: 1317912", "target": 0}
{"idx": 2585, "commit_message": "refactor eosio_exit for WAVM; improve long running performance  WAVM becomes increasingly slow as more and more contracts are activated. The ultimate reason is due to high exception overhead from eosio_exit. I believe this steams from the huge number of memory mappings and interaction with the unwinder. Refactor eosio_exit implementation on WAVM to not use exceptions and instead longjmp out of the running wasm code.", "target": 1}
{"idx": 1243, "commit_message": "Optimize ApplicationPool priority queues  This is done by increasing their arity. This improves CPU cache locality despite needing more comparisons", "target": 1}
{"idx": 3742, "commit_message": "Improve performance when retrieving large ResultSets consisting of Strings, ints, and longs.  Improve String retrieval by avoiding a copy from the network buffer and using it directly to create the String instance.  Improve integer retrieval by using a custom byte to number conversion that uses knowledge of the encoding to avoid creating an intermediate String representation first.  Mikko Tiihonen", "target": 1}
{"idx": 1623, "commit_message": "gpu_pixel_test: Re-enable rebaselined tests.  [URL]  Bug: 815045 Cq-Include-Trybots: master.tryserver.chromium.android:android_optional_gpu_tests_rel;master.tryserver.chromium.linux:linux_optional_gpu_tests_rel;master.tryserver.chromium.mac:mac_optional_gpu_tests_rel;master.tryserver.chromium.win:win_optional_gpu_tests_rel", "target": 0}
{"idx": 3761, "commit_message": "zram: introduce compressing backend abstraction  ZRAM performs direct LZO compression algorithm calls, making it the one and only option.  While LZO is generally performs well, LZ4 algorithm tends to have a faster decompression (see [URL]/p/lz4/ for full report)  \tName            Ratio  C.speed D.speed \t                        MB/s    MB/s \tLZ4 (r101)      2.084    422    1820 \tLZO 2.06        2.106    414     600  Thus, users who have mostly read (decompress) usage scenarious or mixed workflow (writes with relatively high read ops number) will benefit from using LZ4 compression backend.  Introduce compressing backend abstraction zcomp in order to support multiple compression algorithms with the following set of operations:          .create         .destroy         .compress         .decompress  Schematically zram write() usually contains the following steps: 0) preparation (decompression of partioal IO, etc.) 1) lock buffer_lock mutex (protects meta compress buffers) 2) compress (using meta compress buffers) 3) alloc and map zs_pool object 4) copy compressed data (from meta compress buffers) to object allocated by 3) 5) free previous pool page, assign a new one 6) unlock buffer_lock mutex  As we can see, compressing buffers must remain untouched from 1) to 4), because, otherwise, concurrent write() can overwrite data.  At the same time, zram_meta must be aware of a) specific compression algorithm memory requirements and b) necessary locking to protect compression buffers.  To remove requirement a) new struct zcomp_strm introduced, which contains a compress/decompress `buffer' and compression algorithm `private' part. While struct zcomp implements zcomp_strm stream handling and locking and removes requirement b) from zram meta.  zcomp ->create() and ->destroy(), respectively, allocate and deallocate algorithm specific zcomp_strm `private' part.  Every zcomp has zcomp stream and mutex to protect its compression stream. Stream usage semantics remains the same -- only one write can hold stream lock and use its buffers.  zcomp_strm_find() turns caller into exclusive user of a stream (holding stream mutex until zram release stream), and zcomp_strm_release() makes zcomp stream available (unlock the stream mutex).  Hence no concurrent write (compression) operations possible at the moment.  iozone -t 3 -R -r 16K -s 60M -I +Z         test            base           patched --------------------------------------------------   Initial write      597992.91       591660.58         Rewrite      609674.34       616054.97            Read     2404771.75      2452909.12         Re-read     2459216.81      2470074.44    Reverse Read     1652769.66      1589128.66     Stride read     2202441.81      2202173.31     Random read     2236311.47      2276565.31  Mixed workload     1423760.41      1709760.06    Random write      579584.08       615933.86          Pwrite      597550.02       594933.70           Pread     1703672.53      1718126.72          Fwrite     1330497.06      1461054.00           Fread     3922851.00      3957242.62  Usage examples:  \tcomp = zcomp_create(NAME) /* NAME e.g. \"lzo\" */  which initialises compressing backend if requested algorithm is supported.  Compress: \tzstrm = zcomp_strm_find(comp) \tzcomp_compress(comp, zstrm, src, &dst_len) \t[..] /* copy compressed data */ \tzcomp_strm_release(comp, zstrm)  Decompress: \tzcomp_decompress(comp, src, src_len, dst);  Free compessing backend and its zcomp stream: \tzcomp_destroy(comp)", "target": 1}
{"idx": 1233, "commit_message": "improve media lookup for batch media create", "target": 1}
{"idx": 3735, "commit_message": "arm64: Convert asm/tlb.h to generic mmu_gather  Over the past couple of years, the generic mmu_gather gained range tracking - 597e1c3580b7 (mm/mmu_gather: enable tlb flush range in generic mmu_gather), 2b047252d087 (Fix TLB gather virtual address range invalidation corner cases) - and tlb_fast_mode() has been removed - 29eb77825cc7 (arch, mm: Remove tlb_fast_mode()).  The new mmu_gather structure is now suitable for arm64 and this patch converts the arch asm/tlb.h to the generic code. One functional difference is the shift_arg_pages() case where previously the code was flushing the full mm (no tlb_start_vma call) but now it flushes the range given to tlb_gather_mmu() (possibly slightly more efficient previously).", "target": 0}
{"idx": 3484, "commit_message": "SVN MAIN Commit: Bug#266201 262762, empty uow, returning test failure  [URL]/bugs/show_bug.cgi?id=262762  [URL]/bugs/show_bug.cgi?id=266201  Changes: - Added JPA concurrency tests - Added JPA clustered concurrency tests - Fixed bug in UOW for empty transaction with SQL causing rollback, added tests in custom SQL and JPA advanced query suites. - Re-org'd performance tests into sub-dirs - Fixed Returning test failure from negative test being no longer valid.    Former-commit-id: 28aa992d7e736a5009d8d6a00046f6ee56046785", "target": 0}
{"idx": 4116, "commit_message": "[PATCH] Step towards better performance regarding second convergence\n test in bicgstab", "target": 1}
{"idx": 3439, "commit_message": "1) BaseFileAdapter now actually checks behaviors before deciding whether an object can be batched 2) Fixed the Fileeffectiverights optimization, which assumed object IDs were unique (which neglected the possibility of variable permutations in the batch queue) 3) Optimized the Textfilecontent54Adapter performance, by grouping together batched objects that all scan the same file, and downloading it only once.", "target": 1}
{"idx": 1132, "commit_message": "added test for distances, few corrections and improvements to computation of certain distances", "target": 0}
{"idx": 1915, "commit_message": "Fully switched the addon manager to the new network subsystem.", "target": 0}
{"idx": 3163, "commit_message": "remove unused purephp classes in favor of third party libraries, usage of Illuminate Dispatcher and Illuminate string helpers, pure classes have been moved to the app/src dir, Controller class not found fix, and other minor changes, fixes and improvements", "target": 0}
{"idx": 2124, "commit_message": "Fixed memory leaks. Notied that LTAO has worse performance than v2.3. The reasons include 1) sim.htel=4000, 2) lower signal level, 3) sim.dt, and 4) TT WFS location.", "target": 1}
{"idx": 3681, "commit_message": "Code formatting, smaller refacs, robustness.  * Performance: Prefix increment in loops. * Check VirtualAlloc return * Check for successful memory allocation in cloneCode * Swap assignment of pCode and uiCode (if alloc were to fail and not assign, uiCode shouldn't be nulled either) * declare statics before non-static members * Introduce variables replacing magic constants * Reduce varscopes", "target": 1}
{"idx": 2536, "commit_message": "[PATCH] uml: Improve SIGBUS diagnostics  UML can get a SIGBUS anywhere if the tmpfs mount being used for its memory runs out of space.  This patch adds a printk before the panic to provide a clue as to what likely went wrong.", "target": 0}
{"idx": 3724, "commit_message": "zram: replace global tb_lock with fine grain lock  Currently, we use a rwlock tb_lock to protect concurrent access to the whole zram meta table.  However, according to the actual access model, there is only a small chance for upper user to access the same table[index], so the current lock granularity is too big.  The idea of optimization is to change the lock granularity from whole meta table to per table entry (table -> table[index]), so that we can protect concurrent access to the same table[index], meanwhile allow the maximum concurrency.  With this in mind, several kinds of locks which could be used as a per-entry lock were tested and compared:  Test environment: x86-64 Intel Core2 Q8400, system memory 4GB, Ubuntu 12.04, kernel v3.15.0-rc3 as base, zram with 4 max_comp_streams LZO.  iozone test: iozone -t 4 -R -r 16K -s 200M -I +Z (1GB zram with ext4 filesystem, take the average of 10 tests, KB/s)        Test       base      CAS    spinlock    rwlock   bit_spinlock -------------------------------------------------------------------  Initial write  1381094   1425435   1422860   1423075   1421521        Rewrite  1529479   1641199   1668762   1672855   1654910           Read  8468009  11324979  11305569  11117273  10997202        Re-read  8467476  11260914  11248059  11145336  10906486   Reverse Read  6821393   8106334   8282174   8279195   8109186    Stride read  7191093   8994306   9153982   8961224   9004434    Random read  7156353   8957932   9167098   8980465   8940476 Mixed workload  4172747   5680814   5927825   5489578   5972253   Random write  1483044   1605588   1594329   1600453   1596010         Pwrite  1276644   1303108   1311612   1314228   1300960          Pread  4324337   4632869   4618386   4457870   4500166  To enhance the possibility of access the same table[index] concurrently, set zram a small disksize(10MB) and let threads run with large loop count.  fio test: fio --bs=32k --randrepeat=1 --randseed=100 --refill_buffers --scramble_buffers=1 --direct=1 --loops=3000 --numjobs=4 --filename=/dev/zram0 --name=seq-write --rw=write --stonewall --name=seq-read --rw=read --stonewall --name=seq-readwrite --rw=rw --stonewall --name=rand-readwrite --rw=randrw --stonewall (10MB zram raw block device, take the average of 10 tests, KB/s)      Test     base     CAS    spinlock    rwlock  bit_spinlock ------------------------------------------------------------- seq-write   933789   999357   1003298    995961   1001958  seq-read  5634130  6577930   6380861   6243912   6230006    seq-rw  1405687  1638117   1640256   1633903   1634459   rand-rw  1386119  1614664   1617211   1609267   1612471  All the optimization methods show a higher performance than the base, however, it is hard to say which method is the most appropriate.  On the other hand, zram is mostly used on small embedded system, so we don't want to increase any memory footprint.  This patch pick the bit_spinlock method, pack object size and page_flag into an unsigned long table.value, so as to not increase any memory overhead on both 32-bit and 64-bit system.  On the third hand, even though different kinds of locks have different performances, we can ignore this difference, because: if zram is used as zram swapfile, the swap subsystem can prevent concurrent access to the same swapslot; if zram is used as zram-blk for set up filesystem on it, the upper filesystem and the page cache also prevent concurrent access of the same block mostly.  So we can ignore the different performances among locks.  Acked-by: Sergey Senozhatsky [URL]>", "target": 1}
{"idx": 2875, "commit_message": "improve performance by compiling the OEMASK regexp out of the loop catch faulty OEMASKs and emit a user friendly error message", "target": 1}
{"idx": 3238, "commit_message": "vlib: send full error message to syslog  Currently the last character of the error message string is temporarily changed to a null byte '0' before the string is sent to syslog(3), resulting in confusingly incomplete log entries.  This patch changes the syslog format to \"%.*s\" so that the maximum number of characters to be printed could be controlled.  Type: improvement", "target": 0}
{"idx": 1149, "commit_message": "Updated the NCSS reference doc. * The changes are mostly improvements to the formatting. * WaterML2 is a supported output format.", "target": 0}
{"idx": 3240, "commit_message": "spi/spi_sh_msiof: consolidate data in 8-bit mode into 32-bit words  Instead of sending data 8 bits at a time in 8-bit SPI mode, swap bytes and send and receive them 32 bits at a time. Tested with an SD-card, with which this patch reduced the number of interrupts by 50%, when reading 5MiB of data (there are also small service packets, the number of interrupts, produced by 512-byte sectors should, of course, drop by 75%), and improved throughput by more than 40%.", "target": 1}
{"idx": 1208, "commit_message": "cpu cache line length detection from mplayerxp (Nick Kurshev < >)", "target": 0}
{"idx": 2189, "commit_message": "- Patch #268914 by catch: small usability improvements to taxonomy and content type overview pages.", "target": 0}
{"idx": 3350, "commit_message": "Clean up the account list code, make it less redundant and more efficient, fix a few bugs (like random position loss for long lists) along the way.", "target": 1}
{"idx": 1027, "commit_message": "[Private sites] Hide VideoPress switch on private atomic sites (#40470)  * Move EligibilityWarnings gate from CDN features fo main performance tab and hide Videopress behind it    * Remove obsolete class name    * Add videoPress to list of blacklisted modules in the selector", "target": 0}
{"idx": 2924, "commit_message": "kmem: First pass implementation of kmem - a general purpose kernel memory allocator  kmem: -- Allocates memory based on fixed-size power-of-2 sized blocks (for now it's 32B to 16KB) -- Each power-of-2 block size is allocated from a slab -- slabs are kept in an array so lookups for a given size are fast -- If a slab is out of blocks, _kmem_grow is invoked to calculate how much larger to increase the slab by -- Calculation is based off the ratio of allocations from that slab to to the total number of allocations across all slabs -- It will then try to steal free slab buffers from least recently used slabs -- Finally it will grab memory from vm_km to satisfy the rest of the size increase for the slab", "target": 0}
{"idx": 2836, "commit_message": "Add glossary documentation to the perf dashboard code.  This is a slightly expanded version of the glossary at [URL]/dev/developers/speed-infra/performance-dashboard/hacking-on  BUG=catapult:#1984  Review URL: [URL]/1681683004", "target": 0}
{"idx": 1254, "commit_message": "configs: Add a BaseSimpleSystem  This is a preparing patch, disentangling common platform configurations from the memory setup (which is classic oriented)", "target": 0}
{"idx": 2470, "commit_message": "EC: Improved performance of row filtering (Use precalculated colum indexes)", "target": 1}
{"idx": 3817, "commit_message": "Merge pull request #1618 from axelheer/biginteger-performance  Improve performance of BigInteger.Add/Sub/Div/Rem", "target": 1}
{"idx": 371, "commit_message": "[now-client] Retry on network error (#3072)  This PR improves handling of occasional network errors in `now-client` which should improve benchmarking introduced in #3062", "target": 0}
{"idx": 119, "commit_message": "interface to load old Network Diary data to LifePIM", "target": 0}
{"idx": 2231, "commit_message": "Extend download deep scanning metrics  This CL extends a number of metrics related to download deep scanning. These are useful for monitoring both the upcoming launch of download deep scanning for Advanced Protection users and the performance as the user count for enterprise download scanning increases. We'd like to get enough usage on these histograms to understand the performance of each subcomponent before expiring these fine-grained histograms.  M90 was chosen because several other metrics for this feature were already extended to M90, so it makes sense to evaluate all the metrics then.  Fixed: 1089452, 1089443, 1089442, 1089383", "target": 0}
{"idx": 3867, "commit_message": "HydraPaper Updated so folders are not rescanned every time the image is rotated. This should improve performance for directories with lots of files. Added icons to indicated status of Hydrapaper (running, stopped, blanked). Disabled direct entry into the path fields.", "target": 1}
{"idx": 3896, "commit_message": "Clean up the git-p4 documentation  This patch massages the documentation a bit for improved readability and cleans it up from outdated options/commands.", "target": 0}
{"idx": 2773, "commit_message": "performance fix: Float32Array.from is slow, use a loop, 100x faster", "target": 1}
{"idx": 1335, "commit_message": "Merge PR #614 (lib.pmu improvement) into next", "target": 0}
{"idx": 3725, "commit_message": "UBI: Fix invalid vfree()  The logic of vfree()'ing vol->upd_buf is tied to vol->updating. In ubi_start_update() vol->updating is set long before vmalloc()'ing vol->upd_buf. If we encounter a write failure in ubi_start_update() before vmalloc() the UBI device release function will try to vfree() vol->upd_buf because vol->updating is set. Fix this by allocating vol->upd_buf directly after setting vol->updating.  Fixes: [   31.559338] UBI warning: vol_cdev_release: update of volume 2 not finished, volume is damaged [   31.559340] ------------[ cut here ]------------ [   31.559343] WARNING: CPU: 1 PID: 2747 at mm/vmalloc.c:1446 __vunmap+0xe3/0x110() [   31.559344] Trying to vfree() nonexistent vm area (ffffc90001f2b000) [   31.559345] Modules linked in: [   31.565620]  0000000000000bba ffff88002a0cbdb0 ffffffff818f0497 ffff88003b9ba148 [   31.566347]  ffff88002a0cbde0 ffffffff8156f515 ffff88003b9ba148 0000000000000bba [   31.567073]  0000000000000000 0000000000000000 ffff88002a0cbe88 ffffffff8156c10a [   31.567793] Call Trace: [   31.568034]  [<ffffffff818f0497>] dump_stack+0x4e/0x7a [   31.568510]  [<ffffffff8156f515>] ubi_io_write_vid_hdr+0x155/0x160 [   31.569084]  [<ffffffff8156c10a>] ubi_eba_write_leb+0x23a/0x870 [   31.569628]  [<ffffffff81569b36>] vol_cdev_write+0x226/0x380 [   31.570155]  [<ffffffff81179265>] vfs_write+0xb5/0x1f0 [   31.570627]  [<ffffffff81179f8a>] SyS_pwrite64+0x6a/0xa0 [   31.571123]  [<ffffffff818fde12>] system_call_fastpath+0x16/0x1b  Cc: [URL]>", "target": 0}
{"idx": 938, "commit_message": "Shorthand action: rewritten to allow dynamic arguments", "target": 0}
{"idx": 2837, "commit_message": "Bump [URL]/cloudfoundry-incubator/bits-service  Bump [URL]/cloudfoundry-incubator/bits-service   Peter Goetz:      Improve performance for Openstack DeleteDir implementation", "target": 1}
{"idx": 451, "commit_message": "Optimizer: check validity moved and cleared function", "target": 0}
{"idx": 1583, "commit_message": "doc: kernel-parameters.txt: fix documentation of elevator parameter  Legacy IO schedulers (cfq, deadline and noop) were removed in f382fb0bcef4.  The documentation for deadline was retained because it carries over to mq-deadline as well, but location of the doc file was changed over time.  The old iosched algorithms were removed from elevator= kernel parameter and mq-deadline, kyber and bfq were added with a reference to their documentation.  Fixes: f382fb0bcef4 (\"block: remove legacy IO schedulers\")", "target": 0}
{"idx": 3626, "commit_message": "app/composite/gimp-composite-generic.c app/composite/gimp-composite-mmx.c  * app/composite/gimp-composite-generic.c * app/composite/gimp-composite-mmx.c * app/composite/gimp-composite-sse.c Incorporated a very clean patch from [URL] (Frederic Leroy) which improves the generic performance of the burn compositing function.  Speed is improved at a cost of a 64k look-up table which is probably manageable for 8bpp images, but at larger bpp images (which currently are not supported by the GIMP) this is unlikely to be tolerable.  The generic C implementation of the burn function uses this look-up table, the mmx/sse implementations have been commented out.", "target": 1}
{"idx": 3189, "commit_message": "replace Is_Standard_Entity with Is_Standard_Type  Routine Is_Standard_Entity was only used to detect standard types in CE. For this specialized use-case we can make it more efficient.  (no-tn-check)  * gnat2why/spark/spark_util-types.ads * gnat2why/spark/spark_util-types.adb (Is_Standard_Type): now a specialized version of Is_Standard_Entity.  * gnat2why/spark/spark_util.ads * gnat2why/spark/spark_util.adb (Is_Standard_Entity): no longer used, so removed.  * gnat2why/counterexamples/ce_pretty_printing.adb Adapt callers.", "target": 1}
{"idx": 63, "commit_message": "Improve sharee controller remote user search tests", "target": 0}
{"idx": 437, "commit_message": "ehci-hcd: fix memory leak in lowlevel init  usb_lowlevel_init() allocates a new periodic_list each time it is invoked, without freeing the original list. Since it is initialized later on in the code, just reuse the first-allocated list in future invocations of usb_lowlevel_init.  Cc: Marek Vasut < > Cc: Igor Grinberg < >", "target": 0}
{"idx": 4088, "commit_message": "[PATCH] Modified nb_accv to improve performance of accumulates to\n processors on the same SMP node.", "target": 1}
{"idx": 3303, "commit_message": "f2fs: fallocate data blocks in single locked node page  This patch is to improve the expand_inode speed in fallocate by allocating data blocks as many as possible in single locked node page.  In SSD,  # time fallocate -l 500G $MNT/testfile  Before : 1m 33.410 s After  : 24.758 s  Reported-by: Stephen Bates [URL]>", "target": 1}
{"idx": 2333, "commit_message": "nepomuk: implement custom QueryMaker  This changes the nepomuk backend behaviour drastically. Instead of retrieving all the data, it now builds SPARQL queries on the fly.  Some features are still missing, and there are some questions regarding performance, that should be resolved in the future.", "target": 0}
{"idx": 3029, "commit_message": "bug fix, better performance.   Former-commit-id: e60ad79bcca9b988062a95710c1b7baa7aeea82f", "target": 1}
{"idx": 3772, "commit_message": "-- Graph streaming is now working -- Used MapDB to be able to memoize the trees produced from parsing sentences, improving performance of the application.  Signed off by Mark [URL]>", "target": 1}
{"idx": 1601, "commit_message": "Fix typo bug in frame acccumulator. Remove sender modification of size array, memory might be read by kernel while we modify", "target": 0}
{"idx": 3809, "commit_message": "Improved the performance of large outer reductions on cuda", "target": 1}
{"idx": 195, "commit_message": "chapter 10: migrate pinIt from foundation to bootstrap and make it dynamic with localStorage", "target": 0}
{"idx": 2580, "commit_message": "- Patch #234785 by Rowanw, yoroy, flobruit, et al: usability: improve visibility of the 'more help' link by adding an icon.", "target": 0}
{"idx": 59, "commit_message": "cpufreq_conservative: Improve support for micro idle accounting  The minimum samplerate calculations of the current conservative implementation assume that there is not micro idle accounting present, however, we do have that capability in our idle estimates.  As a result, we can support lower polling intervals just like ondemand does.", "target": 0}
{"idx": 3237, "commit_message": "net: calxedaxgmac: enable rx cut-thru  There is no reason to wait for the entire frame to start DMA on receive, so enable rx cut-thru for better performance.", "target": 1}
{"idx": 2228, "commit_message": "Fixed processing of events when debugger is active and performance is stopped", "target": 0}
{"idx": 1202, "commit_message": "Drop implicit types from summaries.  Previously, implicit types were serialized in the summary as references to `dynamic`.  Now, we simply omit the types from the summary and the dynamic type is inferred at resynthesis time.  This should reduce the summary size and simplify the implementation of inferred types.  [URL]  Review URL: [URL]/1622673002 .", "target": 1}
{"idx": 261, "commit_message": "Use average dynamic for chords, not sum  Fix #251", "target": 0}
{"idx": 2507, "commit_message": "NEW - bug 284945: [performance] make task editor open feel instant [URL]/bugs/show_bug.cgi?id=284945", "target": 1}
{"idx": 2093, "commit_message": "Fixed mp to workaround block retention bug. Added more benchmarks. Did some, probably, unnecessary cleanup on stylers. Optimized apply_style for bug and performance", "target": 1}
{"idx": 1360, "commit_message": "Increase serialize(no-crc) target benchmark  Following changes to the Linux Kernel to handle RETBLEED mitigations Skylake CPUs perform signicantly worse.  This affects the Firecracker baseline for all Intel testing. Until Firecracker's CI and performance pipelines can move off of Skylake, we will need drop our baseline to prevent unrelated disruptions to our pipeline.", "target": 0}
{"idx": 1814, "commit_message": "switch mem3 cache from ets to mochiglobal, 20% speedup :)", "target": 1}
{"idx": 2528, "commit_message": "revlog: add an experimental option to mitigated delta issues (issue5480)  The general delta heuristic to select a delta do not scale with the number of branch. The delta base is frequently too far away to be able to reuse a chain according to the \"distance\" criteria. This leads to insertion of larger delta (or even full text) that themselves push the bases for the next delta further away leading to more large deltas and full texts. This full text and frequent recomputation throw Mercurial performance in disarray.  For example of a slightly large repository    280 000 files (2 150 000 versions)   430 000 changesets (10 000 topological heads)  Number below compares repository with and without the distance criteria:  manifest size:     with:    21.4 GB     without:  0.3 GB  store size:     with:    28.7 GB     without   7.4 GB  bundle last 15 00 revisions:     with:    800 seconds              971 MB     without:  50 seconds               73 MB  unbundle time (of the last 15K revisions):     with:    1150 seconds (~19 minutes)     without:   35 seconds  Similar issues has been observed in other repositories.   Adding a new option or \"feature\" on stable is uncommon. However, given that this issues is making Mercurial practically unusable, I'm exceptionally targeting this patch for stable.  What is actually needed is a full rework of the delta building and reading logic. However, that will be a longer process and churn not suitable for stable.  In the meantime, we introduces a quick and dirty mitigation of this in the 'experimental' config space. The new option introduces a way to set the maximum amount of memory usable to store a diff in memory. This extend the ability for Mercurial to create chains without removing all safe guard regarding memory access. The option should be phased out when core has a more proper solution available.  Setting the limit to '0' remove all limits, setting it to '-1' use the default limit (textsize x 4).", "target": 1}
{"idx": 2600, "commit_message": "[Foundation] Performance improvements for IndexPath bridging and comparison (#9339)  * [Foundation] Refactor the backing of IndexPath to favor stack allocations    The previous implementation of IndexPath would cause a malloc of the underlying array buffer upon bridging from ObjectiveC. This impacts graphical APIs (such as UICollectionView or AppKit equivalents) when calling delegation patterns. Since IndexPath itself can be a tagged pointer and most often just a pair of elements it can  be represented as an enum of common cases. Those common cases of empty, single, or pair can be represented respectively as no associated value, a single Int, and a tuple of Ints. These cases will be exclusively stack allocations, which is markably faster than the allocating code-path. IndexPaths that have a count greater than 2 will still fall into the array storage case. As an added performance benefit, accessing count and subscripting is now faster by aproximately 30% due to more tightly coupled inlining potential under whole module optimizations. Accessing count is also faster since it has better cache-line effeciency (lesson learned: the branch predictor is more optimized than pointer indirection chasing).    Benchmarks performed on x86_64, arm and arm64 still pending results but should be applicable across the board.    Resolves the following issues:  [URL]/browse/SR-3655  [URL]/browse/SR-2769    Resolves the following radars:  rdar://problem/28207534  rdar://problem/28209456    * [Foundation] remove temp IndexPath hashing that required bridging to ref types    * [Foundation] IndexPath does not guarentee hashing to be the same as objc", "target": 1}
{"idx": 3936, "commit_message": "disable some useless jffs bbc compressors (improves performance in size mode)", "target": 1}
{"idx": 1066, "commit_message": "improve string search and icon positioning", "target": 0}
{"idx": 3344, "commit_message": "more efficient for empty to be constant", "target": 1}
{"idx": 1013, "commit_message": "Move to the counting executor to speedup tests. am: a705df8d15", "target": 1}
{"idx": 923, "commit_message": "network module: allow to generate ifcfg files in optional root  For now it is required mostly for unit tests, but can become handy in the future.", "target": 0}
{"idx": 3983, "commit_message": "RANGER-2510: Support for Incremental tag updates to improve performance - handle updates to tag policies", "target": 1}
{"idx": 1873, "commit_message": "arm: vfp: Fix memory corruption on PM suspend  Commit 36af2a47 (\"ARM: vfp: Always save VFP state in vfp_pm_suspend\") introduced a potential use-after-free bug. On SMP systems, vfp_current_hw_state might hold dangling pointers in case a task which used the VFP last migrates to another CPU and then exits. If vfp_pm_suspend is called while vfp_current_hw_state still holds a pointer to the freed thread_info, that memory location will be written, potentially overwriting a new object allocated there.  The original problem is only relevant to UP systems in which the VFP state is stored lazily.  Fix this by only storing the VFP state on UP systems, and avoid doing so on SMP ones.", "target": 0}
{"idx": 2322, "commit_message": "f2fs: add roll-forward recovery process for encrypted dentry  Add roll-forward recovery process for encrypted dentry, so the first fsync issued to an encrypted file does not need writing checkpoint.  This improves the performance of the following test at thousands of small files: open -> write -> fsync -> close", "target": 1}
{"idx": 1110, "commit_message": "kvm: x86: fix stale mmio cache bug  commit 56f17dd3fbc44adcdbc3340fe3988ddb833a47a7 upstream.  The following events can lead to an incorrect KVM_EXIT_MMIO bubbling up to userspace:  (1) Guest accesses gpa X without a memory slot. The gfn is cached in struct kvm_vcpu_arch (mmio_gfn). On Intel EPT-enabled hosts, KVM sets the SPTE write-execute-noread so that future accesses cause EPT_MISCONFIGs.  (2) Host userspace creates a memory slot via KVM_SET_USER_MEMORY_REGION covering the page just accessed.  (3) Guest attempts to read or write to gpa X again. On Intel, this generates an EPT_MISCONFIG. The memory slot generation number that was incremented in (2) would normally take care of this but we fast path mmio faults through quickly_check_mmio_pf(), which only checks the per-vcpu mmio cache. Since we hit the cache, KVM passes a KVM_EXIT_MMIO up to userspace.  This patch fixes the issue by using the memslot generation number to validate the mmio cache.", "target": 0}
{"idx": 1659, "commit_message": "improved text formatting of \"long\" messages in QueueView TicketZoom, TicketPlain and TicketSearch", "target": 0}
{"idx": 4066, "commit_message": "[PATCH] Wrote the compute_children_node_keys() function in elem.h\n which allows one to generate appropriate node keys while reading in a mesh\n with multiple refinement levels. This allows us to avoid a linear search in\n the MeshRefinement::add_point routine since all the nodes can now be found in\n the nodes hash table.  The resulting performance improvement was significant.\n\ngit-svn-id: file:///Users/petejw/Documents/libmesh_svn_bak@1263 434f946d-2f3d-0410-ba4c-cb9f52fb0dbf", "target": 1}
{"idx": 2905, "commit_message": "Call NS AnalyzeCaptureAudio before AEC  This attenuates the noise pumping generated from the NS adapting to the AEC comfort noise.  When there is echo present the AEC suppresses it and adds comfort noise. This is underestimated on purpose to avoid adding more than the original background noise. The NS has to be called after the AEC, because every non-linear processing before it can ruin its performance. Therefore the noise estimation can adapt to this comfort noise, making it less aggressive and generating noise pumping.  By putting the noise estimation analysis stage from the NS before the AEC, this effect can be avoided. This has been tested manually on recordings where noise pumping was present: Two long recordings done in our team by bjornv and kwiberg plus the most noisy (5) recordings in the QA set.  On the other hand, one risk of doing this is to not adapt to the comfort noise and therefore suppress too much. As verified in the tested files, this is not a problem in practice.  BUG=webrtc:3763 [URL], [URL]  Review URL: [URL]/24679004  Cr-Mirrored-From: [URL]/external/webrtc Cr-Mirrored-Commit: a0ce9fa2a65a693ca9a6ee4920fb41d5cdd92e3b", "target": 9}
{"idx": 4133, "commit_message": "[PATCH] pathf90 v2.1 better performance with ro=1 vs. ro=2", "target": 1}
{"idx": 3736, "commit_message": "Some performance improvements to the iterator library", "target": 1}
{"idx": 2984, "commit_message": "rbd: return earlier in rbd_header_from_disk()  The only caller of rbd_header_from_disk() is rbd_read_header(). It passes as allocated_snaps the number of snapshots it will have received from the server for the snapshot context that rbd_header_from_disk() is to interpret.  The first time through it provides 0--mainly to extract the number of snapshots from the snapshot context header--so that it can allocate an appropriately-sized buffer to receive the entire snapshot context from the server in a second request.  rbd_header_from_disk() will not fill in the array of snapshot ids unless the number in the snapshot matches the number the caller had allocated.  This patch adjusts that logic a little further to be more efficient. rbd_read_header() doesn't even examine the snapshot context unless the snapshot count (stored in header->total_snaps) matches the number of snapshots allocated.  So rbd_header_from_disk() doesn't need to allocate or fill in the snapshot context field at all in that case.", "target": 1}
{"idx": 3604, "commit_message": "Reviewed by Darin Adler.                  Updated <rdar://problem/4871518> fix based on Darin's comments.          Instead of searching the frame tree to retrieve the new frame, put it in         a RefPtr, and then explicitly check for its removal. This option is slightly         more efficient, and it avoids problems that can occur due to frame name collision.                  * WebCoreSupport/WebFrameBridge.mm:         (-[WebFrameBridge createChildFrameNamed:withURL:referrer:ownerElement:allowsScrolling:marginWidth:marginHeight:]):", "target": 1}
{"idx": 3906, "commit_message": "Release google-cloud-bigquery 1.14.0 (#3872)  #### Features    * Support overriding of service endpoint    #### Performance Improvements    * Use MiniMime to detect content types    #### Documentation    * Update documentation", "target": 1}
{"idx": 1721, "commit_message": "Merge pull request #544 from alphagov/improve-logit-signin-instructions  Improve Logit sign-in instructions", "target": 0}
{"idx": 2015, "commit_message": "use functions over blocks  should lead to better performance in Rubinius and jRuby", "target": 1}
{"idx": 1731, "commit_message": "Core/Spells: Fix potions cooldown in combat  Fix a cooldown issue related to potions allowing Players in combat to use more than 1 potion in a row, especially with high latency. This also fixes an exploit about using infinite potions in combat just by skipping the client-side check. The original implementation c064c2e2e1eebd43b273365583dd181293bafa22 was missing a check in Spell::CheckCast() about this particular case since Potion cooldown is added only after the Player goes out of combat. Fixes #1259 .", "target": 0}
{"idx": 370, "commit_message": "0.3.6 Dev 20 : Minor Memory optimizations; leak fixed", "target": 1}
{"idx": 2383, "commit_message": "vaapi/jpeg_enc: Fix quantization scaling  This is a workaround to match with iHD media driver that shifts the quantization values by 50 while encoding. [URL]/intel/media-driver/blob/master/media_driver/linux/common/codec/ddi/media_ddi_encode_jpeg.cpp#L694  The patch ensures the shifted value in the middleware generated packed header. Linux media stack test cases claiming to have a significant psnr improvement in Y plane (41.27 to 48.31) with this quirk.  BUG=None TEST=./jpeg_encode_accelerator_unittest", "target": 0}
{"idx": 2393, "commit_message": "Performance improvements for Find. Convert positions to x,y ranges in batches. Cache block position in findSubstring:stopAt.", "target": 1}
{"idx": 2154, "commit_message": "* Use a map to lookup primops. * Various performance improvements in the evaluator. * Do not link against unused (and missing!) libraries (-lsglr, etc.).", "target": 1}
{"idx": 1833, "commit_message": "Use symbols instead of strings in the game board. First pass at an algorithm to detect wins.  Failure!", "target": 0}
{"idx": 2632, "commit_message": "Fixed minor performance loss due to accessing serialized vectors repeatedly pthreads serializes objects assigned as members of Threaded objects, so every time you access it you're creating a new object and incurring the overhead of unserializing it again for reading. Store these in local variables to avoid the serialization penalty.  This produces a modest 5% performance improvement.", "target": 1}
{"idx": 456, "commit_message": "Merge pull request #195 from ccawley2011/patch-1  Avoid using unaligned memory access in UBSan builds", "target": 0}
{"idx": 1502, "commit_message": "feat: created a networks config in docker-compose, added new networks to the devserver and reaction services", "target": 0}
{"idx": 3590, "commit_message": "Correctly iterate over all SSA functions  Include methods and anonymous functions, and do it more efficiently.", "target": 1}
{"idx": 2772, "commit_message": "improve non-forked performance and minor improvements.", "target": 1}
{"idx": 1258, "commit_message": "Propagate error message from unfound dynamic lib when not found as builtin either. Fixes issue #282.", "target": 0}
{"idx": 3279, "commit_message": "JavaScriptCore does not have a good mechanism for performance regression testing [URL]/show_bug.cgi?id=67177  Reviewed by Darin Adler.  Added a new script, which allows for testing one, two, or more VMs at once on SunSpider, V8, and Kraken benchmarks.  Benchmark/VM runs are interleaved at random to minimize systematics.  The results that bencher prints includes all possible relevant information about how bencher was invoked.  Bencher can be easily used to measure performance changes down to fractions of a percent.  Bencher also includes experimental support for running benchmarks in a DumpRenderTree release build.  This works in SunSpider and V8, but not yet in Kraken.  Running benchmarks in DumpRenderTree more closely mimics the performance when running in browser.  * Scripts/bencher: Added.", "target": 0}
{"idx": 268, "commit_message": "Improve cli application bootstrap - based on doctrine-module", "target": 1}
{"idx": 1533, "commit_message": "Remove most of NetworkUIData.  As client certificate information is now retrieved from policy, most of NetworkUIData can be removed except ONCSource to indicate whether a network was managed after the policy got removed.  BUG=391292 [URL]  Review URL: [URL]/370623002", "target": 0}
{"idx": 2252, "commit_message": "Merge from gnus--rel--5.10  Patches applied:   * gnus--rel--5.10  (patch 145-148)     - Merge from emacs--devo--0    - Update from CVS  2006-10-04  Reiner Steib  < >     * lisp/gnus/gnus-sum.el (gnus-summary-make-menu-bar): Clarify    gnus-summary-limit-to-articles.  2006-10-04  Romain Francoise  [URL]>     * lisp/gnus/gnus-util.el (gnus-alist-to-hashtable, gnus-hashtable-to-alist):    Moved here (and renamed) from gnus-registry.el.     * lisp/gnus/gnus-registry.el: Require gnus-util.    Use `gnus-alist-to-hashtable' and `gnus-hashtable-to-alist'.  2006-10-04  Reiner Steib  < >     * lisp/gnus/pop3.el (pop3-authentication-scheme): Clarify doc.    (pop3-movemail): Warn about pop3-leave-mail-on-server.  2006-10-04  Dave Love  [URL]>     * lisp/gnus/pop3.el (pop3-authentication-scheme): Add custom version.  2006-10-04  Jesper Harder  < >     * lisp/gnus/pop3.el (pop3-leave-mail-on-server): Don't quote nil in    doc string.  Improve doc string.  2006-10-03  Katsumi Yamaoka  [URL]>     * lisp/gnus/gnus-util.el (gnus-with-local-quit): New macro.     * lisp/gnus/gnus-demon.el (gnus-demon): Replace with-local-quit with it.  2006-10-06  Reiner Steib  < >     * man/gnus.texi (Image Enhancements): Update for Emacs 22.     * man/gnus-faq.texi ([1.3]): Update.  Revision: [URL]/emacs--devo--0--patch-466", "target": 0}
{"idx": 2164, "commit_message": "For a while now, we've been using a stupid object I wrote called \"BogusQuerySet\" which would make a list look like a QuerySet object.  This really limited us in terms of sorting and ordering, but it was necessary because the \"incoming reviews\" dashboard page couldn't be created without it.  The reason behind this was that the OR operator on Q() objects was really dumb when it encountered a foreign key, and used an inner join.  This meant that instead of getting a union of everything, it gave some random collection of relations within the database.  Fortunately, some awesome person on [URL] write a Q implementation called QLeftOuterJoins which does what we want!  This lets us use an actual QuerySet, which means less code and much better performance.  Woo!  Reviewed at [URL]/r/155/", "target": 1}
{"idx": 691, "commit_message": "PERF: add the IsTranslucent method to the texture class. Returns true only if some pixels have values not fully transparent and not fully opaque, or if there are both opaque and transparent pixels and the Interpolate flag is ON. The result of this method is cached. Change the vtkActor::HasTranslucentPolygonalGeometry to use this method to detect translucent texture. This improves the point sprite mapper perf in sphere texture mode.", "target": 1}
{"idx": 3630, "commit_message": "MAGETWO-96463: Add caching to improve admin performance  - refactor fix in MagentoFrameworkConfigView", "target": 1}
{"idx": 3423, "commit_message": "cc: Replace recorded region with direct map lookup  If the viewport is extremely large, then keeping track of the recorded region in PicturePile with an actual Region becomes extremely slow due to a large number of rects being inserted into it.  The recorded region behaves as a cache to the picture map; it's a simpler way to know the state of all of the recordings contained within.  In practice, the recorded region is only used for two things: a \"should this pile bother to create tilings\" optimization and a \"can a tile be rastered in this content rect\" check aka CanRaster.  The optimization for \"should create tilings\" is replaced by a has_any_recordings_ boolean, which could have a false positive in theory (resizing to a smaller but non-empty size), but which shouldn't happen in practice.  Even if it did, this would only be a performance penalty for creating no-op tilings that can't create tiles (due to CanRaster).  The CanRaster check is replaced by a viewport hint, as most tiles that the tiling creates will be inside of the very large expanded viewport during recording, turning an expensive Region.Contains check to a Rect.Contains one.  In the edge cases where tiles are being created outside of that expanded viewport, it will check the picture map directly.  This should only happen when the user has scrolled thousands of pixels without a commit.  BUG=353346  Committed: [URL]/viewvc/chrome?view=rev&revision=256953  Review URL: [URL]/196343005", "target": 1}
{"idx": 3766, "commit_message": "python3-pywbem: Upgrade 1.1.3 -> 1.2.0  Upgrade to release 1.2.0 with bug fixes and enhancements:  - Finalized the pywbem mock support - Logging: Added a value 'off' for the log destination in the   pywbem.configure_logging() function that disables logging - Improved exception handling during the parsing of CIM-XML   responses received from a WBEM server - Reduced memory consumption of CIM objects and CIM types by   defining their attributes to use Python slots - Reduced memory consumption of CIM objects by using lazy   initialization of dictionary-type attributes - Unsupported versions for CIM infrastructure, DTD or protocol   version returned in CIM-XML responses from WBEM servers are   now raised as new exceptions pywbem - In the makefile, added an ignore list for issues reported by   safety along with the reasons why each issue is ignored - Improvements in the log messages of the MOFCompiler class - Added a conn_close() method to the pywbem.MOFCompiler class   that closes the underlying connection - Added 'make perftest' to run performance tests", "target": 1}
{"idx": 3257, "commit_message": "Making the namespace more specific in psr0 autoloader of Composer. This will help improve performance by reducing the number of useless calls to file_exists.", "target": 1}
{"idx": 95, "commit_message": "ACPICA: Add macros to extract flag bits from resource descriptors.  Improves readability and maintainability of the code.  Fixes a problem with the UART serial bus descriptor for the number of data bits flags (was incorrectly 2 bits, should be 3).", "target": 0}
{"idx": 4128, "commit_message": "[PATCH] More efficient generation of random numbers", "target": 1}
{"idx": 1717, "commit_message": "New UserSalt with every Login - Improvement", "target": 0}
{"idx": 1852, "commit_message": "Version 1.3.6  Add support for forceful termination of JavaScript execution.  Add low memory notification to the API. The embedding host can signal a low memory situation to V8.  Changed the handling of global handles (persistent handles in the API sense) to avoid issues regarding allocation of new global handles during weak handle callbacks.  Changed the growth policy of the young space.  Fixed a GC issue introduced in version 1.3.5.", "target": 0}
{"idx": 2909, "commit_message": "mutex: Queue mutex spinners with MCS lock to reduce cacheline contention  The current mutex spinning code (with MUTEX_SPIN_ON_OWNER option turned on) allow multiple tasks to spin on a single mutex concurrently. A potential problem with the current approach is that when the mutex becomes available, all the spinning tasks will try to acquire the mutex more or less simultaneously. As a result, there will be a lot of cacheline bouncing especially on systems with a large number of CPUs.  This patch tries to reduce this kind of contention by putting the mutex spinners into a queue so that only the first one in the queue will try to acquire the mutex. This will reduce contention and allow all the tasks to move forward faster.  The queuing of mutex spinners is done using an MCS lock based implementation which will further reduce contention on the mutex cacheline than a similar ticket spinlock based implementation. This patch will add a new field into the mutex data structure for holding the MCS lock. This expands the mutex size by 8 bytes for 64-bit system and 4 bytes for 32-bit system. This overhead will be avoid if the MUTEX_SPIN_ON_OWNER option is turned off.  The following table shows the jobs per minute (JPM) scalability data on an 8-node 80-core Westmere box with a 3.7.10 kernel. The numactl command is used to restrict the running of the fserver workloads to 1/2/4/8 nodes with hyperthreading off.  +-----------------+-----------+-----------+-------------+----------+ |  Configuration  | Mean JPM  | Mean JPM  |  Mean JPM   | % Change | |                 | w/o patch | patch 1   | patches 1&2 |  1->1&2  | +-----------------+------------------------------------------------+ |                 |              User Range 1100 - 2000            | +-----------------+------------------------------------------------+ | 8 nodes, HT off |  227972   |  227237   |   305043    |  +34.2%  | | 4 nodes, HT off |  393503   |  381558   |   394650    |   +3.4%  | | 2 nodes, HT off |  334957   |  325240   |   338853    |   +4.2%  | | 1 node , HT off |  198141   |  197972   |   198075    |   +0.1%  | +-----------------+------------------------------------------------+ |                 |              User Range 200 - 1000             | +-----------------+------------------------------------------------+ | 8 nodes, HT off |  282325   |  312870   |   332185    |   +6.2%  | | 4 nodes, HT off |  390698   |  378279   |   393419    |   +4.0%  | | 2 nodes, HT off |  336986   |  326543   |   340260    |   +4.2%  | | 1 node , HT off |  197588   |  197622   |   197582    |    0.0%  | +-----------------+-----------+-----------+-------------+----------+  At low user range 10-100, the JPM differences were within +/-1%. So they are not that interesting.  The fserver workload uses mutex spinning extensively. With just the mutex change in the first patch, there is no noticeable change in performance.  Rather, there is a slight drop in performance. This mutex spinning patch more than recovers the lost performance and show a significant increase of +30% at high user load with the full 8 nodes. Similar improvements were also seen in a 3.8 kernel.  The table below shows the %time spent by different kernel functions as reported by perf when running the fserver workload at 1500 users with all 8 nodes.  +-----------------------+-----------+---------+-------------+ |        Function       |  % time   | % time  |   % time    | |                       | w/o patch | patch 1 | patches 1&2 | +-----------------------+-----------+---------+-------------+ | __read_lock_failed    |  34.96%   | 34.91%  |   29.14%    | | __write_lock_failed   |  10.14%   | 10.68%  |    7.51%    | | mutex_spin_on_owner   |   3.62%   |  3.42%  |    2.33%    | | mspin_lock            |    N/A    |   N/A   |    9.90%    | | __mutex_lock_slowpath |   1.46%   |  0.81%  |    0.14%    | | _raw_spin_lock        |   2.25%   |  2.50%  |    1.10%    | +-----------------------+-----------+---------+-------------+  The fserver workload for an 8-node system is dominated by the contention in the read/write lock. Mutex contention also plays a role. With the first patch only, mutex contention is down (as shown by the __mutex_lock_slowpath figure) which help a little bit. We saw only a few percents improvement with that.  By applying patch 2 as well, the single mutex_spin_on_owner figure is now split out into an additional mspin_lock figure. The time increases from 3.42% to 11.23%. It shows a great reduction in contention among the spinners leading to a 30% improvement. The time ratio 9.9/2.33=4.3 indicates that there are on average 4+ spinners waiting in the spin_lock loop for each spinner in the mutex_spin_on_owner loop. Contention in other locking functions also go down by quite a lot.  The table below shows the performance change of both patches 1 & 2 over patch 1 alone in other AIM7 workloads (at 8 nodes, hyperthreading off).  +--------------+---------------+----------------+-----------------+ |   Workload   | mean % change | mean % change  | mean % change   | |              | 10-100 users  | 200-1000 users | 1100-2000 users | +--------------+---------------+----------------+-----------------+ | alltests     |      0.0%     |     -0.8%      |     +0.6%       | | five_sec     |     -0.3%     |     +0.8%      |     +0.8%       | | high_systime |     +0.4%     |     +2.4%      |     +2.1%       | | new_fserver  |     +0.1%     |    +14.1%      |    +34.2%       | | shared       |     -0.5%     |     -0.3%      |     -0.4%       | | short        |     -1.7%     |     -9.8%      |     -8.3%       | +--------------+---------------+----------------+-----------------+  The short workload is the only one that shows a decline in performance probably due to the spinner locking and queuing overhead.  [myfluxi: On our 3.4 base, this patch series gives another reproducable 3.5% advantage compared to commit a84eb3bd6fee57881e9405f6b1e2c91e2e88c5e0, which is significantly above the +- 1-2% standard variation.   Performance counter stats for 'hackbench 10  ' (10 runs):         2885.888073 task-clock                #    3.565 CPUs utilized  ( +-  0.75% )              16429 context-switches          #    0.006 M/sec  ( +-  7.47% )               4234 CPU-migrations            #    0.001 M/sec  ( +- 11.08% )              21541 page-faults               #    0.007 M/sec  ( +-  0.02% )         5959743473 cycles                    #    2.065 GHz  ( +-  0.70% ) [85.81%]                  0 stalled-cycles-frontend   #    0.00% frontend cycles idle  ( +-  0.00% ) [86.55%]                  0 stalled-cycles-backend    #    0.00% backend  cycles idle  ( +-  0.00% ) [88.53%]         2018815336 instructions              #    0.34  insns per cycle  ( +-  0.57% ) [88.31%]          195542833 branches                  #   67.968 M/sec  ( +-  0.80% ) [89.30%]            4178524 branch-misses             #    2.14% of all branches  ( +-  2.39% ) [76.06%]         0.807441968 seconds time elapsed  ( +-  1.86% )]", "target": 1}
{"idx": 1616, "commit_message": "Use explicit named scope, more query optimizations!", "target": 1}
{"idx": 1724, "commit_message": "cma: make default CMA area size zero for x86  This makes CMA memory area size zero for x86 in default configuration (doesn't change on the other architectures).  If default CMA size is zero, DMA_CMA is disabled.  It can be enabled by passing cma= to the kernel.  This makes less impact on x86.  Because there is no mainline driver that requires it for x86, and Peter Hurley reported the performance regression, as this is trying to drive _all_ dma mapping allocations through a _very_ small window.", "target": 0}
{"idx": 2991, "commit_message": "Remove the CoordinationTransformer from the coref system... makes the SemanticHeadFinder slightly worse but removing this makes it more efficient", "target": 1}
{"idx": 662, "commit_message": "re-fix Improve error tag message of JSON data format error.", "target": 0}
{"idx": 1410, "commit_message": "general AI + player controler improved", "target": 0}
{"idx": 3749, "commit_message": "Fixed one-to-one relation bug, with foreignkey [worked only with localkey] Fixed session flushing bug Faster session flushing algorithm Fixed couple of require_once errors", "target": 0}
{"idx": 3799, "commit_message": "Fixed mdl showing an error, and made code more efficient overall", "target": 1}
{"idx": 2785, "commit_message": "chunkd: eliminate double-writing of per-file object metadata  Previously, a PUT would         <write metadata header>         <write data>         <seek to beginning>         <write metadata header>  Eliminate the double-writing of the initial obj header by simply seek'ing to the data area immediately after opening the file. After the object is transferred and metadata may be filled in, write metadata fully at that time (immediately prior to close).  This reduces the amount of data written, should be more efficient for small objects, and eases future changes to object metadata area.", "target": 1}
{"idx": 2944, "commit_message": "Remove custom batch methods, smarter cholesky inverse, no dtype cast  This PR  1. Removes the custom batch_svd and batch_qr, methods since these are natively supported in pytorch 1.2.0 2. Replaces a `.inverse()` call on a cholesky factor with a triangular solve agaist the identity (using broadcasting across batches). This results in significant speedups for large matrices. 3. Removes casting to double before performing choleksy decompostion and cholesky solve. Profiling reveals that a non-trivial amount of time is being spent on these conversions. I believe these were added for numerical stability in the past, but with the changes to cholesky (both internal and upstream) this may not be an issue anymore.", "target": 1}
{"idx": 919, "commit_message": "Improve handling of custom type constructors", "target": 0}
{"idx": 2549, "commit_message": "Session helpers are improved with better dot notation access in performance.", "target": 1}
{"idx": 2392, "commit_message": "PR#5201: ocamlbuild: add --norc to the bash invocation to help Windows performances  This change was recommend by daweil on the bugtracker. According to the Bash documentation, the option -c that is already passed by ocamlbuild should already imply --norc, but daweil reported a 30% performance speedup with this change anyway. I'm a bit surprised, but this cannot hurt...", "target": 1}
{"idx": 980, "commit_message": "perf(py): Compute initial interfaces without seadsa callgraphs  We compute the initial interfaces using LLVM callgraphs.  After intra- and inter-specialization and optimization have been completed we use seadsa callgraphs to compute again interfaces and propagate informatino until fixpoint.  This approach should not affect precision but it should be faster. The idea is to use a cheap callgraph first and then use a more expensive but precise callgraph once the modules have been already optimized.", "target": 1}
{"idx": 2903, "commit_message": "significantly improving mysql performance - as planned a while ago", "target": 1}
{"idx": 1180, "commit_message": "refactor(form-builder): improve use of `@sanity/ui` in FileInput", "target": 0}
{"idx": 3467, "commit_message": "lib/int_sqrt.c: optimize square root algorithm  Optimize the current version of the shift-and-subtract (hardware) algorithm, described by John von Newmann[1] and Guy L Steele.  Iterating 1,000,000 times, perf shows for the current version:   Performance counter stats for './sqrt-curr' (10 runs):           27.170996 task-clock                #    0.979 CPUs utilized            ( +-  3.19% )                  3 context-switches          #    0.103 K/sec                    ( +-  4.76% )                  0 cpu-migrations            #    0.004 K/sec                    ( +-100.00% )                104 page-faults               #    0.004 M/sec                    ( +-  0.16% )         64,921,199 cycles                    #    2.389 GHz                      ( +-  0.03% )         28,967,789 stalled-cycles-frontend   #   44.62% frontend cycles idle     ( +-  0.18% )    <not supported> stalled-cycles-backend        104,502,623 instructions              #    1.61  insns per cycle                                              #    0.28  stalled cycles per insn  ( +-  0.00% )         34,088,368 branches                  # 1254.587 M/sec                    ( +-  0.00% )              4,901 branch-misses             #    0.01% of all branches          ( +-  1.32% )         0.027763015 seconds time elapsed                                          ( +-  3.22% )  And for the new version:  Performance counter stats for './sqrt-new' (10 runs):            0.496869 task-clock                #    0.519 CPUs utilized            ( +-  2.38% )                  0 context-switches          #    0.000 K/sec                  0 cpu-migrations            #    0.403 K/sec                    ( +-100.00% )                104 page-faults               #    0.209 M/sec                    ( +-  0.15% )            590,760 cycles                    #    1.189 GHz                      ( +-  2.35% )            395,053 stalled-cycles-frontend   #   66.87% frontend cycles idle     ( +-  3.67% )    <not supported> stalled-cycles-backend            398,963 instructions              #    0.68  insns per cycle                                              #    0.99  stalled cycles per insn  ( +-  0.39% )             70,228 branches                  #  141.341 M/sec                    ( +-  0.36% )              3,364 branch-misses             #    4.79% of all branches          ( +-  5.45% )         0.000957440 seconds time elapsed                                          ( +-  2.42% )  Furthermore, this saves space in instruction text:     text    data     bss     dec     hex filename     111       0       0     111      6f lib/int_sqrt-baseline.o      89       0       0      89      59 lib/int_sqrt.o  [1] [URL]/wiki/First_Draft_of_a_Report_on_the_EDVAC", "target": 1}
{"idx": 1987, "commit_message": "Improved layout for top 10 companies widget", "target": 0}
{"idx": 1644, "commit_message": "Improved help output and added -tc list.", "target": 0}
{"idx": 2380, "commit_message": "Getting summary from Algolia API  Much improved performance!", "target": 1}
{"idx": 3612, "commit_message": "When accessing an Django model object via another for the sole purpose of using that object in a lookup, then it's wasteful to possibly cause a database hit, when all you really want is the id of the object.  For example, in    TranslationProject.objects.filter(project=translation_project.project)  the code    translation_project.project  might result in a database hit to load the 'project' object. But here we are actually interested only in the id of the project object. Therefore it's more efficient to rewrite the above as    TranslationProject.objects.filter(project=translation_project.project_id)", "target": 1}
{"idx": 1809, "commit_message": "memcg: make mem_cgroup_read_stat() unsigned  mem_cgroup_read_stat() returns a page count by summing per cpu page counters.  The summing is racy wrt.  updates, so a transient negative sum is possible.  Callers don't want negative values:   - mem_cgroup_wb_stats() doesn't want negative nr_dirty or nr_writeback.    This could confuse dirty throttling.   - oom reports and memory.stat shouldn't show confusing negative usage.   - tree_usage() already avoids negatives.  Avoid returning negative page counts from mem_cgroup_read_stat() and convert it to unsigned.  [URL]: fix old typo while we're in there]", "target": 0}
{"idx": 1398, "commit_message": "Performance enhancement to isConnected();   It's much quicker to check null (internally Z_TYPE macro), before checking instanceof.  This method has efficiently been applied to initialize().", "target": 1}
{"idx": 3629, "commit_message": "Use atomic operations on pending_threads and spin when stopping the world  This greatly improves performance of the gc_dependent / gc_independent barrier. This barrier is often crossed for potentially blocking and GC indepedenent functions such as FFI and IO calls.  This makes these calls a lot cheaper because in the common case of not needing to GC they only have to automatically increase and decrease the pending_threads_ counter instead of doing a full lock / unlock.", "target": 1}
{"idx": 1135, "commit_message": "Add fitMode property on Image Elements. (#4206)  * Add aspectRatio setting on Image Elements.    * Add comments and test name.    * Refactor preserveAspect to be a string instead of number; Improve checks.    * Rename to fitMode.    * Rename constants.    * Improve comments and documentation.", "target": 0}
{"idx": 1643, "commit_message": "[AIR CUJ] Add wait_for_nodes for 4x4 gpu test", "target": 0}
{"idx": 3183, "commit_message": "[stats] Improved materialized views for better performance in queries", "target": 1}
{"idx": 3487, "commit_message": "fix linestring/polygon lineDasharray render performance is poor (#1464)  * fix polygon lineDasharray render performance is poor    * update    * fix linestring linDasharray render performance is poor    * linestring clip not buffer clipbbox    * VectorLayer  support options.clipBBoxBufferSize config    * fix linestring pixel clip error    * update    * update    * style util add isDashLine func    * symbol lineDash pixel clip test", "target": 1}
{"idx": 1739, "commit_message": "arm: dra7xx: Add gpu hwmod  GPU hwmod data for DRA7xx", "target": 0}
{"idx": 3856, "commit_message": "[SPARK-37915][SQL] Combine unions if there is a project between them  ### What changes were proposed in this pull request?  This pr makes `CombineUnions` combine unions if there is a project between them. For example: ```scala spark.range(1).selectExpr(\"CAST(id AS decimal(18, 1)) AS id\").write.saveAsTable(\"t1\") spark.range(2).selectExpr(\"CAST(id AS decimal(18, 2)) AS id\").write.saveAsTable(\"t2\") spark.range(3).selectExpr(\"CAST(id AS decimal(18, 3)) AS id\").write.saveAsTable(\"t3\") spark.range(4).selectExpr(\"CAST(id AS decimal(18, 4)) AS id\").write.saveAsTable(\"t4\") spark.range(5).selectExpr(\"CAST(id AS decimal(18, 5)) AS id\").write.saveAsTable(\"t5\")  spark.sql(\"SELECT id FROM t1 UNION SELECT id FROM t2 UNION SELECT id FROM t3 UNION SELECT id FROM t4 UNION SELECT id FROM t5\").explain(true) ```  Before this pr: ``` == Optimized Logical Plan == Aggregate [id#36], [id#36] +- Union false, false    :- Aggregate [id#34], [cast(id#34 as decimal(22,5)) AS id#36]    :  +- Union false, false    :     :- Aggregate [id#32], [cast(id#32 as decimal(21,4)) AS id#34]    :     :  +- Union false, false    :     :     :- Aggregate [id#30], [cast(id#30 as decimal(20,3)) AS id#32]    :     :     :  +- Union false, false    :     :     :     :- Project [cast(id#25 as decimal(19,2)) AS id#30]    :     :     :     :  +- Relation default.t1[id#25] parquet    :     :     :     +- Project [cast(id#26 as decimal(19,2)) AS id#31]    :     :     :        +- Relation default.t2[id#26] parquet    :     :     +- Project [cast(id#27 as decimal(20,3)) AS id#33]    :     :        +- Relation default.t3[id#27] parquet    :     +- Project [cast(id#28 as decimal(21,4)) AS id#35]    :        +- Relation default.t4[id#28] parquet    +- Project [cast(id#29 as decimal(22,5)) AS id#37]       +- Relation default.t5[id#29] parquet ```  After this pr: ``` == Optimized Logical Plan == Aggregate [id#36], [id#36] +- Union false, false    :- Project [cast(id#25 as decimal(22,5)) AS id#36]    :  +- Relation default.t1[id#25] parquet    :- Project [cast(id#26 as decimal(22,5)) AS id#46]    :  +- Relation default.t2[id#26] parquet    :- Project [cast(id#27 as decimal(22,5)) AS id#45]    :  +- Relation default.t3[id#27] parquet    :- Project [cast(id#28 as decimal(22,5)) AS id#44]    :  +- Relation default.t4[id#28] parquet    +- Project [cast(id#29 as decimal(22,5)) AS id#37]       +- Relation default.t5[id#29] parquet ```  ### Why are the changes needed?  Improve query performance by reduce shuffles.  ### Does this PR introduce _any_ user-facing change?  No.  ### How was this patch tested?  Unit test.  Closes #35214 from wangyum/SPARK-37915.  Authored-by: Yuming Wang [URL]>", "target": 1}
{"idx": 2429, "commit_message": "updated cropping sheme (about factor 2 performance improvement) and changed trading income parameters such that traders increase income more quickly", "target": 1}
{"idx": 1735, "commit_message": "Add:  template<class Type>  void vpImageTools::binarise(vpImage<Type> &I,                              Type threshold1, Type threshold2,                              Type value1, Type value2, Type value3) Doc improvement", "target": 0}
{"idx": 3886, "commit_message": "workqueue: reimplement work_on_cpu() using system_wq  The existing work_on_cpu() implementation is hugely inefficient.  It creates a new kthread, execute that single function and then let the kthread die on each invocation.  Now that system_wq can handle concurrent executions, there's no advantage of doing this.  Reimplement work_on_cpu() using system_wq which makes it simpler and way more efficient.  stable: While this isn't a fix in itself, it's needed to fix a         workqueue related bug in cpufreq/powernow-k8.  AFAICS, this         shouldn't break other existing users.", "target": 1}
{"idx": 868, "commit_message": "intelli_plug: use mp_decision to reduce online persistence count for cores  this should bring down the cores faster when run queue is low also optimized code a bit using local vars", "target": 1}
{"idx": 2765, "commit_message": "Slightly more efficient _remove_slashes() method on Resource", "target": 1}
{"idx": 2674, "commit_message": "very minor performance optimization to the site method  ( )", "target": 1}
{"idx": 2221, "commit_message": "- Updated  @refine to take account of MAX_REFINE, thanks to Omega... GM Designer. - Also optimized the @refine loop for better performance.", "target": 1}
{"idx": 1044, "commit_message": "This might still not be optimal  The \"write\" might not be an actual write, and in that case it need not open the device file which would be much better. I would need to verify that but in the meantime this is an improvement over \"manage\" if it works.", "target": 0}
{"idx": 3828, "commit_message": "some clearification in the readme, nicer output  changed to clang to produce better looking assembly (it seems clang helps on performance as well)", "target": 0}
{"idx": 3316, "commit_message": "Lazily resolve the callable for better performance", "target": 1}
{"idx": 3424, "commit_message": "Update BFQ to v7r4  Budget Fair Queueing I/O Scheduler ==================================  This patchset introduces BFQ-v7r4 into Linux 3.4.0. For further information: http://www.algogroup.unimo.it/people/paolo/disk_sched/.  CHANGELOG  v7r4: . BUGFIX. Modified the code so as to be robust against late detection of   NCQ support for a rotational device. . BUGFIX. Removed a bug that hindered the correct throughput distribution   on flash-based devices when not every process had to receive the same   fraction of the throughput. This fix entailed also a little efficiency   improvement, because it implied the removal of a short function executed   in a hot path. . CODESTYLE IMPROVEMENT: removed quoted strings split across lines.  CREDIT: Paolo Valente", "target": 1}
{"idx": 3323, "commit_message": "Fixed yet another (last?) issue in clean exit.  When peers are closing, timeout (2 seconds) is used (in case remote peer is not reachable, local peer at most waits timeout period). The timeout is not removed in case of successful delivery of message (it is more efficient to just cleanup while going through invalid timeouts instead of maintaining and cleaning timeouts). The fix now is to introduce a dummy short timeout in '_exit' so that the scheduler doesn't wait for next timeout. This should fix closing asyncoro when timeouts are used in coroutines that didn't wait until timeouts (e.g., daemons).  Now discoronode cleanly exits without (sometimes) waiting for timeout.", "target": 0}
{"idx": 1567, "commit_message": "auto_execute turned off during module creation and also during network deserialisation.", "target": 0}
{"idx": 3419, "commit_message": "Use [URL] JSON format in results page [URL]/show_bug.cgi?id=110842  Reviewed by Benjamin Poulain.  PerformanceTests:   Updated the results page template to use the new JSON format.  Since new JSON format doesn't contain statistics such as stdev and min, added statistics.js to compute these values. Also use 95% percentile confidence interval instead of standard deviation in various places.  * resources/results-template.html: Added statistics.js as dependency. (TestResult): Updated to take a metric instead of its test. Replaced stdev() with confidenceIntervalDelta() now that we have a fancy Statistics class.  (TestRun.webkitRevision): (PerfTestMetric): Renamed from PerfTest since this object now encapsulates each measurement (such as time, JS heap, and malloc) in test. Also added a conversion table from a metric name to a unit since new format doesn't contain units. (PerfTestMetric.name): Updated to compute the full metric name from test name and metric name, matching the old behavior. (PerfTestMetric.isMemoryTest): Explicitly look for 'JSHeap' and 'Malloc' tests. (PerfTestMetric.smallerIsBetter):  (attachPlot): Deleted the code to deal with tests that don't provide individual iteration measurement since such tests no longer exist. Also fixed up the code compute y-axis range.  (createTableRow.markupForRun): Updated to use confidenceIntervalDelta() instead of stdev().          (init.addTests): Added. Recursively add metrics.  * resources/statistics.js: Added. Imported from [URL]. (Statistics.max): (Statistics.min): (Statistics.sum): (Statistics.squareSum): (Statistics.sampleStandardDeviation): (Statistics.supportedConfidenceLevels): (Statistics.confidenceIntervalDelta): (Statistics.confidenceInterval):  Tools:   Change the default JSON format from that of [URL] to that of [URL].  A whole bunch of integration tests have been updated to use the new JSON format.  * Scripts/webkitpy/performance_tests/perftestsrunner.py: (PerfTestsRunner._generate_and_show_results): Renamed output and output_path to legacy_output and legacy_output_json_path respectively. (PerfTestsRunner._generate_results_dict): Don't assume meta build information is always available. (PerfTestsRunner._generate_output_files): Make json_output, which is used to generate the default JSON file and the results page out of perf_webkit_output instead of legacy_output.  * Scripts/webkitpy/performance_tests/perftestsrunner_integrationtest.py: (MainTest.test_run_memory_test): (MainTest._test_run_with_json_output.mock_upload_json): (MainTest): (MainTest.test_run_with_json_output): (MainTest.test_run_with_description): (MainTest.test_run_generates_json_by_default): (MainTest.test_run_merges_output_by_default): (MainTest.test_run_respects_reset_results): (MainTest.test_run_generates_and_show_results_page): (MainTest.test_run_with_slave_config_json): (MainTest.test_run_with_multiple_repositories): (MainTest.test_run_with_upload_json): (MainTest.test_run_with_upload_json_should_generate_perf_webkit_json):", "target": 0}
{"idx": 2727, "commit_message": "chrony: upgrade 4.1 -> 4.2  refresh arm_eabi.patch  Changelog: ========== Enhancements -Add support for NTPv4 extension field improving synchronisation stability and resolution of root delay and dispersion (experimental) -Add support for NTP over PTP (experimental) -Add support for AES-CMAC and hash functions in GnuTLS -Improve server interleaved mode to be more reliable and support multiple clients behind NAT -Update seccomp filter -Add statistics about interleaved mode to serverstats report  Bug fixes -Fix RTC support with 64-bit time_t on 32-bit Linux -Fix seccomp filter to work correctly with bind*device directives -Suppress kernel adjustments of system clock (dosynctodr) on illumos  Other changes -Switch Solaris support to illumos", "target": 0}
{"idx": 3727, "commit_message": "git.el: Set process-environment instead of invoking env  This will make it a little less posix-dependent, and more efficient.  Included is also a minor doc improvement.", "target": 1}
{"idx": 3094, "commit_message": "Merge pull request #1515 from endocode/tixxdz/fleetd-quick-units-optimisations-v1  fleetd:registry: improve Units() performance remove extra loops when fetching Jobs list from etcd", "target": 1}
{"idx": 1568, "commit_message": "Added contiguous_range and string_view  contiguous_range:   Allows for a read/write view into a contiguous part of memory   Has a number of the iteration concepts of containers  string_view:   Allows for a read-only view into a contiguous part of string data (string/char*/char[])   Has a number of the iteration concepts of containers   Has a number of the string read only concepts (find/rfind/find_first_of/find_last_of)  Removed WNContainers overall header.  No need for this anymore. Added natvis for new types", "target": 0}
{"idx": 1509, "commit_message": "msm: kgsl: Don't make assumptions about VMA regions  We cannot assume that a VMA region created as a result of an mmap belongs exclusively to us.  Allow the user to pass the size of the vmalloc region through the 'gpuaddr' member of the ioctl struct and do strict checking on the returned vma to make sure it is valid.  Wei Zou [URL]> Modded by faux123", "target": 0}
{"idx": 2290, "commit_message": "Now using singleton nullptr object that improves performance.", "target": 1}
{"idx": 712, "commit_message": "KVM: x86: Improve thread safety in pit  commit 2febc839133280d5a5e8e1179c94ea674489dae2 upstream.  There's a race condition in the PIT emulation code in KVM.  In __kvm_migrate_pit_timer the pit_timer object is accessed without synchronization.  If the race condition occurs at the wrong time this can crash the host kernel.  This fixes CVE-2014-3611.", "target": 0}
{"idx": 798, "commit_message": "Bug#11902767/Bug#60580: Statement improperly replicated crashes slave SQL thread  If LOAD DATA INFILE featured a SET clause, the name=value pairs would be regenerated using item::print. Unfortunately, that code is mostly optimized for EXPLAIN EXTENDED output and such, and can not be relied on to return valid SQL.  We now name each value its original, user-supplied form and use that to create LOAD DATA INFILE statements for statement-based replication.", "target": 0}
{"idx": 160, "commit_message": "Improve icon set  Change Log: ----------- * Change 'add question' and 'study plan' icons to a consistent style with the rest of the button icons * Change warning icon to a 'honey mustard yellow'", "target": 0}
{"idx": 237, "commit_message": "sched/cpufreq_sched: fix thermal capping events  cpufreq_sched_limits (called when CPUFREQ_GOV_LIMITS event happens) bails out if policy->rwsem is already locked. However, that rwsem is always guaranteed to be locked when we get here after a thermal throttling event happens:   th_throttling ->    cpufreq_update_policy()      ...      down_write(&policy->rwsem);      ...      cpufreq_set_policy() ->        ...        __cpufreq_governor(policy, CPUFREQ_GOV_LIMITS); ->          cpufreq_sched_limits()          ...          if (!down_write_trylock(&policy->rwsem))                  return; <-- BAIL OUT!  So, we don't currently react immediately to thermal capping event (even if reaction is still quick in practice, ~1ms, as lots of events are likely to trigger a frequency selection on a high loaded system).  Fix this bug by removing the bail out condition.  While we are at it we also slightly change handling of the new limits by clamping the last requested_freq between policy's max and min. Doing so gives us the oppurtunity to correctly restore the last requested frequency as soon as a thermal unthrottling event happens.  bug: 30481949", "target": 0}
{"idx": 2055, "commit_message": "Tweak how we match wildcard ad filters to fix a major performance problem  matching some very long URLs reported by maelcum   svn path=/branches/KDE/4.4/kdelibs/; revision=1095892", "target": 1}
{"idx": 2232, "commit_message": "i965: Fix cross-primitive scratch corruption when changing the per-thread allocation.  I haven't found any mention of this in the hardware docs, but experimentally what seems to be going on is that when the per-thread scratch slot size is changed between two pipelined draw calls, shader invocations using the old and new scratch size setting may end up being executed in parallel, causing their scratch offset calculations to be based in a different partitioning of the scratch space, which can cause their thread-local scratch space to overlap leading to cross-thread scratch corruption.  I've been experimenting with alternative workarounds, like emitting a PIPE_CONTROL with DC flush and CS stall between draw (or dispatch compute) calls using different per-thread scratch allocation settings, or avoiding reuse of the scratch BO if the per-thread scratch allocation doesn't exactly match the original.  Both seem to be as effective as this workaround, but they have potential performance implications, while this should be basically for free.  Fixes over 40 failures in our CI system with spilling forced on (including CTS, dEQP and Piglit failures) on a number of different platforms from Gen4 to Gen9.  The 'glsl-max-varyings' piglit test seems to be able to reproduce this bug consistently in the vertex shader on at least Gen4, Gen8 and Gen9 with spilling forced on.  Cc: [URL]>", "target": 0}
{"idx": 4005, "commit_message": "[PATCH] Tiny libmesh_assert_valid_boundary_ids speedup\n\nThis is actually pretty slow in parallel.  Truly making it faster\nwould require lumping multiple verification communications together,\nbut eliminating redundant verification is a start, at a slightly lower\npenalty to readability and usability.", "target": 1}
{"idx": 3098, "commit_message": "Revert of Shape unicode-range: font faces in only one iteration (patchset #7 id:180001 of [URL]/1806653002/ )  Reason for revert: Reverting on a suspicion that this is a root cause to the failures of webkit_unit_tests on Webkit Android (Nexus4) bots, e.g. [URL]/p/chromium.webkit/builders/WebKit%20Android%20%28Nexus4%29/builds/44725  Original issue's description: > Shape unicode-range: font faces in only one iteration > > Previously, we incorrectly split CSS composite faces into multiple faces > for shaping, one for each comma-separated entry of unicode-range:. This > breaks shaping of ligatures and other features when the characters that > ought to be shaped combined were in different unicode-range entries. It > is also inefficient for subsetted web fonts that use unicode-range: > extensively, for example Google Fonts and Adobe TypeKit. > > The fix is to transfer the UnicodeRangeSet information from CSSFontFace > to HarfBuzzFace and only restrict the glyph lookup function to the whole > unicode-range information, instead of restricting it to a single entry > and shaping multiple times with the same face. This should have a slight > performance benefit as well. > > BUG=583450 > TEST=fast/css/font-face-unicode-range-ligatures.html > R=eae, behdad > > Committed: [URL]/9694005f93116f9c9cc73fa99132fa4475a0cdab >", "target": 1}
{"idx": 2094, "commit_message": "-Droid Assemblers now spawn all types of droids -Droid Assemblers now spawn based on their facing. -Droid SMG damage increased slightly. -added Clockwork Riflebot, an early-game slow firing medium-long range bot. -Terminator ammo category changed to combat-robot-laser to take advantage of robot damage upgrade tree -Clockwork rifle bot and SMG bot use the player's gun damage and shooting speed upgrades ammo category (not changed, just noted) -massive performance improvements, fixed droids \"dancing", "target": 1}
{"idx": 2564, "commit_message": "NN: always use full EBox::Sudo namespace and group commands to improve performance when possible", "target": 1}
{"idx": 2500, "commit_message": "f2fs: remove percpu_count due to performance regression  This patch removes percpu_count usage due to performance regression in iozone.  Fixes: 523be8a6b3 (\"f2fs: use percpu_counter for page counters\")", "target": 1}
{"idx": 177, "commit_message": "Match: use targeting logic to manage discarding. Also optimize Text", "target": 1}
{"idx": 3776, "commit_message": "Merge pull request #26119 from dimagi/bmb/SAASP-10103  [Exports] Improve performance of get_column in TableConfiguration", "target": 1}
{"idx": 2604, "commit_message": "Minor performance improvements.  Ignore-this: 6a7640a9d47a2a7ed041ced3f7e94abf  darcs-hash:20090308125422-ed7c9-6568c5f9499b5e6d86cb05e22db920c62dc8f51f.gz", "target": 1}
{"idx": 3685, "commit_message": "Allow Drydock Blueprints to control \"supplemental allocation\" behavior so all hosts in an Almanac pool get used  Summary: Fixes T12145. Ref T13210. See PHI570. See PHI536.  Currently, when you give Drydock an Almanac host pool with more than one host, it never voluntarily builds a second host resource: there is no way to say \"maximum X working copies per host\" (only \"maximum X global working copies\") to make the first host overflow, and the allocator tries to pack resources as tightly as possible.  If you can force it to allocate the 2nd..Nth host, things will work reasonably well from there (it will spread working copies across the hosts randomly), but tricking it is very hard, especially before D19761.  To deal with this, give blueprints a new behavior around \"supplemental allocations\". The idea here is that a blueprint may decide that it would prefer to allocate a fresh new resource instead of allowing an otherwise valid acquisition to occur.  These supplemental allocations follow all the normal allocation rules (they can't exceed limits or actually replace existing resources), so they can only happen if there's free space in the resource pool. But a blueprint can elect for a supplemental allocation to provide a \"grow the pool\" hint.  The only useful policies here are probably \"true\" (immediately use all resources, like Almanac) or \"false\" (pack resources as efficiently as possible) but some other policies //might// be useful (perhaps \"start growing the pool when we're getting a bit full even if we aren't at the limit yet, since our workload is bursty\").  Then, give Almanac host resources a \"true\" policy (always allocate supplemental resources) so they use all hosts once a similar number of concurrent jobs arrive.  One aspect of this approach is that we only do supplemental resources if the normal allocation algorithm already decided that the best resource to acquire was part of the same blueprint. I started with an approach like \"look at all the blueprints and see if any of them want to be greedy\", but then a not-very-desirable blueprint would end up filling up its whole pool before we skipped the supplemental allocation part and ended up picking a different resource. That felt a bit silly and this feels a little cleaner and more focused.  Test Plan:   - Without changing the Almanac blueprint policy, allocated hosts. Got A, A, A, A, ... (second host never used).   - Changed the Almanac policy.   - Allocated hosts, got A, B, random mix of A and B.   - Destroyed B. Destroyed all leases on A. Allocated. Got A. This tests the \"don't build a supplemental resource if there are no leases on the natural resource\".  Reviewers: amckinley  Reviewed By: amckinley  Subscribers: yelirekim, PHID-OPKG-gm6ozazyms6q6i22gyam  Maniphest Tasks: T13210, T12145  Differential Revision: [URL]/D19762", "target": 0}
{"idx": 144, "commit_message": "Added new test suite to detect regressions for optimizations.", "target": 0}
{"idx": 2040, "commit_message": "Make even more efficient RmAddr calculation - good optimizing compiler could make more efficient code than it was before", "target": 1}
{"idx": 464, "commit_message": "ErrorMsg  Improve error message log for user", "target": 0}
{"idx": 3242, "commit_message": "* added asynchronous allocation of array through unique_ptr construct very useful for the dynamic pipeline layout and for scratch/temporary arrays therein;  * optimized the use of temporary objects during   dynamic_pipeline::encode call by using scratch space allocated asynchronously  * these improvements pushed the runtime of a simple pass_through pipeline (only copying the inputs to the outputs) from 1GB/s to 8GB/s. For any payload above LLC size, this is about the performance of an isolated call to std::copy (i.e. the dynamic pipeline has negligable overhead)", "target": 1}
{"idx": 3686, "commit_message": "PHANTOM-76: Add lightweight transaction support for inserts. PHANTOM-75: Re-structure the query mechanism to allow more efficient sharing of methods.", "target": 1}
{"idx": 2677, "commit_message": "Merge branch '4.2'  * 4.2: (45 commits)   [Form] various minor fixes   Ensure the parent process is always killed   bugfix: the terminal state was wrong and not reseted   [Console] Fix inconsistent result for choice questions in non-interactive mode   Define null return type for Constraint::getDefaultOption()   [Routing] Fix: annotation loader ignores method's default values   [HttpKernel] Fix DebugHandlersListener constructor docblock   Skip Glob brace test when GLOB_BRACE is unavailable   bumped Symfony version to 4.2.6   updated VERSION for 4.2.5   updated CHANGELOG for 4.2.5   bumped Symfony version to 3.4.25   updated VERSION for 3.4.24   update CONTRIBUTORS for 3.4.24   updated CHANGELOG for 3.4.24   [EventDispatcher] cleanup   fix testIgnoredAttributesInContext   Re-generate icu 64.1 data   Improve PHPdoc / IDE autocomplete for config tree builder   [Bridge][Twig] DebugCommand - fix escaping and filter   ...", "target": 0}
{"idx": 2116, "commit_message": "Fixing support for multi-segment SICDs.  Allocating memory more efficiently and using an RAII class.  Adding the ability to set the version of the SICD/SIDD XML that's written out.  #292.", "target": 1}
{"idx": 2615, "commit_message": "Merge pull request #109 from miraaz/patch-1  rc.local improvement", "target": 0}
{"idx": 3715, "commit_message": "new append functionality/performance improvement for ham_cursor_insert", "target": 1}
{"idx": 1799, "commit_message": "Normalize all merge/split code into block-type agnostic class  Hooray, a single class for all the merge/split code. It probably still needs a cleanup, but this is a vast improvement from what we had before. No more sub-class for every block type that each contained hundreds of lines of duplicated code!", "target": 0}
{"idx": 1375, "commit_message": "Improve documentation of debugging Lisp syntax error  * doc/lispref/debugging.texi (Syntax Errors, Excess Open) (Excess Close): Name the commands invoked by the key sequences.  Add cross-references to appropriate sections of the Emacs manual.  (Bug#21385)", "target": 0}
{"idx": 2036, "commit_message": "C binding for leveldb, better readseq benchmark for SQLite.  - Added a C binding for LevelDB.   May be useful as a stable ABI that can be used by    programs that keep leveldb in a shared library,    or for JNI API.  - Replaced SQLite's readseq benchmark to a more efficient version.    SQLite readseq speeds increased by about a factor of 2x    from the previous version. Also updated benchmark page to   reflect readseq speed up.", "target": 1}
{"idx": 4046, "commit_message": "[PATCH] #1285 Refactred substituteInPlace. Now more efficient and has\n same signature for SX and MX.", "target": 1}
{"idx": 3404, "commit_message": "Merge pull request #14 from ReactKit/refactor/remove-SwiftState  Remove SwiftState dependency for significant performance improvement.", "target": 1}
{"idx": 2826, "commit_message": "ARM Skia NEON patches - 23 - S32_D565_Opaque_Dither cleanup/bugfix/speed     BlitRow565: S32_D565_Opaque_Dither: cleaning / bugfix  This patch brings a little code cleaning (spaces/comments) and a little speed improvement (by using post-incrementation in the asm) but more importantly it fixes a bug on Linux. The new code now supports ARGB as well as ABGR.  I removed the comment as I have confirmed with benchmarks that this code bring a *massive* (3x-7x) speedup compared to the C code.", "target": 1}
{"idx": 2459, "commit_message": "IMPALA-8214: Fix bad plan in load_nested.py  The previous plan had the larger input on the build side of the join and did a broadcast join, which is very suboptimal.  This speeds up data loading on my minicluster - 18s vs 31s and has a more significant impact on a real cluster, where queries execute much faster, the memory requirement is significantly reduced and the data loading can potentially be broken up into fewer chunks.  I also considered computing stats on the table to let Impala generate the same plan, but this achieves the same goal more efficiently.  Testing: Run core tests. Resource estimates in planner tests changed slightly because of the different distribution of data.", "target": 1}
{"idx": 3245, "commit_message": "[PATCH] libata: Marvell SATA support (DMA mode) (resend: v0.22)  This is my libata compatible low level driver for the Marvell SATA family.  Currently it runs in DMA mode on a 6081 chip.  The 5xxx series parts are not yet DMA capable in this driver because the registers have differences that haven't been accounted for yet. Basically, I'm focused on the 6xxx series right now.  I apologize for those seeing problems on the 5xxx series, I've not had a chance to look at those problems yet.  For those curious, the previous bug causing the SCSI timeout and subsequent panics was caused by an improper clear of hc_irq_cause in mv_host_intr().  This version is running well in my environment (6081 chips, with/without SW raid1) and is showing equal or better performance compared to the Marvell driver (mv_sata) in my initial tests (timed dd's of reads/writes to/from memory/disk).  I still need to look at the causes of occasional problems such as this:  ata11: translating stat 0x35 err 0x00 to sense ata11: status=0x35 { DeviceFault SeekComplete CorrectedError Error } SCSI error : <10 0 0 0> return code = 0x8000002 Current sda: sense key Hardware Error end_request: I/O error, dev sda, sector 3155010  and this, seen at init time:  ATA: abnormal status 0x80 on port 0xE093911C  but they aren't showstoppers.", "target": 1}
{"idx": 2350, "commit_message": "Provide better support for libucontext  For some reason, the Makefile in libucontext is broken -- building it with meson fixes the generated libraries, which do not export the symbols and as a result, no symbol interposition ends up taking place.  To force those symbols to be used, use the `libucontext_` prefixed versions; at least we'll get a build error in Lwan if libucontext wasn't built correctly rather than silently building and then using the libc ucontext functions and definitions.  I have confirmed that Lwan doesn't make calls to block/unblock the signal mask on AARCH64, which happens when using the libc ucontext functions.  This should improve performance on non-x86 systems where libucontext is supported.", "target": 1}
{"idx": 3921, "commit_message": "[FLINK-22022][table-planner-blink] Reduce the ExecNode scan scope to improve performance when converting json plan to ExecNodeGraph  This closes #15426", "target": 1}
{"idx": 2853, "commit_message": "resize placeholder images for better performance", "target": 1}
{"idx": 2026, "commit_message": "finagle-http: Improve performance of TraceInfo  Problem  `c.t.f.http.TraceInfo` has some easy opportunities for optimizimation.  Solution  Do our basics:  * Convert `Option.map` into `match` * Avoid `foreach` when manual iteration will do * Use `try-catch` instead of a `Try`  Result  Less allocations in common code.  This also moves the code off of the internally exposed Netty3 APIs onto our public APIs.  Also removes some `private[finagle]` code that was only used in tests.  RB_ID=887684", "target": 1}
{"idx": 3907, "commit_message": "fixed chole-err bug  adjusted max-multimin to be a bit more generous in the stopping criteria and reduced the stringency of the linesearch, this appears to improve performance  added additional feedback to the threads - likelihood output from the estimation process, now prints the actual winning thetas for each thread  made the output more consistant in interactive emulator and across the board", "target": 1}
{"idx": 2612, "commit_message": "Avoid multiple recursions through the tree when calculating percent height  Test=PerformanceTests/Layout/nested-blocks-with-percent-height-and-max-height.html  BUG=512545  Review URL: [URL]/1405953005", "target": 0}
{"idx": 1492, "commit_message": "py: fix: memory leaks with PySequence_GetItem().  I used to live under the impression that PySequence_GetItem() returns the same reference.", "target": 0}
{"idx": 3593, "commit_message": "Re-land \"Add methods to enable configuration of ResourceConstraints based on limits derived at runtime.\"  Adds ConfigureResourceConstraintsForCurrentPlatform and SetDefaultResourceConstraintsForCurrentPlatform which configure the heap based on the available physical memory, rather than hard-coding by platform as previous. This change also adds OS::TotalPhysicalMemory to platform.h.  The re-land fix the performance regression caused by accidental change in default max young space size.  BUG=292928 [URL]  Review URL: [URL]/24989003  Patch from Ross McIlroy [URL]>.", "target": 1}
{"idx": 2178, "commit_message": "mmc: clk_scaling: add sysfs for avoiding scale down in write  Change Ia7a578434d7db8983493788ab2d7f9383d703169 introduced a degradation in performance. That change tried to fix a problem for clock scaling during write requests. During write request the invalid_state is always set due to CMD13 that is sent after each write. In the attempt to fix that issue the change above added the ability to scale down although invalid_state was set. Thus, creating a favor for downscale over upscale. Some customers prefer performance over power. This change introduces a sysfs entry that will allow the driver to retain its old behavior which had better performance.  It can be controlled from new sysfs entry: \"scale_down_in_low_wr_load\" found under /sys/class/mmc_host/mmcX/clk_scaling/ The default value for it is \"0\". In case customers want to gain performance over power they should set it to \"1\".", "target": 1}
{"idx": 4137, "commit_message": "[PATCH] Improved consistency of the ApplyPackedReflectors routines\n (as well as performance in several cases) and several more implementations,\n fixed mistakes in the build section of the documentation, added a short\n description of the new SVD function, and fixed mistakes in HouseholderSolve\n after adding a simple example driver.", "target": 1}
{"idx": 1572, "commit_message": "USB: cdc-wdm: use two mutexes to allow simultaneous read and write  commit e8537bd2c4f325a4796da33564ddcef9489b7feb upstream.  using a separate read and write mutex for locking is sufficient to make the driver accept simultaneous read and write. This improves useability a lot.", "target": 0}
{"idx": 2663, "commit_message": "mmc: mmc_test: add tests to measure large sequential I/O performance  Add two large sequential I/O performance tests:         35. Large sequential read into scattered pages         36. Large sequential write from scattered pages  The tests measure transfer times for 10MiB, 100MiB, 1000MiB.", "target": 0}
{"idx": 1606, "commit_message": "Added tests for 'hitTestBlock' method of 'DynamicBody' class.", "target": 0}
{"idx": 138, "commit_message": "Updated grammar with Unicode support  Added UnicodeCharacter rule which matches any valid unicode character, including surrogate pairs. The performance of this rule should be quite good for normal characters, which I think is probably the only case that matters. Replaced all instances of Wildcard usage in grammar with UnicodeCharacter Updated IdentifierExpression grammar to match unicode character categories per ECMAScript spec Moved markdom.cs.{Utils => Grammar}.UnicodeCategories; I think this is a good home for it, as it is intrinsically related to the grammar Added helper method to MarkdomGrammar for building unicode character set rules", "target": 0}
{"idx": 347, "commit_message": "iwlwifi: improve the reports in TX path  Also when things go wrong (queues don't get emtpy), try to get some data from the HW.", "target": 0}
{"idx": 2799, "commit_message": "When adding value at end of array use assignment instead of push to improve performance on mobile. Fixes #32", "target": 1}
{"idx": 2105, "commit_message": "iommu/arm-smmu: Optimize ->tlb_flush_walk() for qcom implementation  Currently for iommu_unmap() of large scatter-gather list with page size elements, the majority of time is spent in flushing of partial walks in __arm_lpae_unmap() which is a VA based TLB invalidation invalidating page-by-page on iommus like arm-smmu-v2 (TLBIVA).  For example: to unmap a 32MB scatter-gather list with page size elements (8192 entries), there are 16->2MB buffer unmaps based on the pgsize (2MB for 4K granule) and each of 2MB will further result in 512 TLBIVAs (2MB/4K) resulting in a total of 8192 TLBIVAs (512*16) for 16->2MB causing a huge overhead.  On qcom implementation, there are several performance improvements for TLB cache invalidations in HW like wait-for-safe (for realtime clients such as camera and display) and few others to allow for cache lookups/updates when TLBI is in progress for the same context bank. So the cost of over-invalidation is less compared to the unmap latency on several usecases like camera which deals with large buffers. So, ASID based TLB invalidations (TLBIASID) can be used to invalidate the entire context for partial walk flush thereby improving the unmap latency.  For this example of 32MB scatter-gather list unmap, this change results in just 16 ASID based TLB invalidations (TLBIASIDs) as opposed to 8192 TLBIVAs thereby increasing the performance of unmaps drastically.  Test on QTI SM8150 SoC for 10 iterations of iommu_{map_sg}/unmap: (average over 10 iterations)  Before this optimization:      size        iommu_map_sg      iommu_unmap       4K            2.067 us         1.854 us      64K            9.598 us         8.802 us       1M          148.890 us       130.718 us       2M          305.864 us        67.291 us      12M         1793.604 us       390.838 us      16M         2386.848 us       518.187 us      24M         3563.296 us       775.989 us      32M         4747.171 us      1033.364 us  After this optimization:      size        iommu_map_sg      iommu_unmap       4K            1.723 us         1.765 us      64K            9.880 us         8.869 us       1M          155.364 us       135.223 us       2M          303.906 us         5.385 us      12M         1786.557 us        21.250 us      16M         2391.890 us        27.437 us      24M         3570.895 us        39.937 us      32M         4755.234 us        51.797 us  Real world data also shows big difference in unmap performance as below:  There were reports of camera frame drops because of high overhead in iommu unmap without this optimization because of frequent unmaps issued by camera of about 100MB/s taking more than 100ms thereby causing frame drops.", "target": 1}
{"idx": 571, "commit_message": "OOZIE-2963 Use net.hydromatic instead of org.pentaho aggdesigner-algorithmin pomfilesi (dbist13 via gezapeti)", "target": 0}
{"idx": 3064, "commit_message": "rebase -i: also expand/collapse the SHA-1s via the rebase--helper  This is crucial to improve performance on Windows, as the speed is now mostly dominated by the SHA-1 transformation (because it spawns a new rev-parse process for *every* line, and spawning processes is pretty slow from Git for Windows' MSYS2 Bash).", "target": 1}
{"idx": 3485, "commit_message": "Implement MetaApi in ArgUtils; split implementations for better IDEA performance.", "target": 1}
{"idx": 1909, "commit_message": "Added to the card management interface and stubbed out an in-memory implementation.", "target": 0}
{"idx": 2818, "commit_message": "Large update/refactor of desktop widgets. This reduces the number of widgets in the stack by 1, and seems to help performance a bit.", "target": 1}
{"idx": 3503, "commit_message": "Made moving between tabbed/more efficient, doc++", "target": 0}
{"idx": 1652, "commit_message": "code formatting improved to keep only real changes done for KEYCLOAK-1074", "target": 0}
{"idx": 128, "commit_message": "add information about network programming in python", "target": 0}
{"idx": 2775, "commit_message": "lib: add lz4 compressor module  This patchset is for supporting LZ4 compression and the crypto API using it.  As shown below, the size of data is a little bit bigger but compressing speed is faster under the enabled unaligned memory access.  We can use lz4 de/compression through crypto API as well.  Also, It will be useful for another potential user of lz4 compression.  lz4 Compression Benchmark: Compiler: ARM gcc 4.6.4 ARMv7, 1 GHz based board    Kernel: linux 3.4    Uncompressed data Size: 101 MB          Compressed Size  compression Speed    LZO   72.1MB                  32.1MB/s, 33.0MB/s(UA)    LZ4   75.1MB                  30.4MB/s, 35.9MB/s(UA)    LZ4HC 59.8MB                   2.4MB/s,  2.5MB/s(UA) - UA: Unaligned memory Access support - Latest patch set for LZO applied  This patch:  Add support for LZ4 compression in the Linux Kernel.  LZ4 Compression APIs for kernel are based on LZ4 implementation by Yann Collet and were changed for kernel coding style.  LZ4 homepage : [URL]/p/lz4.html LZ4 source repository : [URL]/p/lz4/ svn revision : r90  Two APIs are added:  lz4_compress() support basic lz4 compression whereas lz4hc_compress() support high compression or CPU performance get lower but compression ratio get higher.  Also, we require the pre-allocated working memory with the defined size and destination buffer must be allocated with the size of lz4_compressbound.  [URL]: make lz4_compresshcctx() static]", "target": 1}
{"idx": 2158, "commit_message": "Merge pull request #3267 from danieldresser-ie/performanceMonitorFix  Fix Crash When Rendering With Performance Monitor", "target": 0}
{"idx": 2707, "commit_message": "Use 'while true' instead of 'loop' for better performance", "target": 1}
{"idx": 3764, "commit_message": "Fixes bugs in TH1::Merge(), TH2::Merge() and TH3::Merge()  - THx::Merge(): Do not skip empty histograms. The performance penalty is   marginal and there are cases in which users are interested in such a   merge. If they want to remove empty histograms, they should do so   before entering the Merge function.  - In TH2:: and TH3::Merge() the under and overflow bin entries create   only problems if they are on an axis which does not have the same   binning in all the merged histograms. If it has the same binning the   entries in these bins can be merged normally. This is fixed by   checking each axis individually for limit consistency.  - TH1::RecomputeAxisLimits can now also merge an equidistant user   binning.", "target": 0}
{"idx": 2407, "commit_message": "With LTO gcc will do whole program optimizations for the whole kernel and each module. This increases compile time, but can generate faster and smaller code and allows the compiler to do global checking. For example the compiler can complain now about type mismatches for symbols between different files. LTO allows gcc to inline functions between different files and do various other optimization across the whole binary.  It might also trigger bugs due to more aggressive optimizations. It allows gcc to drop unused code. It also allows it to check types over the whole program.  The compile time is definitely slower. For gcc 4.8 on a typical monolithic config it is about 58% slower. 4.9 drastically improved performance, with slowdown being 38% or so. Also incremenential rebuilds are somewhat slower, as the whole kernel always needs to be reoptimized. Very modular kernels have less build time slow down, as the LTO will run for each module individually.  This adds the basic Kbuild plumbing for LTO:  - In Kbuild add a new scripts/Makefile.lto that checks the tool chain (note the checks may not be fully bulletproof) and when the tests pass sets the LTO options Currently LTO is very finicky about the tool chain. - Add a new LDFINAL variable that controls the final link for vmlinux or module. In this case we call gcc-ld instead of ld, to run the LTO step. - For slim LTO builds (object files containing no backup executable) force AR to gcc-ar - Theoretically LTO should pass through compiler options from the compiler to the link step, but this doesn't work for all options. So the Makefile sets most of these options manually. - Kconfigs: Since LTO with allyesconfig needs more than 4G of memory (~8G) and has the potential to makes people's system swap to death. I used a nested config that ensures that a simple allyesconfig disables LTO. It has to be explicitely enabled. - Some depencies on other Kconfigs: MODVERSIONS, GCOV, FUNCTION_TRACER, KALLSYMS_ALL, single chain WCHAN are incompatible with LTO currently, mostly because they they require setting special compiler options for specific files, which LTO currently doesn't support. MODVERSIONS should in principle work with gcc 4.9, but still disabled. FUNCTION_TRACER/GCOV can be fixed with a unmerged gcc patch. - Also disable strict copy user checks because they trigger errors with LTO. - modpost symbol checking is downgraded to a warning, as in some cases modpost runs before the final link and it cannot resolve LTO symbols at this point.  For more information see Documentation/lto-build  Thanks to HJ Lu, Joe Mario, Honza Hubicka, Richard Guenther, Don Zickus, Changlong Xie who helped with this project (and probably some more who I forgot, sorry)  v2: Merge documentation file into this patch Improve documentation and Kconfig, fix a lot of obsolete comments. Exclude READABLE_ASM Some random fixes", "target": 1}
{"idx": 1975, "commit_message": "Add dynamic_GL linux versions.  Need a flag thing.", "target": 0}
{"idx": 1580, "commit_message": "tried to optimize code --that's what mjpg2 is", "target": 1}
{"idx": 3372, "commit_message": "mononoke: start logging repo name to scribe commit queue  Summary: Let's log repo name since it's clearer for people than repo ids. And in my mind logging repo ids was a mistake - repo id is an implementation detail (we use repo ids because they are more efficient to store in xdb table than strings), and Mononoke users shouldn't need to care about repo ids. So let's start loggin repo names.  Reviewed By: krallin  Differential Revision: D30040409  fbshipit-source-id: 71c2794d8122e616850662cda27c8092d382de7a", "target": 0}
{"idx": 3371, "commit_message": "lib/sha1: use the git implementation of SHA-1  For ChromiumOS, we use SHA-1 to verify the integrity of the root filesystem.  The speed of the kernel sha-1 implementation has a major impact on our boot performance.  To improve boot performance, we investigated using the heavily optimized sha-1 implementation used in git.  With the git sha-1 implementation, we see a 11.7% improvement in boot time.  10 reboots, remove slowest/fastest.  Before:    Mean: 6.58 seconds Stdev: 0.14  After (with git sha-1, this patch):    Mean: 5.89 seconds Stdev: 0.07  The other cool thing about the git SHA-1 implementation is that it only needs 64 bytes of stack for the workspace while the original kernel implementation needed 320 bytes.", "target": 1}
{"idx": 3891, "commit_message": "driver: eth_mcux: gptp: limit rate_adjust range  Limit gptp range_adjust range for improved performance.", "target": 1}
{"idx": 3618, "commit_message": "misc: vpe.api messages dynamically allocated  This is the last in the series of moving API messages from vpp/api/vpe.api to vlibmemory/memclnt.api. This patch makes the remaining vpe.api messages dynamic, to help VAT2 binary-api command. Moves the VAT test code to a separate file and removes the now unnused API meta files.  Type: improvement", "target": 0}
{"idx": 3356, "commit_message": "lib/memcopy: use glibc version  the kernel's memcpy and memmove is very inefficient. But the glibc version is quite fast, in some cases it is 10 times faster than the kernel version. So I introduce some memory copy macros and functions of the glibc to improve the kernel version's performance.  The strategy of the memory functions is: 1. Copy bytes until the destination pointer is aligned. 2. Copy words in unrolled loops.  If the source and destination are not    aligned in the same way, use word memory operations, but shift and merge    two read words before writing. 3. Copy the few remaining bytes.", "target": 1}
{"idx": 262, "commit_message": "Rework Worldline::IntegState and Gyoto::Error Improve doc", "target": 0}
{"idx": 875, "commit_message": "Rebaseline JavaConfigurationPerformanceTest  Toolchain change introduces 3% regression", "target": 0}
{"idx": 1764, "commit_message": "completion: reduce overhead of cancellation  We shouldn't need to alter the display unless we have a context, so avoid that code path in the cancellation case.", "target": 1}
{"idx": 1118, "commit_message": "Rewrite how we do lottery preferences  This commit represents both a reorganization of the lottery preferences page as well as a few coding improvements. It also accepts a bit of a regression in functionality to support future refactors.  Reorganize the page =================== Some messages have been moved around, spacing adjusted, etc. There's a lot going on with this page, and trying to (succintly) inform the user the minimum they need to know is worthwhile.  Outside of Winter School, the right sidebar can be repurposed to show information about lottery pairing, since trip ranking won't happen there.  Stop collecting car information on the page =========================================== As is, the process of collecting car information at the time of the lottery preferences is a weird pattern. Some people have access to different cars, or might change what car they drive for a given trip. Our system naively assumes that car owners have just one car, and they'll only drive that one car week after week. From a process standpoint, these assumptions are not good.  Furthermore, the technical way we've implemented car submission from lottery preferences -- submitting a JSON payload representing a car then saving a form from that -- is very much not a good Django pattern.  Replace this all, and go with a really simple version - where we prompt users to go to their profile if they need to edit their car.  This may have downsides, namely that users say they can drive a car, but never give details. Hopefully we fix that by WS 2022 (if it happens). Ideally, we'll want to add the ability to manage *multiple* cars per participant, so that should be the goal.  Pass JSON from backend to frontend better ========================================= We want to supply a list of ranked signups from the backend to be consumed by the AngularJS frontend, without the need for API calls.  In the future, we could instead opt for an API call (probably ideal when refactoring to use VueJS). However, we can at least now stop inserting a `<script>` take with executable code, and use the safer (XSS-resistant) `json_script`. This will help enforce a stronger CSP.  Warn participants who only sign up for a few trips in WS ======================================================== It doesn't happen often anymore, but a few participants only sign up for one or two trips, and are disappointed when they are placed on no trips. We should give a specific warning for anybody who selects 3 or fewer trips.  Experimentally, there's a huge cutoff in placement likelihood between participants who selected 3 or fewer trips and those who selected more.  Drop Django-Angular =================== The form we used for lottery preferences was the last to use Django-Angular! We can clean up dependence on this package now.  Additionally, we remove an old dependency from the AngularJS `lotteryController` that was breaking form submission. This was an incomplete cleanup from 27b9e70cb4f9b022a0daf78deed48ffbfb245c06", "target": 0}
{"idx": 1347, "commit_message": "Improvement typing (#2735)  * Fix: Circular dependencies of internal files    * Change: dt.date for Date and dt.datetime for DateTime    * Use NewType if available    * FIX: Wrong version test    * Remove: Date and DateTime types due to error    * Change to HomeAssistantType    * General Improvement of Typing    * Improve typing config_validation    * Improve typing script    * General Typing Improvements    * Improve NewType check    * Improve typing db_migrator    * Improve util/__init__ typing    * Improve helpers/location typing    * Regroup imports and remove pylint: disable=ungrouped-imports    * General typing improvements", "target": 0}
{"idx": 3493, "commit_message": "PERFORMANCE  * hapus yang ga penting * balik lagi pake CActiveRecords * FIX: onMissingTranslation di set cuma pas debuging", "target": 0}
{"idx": 2802, "commit_message": "Merge pull request #749 from dr3amf4ll/patch-1  Documentation frontend improvement", "target": 0}
{"idx": 3505, "commit_message": "[IMP] base: improve qweb barcode widget  When printing barcodes for a large amount of records, wkhtmltopdf will make the same amount of http requests to the server in order to retrieve barcodes. This can lead to performance issues or wkhtml to crash.  Fortunately, an already existsing qweb widget exists that include barcodes images as inline base64.  With this commit, the web widget is a bit improved to accept attributes for the generated image tag. Each option dictionary key starting with `img_` will be converted into a tag attribute with the corresponding value.  e.g.: `'img_alt': 'Barcode'` will result in `<img alt=\"Barcode\"...`  The `alt` img attribute now defaults to `'Barcode %s' % value` with the barcode value.  Also, the `quiet` reportlab option is also avalaible in the widget options, as well as the `mask` option.  Finally, if the `symbology` option is not given, the widget defaults to `Code128`. If `symbology` is set to `auto`, the action report will try to guess the barcode type, based on the len of the value.", "target": 1}
{"idx": 2996, "commit_message": "Fixed performance  Packet stuff are now abstract classes", "target": 1}
{"idx": 1882, "commit_message": "Merge commit '502e64fe23f19c086d42f6178cdda19e58996080' into upstream-merge  * commit '502e64fe23f19c086d42f6178cdda19e58996080': (23 commits)   target-arm: fix strexd   linux-user: fix build with gcc-4.1   linuxboot.bin is a generated file   qemu-nbd: fix OpenBSD linker warning   e1000: add link to data sheet   qemu-io: suppress a warning with gcc 4.0.2   Compile qemu-nbd also on OpenBSD and Solaris   USB: Improve usbdevice error messages   target-alpha: Initialize fpcr   tcg-sparc: Implement brcond2.   tcg-sparc: Use TCG_TARGET_REG_BITS in conditional compilation.   tcg-sparc: Improve tcg_out_movi for sparc64.   tcg-sparc: Fix imm13 check in movi.   ARM PBX-A9 memory map tweaks   LAN9118 improvements   PPC: Make DCR uint32_t   PPC64: Fix alternate timebase   PPC64: Fix timebase   target-alpha: Emit tcg debug_insn_start.   linux-user: Add aliases for some Alpha syscalls   ...", "target": 0}
{"idx": 1886, "commit_message": "Replace '--' with None (fixed #27) (#35)  * Unify the retry behavior in TWSEFetcher and TPEXFetcher, and improve coding style    * Replace '--' with None    * Add unit test for data with prices '--'", "target": 0}
{"idx": 3783, "commit_message": "KEYS: Fix short sprintf buffer in /proc/keys show function  This fixes CVE-2016-7042.  Fix a short sprintf buffer in proc_keys_show().  If the gcc stack protector is turned on, this can cause a panic due to stack corruption.  The problem is that xbuf[] is not big enough to hold a 64-bit timeout rendered as weeks:  \t(gdb) p 0xffffffffffffffffULL/(60*60*24*7) \t$2 = 30500568904943  That's 14 chars plus NUL, not 11 chars plus NUL.  Expand the buffer to 16 chars.  I think the unpatched code apparently works if the stack-protector is not enabled because on a 32-bit machine the buffer won't be overflowed and on a 64-bit machine there's a 64-bit aligned pointer at one side and an int that isn't checked again on the other side.  The panic incurred looks something like:  Kernel panic - not syncing: stack-protector: Kernel stack is corrupted in: ffffffff81352ebe CPU: 0 PID: 1692 Comm: reproducer Not tainted 4.7.2-201.fc24.x86_64 #1 Hardware name: Red Hat KVM, BIOS 0.5.1 01/01/2011  0000000000000086 00000000fbbd2679 ffff8800a044bc00 ffffffff813d941f  ffffffff81a28d58 ffff8800a044bc98 ffff8800a044bc88 ffffffff811b2cb6  ffff880000000010 ffff8800a044bc98 ffff8800a044bc30 00000000fbbd2679 Call Trace:  [<ffffffff813d941f>] dump_stack+0x63/0x84  [<ffffffff811b2cb6>] panic+0xde/0x22a  [<ffffffff81352ebe>] ? proc_keys_show+0x3ce/0x3d0  [<ffffffff8109f7f9>] __stack_chk_fail+0x19/0x30  [<ffffffff81352ebe>] proc_keys_show+0x3ce/0x3d0  [<ffffffff81350410>] ? key_validate+0x50/0x50  [<ffffffff8134db30>] ? key_default_cmp+0x20/0x20  [<ffffffff8126b31c>] seq_read+0x2cc/0x390  [<ffffffff812b6b12>] proc_reg_read+0x42/0x70  [<ffffffff81244fc7>] __vfs_read+0x37/0x150  [<ffffffff81357020>] ? security_file_permission+0xa0/0xc0  [<ffffffff81246156>] vfs_read+0x96/0x130  [<ffffffff81247635>] SyS_read+0x55/0xc0  [<ffffffff817eb872>] entry_SYSCALL_64_fastpath+0x1a/0xa4", "target": 0}
{"idx": 3415, "commit_message": "mfd: rtsx: Read vendor setting from config space  Normally OEMs will set vendor setting to the config space of Realtek card reader in BIOS stage. This patch reads the setting at the first, and configure the internal registers according to it, to improve card reader's compatibility condition.", "target": 0}
{"idx": 3483, "commit_message": "performance/write-behind - bug fix in open() and create().  open() & create() calls should reset frame->local to NULL.  bz# 104", "target": 0}
{"idx": 2616, "commit_message": "[Driver] Default all Android ARM targets to NEON.  Summary: There are an insignificant number of ARM Android devices that don't support NEON. Default to using NEON since that will improve performance on the majority of devices. Users that need to target non-NEON devices can still explicitly disable NEON.  Reviewers: srhines, pirama, kristof.beyls  Reviewed By: pirama  Subscribers: efriedma, javed.absar, cfe-commits  Tags: #clang  Differential Revision: [URL]/D58153", "target": 1}
{"idx": 2950, "commit_message": "Refactoring StringExtensions  I've got more efficient routine tricks that shorten code for getting n-th indexed character from string.", "target": 1}
{"idx": 3364, "commit_message": "readahead: bump up the default readahead size  Use 512kb max readahead size, and 32kb min readahead size.  The former helps io performance for common workloads. The latter will be used in the thrashing safe context readahead.  -- Rationals on the 512kb size --  I believe it yields more I/O throughput without noticeably increasing I/O latency for today's HDD.  For example, for a 100MB/s and 8ms access time HDD, its random IO or highly concurrent sequential IO would in theory be:  io_size KB  access_time  transfer_time  io_latency   util%   throughput KB/s 4           8             0.04           8.04        0.49%    497.57 8           8             0.08           8.08        0.97%    990.33 16          8             0.16           8.16        1.92%   1961.69 32          8             0.31           8.31        3.76%   3849.62 64          8             0.62           8.62        7.25%   7420.29 128         8             1.25           9.25       13.51%  13837.84 256         8             2.50          10.50       23.81%  24380.95 512         8             5.00          13.00       38.46%  39384.62 1024        8            10.00          18.00       55.56%  56888.89 2048        8            20.00          28.00       71.43%  73142.86 4096        8            40.00          48.00       83.33%  85333.33  The 128KB => 512KB readahead size boosts IO throughput from ~13MB/s to ~39MB/s, while merely increases (minimal) IO latency from 9.25ms to 13ms.  As for SSD, I find that Intel X25-M SSD desires large readahead size even for sequential reads:  \trasize\t1st run\t\t2nd run \t---------------------------------- \t  4k\t123 MB/s\t122 MB/s \t 16k  \t153 MB/s\t153 MB/s \t 32k\t161 MB/s\t162 MB/s \t 64k\t167 MB/s\t168 MB/s \t128k\t197 MB/s\t197 MB/s \t256k\t217 MB/s\t217 MB/s \t512k\t238 MB/s\t234 MB/s \t  1M\t251 MB/s\t248 MB/s \t  2M\t259 MB/s\t257 MB/s    \t  4M\t269 MB/s\t264 MB/s \t  8M\t266 MB/s\t266 MB/s The two other impacts of an enlarged readahead size are  - memory footprint (caused by readahead miss) \tSequential readahead hit ratio is pretty high regardless of max \treadahead size; the extra memory footprint is mainly caused by \tenlarged mmap read-around. \tI measured my desktop: \t- under Xwindow: \t\t128KB readahead hit ratio = 143MB/230MB = 62% \t\t512KB readahead hit ratio = 138MB/248MB = 55% \t\t  1MB readahead hit ratio = 130MB/253MB = 51% \t- under console: (seems more stable than the Xwindow data) \t\t128KB readahead hit ratio = 30MB/56MB   = 53% \t\t  1MB readahead hit ratio = 30MB/59MB   = 51% \tSo the impact to memory footprint looks acceptable.  - readahead thrashing \tIt will now cost 1MB readahead buffer per stream.  Memory tight \tsystems typically do not run multiple streams; but if they do \tso, it should help I/O performance as long as we can avoid \tthrashing, which can be achieved with the following patches.  -- Benchmarks by Vivek Goyal --  I have got two paths to the HP EVA and got multipath device setup(dm-3). I run increasing number of sequential readers. File system is ext3 and filesize is 1G. I have run the tests 3 times (3sets) and taken the average of it.  Workload=bsr      iosched=cfq     Filesz=1G   bs=32K ======================================================================                     2.6.33-rc5                2.6.33-rc5-readahead job   Set NR  ReadBW(KB/s)   MaxClat(us)    ReadBW(KB/s)   MaxClat(us) ---   --- --  ------------   -----------    ------------   ----------- bsr   3   1   141768         130965         190302         97937.3 bsr   3   2   131979         135402         185636         223286 bsr   3   4   132351         420733         185986         363658 bsr   3   8   133152         455434         184352         428478 bsr   3   16  130316         674499         185646         594311 I ran same test on a different piece of hardware. There are few SATA disks (5-6) in striped configuration behind a hardware RAID controller.  Workload=bsr      iosched=cfq     Filesz=1G   bs=32K ======================================================================                     2.6.33-rc5                2.6.33-rc5-readahead job   Set NR  ReadBW(KB/s)   MaxClat(us)    ReadBW(KB/s)   MaxClat(us) ---   --- --  ------------   -----------    ------------   ----------- bsr   3   1   147569         14369.7        160191         22752 bsr   3   2   124716         243932         149343         184698 bsr   3   4   123451         327665         147183         430875 bsr   3   8   122486         455102         144568         484045 bsr   3   16  117645         1.03957e+06    137485         1.06257e+06 Tested-by: Vivek Goyal [URL]> CC: Jens Axboe [URL]> CC: Chris Mason [URL]> CC: Peter Zijlstra < > CC: Martin Schwidefsky [URL]> CC: Christian Ehrhardt [URL]>", "target": 1}
{"idx": 2057, "commit_message": "Handle V4HI vector initialization more efficiently on VIS1.  \t* config/sparc/sparc.c (vector_init_faligndata): New function. \t(sparc_expand_vector_init): Use it for V4HImode on VIS1.", "target": 1}
{"idx": 2270, "commit_message": "[performance] rewrite DWT in rawdenoise (#7084)  * refactor: split out code common to Bayer and X-Trans    Create new functions compute_channel_noise() and dwt_denoise(), and  make the Bayer version wavelet_denoise() call them.  wavelet_denoise_xtrans() remains unchanged for now.    * initial rewrite in the style of dwt_decompose    Moved management of scratch buffers into dwt_denoise  Ensured vectorizability of loops in horizontal and vertical passes    Now uses less working memory (3/4 of the size of the input image  instead of equal to size of input image).    Speed is about 3x at 2 threads, 2x at 8 threads, 10% faster at 32  threads (memory bandwidth is the limiting factor).    * add 'const' and 'restrict'    Ensure that everything which could be declared const or restrict  actually is declared that way.", "target": 1}
{"idx": 3550, "commit_message": "Load smaller images in streams  Loading images is taking a long time. We should see big speed and performance improvements by using smaller image files. Grid layout now uses ldpi and single column layout now uses mdpi.  [Finishes #91946040]", "target": 1}
{"idx": 3526, "commit_message": "Refine stack op to improve xlnet performance, test=develop (#22142)  stack's wait cost a lot of cpu time, use cuda kernel to do memory copy  will reduce cpu time.", "target": 1}
{"idx": 2437, "commit_message": "take work out of d3 ticker loop to improve performance", "target": 1}
{"idx": 657, "commit_message": "Set ByteCompile on installation (#151)  * Set ByteCompile on installation    At UseR!2017 @csgillespie emphasized the importance of adding the BytCompile flag to packages. It is a an easy way to increase performance of the package. See [Efficient R Programming](https://csgillespie.github.io/efficientR/7-4-the-byte-compiler.html) for reference.    * Removed stray newlines", "target": 1}
{"idx": 3535, "commit_message": "OSD: \tOpenFileTable: improved performance by storing open files in a tree set instead of a priority queue \tversioning/COW: fixes and performance tweaks", "target": 1}
{"idx": 2480, "commit_message": "xfs: align initial file allocations correctly  The function xfs_bmap_isaeof() is used to indicate that an allocation is occurring at or past the end of file, and as such should be aligned to the underlying storage geometry if possible.  Commit 27a3f8f (\"xfs: introduce xfs_bmap_last_extent\") changed the behaviour of this function for empty files - it turned off allocation alignment for this case accidentally. Hence large initial allocations from direct IO are not getting correctly aligned to the underlying geometry, and that is cause write performance to drop in alignment sensitive configurations.  Fix it by considering allocation into empty files as requiring aligned allocation again.", "target": 1}
{"idx": 481, "commit_message": "optimized nitf_TRE_isDone by cloning the cursor rather than repetitively iterating to the same point - this included a fix in the IntStack clone method", "target": 1}
{"idx": 3222, "commit_message": "Improve DiffViewModel update performance by checking for an overlap with the view's FormattedSpan", "target": 1}
{"idx": 2413, "commit_message": "input: touchscreen: mediatek: S3203: Update Touch Firmware For waterproof performance  Update Touch firmware  to new version that improves waterproof performance", "target": 1}
{"idx": 1032, "commit_message": "Implement upgrade feature and do some cleanup and improvements", "target": 0}
{"idx": 2910, "commit_message": "fixed bugs in IsSubsetOfPerformance, added new log", "target": 0}
{"idx": 1932, "commit_message": "Adding generic fundamental matrix solver and a derived class that implements the eight-point algorithm. Compiles but not tested.", "target": 0}
{"idx": 61, "commit_message": "sched: fix bug in small task CPU selection  The maximum capacity CPU is a fallback option for small tasks and selected only when all the allowed lower capacity CPUs are overloaded. When the first such fallback CPU is encountered during the search, its cluster cpumask is computed and removed from the search.  cpumask_and(&fb_search_cpu, &search_cpu, &rq->freq_domain_cpumask); cpumask_andnot(&search_cpu, &search_cpu, &rq->freq_domain_cpumask);  The iterator CPU is cleared from the search_cpu mask before this, due to which it is not set in fb_search_cpu mask. Later, this mask is used to construct a search mask for iterating over the lower capacity CPUs to find the busy CPU.  cpumask_and(&search_cpu, tsk_cpus_allowed(p), cpu_online_mask); cpumask_andnot(&search_cpu, &search_cpu, &fb_search_cpu);  The search_cpu mask has now a maximum capacity CPU due to the above mentioned bug and may get selected instead of a lower capacity CPU that can accommodate this small task under spill threshold.", "target": 0}
{"idx": 2398, "commit_message": "list: set internal box as homogeneous if no separator items are present  this is a significant performance optimization since all non-separator items should always be sized identically", "target": 1}
{"idx": 2973, "commit_message": "Added functions for more efficiently retrieving the DD for 'greater than constant', 'greater or equal than constant' and 'notZero'.   Former-commit-id: 9d80c29f271a83bc492027443a8d2e430f97f47c", "target": 1}
{"idx": 887, "commit_message": "Merge pull request #16 from khufkens/new_optimizations  New optimizations using BayesianTools", "target": 1}
{"idx": 2173, "commit_message": "Rebaseline performance test  Merkle tree snapshots improve up-to-date builds by 3% when the build scan plugin is applied or the build cache enabled, so we can accept this < 1 % regression for `assemble for non-abi change on largeJavaMultiProject`.", "target": 1}
{"idx": 786, "commit_message": "Improved user experience when deleting causes databsae constraints to fail", "target": 0}
{"idx": 997, "commit_message": "[qt] Improve watchonly display (squashed)  939ed97 Add boolean HaveWatchonly and signal NotifyWatchonlyChanged 1c5f0af Add column Watch-only to transactions list", "target": 0}
{"idx": 86, "commit_message": "block: fix use-after-free in sys_ioprio_get()  get_task_ioprio() accesses the task->io_context without holding the task lock and thus can race with exit_io_context(), leading to a use-after-free. The reproducer below hits this within a few seconds on my 4-core QEMU VM:  int main(int argc, char **argv) { \tpid_t pid, child; \tlong nproc, i;  \t/* ioprio_set(IOPRIO_WHO_PROCESS, 0, IOPRIO_PRIO_VALUE(IOPRIO_CLASS_IDLE, 0)); */ \tsyscall(SYS_ioprio_set, 1, 0, 0x6000);  \tnproc = sysconf(_SC_NPROCESSORS_ONLN);  \tfor (i = 0; i < nproc; i++) { \t\tpid = fork(); \t\tassert(pid != -1); \t\tif (pid == 0) { \t\t\tfor (;;) { \t\t\t\tpid = fork(); \t\t\t\tassert(pid != -1); \t\t\t\tif (pid == 0) { \t\t\t\t\t_exit(0); \t\t\t\t} else { \t\t\t\t\tchild = wait(NULL); \t\t\t\t\tassert(child == pid); \t\t\t\t} \t\t\t} \t\t}  \t\tpid = fork(); \t\tassert(pid != -1); \t\tif (pid == 0) { \t\t\tfor (;;) { \t\t\t\t/* ioprio_get(IOPRIO_WHO_PGRP, 0); */ \t\t\t\tsyscall(SYS_ioprio_get, 2, 0); \t\t\t} \t\t} \t}  \tfor (;;) { \t\t/* ioprio_get(IOPRIO_WHO_PGRP, 0); */ \t\tsyscall(SYS_ioprio_get, 2, 0); \t}  \treturn 0; }  This gets us KASAN dumps like this:  [   35.526914] ================================================================== [   35.530009] BUG: KASAN: out-of-bounds in get_task_ioprio+0x7b/0x90 at addr ffff880066f34e6c [   35.530009] Read of size 2 by task ioprio-gpf/363 [   35.530009] ============================================================================= [   35.530009] BUG blkdev_ioc (Not tainted): kasan: bad access detected [   35.530009] -----------------------------------------------------------------------------  [   35.530009] Disabling lock debugging due to kernel taint [   35.530009] INFO: Allocated in create_task_io_context+0x2b/0x370 age=0 cpu=0 pid=360 [   35.530009] \t___slab_alloc+0x55d/0x5a0 [   35.530009] \t__slab_alloc.isra.20+0x2b/0x40 [   35.530009] \tkmem_cache_alloc_node+0x84/0x200 [   35.530009] \tcreate_task_io_context+0x2b/0x370 [   35.530009] \tget_task_io_context+0x92/0xb0 [   35.530009] \tcopy_process.part.8+0x5029/0x5660 [   35.530009] \t_do_fork+0x155/0x7e0 [   35.530009] \tSyS_clone+0x19/0x20 [   35.530009] \tdo_syscall_64+0x195/0x3a0 [   35.530009] \treturn_from_SYSCALL_64+0x0/0x6a [   35.530009] INFO: Freed in put_io_context+0xe7/0x120 age=0 cpu=0 pid=1060 [   35.530009] \t__slab_free+0x27b/0x3d0 [   35.530009] \tkmem_cache_free+0x1fb/0x220 [   35.530009] \tput_io_context+0xe7/0x120 [   35.530009] \tput_io_context_active+0x238/0x380 [   35.530009] \texit_io_context+0x66/0x80 [   35.530009] \tdo_exit+0x158e/0x2b90 [   35.530009] \tdo_group_exit+0xe5/0x2b0 [   35.530009] \tSyS_exit_group+0x1d/0x20 [   35.530009] \tentry_SYSCALL_64_fastpath+0x1a/0xa4 [   35.530009] INFO: Slab 0xffffea00019bcd00 objects=20 used=4 fp=0xffff880066f34ff0 flags=0x1fffe0000004080 [   35.530009] INFO: Object 0xffff880066f34e58 @offset=3672 fp=0x0000000000000001 [   35.530009] ==================================================================  Fix it by grabbing the task lock while we poke at the io_context.", "target": 0}
{"idx": 362, "commit_message": "Bump rubocop-performance from 1.6.0 to 1.6.1  Bumps [URL]/rubocop-hq/rubocop-performance) from 1.6.0 to 1.6.1. - [Release [URL]/rubocop-hq/rubocop-performance/releases) - [URL]/rubocop-hq/rubocop-performance/blob/master/CHANGELOG.md) - [URL]/rubocop-hq/rubocop-performance/compare/v1.6.0...v1.6.1)", "target": 0}
{"idx": 3374, "commit_message": "Revert \"rcu: Move PREEMPT_RCU preemption to switch_to() invocation\"  This reverts commit 616c310e83b872024271c915c1b9ab505b9efad9. (Move PREEMPT_RCU preemption to switch_to() invocation). Testing by Sasha Levin [URL]> showed that this can result in deadlock due to invoking the scheduler when one of the runqueue locks is held.  Because this commit was simply a performance optimization, revert it.  CRs-fixed: 657837", "target": 0}
{"idx": 517, "commit_message": "Reduce memory footprint of closed http/2 streams  This refactoring replaces closed streams with a new RecycledStream object and changes the mechanism used to look up known streams. Pull-up isClosedFinal()", "target": 1}
{"idx": 3138, "commit_message": "[PATCH] sched: fix ->nr_uninterruptible handling bugs  PREEMPT_RT on SMP systems triggered weird (very high) load average values rather easily, which turned out to be a mainline kernel ->nr_uninterruptible handling bug in try_to_wake_up().  the following code:          if (old_state == TASK_UNINTERRUPTIBLE) {                 old_rq->nr_uninterruptible--;  potentially executes with old_rq potentially being != rq, and hence updating ->nr_uninterruptible without the lock held. Given a sufficiently concurrent preemption workload the count can get out of whack and updates might get lost, permanently skewing the global count.  Nothing except the load-average uses nr_uninterruptible() so this condition can go unnoticed quite easily.  the fix is to update ->nr_uninterruptible always on the runqueue where the task currently is. (this is also a tiny performance plus for try_to_wake_up() as a stackslot gets freed up.)  while fixing this bug i found three other ->nr_uninterruptible related bugs:   - the update should be moved from deactivate_task() into schedule(),    beacause e.g. setscheduler() does deactivate_task()+activate_task(),    which in turn may result in a -1 counter-skew if setscheduler() is    done on a task asynchronously, which task is still on the runqueue    but has already set ->state to TASK_UNINTERRUPTIBLE.     sys_sched_setscheduler() is used rarely, but the bug is real. (The    fix is also a small performance enhancement.)     The rules for ->nr_uninterruptible updating are the following: it    gets increased by schedule() only, when a task is moved off the    runqueue and it has a state of TASK_UNINTERRUPTIBLE. It is decreased    by try_to_wake_up(), by the first wakeup that materially changes the    state from TASK_UNINTERRUPTIBLE back to TASK_RUNNING, and moves the    task to the runqueue.   - on CPU-hotplug down we might zap a CPU that has a nonzero counter.    Due to the fuzzy nature of the global counter a CPU might hold a    nonzero ->nr_uninterruptible count even if it has no tasks anymore.    The solution is to 'migrate' the counter to another runqueue.   - we should not return negative counter values from the    nr_uninterruptible() function, since it accesses them without taking    the runqueue locks, so the total sum might be slightly above or    slightly below the real count.  I tested the attached patch on x86 SMP and it solves the load-average problem. (I have tested CPU_HOTPLUG compilation but not functionality.)  I think this is a must-have for 2.6.10, because there are apps that go berzerk if load-average is too high (e.g. sendmail).", "target": 0}
{"idx": 686, "commit_message": "* reduced wasted memory for tile- and posStrings", "target": 1}
{"idx": 3190, "commit_message": "Performance improvement for searching for line terminators.  Bug: 841549 Cq-Include-Trybots: master.tryserver.chromium.linux:linux_mojo", "target": 1}
{"idx": 621, "commit_message": "Added function to dynamically add table values", "target": 0}
{"idx": 2317, "commit_message": "Improving performance of code, trying to fix an interesting bug in broadphase", "target": 1}
{"idx": 1503, "commit_message": "Improved repeat generation of master password suggestions.", "target": 0}
{"idx": 714, "commit_message": "Remove Mac ASan Tests (1) from chromium.memory.  It doesn't exist anymore on [URL]/p/chromium.memory/builders.  [URL] BUG=  Review URL: [URL]/1197723006", "target": 0}
{"idx": 92, "commit_message": "Remove \"Topics\" nav link and improve styles  The \"Topics\" link is useless now that private messages are not tied to a messageboard.", "target": 0}
{"idx": 4093, "commit_message": "[PATCH] Performance improvments. BuildWeightMatrix() is probably\n unnecessary entirely.", "target": 1}
{"idx": 104, "commit_message": "Add ordering for serializing and other improvement.", "target": 0}
{"idx": 4094, "commit_message": "[PATCH] Move orb LUT in CUDA backend to texture memory\n\ncuda::kernel::extract_orb is the CUDA kernel that uses the orb\nlookup table. Shared below is performance of the kernel using constant\nmemory vs texture memory. There is neglible to no difference between two\nversions. Hence, shifted to texture memory LUT to reduce global constant\nmemory usage.\n\nPerformance using constant memory LUT\n-------------------------------------\n\nTime(%)  Time   Calls      Avg       Min       Max  Name\n\n3.02%  292.26us   24  12.177us  11.360us  14.528us  void cuda::kernel::extract_orb<float>\n2.16%  209.00us   16  13.062us  11.616us  16.033us  void cuda::kernel::extract_orb<double>\n\nPerformance using texture LUT\n-----------------------------\n\nTime(%)    Time   Calls      Avg       Min       Max  Name\n\n2.84%  270.63us     24  11.276us  9.6970us  15.040us  void cuda::kernel::extract_orb<float>\n2.20%  209.28us     16  13.080us  10.688us  16.960us  void cuda::kernel::extract_orb<double>", "target": 1}
{"idx": 2391, "commit_message": "Write the recent tracks file a bit later so that changes to the list are batched and done in one go. Might improve windows startup performance.", "target": 1}
{"idx": 494, "commit_message": "Merge pull request #3107 from magfest/speed-up-at-door-page  Remove Stripe forms from Recent At-Door Registrations page", "target": 0}
{"idx": 3116, "commit_message": "Merged revisions 817668-818612 via svnmerge from  [URL]/home/kde/trunk/KDE/kdepim  ........   r817668 | winterz | 2008-06-06 17:10:17 +0200 (Fri, 06 Jun 2008) | 3 lines      fix running kjots standalone killing kontact.   as usual, dfaure (aka \"The Guru\") solved this for us. ........   r817696 | winterz | 2008-06-06 18:42:15 +0200 (Fri, 06 Jun 2008) | 6 lines      port newInstance() to DBus interface.   rewrite a bit to make it more consistent the other plugins.      we still have a bug though: starting akregator standalone while kontact   is running brings the Summary view forward, not the Akregator plugin. ........   r817875 | scripty | 2008-06-06 23:51:55 +0200 (Fri, 06 Jun 2008) | 1 line      SVN_SILENT made messages (.desktop file) ........   r817923 | winterz | 2008-06-07 02:53:17 +0200 (Sat, 07 Jun 2008) | 13 lines      Add UniqueAppHandler support (but it doesn't work correctly yet).   Make \"New Task\" from the menu work.   i18n(\"New Task\")   fix invisibleToolbarActions   other general cleanups      Thorsten: several problems remain, including:     no ktimetracker toolbar when embedded into kontact     no ktimetracker timer in the systray when embedded into kontact     we need a DBus interface to use in the newInstance()      ........   r817931 | knight | 2008-06-07 05:05:10 +0200 (Sat, 07 Jun 2008) | 4 lines      Use current locale settings when formatting the publishing date of   an article for display in the article list, with fancy rendition   of dates less than one week old (eg. \"Today <time>\", \"Yesterday <time>\") ........   r818015 | ereslibre | 2008-06-07 14:37:09 +0200 (Sat, 07 Jun 2008) | 7 lines      Tool tips are shown now. Is a pity KFileItemDelegate tries to draw different tooltips. Will talk with Fredrik to see if we can get normal tooltips using KFileItemDelegate. Anyway, QStyledItemDelegate   doesn't get us in any regressions, and works as expected.      Tool tips are only shown if the mode of view is \"Icons Only\".    ........   r818025 | winterz | 2008-06-07 15:47:03 +0200 (Sat, 07 Jun 2008) | 3 lines      disable the newsticker summary plugin. ........   r818045 | winterz | 2008-06-07 16:51:23 +0200 (Sat, 07 Jun 2008) | 4 lines      it might help the newstickerplugin if it had the correct version.   still, we keep this plugin disabled for KDE 4.1 ........   r818049 | winterz | 2008-06-07 16:53:43 +0200 (Sat, 07 Jun 2008) | 5 lines      I don't see any reason to keep a KDE 3.2 version of the akregator plugin.   but maybe I'm wrong.  Frank?    ........   r818068 | winterz | 2008-06-07 17:48:21 +0200 (Sat, 07 Jun 2008) | 2 lines      change the weight so feeds shows up under to-do list, but above usenet. ........   r818080 | winterz | 2008-06-07 18:30:57 +0200 (Sat, 07 Jun 2008) | 7 lines      fix KJots \"about\" data when embedded into Kontact.   Steve: you really need to combine this and the kjots/main.cpp about data   data into 1 about and make this available to the standalone and part.      you might look at korganizer/aboutdata for example ........   r818102 | tmcguire | 2008-06-07 20:17:06 +0200 (Sat, 07 Jun 2008) | 4 lines      Store local subscription info immediately. Might help with bug 163268    ........   r818122 | tmcguire | 2008-06-07 21:28:39 +0200 (Sat, 07 Jun 2008) | 7 lines      Don't crash in a debug function.      This might also fix bug 156319, although the backtrace misses the   last function it it.    ........   r818123 | tmcguire | 2008-06-07 21:34:03 +0200 (Sat, 07 Jun 2008) | 3 lines      tabs--   SVN_SILENT ........   r818126 | tmcguire | 2008-06-07 22:01:16 +0200 (Sat, 07 Jun 2008) | 6 lines      When the config file says the folders patch is .kde/share/apps/kmail/mail, but that   doesn't exist, try .kde4/share/apps/kmail/mail instead, as some distros change KDEHOME   to .kde4.      I myself made that error when migrating my data, and some others as well. ........   r818181 | toma | 2008-06-08 03:24:44 +0200 (Sun, 08 Jun 2008) | 2 lines      Reinstate the integrity() function from mailody3, ported to akonadi. This should make the resource fetch the mail based on uidnext and uidvalidity checks. Basically means that it can now do the 'checkmail' properly and efficiently. Too bad Akonadi does not seem to call retrieveItems( const Akonadi::Collection & col ) on the intervals. I might be missing something.  ........   r818274 | tstaerk | 2008-06-08 09:02:15 +0200 (Sun, 08 Jun 2008) | 5 lines      Renaming KArm to ktimetracker. Now that this is consistent, also the   \"new task\" functionality works.   BUGS:162725   CCBUGS:125862 ........   r818294 | tstaerk | 2008-06-08 10:49:55 +0200 (Sun, 08 Jun 2008) | 1 line      Allow the user to name a task as he likes. ........   r818298 | tstaerk | 2008-06-08 11:05:48 +0200 (Sun, 08 Jun 2008) | 5 lines      Renaming KArm to ktimetracker. As this is now consistent, also the   toolbars work.   BUGS:162724 162726   CCBUGS:125862 ........   r818299 | tstaerk | 2008-06-08 11:12:47 +0200 (Sun, 08 Jun 2008) | 1 line      Have the icons in the 'main bar' ........   r818339 | osterfeld | 2008-06-08 13:09:03 +0200 (Sun, 08 Jun 2008) | 1 line      return data for EditRole ........   r818341 | toma | 2008-06-08 13:13:30 +0200 (Sun, 08 Jun 2008) | 2 lines      When there is an error in selecting the mailbox, don't lock up. ........   r818344 | gberg | 2008-06-08 13:31:10 +0200 (Sun, 08 Jun 2008) | 1 line      Fix issue with text not wrapping on first page of anti-spam wizard. ........   r818346 | osterfeld | 2008-06-08 13:42:41 +0200 (Sun, 08 Jun 2008) | 2 lines      add sort role, to fix sorting of fancy dates   remove old ArticleListView impl ........   r818352 | toma | 2008-06-08 14:04:34 +0200 (Sun, 08 Jun 2008) | 2 lines      Add a noselect attribute. This way we can prevent accessing a folder which has this property on the server. This prevents useless server roundtrips. ........   r818355 | gberg | 2008-06-08 14:08:51 +0200 (Sun, 08 Jun 2008) | 1 line      Fix image in the anti-spam and anti-virus wizards so they don't move and the frame doesn't resize around them when resizing the dialog. ........   r818362 | tmcguire | 2008-06-08 14:24:51 +0200 (Sun, 08 Jun 2008) | 2 lines      Also disable the filter actions in the toolbar when no message is selected. ........   r818365 | osterfeld | 2008-06-08 14:28:16 +0200 (Sun, 08 Jun 2008) | 1 line      fix author column: store author name, email, url separatedly instead of storing it as HTML ........   r818383 | toma | 2008-06-08 15:12:31 +0200 (Sun, 08 Jun 2008) | 2 lines      In the past we did nothing if the message count in mailody matched the amount on the imap server. Now we need to emit a signal that we are done. Another lockup bytes the dust. ........   r818395 | tmcguire | 2008-06-08 15:48:06 +0200 (Sun, 08 Jun 2008) | 7 lines      Don't assert when the password entered is empty.      The password dialog is still shown too many times, but at least   it doesn't crash anymore.    ........   r818405 | tmcguire | 2008-06-08 16:10:38 +0200 (Sun, 08 Jun 2008) | 4 lines      Make sure \"Starting...\" and \"Opening Url..\" disappear from the status bar again   after two seconds. ........   r818418 | winterz | 2008-06-08 16:26:16 +0200 (Sun, 08 Jun 2008) | 2 lines      not \"context\", but \"comment\" property ........   r818421 | msoeken | 2008-06-08 16:29:55 +0200 (Sun, 08 Jun 2008) | 2 lines      Use QStyledItemDelegate and QStyle::drawControl to correctly paint the background of the percentage column. ........   r818437 | tmcguire | 2008-06-08 17:01:20 +0200 (Sun, 08 Jun 2008) | 4 lines      - Make sure that the toolbar filter actions are also disabled right after starting up   - Remove some code that doesn't seem to do anything meaningful   - Put the last line of one function back as the last line ........   r818438 | krake | 2008-06-08 17:03:14 +0200 (Sun, 08 Jun 2008) | 3 lines      Put phone number widgets into a scrollarea and make sure the area can display the initial three without scrollbar.   Fixes an issue discovered during Krush day 2 (widgets being reduced in height when new phone numbers are added) ........   r818440 | tmcguire | 2008-06-08 17:10:58 +0200 (Sun, 08 Jun 2008) | 2 lines      Install the RC file, looks like this was removed by accident in r813516. ........   r818452 | mleupold | 2008-06-08 17:42:39 +0200 (Sun, 08 Jun 2008) | 2 lines      Made the dialog smaller to fit the KCMultiDialog's size on small resolutions. ........   r818456 | aacid | 2008-06-08 17:59:39 +0200 (Sun, 08 Jun 2008) | 2 lines      remove typo spotted by Soenke Dibbern ........   r818459 | tmcguire | 2008-06-08 18:10:26 +0200 (Sun, 08 Jun 2008) | 4 lines      Slightly better place to update the actions, now also works after running the   anti spam wizard.   Also, update all actions, not just those in the toolbar. ........   r818460 | krake | 2008-06-08 18:11:22 +0200 (Sun, 08 Jun 2008) | 2 lines      Fixing enable/disable state tracking depending on selection. ........   r818468 | osterfeld | 2008-06-08 18:30:21 +0200 (Sun, 08 Jun 2008) | 2 lines      convert to plaintext also when updating the title cache ........   r818469 | tmcguire | 2008-06-08 18:30:27 +0200 (Sun, 08 Jun 2008) | 4 lines      Don't crash when inline-forwarding multiple mails.    ........   r818491 | mleupold | 2008-06-08 18:59:57 +0200 (Sun, 08 Jun 2008) | 2 lines      Made the Composer config dialog smaller to fit small resolutions. ........   r818511 | skelly | 2008-06-08 19:34:04 +0200 (Sun, 08 Jun 2008) | 3 lines      Move the about data in KJots to a standalone class instead of repeating the information. ........   r818517 | tstaerk | 2008-06-08 19:40:39 +0200 (Sun, 08 Jun 2008) | 4 lines      Understand the starttime in an iCalendar file.   BUGS:163526 ........   r818532 | krake | 2008-06-08 20:33:46 +0200 (Sun, 08 Jun 2008) | 13 lines      QList::erase changes end() so caching it resulted in a crash.      Reported during Krush day as   \"katastrophe 14:14, 8 June 2008 (CEST) crash if you make a new distribution list and change its name, then click ok\"      Actually already crashes when creating a new distribution list and keeping the default name.      Most likely introduced during Qt4 porting, e.g. different behavior or Qt3's QValueList and Qt4's QList regarding erase() and/or end()   so it could be somewhere else as well.    ........   r818574 | toma | 2008-06-08 22:36:51 +0200 (Sun, 08 Jun 2008) | 2 lines      dont deadlock on entering a folder with no new messages. ........   r818605 | ereslibre | 2008-06-09 01:02:05 +0200 (Mon, 09 Jun 2008) | 6 lines      The sidebar needed lots of intrinsec logic for working properly. This fixes the problem of a huge sidebar when the environment is clean (aka. \"new user\" test). This also fixes some problems with   layouts. Now the sidebar will automagically adopt the needed size, and the only thing one can do with the slider is to hide or show it. I have double reviewed it is correct with the kde pim coding   style, but if something is wrong, please tell me.    ........   r818606 | winterz | 2008-06-09 01:10:28 +0200 (Mon, 09 Jun 2008) | 2 lines      minor style changes (line length <= 100) ........   r818612 | djarvie | 2008-06-09 02:20:36 +0200 (Mon, 09 Jun 2008) | 1 line      Prevent quitIf() calling quitIf() ........  svn path=/branches/kdepim/enterprise4/kdepim/; revision=818683", "target": 0}
{"idx": 2936, "commit_message": "fixed circular import & improved performance", "target": 1}
{"idx": 4027, "commit_message": "[PATCH] #1295 Refactored MX::setSub(IMatrix,IMatrix) The new\n implementation should be much more efficient and handle non-monotone indices\n correctly", "target": 1}
{"idx": 4101, "commit_message": "[PATCH] modified to have 3c and 2c two electron eri sums also prints\n outer loop index to show user about where the computation is.  Also\n statically (modulo) parallelized for better performance\n\nRick Kendall", "target": 1}
{"idx": 1218, "commit_message": "[IMP] improve contract usability  bzr revid: [URL]-20130729054047-z73ocu5isfqc0b3v", "target": 0}
{"idx": 1964, "commit_message": "xspress3: added another IOC shell driver startup param to set the max spectra size, this is needed at startup rather than being set from the database. I improved the range checking on the ROI limits.", "target": 0}
{"idx": 2573, "commit_message": "Merge pull request #25 from pedrovitti/patch-1  Fix typo and small text improvement.", "target": 0}
{"idx": 1112, "commit_message": "Reducing Memory consumption on start by not registering an Active Media Sessions listener as soon as the Notification Listener gets activated, Also showing automatically version number with compilation number, so it'll help me with future debugs1 This registering process now occurs when you enable it so in the Music Widget settings.", "target": 0}
{"idx": 1195, "commit_message": "Simplified shell scripts to extract cpu, os, vendor from config string", "target": 0}
